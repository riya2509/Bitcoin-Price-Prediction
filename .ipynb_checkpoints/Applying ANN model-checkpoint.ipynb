{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b2023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c15e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f600d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce1c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.000</td>\n",
       "      <td>1.193000e+03</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.000</td>\n",
       "      <td>2.620000e+03</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.000</td>\n",
       "      <td>4.048000e+03</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.000</td>\n",
       "      <td>2.341000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.000</td>\n",
       "      <td>2.122000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "      <td>340402</td>\n",
       "      <td>706867.000</td>\n",
       "      <td>433958</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.157542e+20</td>\n",
       "      <td>0.163</td>\n",
       "      <td>8.336367e+09</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>...</td>\n",
       "      <td>93.577</td>\n",
       "      <td>80.644</td>\n",
       "      <td>73.588</td>\n",
       "      <td>64.882</td>\n",
       "      <td>54.040</td>\n",
       "      <td>10.430</td>\n",
       "      <td>7.538</td>\n",
       "      <td>6.497</td>\n",
       "      <td>26.536</td>\n",
       "      <td>1.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "      <td>332402</td>\n",
       "      <td>704883.000</td>\n",
       "      <td>416980</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.253033e+20</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1.365361e+10</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.213</td>\n",
       "      <td>...</td>\n",
       "      <td>94.137</td>\n",
       "      <td>81.436</td>\n",
       "      <td>74.176</td>\n",
       "      <td>65.272</td>\n",
       "      <td>54.195</td>\n",
       "      <td>7.432</td>\n",
       "      <td>10.930</td>\n",
       "      <td>8.061</td>\n",
       "      <td>28.817</td>\n",
       "      <td>2.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "      <td>334290</td>\n",
       "      <td>770486.000</td>\n",
       "      <td>398021</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.113635e+20</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.126273e+10</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>...</td>\n",
       "      <td>87.140</td>\n",
       "      <td>79.116</td>\n",
       "      <td>73.100</td>\n",
       "      <td>64.815</td>\n",
       "      <td>54.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>11.368</td>\n",
       "      <td>5.611</td>\n",
       "      <td>29.412</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "      <td>303573</td>\n",
       "      <td>650769.000</td>\n",
       "      <td>338567</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.201317e+20</td>\n",
       "      <td>0.149</td>\n",
       "      <td>7.668679e+09</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>...</td>\n",
       "      <td>88.385</td>\n",
       "      <td>79.762</td>\n",
       "      <td>73.498</td>\n",
       "      <td>65.058</td>\n",
       "      <td>54.175</td>\n",
       "      <td>0.473</td>\n",
       "      <td>12.499</td>\n",
       "      <td>5.457</td>\n",
       "      <td>31.791</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "      <td>290736</td>\n",
       "      <td>684127.000</td>\n",
       "      <td>257655</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.064910e+20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>6.486338e+09</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>...</td>\n",
       "      <td>88.689</td>\n",
       "      <td>79.897</td>\n",
       "      <td>73.576</td>\n",
       "      <td>65.104</td>\n",
       "      <td>54.192</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.011</td>\n",
       "      <td>6.081</td>\n",
       "      <td>29.624</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD  transactions        size  sentbyaddress    difficulty  \\\n",
       "0        0.0495           235     649.653            390  1.815430e+02   \n",
       "1        0.0726           248     765.285            424  1.815430e+02   \n",
       "2        0.0859           354     756.040            553  1.815430e+02   \n",
       "3        0.0783           413     984.707            632  1.815430e+02   \n",
       "4        0.0767           256     542.483            440  1.815430e+02   \n",
       "...         ...           ...         ...            ...           ...   \n",
       "3483  9349.0000        340402  706867.000         433958  1.546610e+13   \n",
       "3484  9394.0000        332402  704883.000         416980  1.546610e+13   \n",
       "3485  9366.0000        334290  770486.000         398021  1.546610e+13   \n",
       "3486  9393.0000        303573  650769.000         338567  1.546610e+13   \n",
       "3487  9398.0000        290736  684127.000         257655  1.546610e+13   \n",
       "\n",
       "          hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0     2.775561e+09            154298.000  1.193000e+03            0.000010   \n",
       "1     1.554461e+09            401834.000  2.620000e+03            0.000243   \n",
       "2     1.551287e+09            481473.000  4.048000e+03            0.000022   \n",
       "3     1.640430e+09            431831.000  2.341000e+03            0.000000   \n",
       "4     1.723493e+09            460783.000  2.122000e+03            0.000000   \n",
       "...            ...                   ...           ...                 ...   \n",
       "3483  1.157542e+20                 0.163  8.336367e+09            0.561000   \n",
       "3484  1.253033e+20                 0.148  1.365361e+10            0.555000   \n",
       "3485  1.113635e+20                 0.153  1.126273e+10            0.631000   \n",
       "3486  1.201317e+20                 0.149  7.668679e+09            0.541000   \n",
       "3487  1.064910e+20                 0.159  6.486338e+09            0.548000   \n",
       "\n",
       "      median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  \\\n",
       "0                         0.000  ...         0.000         0.000   \n",
       "1                         0.000  ...         0.000         0.000   \n",
       "2                         0.000  ...         0.000         0.000   \n",
       "3                         0.000  ...        82.751         0.000   \n",
       "4                         0.000  ...        78.603         0.000   \n",
       "...                         ...  ...           ...           ...   \n",
       "3483                      0.221  ...        93.577        80.644   \n",
       "3484                      0.213  ...        94.137        81.436   \n",
       "3485                      0.270  ...        87.140        79.116   \n",
       "3486                      0.219  ...        88.385        79.762   \n",
       "3487                      0.206  ...        88.689        79.897   \n",
       "\n",
       "      price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  \\\n",
       "0             0.000          0.000          0.000         0.000         0.000   \n",
       "1             0.000          0.000          0.000         0.000         0.000   \n",
       "2             0.000          0.000          0.000         0.000         0.000   \n",
       "3             0.000          0.000          0.000        58.099         0.000   \n",
       "4             0.000          0.000          0.000         5.652         0.000   \n",
       "...             ...            ...            ...           ...           ...   \n",
       "3483         73.588         64.882         54.040        10.430         7.538   \n",
       "3484         74.176         65.272         54.195         7.432        10.930   \n",
       "3485         73.100         64.815         54.082         3.505        11.368   \n",
       "3486         73.498         65.058         54.175         0.473        12.499   \n",
       "3487         73.576         65.104         54.192         0.041        11.011   \n",
       "\n",
       "      price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0             0.000          0.000          0.000  \n",
       "1             0.000          0.000          0.000  \n",
       "2             0.000          0.000          0.000  \n",
       "3             0.000          0.000          0.000  \n",
       "4             0.000          0.000          0.000  \n",
       "...             ...            ...            ...  \n",
       "3483          6.497         26.536          1.663  \n",
       "3484          8.061         28.817          2.376  \n",
       "3485          5.611         29.412          0.800  \n",
       "3486          5.457         31.791          1.606  \n",
       "3487          6.081         29.624          1.220  \n",
       "\n",
       "[3488 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9928269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_14768\\435521352.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X=df1.drop('priceUSD',1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.000</td>\n",
       "      <td>1.193000e+03</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.000</td>\n",
       "      <td>2.620000e+03</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.000</td>\n",
       "      <td>4.048000e+03</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.000</td>\n",
       "      <td>2.341000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.956</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.000</td>\n",
       "      <td>2.122000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.957</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>340402</td>\n",
       "      <td>706867.000</td>\n",
       "      <td>433958</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.157542e+20</td>\n",
       "      <td>0.163</td>\n",
       "      <td>8.336367e+09</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>9.000</td>\n",
       "      <td>...</td>\n",
       "      <td>93.577</td>\n",
       "      <td>80.644</td>\n",
       "      <td>73.588</td>\n",
       "      <td>64.882</td>\n",
       "      <td>54.040</td>\n",
       "      <td>10.430</td>\n",
       "      <td>7.538</td>\n",
       "      <td>6.497</td>\n",
       "      <td>26.536</td>\n",
       "      <td>1.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>332402</td>\n",
       "      <td>704883.000</td>\n",
       "      <td>416980</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.253033e+20</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1.365361e+10</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.213</td>\n",
       "      <td>9.231</td>\n",
       "      <td>...</td>\n",
       "      <td>94.137</td>\n",
       "      <td>81.436</td>\n",
       "      <td>74.176</td>\n",
       "      <td>65.272</td>\n",
       "      <td>54.195</td>\n",
       "      <td>7.432</td>\n",
       "      <td>10.930</td>\n",
       "      <td>8.061</td>\n",
       "      <td>28.817</td>\n",
       "      <td>2.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>334290</td>\n",
       "      <td>770486.000</td>\n",
       "      <td>398021</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.113635e+20</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.126273e+10</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>10.000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.140</td>\n",
       "      <td>79.116</td>\n",
       "      <td>73.100</td>\n",
       "      <td>64.815</td>\n",
       "      <td>54.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>11.368</td>\n",
       "      <td>5.611</td>\n",
       "      <td>29.412</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>303573</td>\n",
       "      <td>650769.000</td>\n",
       "      <td>338567</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.201317e+20</td>\n",
       "      <td>0.149</td>\n",
       "      <td>7.668679e+09</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>9.536</td>\n",
       "      <td>...</td>\n",
       "      <td>88.385</td>\n",
       "      <td>79.762</td>\n",
       "      <td>73.498</td>\n",
       "      <td>65.058</td>\n",
       "      <td>54.175</td>\n",
       "      <td>0.473</td>\n",
       "      <td>12.499</td>\n",
       "      <td>5.457</td>\n",
       "      <td>31.791</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>290736</td>\n",
       "      <td>684127.000</td>\n",
       "      <td>257655</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.064910e+20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>6.486338e+09</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>10.070</td>\n",
       "      <td>...</td>\n",
       "      <td>88.689</td>\n",
       "      <td>79.897</td>\n",
       "      <td>73.576</td>\n",
       "      <td>65.104</td>\n",
       "      <td>54.192</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.011</td>\n",
       "      <td>6.081</td>\n",
       "      <td>29.624</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transactions        size  sentbyaddress    difficulty      hashrate  \\\n",
       "0              235     649.653            390  1.815430e+02  2.775561e+09   \n",
       "1              248     765.285            424  1.815430e+02  1.554461e+09   \n",
       "2              354     756.040            553  1.815430e+02  1.551287e+09   \n",
       "3              413     984.707            632  1.815430e+02  1.640430e+09   \n",
       "4              256     542.483            440  1.815430e+02  1.723493e+09   \n",
       "...            ...         ...            ...           ...           ...   \n",
       "3483        340402  706867.000         433958  1.546610e+13  1.157542e+20   \n",
       "3484        332402  704883.000         416980  1.546610e+13  1.253033e+20   \n",
       "3485        334290  770486.000         398021  1.546610e+13  1.113635e+20   \n",
       "3486        303573  650769.000         338567  1.546610e+13  1.201317e+20   \n",
       "3487        290736  684127.000         257655  1.546610e+13  1.064910e+20   \n",
       "\n",
       "      mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0               154298.000  1.193000e+03            0.000010   \n",
       "1               401834.000  2.620000e+03            0.000243   \n",
       "2               481473.000  4.048000e+03            0.000022   \n",
       "3               431831.000  2.341000e+03            0.000000   \n",
       "4               460783.000  2.122000e+03            0.000000   \n",
       "...                    ...           ...                 ...   \n",
       "3483                 0.163  8.336367e+09            0.561000   \n",
       "3484                 0.148  1.365361e+10            0.555000   \n",
       "3485                 0.153  1.126273e+10            0.631000   \n",
       "3486                 0.149  7.668679e+09            0.541000   \n",
       "3487                 0.159  6.486338e+09            0.548000   \n",
       "\n",
       "      median_transaction_feeUSD  confirmationtime  ...  price3rsiUSD  \\\n",
       "0                         0.000             8.324  ...         0.000   \n",
       "1                         0.000             8.372  ...         0.000   \n",
       "2                         0.000             8.276  ...         0.000   \n",
       "3                         0.000             7.956  ...        82.751   \n",
       "4                         0.000             6.957  ...        78.603   \n",
       "...                         ...               ...  ...           ...   \n",
       "3483                      0.221             9.000  ...        93.577   \n",
       "3484                      0.213             9.231  ...        94.137   \n",
       "3485                      0.270            10.000  ...        87.140   \n",
       "3486                      0.219             9.536  ...        88.385   \n",
       "3487                      0.206            10.070  ...        88.689   \n",
       "\n",
       "      price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  \\\n",
       "0            0.000          0.000          0.000          0.000         0.000   \n",
       "1            0.000          0.000          0.000          0.000         0.000   \n",
       "2            0.000          0.000          0.000          0.000         0.000   \n",
       "3            0.000          0.000          0.000          0.000        58.099   \n",
       "4            0.000          0.000          0.000          0.000         5.652   \n",
       "...            ...            ...            ...            ...           ...   \n",
       "3483        80.644         73.588         64.882         54.040        10.430   \n",
       "3484        81.436         74.176         65.272         54.195         7.432   \n",
       "3485        79.116         73.100         64.815         54.082         3.505   \n",
       "3486        79.762         73.498         65.058         54.175         0.473   \n",
       "3487        79.897         73.576         65.104         54.192         0.041   \n",
       "\n",
       "      price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0            0.000          0.000          0.000          0.000  \n",
       "1            0.000          0.000          0.000          0.000  \n",
       "2            0.000          0.000          0.000          0.000  \n",
       "3            0.000          0.000          0.000          0.000  \n",
       "4            0.000          0.000          0.000          0.000  \n",
       "...            ...            ...            ...            ...  \n",
       "3483         7.538          6.497         26.536          1.663  \n",
       "3484        10.930          8.061         28.817          2.376  \n",
       "3485        11.368          5.611         29.412          0.800  \n",
       "3486        12.499          5.457         31.791          1.606  \n",
       "3487        11.011          6.081         29.624          1.220  \n",
       "\n",
       "[3488 rows x 735 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "X=df1.drop('priceUSD',1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422bcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transactions', 'size', 'sentbyaddress', 'difficulty', 'hashrate',\n",
      "       'mining_profitability', 'sentinusdUSD', 'transactionfeesUSD',\n",
      "       'median_transaction_feeUSD', 'confirmationtime',\n",
      "       ...\n",
      "       'price3rsiUSD', 'price7rsiUSD', 'price14rsiUSD', 'price30rsiUSD',\n",
      "       'price90rsiUSD', 'price3rocUSD', 'price7rocUSD', 'price14rocUSD',\n",
      "       'price30rocUSD', 'price90rocUSD'],\n",
      "      dtype='object', length=735)\n"
     ]
    }
   ],
   "source": [
    "# creating a list of column names by\n",
    "# calling the .columns\n",
    "list_of_column_names = list(X.columns)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4bf9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543ec303",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    " \n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    " \n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895f30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce60e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e6a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2790, 735)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8d02f",
   "metadata": {},
   "source": [
    "### Building an ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10241636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3527db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee9133",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c85a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf29edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.regularization.dropout.Dropout at 0x13c689c2c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the input layer\n",
    "classifier.add(Dense(units=735,kernel_initializer='normal',activation='relu'))\n",
    "Dropout(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf3b2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.regularization.dropout.Dropout at 0x13c69a1f790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the first hidden layer\n",
    "#2/3*735=units(No of nuerons)\n",
    "classifier.add(Dense(units=490,kernel_initializer='normal',activation='relu'))\n",
    "Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15306208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the second hidden layer\n",
    "classifier.add(Dense(units=327,kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "113fc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the third hidden layer\n",
    "classifier.add(Dense(units=218,kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d4cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the fourth hidden layer\n",
    "classifier.add(Dense(units=146,kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29a3f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the fifth hidden layer\n",
    "classifier.add(Dense(units=98,kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e93a29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=65,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=43,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=29,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=19,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=12,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=5,kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e802d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5150157",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a048f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 3s 10ms/step - loss: 0.6974 - mean_absolute_error: 0.6974 - val_loss: 0.4607 - val_mean_absolute_error: 0.4607\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.1380 - mean_absolute_error: 0.1380 - val_loss: 0.0773 - val_mean_absolute_error: 0.0773\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0641 - mean_absolute_error: 0.0641 - val_loss: 0.0575 - val_mean_absolute_error: 0.0575\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0587 - mean_absolute_error: 0.0587 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0858 - val_mean_absolute_error: 0.0858\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0375 - val_mean_absolute_error: 0.0375\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0461 - mean_absolute_error: 0.0461 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0411 - mean_absolute_error: 0.0411 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0467 - mean_absolute_error: 0.0467 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0493 - mean_absolute_error: 0.0493 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0514 - mean_absolute_error: 0.0514 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0377 - mean_absolute_error: 0.0377 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0439 - mean_absolute_error: 0.0439 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0358 - mean_absolute_error: 0.0358 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0342 - mean_absolute_error: 0.0342 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0346 - val_mean_absolute_error: 0.0346\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0383 - mean_absolute_error: 0.0383 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0388 - mean_absolute_error: 0.0388 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0390 - val_mean_absolute_error: 0.0390\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0430 - mean_absolute_error: 0.0430 - val_loss: 0.0439 - val_mean_absolute_error: 0.0439\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0278 - mean_absolute_error: 0.0278 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0413 - mean_absolute_error: 0.0413 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0402 - mean_absolute_error: 0.0402 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0283 - mean_absolute_error: 0.0283 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0511 - val_mean_absolute_error: 0.0511\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0264 - mean_absolute_error: 0.0264 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0434 - val_mean_absolute_error: 0.0434\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0295 - mean_absolute_error: 0.0295 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0382 - mean_absolute_error: 0.0382 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0238 - mean_absolute_error: 0.0238 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0304 - mean_absolute_error: 0.0304 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0268 - mean_absolute_error: 0.0268 - val_loss: 0.0366 - val_mean_absolute_error: 0.0366\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0300 - mean_absolute_error: 0.0300 - val_loss: 0.0398 - val_mean_absolute_error: 0.0398\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0264 - mean_absolute_error: 0.0264 - val_loss: 0.0652 - val_mean_absolute_error: 0.0652\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0304 - mean_absolute_error: 0.0304 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0265 - mean_absolute_error: 0.0265 - val_loss: 0.0624 - val_mean_absolute_error: 0.0624\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0298 - mean_absolute_error: 0.0298 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5479efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Predictions=classifier.predict(X_test)\n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "039693b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>...</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106842.534674</td>\n",
       "      <td>391416.195014</td>\n",
       "      <td>177251.059830</td>\n",
       "      <td>6.440397e+10</td>\n",
       "      <td>4.605450e+17</td>\n",
       "      <td>-283.060837</td>\n",
       "      <td>3.575059e+08</td>\n",
       "      <td>0.047298</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>9.945521</td>\n",
       "      <td>...</td>\n",
       "      <td>44.883291</td>\n",
       "      <td>46.253476</td>\n",
       "      <td>45.153177</td>\n",
       "      <td>-1.517380</td>\n",
       "      <td>-3.721515</td>\n",
       "      <td>-0.438591</td>\n",
       "      <td>4.595185</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>233.2560</td>\n",
       "      <td>280.065704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251512.464237</td>\n",
       "      <td>820421.502412</td>\n",
       "      <td>351678.607526</td>\n",
       "      <td>2.676350e+11</td>\n",
       "      <td>2.094960e+18</td>\n",
       "      <td>-285.092823</td>\n",
       "      <td>1.176162e+09</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.162072</td>\n",
       "      <td>9.479636</td>\n",
       "      <td>...</td>\n",
       "      <td>84.214584</td>\n",
       "      <td>73.127817</td>\n",
       "      <td>60.198305</td>\n",
       "      <td>4.672256</td>\n",
       "      <td>8.401033</td>\n",
       "      <td>7.769610</td>\n",
       "      <td>14.024262</td>\n",
       "      <td>6.330158</td>\n",
       "      <td>685.3560</td>\n",
       "      <td>727.236694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1272.803324</td>\n",
       "      <td>716.496845</td>\n",
       "      <td>1928.459437</td>\n",
       "      <td>1.597297e+10</td>\n",
       "      <td>1.319383e+17</td>\n",
       "      <td>30778.701439</td>\n",
       "      <td>1.008361e+08</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>5.139880</td>\n",
       "      <td>...</td>\n",
       "      <td>59.182139</td>\n",
       "      <td>65.927310</td>\n",
       "      <td>67.546902</td>\n",
       "      <td>3.247490</td>\n",
       "      <td>4.493242</td>\n",
       "      <td>-10.368397</td>\n",
       "      <td>129.772440</td>\n",
       "      <td>235.398947</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>53.013943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-152.986398</td>\n",
       "      <td>-549.017724</td>\n",
       "      <td>-130.463812</td>\n",
       "      <td>1.597293e+10</td>\n",
       "      <td>1.319379e+17</td>\n",
       "      <td>116472.518063</td>\n",
       "      <td>1.006838e+08</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>7.799599</td>\n",
       "      <td>...</td>\n",
       "      <td>47.056302</td>\n",
       "      <td>53.552222</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>-3.877335</td>\n",
       "      <td>-4.482324</td>\n",
       "      <td>-8.221116</td>\n",
       "      <td>1.926481</td>\n",
       "      <td>1.821389</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>86.137726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288931.657373</td>\n",
       "      <td>882606.207523</td>\n",
       "      <td>433721.413253</td>\n",
       "      <td>5.117552e+11</td>\n",
       "      <td>4.236939e+18</td>\n",
       "      <td>-285.118860</td>\n",
       "      <td>4.830029e+09</td>\n",
       "      <td>0.954517</td>\n",
       "      <td>0.501915</td>\n",
       "      <td>8.162520</td>\n",
       "      <td>...</td>\n",
       "      <td>56.489279</td>\n",
       "      <td>54.073489</td>\n",
       "      <td>56.295050</td>\n",
       "      <td>7.098153</td>\n",
       "      <td>12.610182</td>\n",
       "      <td>9.073494</td>\n",
       "      <td>-11.092650</td>\n",
       "      <td>12.907817</td>\n",
       "      <td>1132.0000</td>\n",
       "      <td>1196.730469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transactions           size  sentbyaddress    difficulty      hashrate  \\\n",
       "0  106842.534674  391416.195014  177251.059830  6.440397e+10  4.605450e+17   \n",
       "1  251512.464237  820421.502412  351678.607526  2.676350e+11  2.094960e+18   \n",
       "2    1272.803324     716.496845    1928.459437  1.597297e+10  1.319383e+17   \n",
       "3    -152.986398    -549.017724    -130.463812  1.597293e+10  1.319379e+17   \n",
       "4  288931.657373  882606.207523  433721.413253  5.117552e+11  4.236939e+18   \n",
       "\n",
       "  mining_profitability  sentinusdUSD transactionfeesUSD  \\\n",
       "0          -283.060837  3.575059e+08           0.047298   \n",
       "1          -285.092823  1.176162e+09           0.255738   \n",
       "2         30778.701439  1.008361e+08           0.011940   \n",
       "3        116472.518063  1.006838e+08           0.011652   \n",
       "4          -285.118860  4.830029e+09           0.954517   \n",
       "\n",
       "  median_transaction_feeUSD confirmationtime  ... price14rsiUSD price30rsiUSD  \\\n",
       "0                  0.034278         9.945521  ...     44.883291     46.253476   \n",
       "1                  0.162072         9.479636  ...     84.214584     73.127817   \n",
       "2                  0.008980         5.139880  ...     59.182139     65.927310   \n",
       "3                  0.008980         7.799599  ...     47.056302     53.552222   \n",
       "4                  0.501915         8.162520  ...     56.489279     54.073489   \n",
       "\n",
       "  price90rsiUSD price3rocUSD price7rocUSD price14rocUSD price30rocUSD  \\\n",
       "0     45.153177    -1.517380    -3.721515     -0.438591      4.595185   \n",
       "1     60.198305     4.672256     8.401033      7.769610     14.024262   \n",
       "2     67.546902     3.247490     4.493242    -10.368397    129.772440   \n",
       "3      0.041790    -3.877335    -4.482324     -8.221116      1.926481   \n",
       "4     56.295050     7.098153    12.610182      9.073494    -11.092650   \n",
       "\n",
       "  price90rocUSD      Price PredictedPrice  \n",
       "0     -0.066915   233.2560     280.065704  \n",
       "1      6.330158   685.3560     727.236694  \n",
       "2    235.398947     0.9350      53.013943  \n",
       "3      1.821389     0.0621      86.137726  \n",
       "4     12.907817  1132.0000    1196.730469  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictors=[list_of_column_names]\n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['Price']=y_test_orig\n",
    "TestingData['PredictedPrice']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49a1cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52f17f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b04244c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ba966",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaeccc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad81d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e0832f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 2.6813 - mean_absolute_error: 0.3272 - val_loss: 0.3295 - val_mean_absolute_error: 0.0975\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.2445 - mean_absolute_error: 0.0784 - val_loss: 0.2098 - val_mean_absolute_error: 0.0728\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1847 - mean_absolute_error: 0.0602 - val_loss: 0.1738 - val_mean_absolute_error: 0.0594\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1570 - mean_absolute_error: 0.0487 - val_loss: 0.1530 - val_mean_absolute_error: 0.0501\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1444 - mean_absolute_error: 0.0441 - val_loss: 0.1436 - val_mean_absolute_error: 0.0467\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1322 - mean_absolute_error: 0.0373 - val_loss: 0.1325 - val_mean_absolute_error: 0.0393\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1264 - mean_absolute_error: 0.0357 - val_loss: 0.1240 - val_mean_absolute_error: 0.0346\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1197 - mean_absolute_error: 0.0318 - val_loss: 0.1168 - val_mean_absolute_error: 0.0327\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1146 - mean_absolute_error: 0.0300 - val_loss: 0.1216 - val_mean_absolute_error: 0.0362\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1131 - mean_absolute_error: 0.0296 - val_loss: 0.1159 - val_mean_absolute_error: 0.0338\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1080 - mean_absolute_error: 0.0265 - val_loss: 0.1108 - val_mean_absolute_error: 0.0301\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1057 - mean_absolute_error: 0.0255 - val_loss: 0.1073 - val_mean_absolute_error: 0.0280\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1052 - mean_absolute_error: 0.0254 - val_loss: 0.1080 - val_mean_absolute_error: 0.0276\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1040 - mean_absolute_error: 0.0256 - val_loss: 0.1077 - val_mean_absolute_error: 0.0296\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1023 - mean_absolute_error: 0.0246 - val_loss: 0.1238 - val_mean_absolute_error: 0.0450\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1004 - mean_absolute_error: 0.0237 - val_loss: 0.1020 - val_mean_absolute_error: 0.0267\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0966 - mean_absolute_error: 0.0212 - val_loss: 0.1019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0976 - mean_absolute_error: 0.0224 - val_loss: 0.0977 - val_mean_absolute_error: 0.0230\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0946 - mean_absolute_error: 0.0204 - val_loss: 0.0943 - val_mean_absolute_error: 0.0218\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0946 - mean_absolute_error: 0.0212 - val_loss: 0.0945 - val_mean_absolute_error: 0.0220\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0936 - mean_absolute_error: 0.0211 - val_loss: 0.0987 - val_mean_absolute_error: 0.0262\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0915 - mean_absolute_error: 0.0202 - val_loss: 0.0956 - val_mean_absolute_error: 0.0235\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0920 - mean_absolute_error: 0.0214 - val_loss: 0.0935 - val_mean_absolute_error: 0.0240\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0894 - mean_absolute_error: 0.0198 - val_loss: 0.0916 - val_mean_absolute_error: 0.0218\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0873 - mean_absolute_error: 0.0186 - val_loss: 0.0892 - val_mean_absolute_error: 0.0210\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0856 - mean_absolute_error: 0.0181 - val_loss: 0.0945 - val_mean_absolute_error: 0.0264\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0872 - mean_absolute_error: 0.0198 - val_loss: 0.0932 - val_mean_absolute_error: 0.0255\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0847 - mean_absolute_error: 0.0179 - val_loss: 0.0912 - val_mean_absolute_error: 0.0243\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0840 - mean_absolute_error: 0.0179 - val_loss: 0.0891 - val_mean_absolute_error: 0.0225\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0847 - mean_absolute_error: 0.0185 - val_loss: 0.1020 - val_mean_absolute_error: 0.0344\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0831 - mean_absolute_error: 0.0178 - val_loss: 0.0858 - val_mean_absolute_error: 0.0201\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0824 - mean_absolute_error: 0.0170 - val_loss: 0.0936 - val_mean_absolute_error: 0.0290\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0810 - mean_absolute_error: 0.0164 - val_loss: 0.0869 - val_mean_absolute_error: 0.0227\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0811 - mean_absolute_error: 0.0169 - val_loss: 0.0835 - val_mean_absolute_error: 0.0198\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0794 - mean_absolute_error: 0.0161 - val_loss: 0.0796 - val_mean_absolute_error: 0.0174\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0778 - mean_absolute_error: 0.0151 - val_loss: 0.0798 - val_mean_absolute_error: 0.0178\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0812 - mean_absolute_error: 0.0184 - val_loss: 0.0861 - val_mean_absolute_error: 0.0230\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0793 - mean_absolute_error: 0.0178 - val_loss: 0.0844 - val_mean_absolute_error: 0.0221\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0779 - mean_absolute_error: 0.0163 - val_loss: 0.0944 - val_mean_absolute_error: 0.0320\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0772 - mean_absolute_error: 0.0161 - val_loss: 0.0821 - val_mean_absolute_error: 0.0205\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0749 - mean_absolute_error: 0.0146 - val_loss: 0.0814 - val_mean_absolute_error: 0.0207\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0773 - mean_absolute_error: 0.0164 - val_loss: 0.0819 - val_mean_absolute_error: 0.0219\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0763 - mean_absolute_error: 0.0164 - val_loss: 0.0859 - val_mean_absolute_error: 0.0261\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0758 - mean_absolute_error: 0.0157 - val_loss: 0.0771 - val_mean_absolute_error: 0.0180\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0727 - mean_absolute_error: 0.0139 - val_loss: 0.0770 - val_mean_absolute_error: 0.0180\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0735 - mean_absolute_error: 0.0150 - val_loss: 0.0773 - val_mean_absolute_error: 0.0184\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0742 - mean_absolute_error: 0.0155 - val_loss: 0.0763 - val_mean_absolute_error: 0.0171\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0709 - mean_absolute_error: 0.0137 - val_loss: 0.0796 - val_mean_absolute_error: 0.0211\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0723 - mean_absolute_error: 0.0145 - val_loss: 0.0764 - val_mean_absolute_error: 0.0196\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0718 - mean_absolute_error: 0.0149 - val_loss: 0.0743 - val_mean_absolute_error: 0.0182\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f117c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "Predictions=classifier.predict(X_test)\n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8491081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>...</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106842.534674</td>\n",
       "      <td>391416.195014</td>\n",
       "      <td>177251.059830</td>\n",
       "      <td>6.440397e+10</td>\n",
       "      <td>4.605450e+17</td>\n",
       "      <td>-283.060837</td>\n",
       "      <td>3.575059e+08</td>\n",
       "      <td>0.047298</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>9.945521</td>\n",
       "      <td>...</td>\n",
       "      <td>44.883291</td>\n",
       "      <td>46.253476</td>\n",
       "      <td>45.153177</td>\n",
       "      <td>-1.517380</td>\n",
       "      <td>-3.721515</td>\n",
       "      <td>-0.438591</td>\n",
       "      <td>4.595185</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>233.2560</td>\n",
       "      <td>259.837067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251512.464237</td>\n",
       "      <td>820421.502412</td>\n",
       "      <td>351678.607526</td>\n",
       "      <td>2.676350e+11</td>\n",
       "      <td>2.094960e+18</td>\n",
       "      <td>-285.092823</td>\n",
       "      <td>1.176162e+09</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.162072</td>\n",
       "      <td>9.479636</td>\n",
       "      <td>...</td>\n",
       "      <td>84.214584</td>\n",
       "      <td>73.127817</td>\n",
       "      <td>60.198305</td>\n",
       "      <td>4.672256</td>\n",
       "      <td>8.401033</td>\n",
       "      <td>7.769610</td>\n",
       "      <td>14.024262</td>\n",
       "      <td>6.330158</td>\n",
       "      <td>685.3560</td>\n",
       "      <td>689.015259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1272.803324</td>\n",
       "      <td>716.496845</td>\n",
       "      <td>1928.459437</td>\n",
       "      <td>1.597297e+10</td>\n",
       "      <td>1.319383e+17</td>\n",
       "      <td>30778.701439</td>\n",
       "      <td>1.008361e+08</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>5.139880</td>\n",
       "      <td>...</td>\n",
       "      <td>59.182139</td>\n",
       "      <td>65.927310</td>\n",
       "      <td>67.546902</td>\n",
       "      <td>3.247490</td>\n",
       "      <td>4.493242</td>\n",
       "      <td>-10.368397</td>\n",
       "      <td>129.772440</td>\n",
       "      <td>235.398947</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>-1.671848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-152.986398</td>\n",
       "      <td>-549.017724</td>\n",
       "      <td>-130.463812</td>\n",
       "      <td>1.597293e+10</td>\n",
       "      <td>1.319379e+17</td>\n",
       "      <td>116472.518063</td>\n",
       "      <td>1.006838e+08</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>7.799599</td>\n",
       "      <td>...</td>\n",
       "      <td>47.056302</td>\n",
       "      <td>53.552222</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>-3.877335</td>\n",
       "      <td>-4.482324</td>\n",
       "      <td>-8.221116</td>\n",
       "      <td>1.926481</td>\n",
       "      <td>1.821389</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>4.044216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288931.657373</td>\n",
       "      <td>882606.207523</td>\n",
       "      <td>433721.413253</td>\n",
       "      <td>5.117552e+11</td>\n",
       "      <td>4.236939e+18</td>\n",
       "      <td>-285.118860</td>\n",
       "      <td>4.830029e+09</td>\n",
       "      <td>0.954517</td>\n",
       "      <td>0.501915</td>\n",
       "      <td>8.162520</td>\n",
       "      <td>...</td>\n",
       "      <td>56.489279</td>\n",
       "      <td>54.073489</td>\n",
       "      <td>56.295050</td>\n",
       "      <td>7.098153</td>\n",
       "      <td>12.610182</td>\n",
       "      <td>9.073494</td>\n",
       "      <td>-11.092650</td>\n",
       "      <td>12.907817</td>\n",
       "      <td>1132.0000</td>\n",
       "      <td>1090.994385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transactions           size  sentbyaddress    difficulty      hashrate  \\\n",
       "0  106842.534674  391416.195014  177251.059830  6.440397e+10  4.605450e+17   \n",
       "1  251512.464237  820421.502412  351678.607526  2.676350e+11  2.094960e+18   \n",
       "2    1272.803324     716.496845    1928.459437  1.597297e+10  1.319383e+17   \n",
       "3    -152.986398    -549.017724    -130.463812  1.597293e+10  1.319379e+17   \n",
       "4  288931.657373  882606.207523  433721.413253  5.117552e+11  4.236939e+18   \n",
       "\n",
       "  mining_profitability  sentinusdUSD transactionfeesUSD  \\\n",
       "0          -283.060837  3.575059e+08           0.047298   \n",
       "1          -285.092823  1.176162e+09           0.255738   \n",
       "2         30778.701439  1.008361e+08           0.011940   \n",
       "3        116472.518063  1.006838e+08           0.011652   \n",
       "4          -285.118860  4.830029e+09           0.954517   \n",
       "\n",
       "  median_transaction_feeUSD confirmationtime  ... price14rsiUSD price30rsiUSD  \\\n",
       "0                  0.034278         9.945521  ...     44.883291     46.253476   \n",
       "1                  0.162072         9.479636  ...     84.214584     73.127817   \n",
       "2                  0.008980         5.139880  ...     59.182139     65.927310   \n",
       "3                  0.008980         7.799599  ...     47.056302     53.552222   \n",
       "4                  0.501915         8.162520  ...     56.489279     54.073489   \n",
       "\n",
       "  price90rsiUSD price3rocUSD price7rocUSD price14rocUSD price30rocUSD  \\\n",
       "0     45.153177    -1.517380    -3.721515     -0.438591      4.595185   \n",
       "1     60.198305     4.672256     8.401033      7.769610     14.024262   \n",
       "2     67.546902     3.247490     4.493242    -10.368397    129.772440   \n",
       "3      0.041790    -3.877335    -4.482324     -8.221116      1.926481   \n",
       "4     56.295050     7.098153    12.610182      9.073494    -11.092650   \n",
       "\n",
       "  price90rocUSD      Price PredictedPrice  \n",
       "0     -0.066915   233.2560     259.837067  \n",
       "1      6.330158   685.3560     689.015259  \n",
       "2    235.398947     0.9350      -1.671848  \n",
       "3      1.821389     0.0621       4.044216  \n",
       "4     12.907817  1132.0000    1090.994385  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictors=[list_of_column_names]\n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['Price']=y_test_orig\n",
    "TestingData['PredictedPrice']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86106fff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#APE=APE.values.reshape(-1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m APE\u001b[38;5;241m=\u001b[39mAPE\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m TestingData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mAPE\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Accuracy of ANN model is:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(APE))\n\u001b[0;32m      8\u001b[0m TestingData\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:3645\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3647\u001b[0m     is_list_like(value)\n\u001b[0;32m   3648\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3649\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3650\u001b[0m ):\n\u001b[0;32m   3651\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:3775\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3773\u001b[0m len_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols)\n\u001b[0;32m   3774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_cols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 3775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3777\u001b[0m \u001b[38;5;66;03m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[0;32m   3778\u001b[0m \u001b[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[0;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   3780\u001b[0m     loc, (\u001b[38;5;28mslice\u001b[39m, Series, np\u001b[38;5;241m.\u001b[39mndarray, Index)\n\u001b[0;32m   3781\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "\n",
    "# Computing the absolute percent error\n",
    "APE=100*(abs(TestingData['Price']-TestingData['PredictedPrice'])/TestingData['Price'])\n",
    "#APE=APE.values.reshape(-1)\n",
    "#APE=pd.Series()\n",
    "TestingData['APE']=APE\n",
    "\n",
    "print('The Accuracy of ANN model is:', 100-np.mean(APE))\n",
    "TestingData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2fcc577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94964e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9712dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a104ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24818d9",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d63243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Logarithmic Loss\n",
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26059d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ac3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d278927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b2cd8",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb623bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44843aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d186af0",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05e9a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cffd2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d1e7448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 8ms/step - loss: 2.6502 - mean_absolute_error: 0.3478 - val_loss: 0.3047 - val_mean_absolute_error: 0.1182\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2495 - mean_absolute_error: 0.0981 - val_loss: 0.2022 - val_mean_absolute_error: 0.0847\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1786 - mean_absolute_error: 0.0722 - val_loss: 0.1677 - val_mean_absolute_error: 0.0793\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1541 - mean_absolute_error: 0.0621 - val_loss: 0.1650 - val_mean_absolute_error: 0.0785\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1328 - mean_absolute_error: 0.0543 - val_loss: 0.1485 - val_mean_absolute_error: 0.0667\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1304 - mean_absolute_error: 0.0512 - val_loss: 0.1202 - val_mean_absolute_error: 0.0524\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1103 - mean_absolute_error: 0.0431 - val_loss: 0.1095 - val_mean_absolute_error: 0.0487\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.1004 - mean_absolute_error: 0.0376 - val_loss: 0.0998 - val_mean_absolute_error: 0.0368\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0981 - mean_absolute_error: 0.0370 - val_loss: 0.1257 - val_mean_absolute_error: 0.0651\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0929 - mean_absolute_error: 0.0341 - val_loss: 0.0940 - val_mean_absolute_error: 0.0375\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0870 - mean_absolute_error: 0.0318 - val_loss: 0.0928 - val_mean_absolute_error: 0.0348\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0825 - mean_absolute_error: 0.0282 - val_loss: 0.0832 - val_mean_absolute_error: 0.0294\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0821 - mean_absolute_error: 0.0288 - val_loss: 0.0969 - val_mean_absolute_error: 0.0418\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0826 - mean_absolute_error: 0.0284 - val_loss: 0.0763 - val_mean_absolute_error: 0.0272\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0765 - mean_absolute_error: 0.0256 - val_loss: 0.0758 - val_mean_absolute_error: 0.0278\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0750 - mean_absolute_error: 0.0249 - val_loss: 0.0747 - val_mean_absolute_error: 0.0258\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0741 - mean_absolute_error: 0.0247 - val_loss: 0.0763 - val_mean_absolute_error: 0.0267\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0716 - mean_absolute_error: 0.0224 - val_loss: 0.0695 - val_mean_absolute_error: 0.0218\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0693 - mean_absolute_error: 0.0215 - val_loss: 0.0706 - val_mean_absolute_error: 0.0246\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0714 - mean_absolute_error: 0.0227 - val_loss: 0.0813 - val_mean_absolute_error: 0.0350\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0680 - mean_absolute_error: 0.0220 - val_loss: 0.0758 - val_mean_absolute_error: 0.0313\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0667 - mean_absolute_error: 0.0210 - val_loss: 0.0679 - val_mean_absolute_error: 0.0228\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0655 - mean_absolute_error: 0.0198 - val_loss: 0.0643 - val_mean_absolute_error: 0.0204\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0670 - mean_absolute_error: 0.0212 - val_loss: 0.0746 - val_mean_absolute_error: 0.0276\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0670 - mean_absolute_error: 0.0209 - val_loss: 0.0777 - val_mean_absolute_error: 0.0319\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0655 - mean_absolute_error: 0.0213 - val_loss: 0.0663 - val_mean_absolute_error: 0.0244\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0645 - mean_absolute_error: 0.0197 - val_loss: 0.0646 - val_mean_absolute_error: 0.0213\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0645 - mean_absolute_error: 0.0204 - val_loss: 0.0682 - val_mean_absolute_error: 0.0208\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0608 - mean_absolute_error: 0.0175 - val_loss: 0.0605 - val_mean_absolute_error: 0.0188\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0596 - mean_absolute_error: 0.0175 - val_loss: 0.0610 - val_mean_absolute_error: 0.0189\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0581 - mean_absolute_error: 0.0170 - val_loss: 0.0635 - val_mean_absolute_error: 0.0217\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0611 - mean_absolute_error: 0.0193 - val_loss: 0.0650 - val_mean_absolute_error: 0.0219\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0593 - mean_absolute_error: 0.0173 - val_loss: 0.0625 - val_mean_absolute_error: 0.0222\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0598 - mean_absolute_error: 0.0174 - val_loss: 0.0614 - val_mean_absolute_error: 0.0222\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0574 - mean_absolute_error: 0.0169 - val_loss: 0.0666 - val_mean_absolute_error: 0.0251\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0589 - mean_absolute_error: 0.0177 - val_loss: 0.0624 - val_mean_absolute_error: 0.0214\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0574 - mean_absolute_error: 0.0166 - val_loss: 0.0599 - val_mean_absolute_error: 0.0205\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0549 - mean_absolute_error: 0.0155 - val_loss: 0.0693 - val_mean_absolute_error: 0.0249\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0572 - mean_absolute_error: 0.0167 - val_loss: 0.0639 - val_mean_absolute_error: 0.0214\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0585 - mean_absolute_error: 0.0175 - val_loss: 0.0617 - val_mean_absolute_error: 0.0229\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0568 - mean_absolute_error: 0.0167 - val_loss: 0.0579 - val_mean_absolute_error: 0.0203\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0546 - mean_absolute_error: 0.0159 - val_loss: 0.0568 - val_mean_absolute_error: 0.0168\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0539 - mean_absolute_error: 0.0155 - val_loss: 0.0604 - val_mean_absolute_error: 0.0205\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0556 - mean_absolute_error: 0.0164 - val_loss: 0.0667 - val_mean_absolute_error: 0.0251\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0553 - mean_absolute_error: 0.0159 - val_loss: 0.0566 - val_mean_absolute_error: 0.0183\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0539 - mean_absolute_error: 0.0148 - val_loss: 0.0596 - val_mean_absolute_error: 0.0201\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0532 - mean_absolute_error: 0.0144 - val_loss: 0.0550 - val_mean_absolute_error: 0.0168\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0510 - mean_absolute_error: 0.0131 - val_loss: 0.0578 - val_mean_absolute_error: 0.0205\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0540 - mean_absolute_error: 0.0149 - val_loss: 0.0687 - val_mean_absolute_error: 0.0309\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0540 - mean_absolute_error: 0.0152 - val_loss: 0.0533 - val_mean_absolute_error: 0.0162\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0544 - mean_absolute_error: 0.0160 - val_loss: 0.0686 - val_mean_absolute_error: 0.0274\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0540 - mean_absolute_error: 0.0148 - val_loss: 0.0672 - val_mean_absolute_error: 0.0248\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0545 - mean_absolute_error: 0.0152 - val_loss: 0.0565 - val_mean_absolute_error: 0.0188\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0534 - mean_absolute_error: 0.0144 - val_loss: 0.0616 - val_mean_absolute_error: 0.0207\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0543 - mean_absolute_error: 0.0161 - val_loss: 0.0839 - val_mean_absolute_error: 0.0415\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0536 - mean_absolute_error: 0.0148 - val_loss: 0.0617 - val_mean_absolute_error: 0.0233\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0525 - mean_absolute_error: 0.0143 - val_loss: 0.0672 - val_mean_absolute_error: 0.0291\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0516 - mean_absolute_error: 0.0130 - val_loss: 0.0554 - val_mean_absolute_error: 0.0180\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0535 - mean_absolute_error: 0.0148 - val_loss: 0.0622 - val_mean_absolute_error: 0.0240\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0544 - mean_absolute_error: 0.0148 - val_loss: 0.0598 - val_mean_absolute_error: 0.0209\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0525 - mean_absolute_error: 0.0143 - val_loss: 0.0560 - val_mean_absolute_error: 0.0165\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0503 - mean_absolute_error: 0.0129 - val_loss: 0.0587 - val_mean_absolute_error: 0.0207\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0515 - mean_absolute_error: 0.0139 - val_loss: 0.0533 - val_mean_absolute_error: 0.0171\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0495 - mean_absolute_error: 0.0125 - val_loss: 0.0534 - val_mean_absolute_error: 0.0169\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0515 - mean_absolute_error: 0.0143 - val_loss: 0.0549 - val_mean_absolute_error: 0.0171\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0510 - mean_absolute_error: 0.0133 - val_loss: 0.0585 - val_mean_absolute_error: 0.0203\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0502 - mean_absolute_error: 0.0131 - val_loss: 0.0589 - val_mean_absolute_error: 0.0217\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0490 - mean_absolute_error: 0.0126 - val_loss: 0.0551 - val_mean_absolute_error: 0.0179\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0508 - mean_absolute_error: 0.0139 - val_loss: 0.0543 - val_mean_absolute_error: 0.0173\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0496 - mean_absolute_error: 0.0128 - val_loss: 0.0601 - val_mean_absolute_error: 0.0237\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0487 - mean_absolute_error: 0.0124 - val_loss: 0.0635 - val_mean_absolute_error: 0.0245\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0498 - mean_absolute_error: 0.0132 - val_loss: 0.0613 - val_mean_absolute_error: 0.0241\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0498 - mean_absolute_error: 0.0135 - val_loss: 0.0542 - val_mean_absolute_error: 0.0178\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0481 - mean_absolute_error: 0.0120 - val_loss: 0.0546 - val_mean_absolute_error: 0.0189\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0494 - mean_absolute_error: 0.0132 - val_loss: 0.0526 - val_mean_absolute_error: 0.0157\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0494 - mean_absolute_error: 0.0123 - val_loss: 0.0511 - val_mean_absolute_error: 0.0153\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0480 - mean_absolute_error: 0.0123 - val_loss: 0.0533 - val_mean_absolute_error: 0.0154\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0498 - mean_absolute_error: 0.0133 - val_loss: 0.0543 - val_mean_absolute_error: 0.0157\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0500 - mean_absolute_error: 0.0129 - val_loss: 0.0504 - val_mean_absolute_error: 0.0153\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0489 - mean_absolute_error: 0.0126 - val_loss: 0.0518 - val_mean_absolute_error: 0.0162\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0474 - mean_absolute_error: 0.0123 - val_loss: 0.0525 - val_mean_absolute_error: 0.0168\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0475 - mean_absolute_error: 0.0123 - val_loss: 0.0564 - val_mean_absolute_error: 0.0208\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0488 - mean_absolute_error: 0.0132 - val_loss: 0.0519 - val_mean_absolute_error: 0.0158\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0476 - mean_absolute_error: 0.0121 - val_loss: 0.0514 - val_mean_absolute_error: 0.0161\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0492 - mean_absolute_error: 0.0131 - val_loss: 0.0506 - val_mean_absolute_error: 0.0163\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0521 - mean_absolute_error: 0.0159 - val_loss: 0.0690 - val_mean_absolute_error: 0.0302\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0491 - mean_absolute_error: 0.0130 - val_loss: 0.0567 - val_mean_absolute_error: 0.0220\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0487 - mean_absolute_error: 0.0137 - val_loss: 0.0520 - val_mean_absolute_error: 0.0166\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0474 - mean_absolute_error: 0.0124 - val_loss: 0.0583 - val_mean_absolute_error: 0.0225\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0462 - mean_absolute_error: 0.0108 - val_loss: 0.0489 - val_mean_absolute_error: 0.0150\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0470 - mean_absolute_error: 0.0121 - val_loss: 0.0565 - val_mean_absolute_error: 0.0210\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0470 - mean_absolute_error: 0.0116 - val_loss: 0.0482 - val_mean_absolute_error: 0.0144\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0463 - mean_absolute_error: 0.0111 - val_loss: 0.0501 - val_mean_absolute_error: 0.0155\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0470 - mean_absolute_error: 0.0113 - val_loss: 0.0561 - val_mean_absolute_error: 0.0201\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0465 - mean_absolute_error: 0.0113 - val_loss: 0.0494 - val_mean_absolute_error: 0.0154\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0470 - mean_absolute_error: 0.0116 - val_loss: 0.0549 - val_mean_absolute_error: 0.0187\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0464 - mean_absolute_error: 0.0111 - val_loss: 0.0504 - val_mean_absolute_error: 0.0162\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0470 - mean_absolute_error: 0.0115 - val_loss: 0.0552 - val_mean_absolute_error: 0.0206\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0462 - mean_absolute_error: 0.0112 - val_loss: 0.0491 - val_mean_absolute_error: 0.0148\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0451 - mean_absolute_error: 0.0103 - val_loss: 0.0506 - val_mean_absolute_error: 0.0166\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d8a36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Predictions=classifier.predict(X_test)\n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1acc00f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>...</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106842.534674</td>\n",
       "      <td>391416.195014</td>\n",
       "      <td>177251.059830</td>\n",
       "      <td>6.440397e+10</td>\n",
       "      <td>4.605450e+17</td>\n",
       "      <td>-283.060837</td>\n",
       "      <td>3.575059e+08</td>\n",
       "      <td>0.047298</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>9.945521</td>\n",
       "      <td>...</td>\n",
       "      <td>44.883291</td>\n",
       "      <td>46.253476</td>\n",
       "      <td>45.153177</td>\n",
       "      <td>-1.517380</td>\n",
       "      <td>-3.721515</td>\n",
       "      <td>-0.438591</td>\n",
       "      <td>4.595185</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>233.2560</td>\n",
       "      <td>265.271759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251512.464237</td>\n",
       "      <td>820421.502412</td>\n",
       "      <td>351678.607526</td>\n",
       "      <td>2.676350e+11</td>\n",
       "      <td>2.094960e+18</td>\n",
       "      <td>-285.092823</td>\n",
       "      <td>1.176162e+09</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.162072</td>\n",
       "      <td>9.479636</td>\n",
       "      <td>...</td>\n",
       "      <td>84.214584</td>\n",
       "      <td>73.127817</td>\n",
       "      <td>60.198305</td>\n",
       "      <td>4.672256</td>\n",
       "      <td>8.401033</td>\n",
       "      <td>7.769610</td>\n",
       "      <td>14.024262</td>\n",
       "      <td>6.330158</td>\n",
       "      <td>685.3560</td>\n",
       "      <td>714.864624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1272.803324</td>\n",
       "      <td>716.496845</td>\n",
       "      <td>1928.459437</td>\n",
       "      <td>1.597297e+10</td>\n",
       "      <td>1.319383e+17</td>\n",
       "      <td>30778.701439</td>\n",
       "      <td>1.008361e+08</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>5.139880</td>\n",
       "      <td>...</td>\n",
       "      <td>59.182139</td>\n",
       "      <td>65.927310</td>\n",
       "      <td>67.546902</td>\n",
       "      <td>3.247490</td>\n",
       "      <td>4.493242</td>\n",
       "      <td>-10.368397</td>\n",
       "      <td>129.772440</td>\n",
       "      <td>235.398947</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>9.429714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-152.986398</td>\n",
       "      <td>-549.017724</td>\n",
       "      <td>-130.463812</td>\n",
       "      <td>1.597293e+10</td>\n",
       "      <td>1.319379e+17</td>\n",
       "      <td>116472.518063</td>\n",
       "      <td>1.006838e+08</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>7.799599</td>\n",
       "      <td>...</td>\n",
       "      <td>47.056302</td>\n",
       "      <td>53.552222</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>-3.877335</td>\n",
       "      <td>-4.482324</td>\n",
       "      <td>-8.221116</td>\n",
       "      <td>1.926481</td>\n",
       "      <td>1.821389</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>34.978054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288931.657373</td>\n",
       "      <td>882606.207523</td>\n",
       "      <td>433721.413253</td>\n",
       "      <td>5.117552e+11</td>\n",
       "      <td>4.236939e+18</td>\n",
       "      <td>-285.118860</td>\n",
       "      <td>4.830029e+09</td>\n",
       "      <td>0.954517</td>\n",
       "      <td>0.501915</td>\n",
       "      <td>8.162520</td>\n",
       "      <td>...</td>\n",
       "      <td>56.489279</td>\n",
       "      <td>54.073489</td>\n",
       "      <td>56.295050</td>\n",
       "      <td>7.098153</td>\n",
       "      <td>12.610182</td>\n",
       "      <td>9.073494</td>\n",
       "      <td>-11.092650</td>\n",
       "      <td>12.907817</td>\n",
       "      <td>1132.0000</td>\n",
       "      <td>1175.788452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transactions           size  sentbyaddress    difficulty      hashrate  \\\n",
       "0  106842.534674  391416.195014  177251.059830  6.440397e+10  4.605450e+17   \n",
       "1  251512.464237  820421.502412  351678.607526  2.676350e+11  2.094960e+18   \n",
       "2    1272.803324     716.496845    1928.459437  1.597297e+10  1.319383e+17   \n",
       "3    -152.986398    -549.017724    -130.463812  1.597293e+10  1.319379e+17   \n",
       "4  288931.657373  882606.207523  433721.413253  5.117552e+11  4.236939e+18   \n",
       "\n",
       "  mining_profitability  sentinusdUSD transactionfeesUSD  \\\n",
       "0          -283.060837  3.575059e+08           0.047298   \n",
       "1          -285.092823  1.176162e+09           0.255738   \n",
       "2         30778.701439  1.008361e+08           0.011940   \n",
       "3        116472.518063  1.006838e+08           0.011652   \n",
       "4          -285.118860  4.830029e+09           0.954517   \n",
       "\n",
       "  median_transaction_feeUSD confirmationtime  ... price14rsiUSD price30rsiUSD  \\\n",
       "0                  0.034278         9.945521  ...     44.883291     46.253476   \n",
       "1                  0.162072         9.479636  ...     84.214584     73.127817   \n",
       "2                  0.008980         5.139880  ...     59.182139     65.927310   \n",
       "3                  0.008980         7.799599  ...     47.056302     53.552222   \n",
       "4                  0.501915         8.162520  ...     56.489279     54.073489   \n",
       "\n",
       "  price90rsiUSD price3rocUSD price7rocUSD price14rocUSD price30rocUSD  \\\n",
       "0     45.153177    -1.517380    -3.721515     -0.438591      4.595185   \n",
       "1     60.198305     4.672256     8.401033      7.769610     14.024262   \n",
       "2     67.546902     3.247490     4.493242    -10.368397    129.772440   \n",
       "3      0.041790    -3.877335    -4.482324     -8.221116      1.926481   \n",
       "4     56.295050     7.098153    12.610182      9.073494    -11.092650   \n",
       "\n",
       "  price90rocUSD      Price PredictedPrice  \n",
       "0     -0.066915   233.2560     265.271759  \n",
       "1      6.330158   685.3560     714.864624  \n",
       "2    235.398947     0.9350       9.429714  \n",
       "3      1.821389     0.0621      34.978054  \n",
       "4     12.907817  1132.0000    1175.788452  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictors=[list_of_column_names]\n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['Price']=y_test_orig\n",
    "TestingData['PredictedPrice']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "140847a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f881e87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162efd9d",
   "metadata": {},
   "source": [
    "### Tuning using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87440492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=800,\n",
    "                                            step=64),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6384e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='project2',\n",
    "    project_name='Price Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93677d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=3,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da785638",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d32dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
