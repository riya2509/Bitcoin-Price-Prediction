{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b2023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c15e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f600d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce1c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.000</td>\n",
       "      <td>1.193000e+03</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.000</td>\n",
       "      <td>2.620000e+03</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.000</td>\n",
       "      <td>4.048000e+03</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.000</td>\n",
       "      <td>2.341000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.000</td>\n",
       "      <td>2.122000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "      <td>340402</td>\n",
       "      <td>706867.000</td>\n",
       "      <td>433958</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.157542e+20</td>\n",
       "      <td>0.163</td>\n",
       "      <td>8.336367e+09</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>...</td>\n",
       "      <td>93.577</td>\n",
       "      <td>80.644</td>\n",
       "      <td>73.588</td>\n",
       "      <td>64.882</td>\n",
       "      <td>54.040</td>\n",
       "      <td>10.430</td>\n",
       "      <td>7.538</td>\n",
       "      <td>6.497</td>\n",
       "      <td>26.536</td>\n",
       "      <td>1.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "      <td>332402</td>\n",
       "      <td>704883.000</td>\n",
       "      <td>416980</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.253033e+20</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1.365361e+10</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.213</td>\n",
       "      <td>...</td>\n",
       "      <td>94.137</td>\n",
       "      <td>81.436</td>\n",
       "      <td>74.176</td>\n",
       "      <td>65.272</td>\n",
       "      <td>54.195</td>\n",
       "      <td>7.432</td>\n",
       "      <td>10.930</td>\n",
       "      <td>8.061</td>\n",
       "      <td>28.817</td>\n",
       "      <td>2.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "      <td>334290</td>\n",
       "      <td>770486.000</td>\n",
       "      <td>398021</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.113635e+20</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.126273e+10</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>...</td>\n",
       "      <td>87.140</td>\n",
       "      <td>79.116</td>\n",
       "      <td>73.100</td>\n",
       "      <td>64.815</td>\n",
       "      <td>54.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>11.368</td>\n",
       "      <td>5.611</td>\n",
       "      <td>29.412</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "      <td>303573</td>\n",
       "      <td>650769.000</td>\n",
       "      <td>338567</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.201317e+20</td>\n",
       "      <td>0.149</td>\n",
       "      <td>7.668679e+09</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>...</td>\n",
       "      <td>88.385</td>\n",
       "      <td>79.762</td>\n",
       "      <td>73.498</td>\n",
       "      <td>65.058</td>\n",
       "      <td>54.175</td>\n",
       "      <td>0.473</td>\n",
       "      <td>12.499</td>\n",
       "      <td>5.457</td>\n",
       "      <td>31.791</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "      <td>290736</td>\n",
       "      <td>684127.000</td>\n",
       "      <td>257655</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.064910e+20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>6.486338e+09</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>...</td>\n",
       "      <td>88.689</td>\n",
       "      <td>79.897</td>\n",
       "      <td>73.576</td>\n",
       "      <td>65.104</td>\n",
       "      <td>54.192</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.011</td>\n",
       "      <td>6.081</td>\n",
       "      <td>29.624</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD  transactions        size  sentbyaddress    difficulty  \\\n",
       "0        0.0495           235     649.653            390  1.815430e+02   \n",
       "1        0.0726           248     765.285            424  1.815430e+02   \n",
       "2        0.0859           354     756.040            553  1.815430e+02   \n",
       "3        0.0783           413     984.707            632  1.815430e+02   \n",
       "4        0.0767           256     542.483            440  1.815430e+02   \n",
       "...         ...           ...         ...            ...           ...   \n",
       "3483  9349.0000        340402  706867.000         433958  1.546610e+13   \n",
       "3484  9394.0000        332402  704883.000         416980  1.546610e+13   \n",
       "3485  9366.0000        334290  770486.000         398021  1.546610e+13   \n",
       "3486  9393.0000        303573  650769.000         338567  1.546610e+13   \n",
       "3487  9398.0000        290736  684127.000         257655  1.546610e+13   \n",
       "\n",
       "          hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0     2.775561e+09            154298.000  1.193000e+03            0.000010   \n",
       "1     1.554461e+09            401834.000  2.620000e+03            0.000243   \n",
       "2     1.551287e+09            481473.000  4.048000e+03            0.000022   \n",
       "3     1.640430e+09            431831.000  2.341000e+03            0.000000   \n",
       "4     1.723493e+09            460783.000  2.122000e+03            0.000000   \n",
       "...            ...                   ...           ...                 ...   \n",
       "3483  1.157542e+20                 0.163  8.336367e+09            0.561000   \n",
       "3484  1.253033e+20                 0.148  1.365361e+10            0.555000   \n",
       "3485  1.113635e+20                 0.153  1.126273e+10            0.631000   \n",
       "3486  1.201317e+20                 0.149  7.668679e+09            0.541000   \n",
       "3487  1.064910e+20                 0.159  6.486338e+09            0.548000   \n",
       "\n",
       "      median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  \\\n",
       "0                         0.000  ...         0.000         0.000   \n",
       "1                         0.000  ...         0.000         0.000   \n",
       "2                         0.000  ...         0.000         0.000   \n",
       "3                         0.000  ...        82.751         0.000   \n",
       "4                         0.000  ...        78.603         0.000   \n",
       "...                         ...  ...           ...           ...   \n",
       "3483                      0.221  ...        93.577        80.644   \n",
       "3484                      0.213  ...        94.137        81.436   \n",
       "3485                      0.270  ...        87.140        79.116   \n",
       "3486                      0.219  ...        88.385        79.762   \n",
       "3487                      0.206  ...        88.689        79.897   \n",
       "\n",
       "      price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  \\\n",
       "0             0.000          0.000          0.000         0.000         0.000   \n",
       "1             0.000          0.000          0.000         0.000         0.000   \n",
       "2             0.000          0.000          0.000         0.000         0.000   \n",
       "3             0.000          0.000          0.000        58.099         0.000   \n",
       "4             0.000          0.000          0.000         5.652         0.000   \n",
       "...             ...            ...            ...           ...           ...   \n",
       "3483         73.588         64.882         54.040        10.430         7.538   \n",
       "3484         74.176         65.272         54.195         7.432        10.930   \n",
       "3485         73.100         64.815         54.082         3.505        11.368   \n",
       "3486         73.498         65.058         54.175         0.473        12.499   \n",
       "3487         73.576         65.104         54.192         0.041        11.011   \n",
       "\n",
       "      price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0             0.000          0.000          0.000  \n",
       "1             0.000          0.000          0.000  \n",
       "2             0.000          0.000          0.000  \n",
       "3             0.000          0.000          0.000  \n",
       "4             0.000          0.000          0.000  \n",
       "...             ...            ...            ...  \n",
       "3483          6.497         26.536          1.663  \n",
       "3484          8.061         28.817          2.376  \n",
       "3485          5.611         29.412          0.800  \n",
       "3486          5.457         31.791          1.606  \n",
       "3487          6.081         29.624          1.220  \n",
       "\n",
       "[3488 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9928269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_20388\\435521352.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X=df1.drop('priceUSD',1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.000</td>\n",
       "      <td>1.193000e+03</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.000</td>\n",
       "      <td>2.620000e+03</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.000</td>\n",
       "      <td>4.048000e+03</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.000</td>\n",
       "      <td>2.341000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.956</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>1.815430e+02</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.000</td>\n",
       "      <td>2.122000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.957</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>340402</td>\n",
       "      <td>706867.000</td>\n",
       "      <td>433958</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.157542e+20</td>\n",
       "      <td>0.163</td>\n",
       "      <td>8.336367e+09</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>9.000</td>\n",
       "      <td>...</td>\n",
       "      <td>93.577</td>\n",
       "      <td>80.644</td>\n",
       "      <td>73.588</td>\n",
       "      <td>64.882</td>\n",
       "      <td>54.040</td>\n",
       "      <td>10.430</td>\n",
       "      <td>7.538</td>\n",
       "      <td>6.497</td>\n",
       "      <td>26.536</td>\n",
       "      <td>1.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>332402</td>\n",
       "      <td>704883.000</td>\n",
       "      <td>416980</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.253033e+20</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1.365361e+10</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.213</td>\n",
       "      <td>9.231</td>\n",
       "      <td>...</td>\n",
       "      <td>94.137</td>\n",
       "      <td>81.436</td>\n",
       "      <td>74.176</td>\n",
       "      <td>65.272</td>\n",
       "      <td>54.195</td>\n",
       "      <td>7.432</td>\n",
       "      <td>10.930</td>\n",
       "      <td>8.061</td>\n",
       "      <td>28.817</td>\n",
       "      <td>2.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>334290</td>\n",
       "      <td>770486.000</td>\n",
       "      <td>398021</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.113635e+20</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.126273e+10</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>10.000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.140</td>\n",
       "      <td>79.116</td>\n",
       "      <td>73.100</td>\n",
       "      <td>64.815</td>\n",
       "      <td>54.082</td>\n",
       "      <td>3.505</td>\n",
       "      <td>11.368</td>\n",
       "      <td>5.611</td>\n",
       "      <td>29.412</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>303573</td>\n",
       "      <td>650769.000</td>\n",
       "      <td>338567</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.201317e+20</td>\n",
       "      <td>0.149</td>\n",
       "      <td>7.668679e+09</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>9.536</td>\n",
       "      <td>...</td>\n",
       "      <td>88.385</td>\n",
       "      <td>79.762</td>\n",
       "      <td>73.498</td>\n",
       "      <td>65.058</td>\n",
       "      <td>54.175</td>\n",
       "      <td>0.473</td>\n",
       "      <td>12.499</td>\n",
       "      <td>5.457</td>\n",
       "      <td>31.791</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>290736</td>\n",
       "      <td>684127.000</td>\n",
       "      <td>257655</td>\n",
       "      <td>1.546610e+13</td>\n",
       "      <td>1.064910e+20</td>\n",
       "      <td>0.159</td>\n",
       "      <td>6.486338e+09</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>10.070</td>\n",
       "      <td>...</td>\n",
       "      <td>88.689</td>\n",
       "      <td>79.897</td>\n",
       "      <td>73.576</td>\n",
       "      <td>65.104</td>\n",
       "      <td>54.192</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.011</td>\n",
       "      <td>6.081</td>\n",
       "      <td>29.624</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transactions        size  sentbyaddress    difficulty      hashrate  \\\n",
       "0              235     649.653            390  1.815430e+02  2.775561e+09   \n",
       "1              248     765.285            424  1.815430e+02  1.554461e+09   \n",
       "2              354     756.040            553  1.815430e+02  1.551287e+09   \n",
       "3              413     984.707            632  1.815430e+02  1.640430e+09   \n",
       "4              256     542.483            440  1.815430e+02  1.723493e+09   \n",
       "...            ...         ...            ...           ...           ...   \n",
       "3483        340402  706867.000         433958  1.546610e+13  1.157542e+20   \n",
       "3484        332402  704883.000         416980  1.546610e+13  1.253033e+20   \n",
       "3485        334290  770486.000         398021  1.546610e+13  1.113635e+20   \n",
       "3486        303573  650769.000         338567  1.546610e+13  1.201317e+20   \n",
       "3487        290736  684127.000         257655  1.546610e+13  1.064910e+20   \n",
       "\n",
       "      mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0               154298.000  1.193000e+03            0.000010   \n",
       "1               401834.000  2.620000e+03            0.000243   \n",
       "2               481473.000  4.048000e+03            0.000022   \n",
       "3               431831.000  2.341000e+03            0.000000   \n",
       "4               460783.000  2.122000e+03            0.000000   \n",
       "...                    ...           ...                 ...   \n",
       "3483                 0.163  8.336367e+09            0.561000   \n",
       "3484                 0.148  1.365361e+10            0.555000   \n",
       "3485                 0.153  1.126273e+10            0.631000   \n",
       "3486                 0.149  7.668679e+09            0.541000   \n",
       "3487                 0.159  6.486338e+09            0.548000   \n",
       "\n",
       "      median_transaction_feeUSD  confirmationtime  ...  price3rsiUSD  \\\n",
       "0                         0.000             8.324  ...         0.000   \n",
       "1                         0.000             8.372  ...         0.000   \n",
       "2                         0.000             8.276  ...         0.000   \n",
       "3                         0.000             7.956  ...        82.751   \n",
       "4                         0.000             6.957  ...        78.603   \n",
       "...                         ...               ...  ...           ...   \n",
       "3483                      0.221             9.000  ...        93.577   \n",
       "3484                      0.213             9.231  ...        94.137   \n",
       "3485                      0.270            10.000  ...        87.140   \n",
       "3486                      0.219             9.536  ...        88.385   \n",
       "3487                      0.206            10.070  ...        88.689   \n",
       "\n",
       "      price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  \\\n",
       "0            0.000          0.000          0.000          0.000         0.000   \n",
       "1            0.000          0.000          0.000          0.000         0.000   \n",
       "2            0.000          0.000          0.000          0.000         0.000   \n",
       "3            0.000          0.000          0.000          0.000        58.099   \n",
       "4            0.000          0.000          0.000          0.000         5.652   \n",
       "...            ...            ...            ...            ...           ...   \n",
       "3483        80.644         73.588         64.882         54.040        10.430   \n",
       "3484        81.436         74.176         65.272         54.195         7.432   \n",
       "3485        79.116         73.100         64.815         54.082         3.505   \n",
       "3486        79.762         73.498         65.058         54.175         0.473   \n",
       "3487        79.897         73.576         65.104         54.192         0.041   \n",
       "\n",
       "      price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0            0.000          0.000          0.000          0.000  \n",
       "1            0.000          0.000          0.000          0.000  \n",
       "2            0.000          0.000          0.000          0.000  \n",
       "3            0.000          0.000          0.000          0.000  \n",
       "4            0.000          0.000          0.000          0.000  \n",
       "...            ...            ...            ...            ...  \n",
       "3483         7.538          6.497         26.536          1.663  \n",
       "3484        10.930          8.061         28.817          2.376  \n",
       "3485        11.368          5.611         29.412          0.800  \n",
       "3486        12.499          5.457         31.791          1.606  \n",
       "3487        11.011          6.081         29.624          1.220  \n",
       "\n",
       "[3488 rows x 735 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "X=df1.drop('priceUSD',1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4bf9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895f30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158905ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766d4368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2790, 735)\n",
      "Testing set:  (698, 735)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: {}\".format(X_train.shape))  \n",
    "print(\"Testing set:  {}\".format(X_test.shape))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3acf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.36463320e-01 -7.74125985e-01 -6.97323313e-01 -5.03766348e-01\n",
      " -5.02730636e-01 -2.32304429e-01 -3.46127805e-01 -2.12567130e-01\n",
      " -1.98319109e-01 -8.02437969e-01 -9.62134717e-02 -9.96663160e-03\n",
      " -5.67947228e-01  1.48316801e-01 -4.69648158e-01 -7.73668961e-01\n",
      " -7.64759230e-01 -7.15729233e-01 -6.74412298e-01 -6.79059790e-01\n",
      " -7.60671037e-01 -7.58323526e-01 -7.33966564e-01 -6.94772985e-01\n",
      " -6.78198632e-01 -7.62839397e-01 -7.68662383e-01 -7.49258143e-01\n",
      " -7.10353600e-01 -6.65384807e-01 -7.67457270e-02 -6.59699955e-01\n",
      " -7.30217750e-01 -1.67727613e-01 -1.99659304e-01  8.50202656e-02\n",
      "  2.45916905e-02 -5.82292545e-01 -6.39209910e-01 -2.21466593e-01\n",
      " -6.24019211e-01 -9.22349391e-01 -4.43376987e-01 -4.14973206e-01\n",
      " -3.56684069e-01 -4.81391473e-01 -6.64657930e-01 -5.50508982e-01\n",
      " -5.41012743e-01 -4.46926810e-01  8.53985758e-01 -1.58126199e-01\n",
      " -7.30188446e-01 -7.78075252e-01 -5.69959034e-01 -2.69978133e-02\n",
      " -4.80341290e-02 -1.59892529e-01 -3.02269360e-01 -2.12710999e-01\n",
      " -7.77078597e-01 -7.98730111e-01 -7.92158076e-01 -7.67656039e-01\n",
      " -7.82697812e-01 -7.85512282e-01 -7.93833642e-01 -7.89976930e-01\n",
      " -7.71123933e-01 -7.75186772e-01 -7.77982537e-01 -7.95441377e-01\n",
      " -7.96677235e-01 -7.86348567e-01 -7.56153017e-01  1.00017285e-01\n",
      " -2.35981003e-01 -6.31137068e-01 -7.99394919e-02 -9.25203909e-02\n",
      "  3.17551751e-01  7.61570226e-02 -8.30197696e-02 -2.95682276e-01\n",
      "  1.42915023e-01 -8.57033421e-01 -8.00771190e-01 -7.97983080e-01\n",
      " -6.26052108e-01 -2.84254831e-01 -4.56834585e-01 -5.69878650e-01\n",
      " -6.19698991e-01 -6.22716173e-01 -4.97544012e-01  4.81849758e-01\n",
      "  1.62560819e-01 -1.74911531e-01 -2.15050818e-01 -7.76843719e-02\n",
      "  9.60602294e-02 -4.60566080e-02 -1.15395007e-01 -2.92850134e-01\n",
      " -1.24980235e-01 -7.72003039e-01 -7.47027650e-01 -7.09712463e-01\n",
      " -6.66909431e-01 -7.39081863e-01 -7.47078670e-01 -7.47477810e-01\n",
      " -7.25027159e-01 -6.93790597e-01 -7.24223428e-01 -7.55553474e-01\n",
      " -7.55922554e-01 -7.40247261e-01 -7.02085372e-01 -6.88494022e-01\n",
      " -1.90929098e-01 -1.25814675e+00 -1.17736652e+00  4.64104674e-01\n",
      "  6.11817670e-01  1.26489129e-01  2.46508188e-01 -4.97759298e-01\n",
      " -3.73524573e-01  2.97336105e-01 -3.41434102e-01 -6.92303185e-01\n",
      " -4.04712799e-01 -3.71060061e-01 -1.94625786e-02 -4.25238608e-01\n",
      " -5.99146899e-01 -5.16296608e-01 -4.83932783e-01 -2.59983960e-01\n",
      "  1.01507536e+00  3.70745019e-01 -1.83142659e-01 -1.68461256e-01\n",
      "  2.39850964e-01  9.98511152e-02  2.33890844e-01 -5.48404000e-01\n",
      " -5.91284519e-01  1.17967667e-01 -5.03672729e-01 -5.03566571e-01\n",
      " -5.03229800e-01 -5.02449065e-01 -4.97618494e-01 -5.03707076e-01\n",
      " -5.03579551e-01 -5.03302827e-01 -5.02464691e-01 -4.99822962e-01\n",
      " -5.03710651e-01 -5.03637418e-01 -5.03455254e-01 -5.03006439e-01\n",
      " -5.00161803e-01 -2.10209922e-01  9.52889478e-01  1.16584651e+00\n",
      "  1.17269732e+00  1.62090379e+00 -1.21420337e-01 -1.89294426e-01\n",
      " -2.59737165e-01 -3.12493124e-01 -3.89741567e-01 -1.59274128e-01\n",
      " -2.65836796e-01 -3.93862387e-01 -4.61819502e-01 -4.96468631e-01\n",
      " -1.04559919e-01 -1.79309044e-01 -2.56355695e-01 -3.08850457e-01\n",
      " -3.41625806e-01  4.61968548e-01  4.84577704e-01  5.28176374e-01\n",
      "  6.05358434e-01  7.81453983e-01 -2.70100529e-01 -3.22752951e-01\n",
      "  3.72454119e-01  2.69771049e-01  6.07810594e-01 -5.03752734e-01\n",
      " -5.04211664e-01 -5.04073615e-01 -5.03502010e-01 -4.99594542e-01\n",
      " -5.03781261e-01 -5.04145000e-01 -5.04119411e-01 -5.03618770e-01\n",
      " -5.01338531e-01 -5.03629493e-01 -5.04119424e-01 -5.04220686e-01\n",
      " -5.03925317e-01 -5.01914365e-01 -3.28435890e-01  3.93382842e-01\n",
      "  9.95140471e-01  1.16047554e+00  1.55659903e+00 -4.34874441e-02\n",
      " -8.35718865e-02 -1.42707323e-01 -2.39825895e-01 -3.63022186e-01\n",
      " -4.33259818e-01 -4.76268404e-01 -4.91493058e-01 -5.01679675e-01\n",
      " -5.15593241e-01 -2.55182434e-01 -3.07562505e-01 -3.37007613e-01\n",
      " -3.59531329e-01 -3.80384727e-01  4.79110435e-01  6.33842681e-01\n",
      "  1.11869848e+00  1.51689712e+00  1.78236957e+00 -4.15995329e-01\n",
      " -7.98544653e-02  2.12117995e-01  3.93780536e-01  5.26039132e-01\n",
      " -2.28825779e-01 -2.31677557e-01 -2.44414615e-01 -2.55704257e-01\n",
      " -2.86046839e-01 -2.31091646e-01 -2.34121515e-01 -2.43087690e-01\n",
      " -2.56237672e-01 -2.69954968e-01 -2.29570660e-01 -2.34398192e-01\n",
      " -2.49963386e-01 -2.69984659e-01 -2.99830757e-01  6.34855310e-01\n",
      " -1.23760175e+00 -1.52744632e+00  3.65760721e-01 -1.27053506e+00\n",
      "  2.57585315e-02  7.19336896e-02  8.70764215e-02  1.05214943e-01\n",
      "  1.67721138e-01 -1.86902867e-01 -1.96367779e-01 -2.24953417e-01\n",
      " -2.21671624e-01 -2.54701535e-01 -7.73383572e-02 -7.77954077e-02\n",
      " -9.77256707e-02 -1.11159427e-01 -1.21680392e-01  2.79728694e-01\n",
      " -2.43448538e-01 -6.44834847e-01 -3.75075186e-01 -1.10806694e-01\n",
      " -1.86494561e-01  7.16314785e-01 -1.09838574e+00 -1.41539921e+00\n",
      " -1.89082984e-01 -4.07275318e-01 -4.37296882e-01 -4.36367644e-01\n",
      " -4.11556354e-01 -4.64965145e-01 -4.06973597e-01 -4.36976735e-01\n",
      " -4.40748648e-01 -4.28803208e-01 -4.69639146e-01 -3.97921619e-01\n",
      " -4.30091882e-01 -4.45307289e-01 -4.34224514e-01 -4.28262873e-01\n",
      "  1.18316355e-01 -1.03581323e+00 -1.21205866e+00  1.61461783e-01\n",
      "  1.91744546e+00  2.41723052e-02  1.74081359e-02 -1.28063113e-01\n",
      " -2.37319307e-01  3.15069598e-02 -1.96642726e-01 -2.37692238e-01\n",
      " -2.33641766e-01 -2.42271628e-01 -2.71479464e-01 -4.27871355e-02\n",
      " -5.81327134e-02 -8.20667613e-02 -1.21460229e-01 -2.15317813e-01\n",
      "  1.05485196e+00 -2.40105594e-01 -6.06351227e-01 -3.16382817e-01\n",
      "  1.31072863e-01  1.17991232e-01  1.23477790e-02 -4.09239445e-01\n",
      " -3.85184032e-01 -4.77611710e-02 -2.07901230e-01 -2.13174176e-01\n",
      " -2.21045020e-01 -2.20124848e-01 -2.67789454e-01 -2.10353998e-01\n",
      " -2.14935792e-01 -2.21724954e-01 -2.33228296e-01 -2.84800792e-01\n",
      " -2.08563062e-01 -2.11166092e-01 -2.17435290e-01 -2.23159387e-01\n",
      " -2.48713083e-01 -1.89829015e-02 -2.99783657e-02 -6.21491748e-01\n",
      " -1.43912042e-01  5.09065633e-01 -5.66601583e-03  2.15175038e-02\n",
      " -4.75190615e-03 -3.32789332e-02  2.33749698e-02 -1.90647443e-01\n",
      " -2.10307100e-01 -2.25221671e-01 -2.14311913e-01 -2.35103094e-01\n",
      " -7.54037446e-02 -9.13447663e-02 -1.17093519e-01 -1.29960437e-01\n",
      " -1.85129594e-01 -6.32433440e-01 -4.06500842e-01 -4.72769737e-01\n",
      " -2.51292403e-01  8.46824910e-02 -1.89676566e-02 -1.93115684e-02\n",
      " -2.22066678e-02 -1.94859318e-02 -3.67658870e-02 -2.00829668e-01\n",
      " -2.04031349e-01 -2.10734092e-01 -2.18098397e-01 -2.73528656e-01\n",
      " -2.01339798e-01 -2.06360631e-01 -2.13571172e-01 -2.30392906e-01\n",
      " -2.88350394e-01 -2.00281830e-01 -2.02961440e-01 -2.07868446e-01\n",
      " -2.16311622e-01 -2.56432283e-01 -1.89354549e-02 -1.89354551e-02\n",
      " -2.01569511e-02  4.56986416e-02 -6.55850503e-02  7.01814490e-03\n",
      "  2.06060125e-02  2.03885277e-03 -1.26733928e-02  1.32500253e-02\n",
      " -2.01573328e-01 -2.11896883e-01 -2.21163085e-01 -2.30393129e-01\n",
      " -2.56818689e-01 -6.96162424e-02 -9.55219220e-02 -1.18419381e-01\n",
      " -1.31488177e-01 -1.84832544e-01  1.00237816e+00  5.20540324e-01\n",
      "  2.49354486e-01  2.69321335e-01  3.01209963e-01 -7.57616309e-02\n",
      "  2.49127863e-01 -1.96978369e-01 -5.27962016e-01 -2.44158863e-02\n",
      " -4.85366425e-01 -8.35254242e-01 -1.27578210e+00 -1.54892392e+00\n",
      " -1.87441028e+00 -7.87257159e-01 -9.01375668e-01 -1.13971258e+00\n",
      " -1.39374375e+00 -1.76796328e+00 -6.69301269e-01 -8.06673730e-01\n",
      " -9.83420276e-01 -1.38248399e+00 -1.60399246e+00  9.54278564e-02\n",
      "  9.93568341e-01  4.64436573e-01  2.06147378e-01 -3.88687669e-01\n",
      "  3.51441747e-01 -7.81379891e-02  7.23667810e-01  6.29450753e-02\n",
      "  3.40198590e-01 -1.44264225e-01 -6.92297869e-01 -2.58922811e-01\n",
      " -6.81035532e-01 -2.88921985e-01 -2.39126551e-01 -4.52598583e-01\n",
      " -2.74103093e-01 -5.39601002e-01 -3.47903108e-01 -3.89119792e-01\n",
      " -3.28542624e-02  1.60516589e-01  2.68860325e-01  2.61538945e-01\n",
      "  3.19463202e-01 -1.53227946e-01  7.33804379e-01 -2.35285743e-02\n",
      "  2.54789352e-01 -1.18495188e-01 -1.58810740e-01 -1.22239298e-01\n",
      "  2.13125038e-02 -1.69465861e-01 -1.20198071e-01 -1.41113211e-01\n",
      " -1.08269506e-01 -3.12188200e-02 -1.26920763e-01 -1.06188782e-01\n",
      " -1.49000304e-01 -1.52406849e-01 -6.57228491e-02 -2.41304112e-02\n",
      "  1.79207853e-01 -6.64964430e-01 -9.43008657e-01  4.82481281e-01\n",
      "  2.59523269e+00  1.04623659e-01  9.25847072e-02 -4.97397703e-01\n",
      " -8.11280367e-01  3.08935855e-01 -1.56456084e-01 -2.00363145e-01\n",
      " -1.80916735e-01 -8.39204665e-02  4.17020609e-02 -4.32598926e-02\n",
      " -5.96121250e-02 -8.29236293e-02 -1.15849861e-01 -1.68937663e-01\n",
      "  5.09193962e-01 -6.78986486e-02 -3.85221098e-01 -1.30096367e-01\n",
      "  2.36320908e-01  8.94218878e-02  1.17815605e-02 -4.35519476e-01\n",
      " -3.95668027e-01  1.13747802e-01 -1.17861098e-01 -3.62192069e-02\n",
      "  2.06360149e-02  2.84143730e-01  8.91651270e-02 -7.19051866e-02\n",
      " -5.25712880e-02  2.51609919e-02  1.72291765e-01  1.29953348e-01\n",
      " -9.48788553e-02 -6.16559700e-02 -3.86490627e-02  1.07380737e-01\n",
      "  2.53834890e-01 -3.58415494e-01 -1.07533956e+00 -1.28551700e+00\n",
      "  3.08530896e-01  2.40261177e+00  1.98148586e-02  2.67138590e-01\n",
      " -4.39913203e-01 -9.02233535e-01  2.38252309e-01  1.33563007e-02\n",
      " -2.18471307e-02  1.27602778e-01  4.55458349e-01  3.57757661e-01\n",
      " -7.96848746e-02 -1.00743177e-01 -9.68860515e-02 -5.20778505e-02\n",
      " -9.44147878e-02  5.92059483e-01 -1.40747040e-01 -6.25035114e-01\n",
      " -3.16188987e-01  1.73129852e-01 -3.81036202e-02 -4.81549913e-02\n",
      " -6.48672170e-02 -6.51288295e-02 -4.35295629e-02 -6.52536496e-01\n",
      " -6.66740456e-01 -6.25534512e-01 -5.85859271e-01 -6.71668279e-01\n",
      " -6.28054685e-01 -6.47448214e-01 -6.34983454e-01 -6.13106977e-01\n",
      " -6.58749675e-01 -6.28079625e-01 -6.58593399e-01 -6.49676599e-01\n",
      " -6.16459313e-01 -6.18218939e-01  9.99825050e-02 -9.83791747e-01\n",
      " -9.93465409e-01  5.80518110e-01  8.31531408e-01  3.24551520e-01\n",
      " -6.40915678e-03 -3.16480743e-01 -1.57112799e-01  4.11437847e-01\n",
      " -2.27712159e-01 -5.66648945e-01 -3.98336808e-01 -3.89217153e-01\n",
      " -1.58430595e-01 -1.83066850e-01 -2.76405170e-01 -2.51260591e-01\n",
      " -2.55958643e-01 -2.70591060e-01  1.56031109e+00  9.07470074e-01\n",
      "  3.47497675e-01  3.22917055e-01  7.37064306e-01  6.27453716e-01\n",
      " -9.99279854e-02 -6.15813146e-01 -4.15631416e-01  3.47757062e-01\n",
      "  1.40815442e-01  1.54113192e-01  1.99619243e-01  1.96335138e-01\n",
      "  4.76019426e-02  1.44596014e-01  1.58902736e-01  1.80614540e-01\n",
      "  1.84226847e-01  8.23757770e-02  1.42435082e-01  1.44512177e-01\n",
      "  1.74165704e-01  2.00008475e-01  1.42432744e-01 -1.17426641e-01\n",
      " -4.31695955e-01  4.77135539e-02  9.91531369e-01  4.21565509e-01\n",
      "  4.25704671e-02 -2.42458474e-01 -3.35306233e-01  2.45488443e-02\n",
      "  9.64623625e-01 -9.99360567e-02  8.88233678e-03  1.41972084e-02\n",
      " -1.56829046e-01  9.19908017e-02 -4.46156977e-02 -6.93448855e-02\n",
      " -9.48877492e-02 -1.57357874e-01 -2.02926646e-01 -1.57209939e-01\n",
      " -9.11458362e-01 -6.12746312e-01  1.05009332e-01  6.72986243e-01\n",
      "  8.52834153e-02 -2.70799414e-01 -3.77899513e-01  5.54862015e-02\n",
      "  1.18827780e+00 -4.66715676e-01 -4.76583379e-01 -4.79752231e-01\n",
      " -4.80290386e-01 -4.30852464e-01 -4.71395679e-01 -4.77753575e-01\n",
      " -4.83560769e-01 -4.81281716e-01 -4.58041269e-01 -4.67472086e-01\n",
      " -4.74163549e-01 -4.79503031e-01 -4.84591154e-01 -4.50170870e-01\n",
      " -1.92489670e-02 -1.63632576e-01 -1.07199540e+00 -1.39742539e+00\n",
      " -6.23180597e-01 -7.91330392e-03 -3.44633154e-05 -1.87831740e-02\n",
      " -6.60923707e-02 -1.33116495e-01 -4.48230014e-01 -5.01533714e-01\n",
      " -5.02294231e-01 -4.54409912e-01 -2.49303458e-01 -1.78078129e-01\n",
      " -1.92124812e-01 -2.24509674e-01 -2.51493832e-01 -2.66784948e-01\n",
      " -7.37375927e-01 -6.84038953e-01 -7.45506759e-01 -4.94470274e-01\n",
      " -1.30407579e-02 -1.89463263e-02 -1.93544140e-02 -2.07669429e-02\n",
      " -1.93990441e-02 -4.10841954e-02 -4.15514886e-01 -4.21249881e-01\n",
      " -4.33655551e-01 -3.99748435e-01 -4.85610551e-01 -4.14920650e-01\n",
      " -4.20406328e-01 -4.21028703e-01 -4.21076700e-01 -4.71436809e-01\n",
      " -4.14609471e-01 -4.17426126e-01 -4.26874542e-01 -4.16243926e-01\n",
      " -4.44486302e-01  6.08671422e-01 -2.34519327e-01 -6.32921355e-01\n",
      "  1.30252757e+00  2.44179172e+00  6.09629866e-03  1.85286096e-01\n",
      " -4.90773025e-02 -3.07913560e-01  2.41655155e-01 -2.71568217e-01\n",
      " -2.53262898e-01 -2.41803450e-01 -1.69151920e-01 -6.75519812e-02\n",
      " -1.55312834e-01 -1.93824177e-01 -2.10095792e-01 -1.99859434e-01\n",
      " -2.31152041e-01  7.38032092e-01  2.01860346e-01 -1.06578623e-01\n",
      "  2.09612784e-02  3.84218862e-01 -4.58712514e-02  8.02728608e-01\n",
      " -3.23155164e-01 -7.26863880e-01  1.59926671e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc00749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.36463320e-01 -7.74125985e-01 -6.97323313e-01 -5.03766348e-01\n",
      " -5.02730636e-01 -2.32304429e-01 -3.46127805e-01 -2.12567130e-01\n",
      " -1.98319109e-01 -8.02437969e-01 -9.62134717e-02 -9.96663160e-03\n",
      " -5.67947228e-01  1.48316801e-01 -4.69648158e-01 -7.73668961e-01\n",
      " -7.64759230e-01 -7.15729233e-01 -6.74412298e-01 -6.79059790e-01\n",
      " -7.60671037e-01 -7.58323526e-01 -7.33966564e-01 -6.94772985e-01\n",
      " -6.78198632e-01 -7.62839397e-01 -7.68662383e-01 -7.49258143e-01\n",
      " -7.10353600e-01 -6.65384807e-01 -7.67457270e-02 -6.59699955e-01\n",
      " -7.30217750e-01 -1.67727613e-01 -1.99659304e-01  8.50202656e-02\n",
      "  2.45916905e-02 -5.82292545e-01 -6.39209910e-01 -2.21466593e-01\n",
      " -6.24019211e-01 -9.22349391e-01 -4.43376987e-01 -4.14973206e-01\n",
      " -3.56684069e-01 -4.81391473e-01 -6.64657930e-01 -5.50508982e-01\n",
      " -5.41012743e-01 -4.46926810e-01  8.53985758e-01 -1.58126199e-01\n",
      " -7.30188446e-01 -7.78075252e-01 -5.69959034e-01 -2.69978133e-02\n",
      " -4.80341290e-02 -1.59892529e-01 -3.02269360e-01 -2.12710999e-01\n",
      " -7.77078597e-01 -7.98730111e-01 -7.92158076e-01 -7.67656039e-01\n",
      " -7.82697812e-01 -7.85512282e-01 -7.93833642e-01 -7.89976930e-01\n",
      " -7.71123933e-01 -7.75186772e-01 -7.77982537e-01 -7.95441377e-01\n",
      " -7.96677235e-01 -7.86348567e-01 -7.56153017e-01  1.00017285e-01\n",
      " -2.35981003e-01 -6.31137068e-01 -7.99394919e-02 -9.25203909e-02\n",
      "  3.17551751e-01  7.61570226e-02 -8.30197696e-02 -2.95682276e-01\n",
      "  1.42915023e-01 -8.57033421e-01 -8.00771190e-01 -7.97983080e-01\n",
      " -6.26052108e-01 -2.84254831e-01 -4.56834585e-01 -5.69878650e-01\n",
      " -6.19698991e-01 -6.22716173e-01 -4.97544012e-01  4.81849758e-01\n",
      "  1.62560819e-01 -1.74911531e-01 -2.15050818e-01 -7.76843719e-02\n",
      "  9.60602294e-02 -4.60566080e-02 -1.15395007e-01 -2.92850134e-01\n",
      " -1.24980235e-01 -7.72003039e-01 -7.47027650e-01 -7.09712463e-01\n",
      " -6.66909431e-01 -7.39081863e-01 -7.47078670e-01 -7.47477810e-01\n",
      " -7.25027159e-01 -6.93790597e-01 -7.24223428e-01 -7.55553474e-01\n",
      " -7.55922554e-01 -7.40247261e-01 -7.02085372e-01 -6.88494022e-01\n",
      " -1.90929098e-01 -1.25814675e+00 -1.17736652e+00  4.64104674e-01\n",
      "  6.11817670e-01  1.26489129e-01  2.46508188e-01 -4.97759298e-01\n",
      " -3.73524573e-01  2.97336105e-01 -3.41434102e-01 -6.92303185e-01\n",
      " -4.04712799e-01 -3.71060061e-01 -1.94625786e-02 -4.25238608e-01\n",
      " -5.99146899e-01 -5.16296608e-01 -4.83932783e-01 -2.59983960e-01\n",
      "  1.01507536e+00  3.70745019e-01 -1.83142659e-01 -1.68461256e-01\n",
      "  2.39850964e-01  9.98511152e-02  2.33890844e-01 -5.48404000e-01\n",
      " -5.91284519e-01  1.17967667e-01 -5.03672729e-01 -5.03566571e-01\n",
      " -5.03229800e-01 -5.02449065e-01 -4.97618494e-01 -5.03707076e-01\n",
      " -5.03579551e-01 -5.03302827e-01 -5.02464691e-01 -4.99822962e-01\n",
      " -5.03710651e-01 -5.03637418e-01 -5.03455254e-01 -5.03006439e-01\n",
      " -5.00161803e-01 -2.10209922e-01  9.52889478e-01  1.16584651e+00\n",
      "  1.17269732e+00  1.62090379e+00 -1.21420337e-01 -1.89294426e-01\n",
      " -2.59737165e-01 -3.12493124e-01 -3.89741567e-01 -1.59274128e-01\n",
      " -2.65836796e-01 -3.93862387e-01 -4.61819502e-01 -4.96468631e-01\n",
      " -1.04559919e-01 -1.79309044e-01 -2.56355695e-01 -3.08850457e-01\n",
      " -3.41625806e-01  4.61968548e-01  4.84577704e-01  5.28176374e-01\n",
      "  6.05358434e-01  7.81453983e-01 -2.70100529e-01 -3.22752951e-01\n",
      "  3.72454119e-01  2.69771049e-01  6.07810594e-01 -5.03752734e-01\n",
      " -5.04211664e-01 -5.04073615e-01 -5.03502010e-01 -4.99594542e-01\n",
      " -5.03781261e-01 -5.04145000e-01 -5.04119411e-01 -5.03618770e-01\n",
      " -5.01338531e-01 -5.03629493e-01 -5.04119424e-01 -5.04220686e-01\n",
      " -5.03925317e-01 -5.01914365e-01 -3.28435890e-01  3.93382842e-01\n",
      "  9.95140471e-01  1.16047554e+00  1.55659903e+00 -4.34874441e-02\n",
      " -8.35718865e-02 -1.42707323e-01 -2.39825895e-01 -3.63022186e-01\n",
      " -4.33259818e-01 -4.76268404e-01 -4.91493058e-01 -5.01679675e-01\n",
      " -5.15593241e-01 -2.55182434e-01 -3.07562505e-01 -3.37007613e-01\n",
      " -3.59531329e-01 -3.80384727e-01  4.79110435e-01  6.33842681e-01\n",
      "  1.11869848e+00  1.51689712e+00  1.78236957e+00 -4.15995329e-01\n",
      " -7.98544653e-02  2.12117995e-01  3.93780536e-01  5.26039132e-01\n",
      " -2.28825779e-01 -2.31677557e-01 -2.44414615e-01 -2.55704257e-01\n",
      " -2.86046839e-01 -2.31091646e-01 -2.34121515e-01 -2.43087690e-01\n",
      " -2.56237672e-01 -2.69954968e-01 -2.29570660e-01 -2.34398192e-01\n",
      " -2.49963386e-01 -2.69984659e-01 -2.99830757e-01  6.34855310e-01\n",
      " -1.23760175e+00 -1.52744632e+00  3.65760721e-01 -1.27053506e+00\n",
      "  2.57585315e-02  7.19336896e-02  8.70764215e-02  1.05214943e-01\n",
      "  1.67721138e-01 -1.86902867e-01 -1.96367779e-01 -2.24953417e-01\n",
      " -2.21671624e-01 -2.54701535e-01 -7.73383572e-02 -7.77954077e-02\n",
      " -9.77256707e-02 -1.11159427e-01 -1.21680392e-01  2.79728694e-01\n",
      " -2.43448538e-01 -6.44834847e-01 -3.75075186e-01 -1.10806694e-01\n",
      " -1.86494561e-01  7.16314785e-01 -1.09838574e+00 -1.41539921e+00\n",
      " -1.89082984e-01 -4.07275318e-01 -4.37296882e-01 -4.36367644e-01\n",
      " -4.11556354e-01 -4.64965145e-01 -4.06973597e-01 -4.36976735e-01\n",
      " -4.40748648e-01 -4.28803208e-01 -4.69639146e-01 -3.97921619e-01\n",
      " -4.30091882e-01 -4.45307289e-01 -4.34224514e-01 -4.28262873e-01\n",
      "  1.18316355e-01 -1.03581323e+00 -1.21205866e+00  1.61461783e-01\n",
      "  1.91744546e+00  2.41723052e-02  1.74081359e-02 -1.28063113e-01\n",
      " -2.37319307e-01  3.15069598e-02 -1.96642726e-01 -2.37692238e-01\n",
      " -2.33641766e-01 -2.42271628e-01 -2.71479464e-01 -4.27871355e-02\n",
      " -5.81327134e-02 -8.20667613e-02 -1.21460229e-01 -2.15317813e-01\n",
      "  1.05485196e+00 -2.40105594e-01 -6.06351227e-01 -3.16382817e-01\n",
      "  1.31072863e-01  1.17991232e-01  1.23477790e-02 -4.09239445e-01\n",
      " -3.85184032e-01 -4.77611710e-02 -2.07901230e-01 -2.13174176e-01\n",
      " -2.21045020e-01 -2.20124848e-01 -2.67789454e-01 -2.10353998e-01\n",
      " -2.14935792e-01 -2.21724954e-01 -2.33228296e-01 -2.84800792e-01\n",
      " -2.08563062e-01 -2.11166092e-01 -2.17435290e-01 -2.23159387e-01\n",
      " -2.48713083e-01 -1.89829015e-02 -2.99783657e-02 -6.21491748e-01\n",
      " -1.43912042e-01  5.09065633e-01 -5.66601583e-03  2.15175038e-02\n",
      " -4.75190615e-03 -3.32789332e-02  2.33749698e-02 -1.90647443e-01\n",
      " -2.10307100e-01 -2.25221671e-01 -2.14311913e-01 -2.35103094e-01\n",
      " -7.54037446e-02 -9.13447663e-02 -1.17093519e-01 -1.29960437e-01\n",
      " -1.85129594e-01 -6.32433440e-01 -4.06500842e-01 -4.72769737e-01\n",
      " -2.51292403e-01  8.46824910e-02 -1.89676566e-02 -1.93115684e-02\n",
      " -2.22066678e-02 -1.94859318e-02 -3.67658870e-02 -2.00829668e-01\n",
      " -2.04031349e-01 -2.10734092e-01 -2.18098397e-01 -2.73528656e-01\n",
      " -2.01339798e-01 -2.06360631e-01 -2.13571172e-01 -2.30392906e-01\n",
      " -2.88350394e-01 -2.00281830e-01 -2.02961440e-01 -2.07868446e-01\n",
      " -2.16311622e-01 -2.56432283e-01 -1.89354549e-02 -1.89354551e-02\n",
      " -2.01569511e-02  4.56986416e-02 -6.55850503e-02  7.01814490e-03\n",
      "  2.06060125e-02  2.03885277e-03 -1.26733928e-02  1.32500253e-02\n",
      " -2.01573328e-01 -2.11896883e-01 -2.21163085e-01 -2.30393129e-01\n",
      " -2.56818689e-01 -6.96162424e-02 -9.55219220e-02 -1.18419381e-01\n",
      " -1.31488177e-01 -1.84832544e-01  1.00237816e+00  5.20540324e-01\n",
      "  2.49354486e-01  2.69321335e-01  3.01209963e-01 -7.57616309e-02\n",
      "  2.49127863e-01 -1.96978369e-01 -5.27962016e-01 -2.44158863e-02\n",
      " -4.85366425e-01 -8.35254242e-01 -1.27578210e+00 -1.54892392e+00\n",
      " -1.87441028e+00 -7.87257159e-01 -9.01375668e-01 -1.13971258e+00\n",
      " -1.39374375e+00 -1.76796328e+00 -6.69301269e-01 -8.06673730e-01\n",
      " -9.83420276e-01 -1.38248399e+00 -1.60399246e+00  9.54278564e-02\n",
      "  9.93568341e-01  4.64436573e-01  2.06147378e-01 -3.88687669e-01\n",
      "  3.51441747e-01 -7.81379891e-02  7.23667810e-01  6.29450753e-02\n",
      "  3.40198590e-01 -1.44264225e-01 -6.92297869e-01 -2.58922811e-01\n",
      " -6.81035532e-01 -2.88921985e-01 -2.39126551e-01 -4.52598583e-01\n",
      " -2.74103093e-01 -5.39601002e-01 -3.47903108e-01 -3.89119792e-01\n",
      " -3.28542624e-02  1.60516589e-01  2.68860325e-01  2.61538945e-01\n",
      "  3.19463202e-01 -1.53227946e-01  7.33804379e-01 -2.35285743e-02\n",
      "  2.54789352e-01 -1.18495188e-01 -1.58810740e-01 -1.22239298e-01\n",
      "  2.13125038e-02 -1.69465861e-01 -1.20198071e-01 -1.41113211e-01\n",
      " -1.08269506e-01 -3.12188200e-02 -1.26920763e-01 -1.06188782e-01\n",
      " -1.49000304e-01 -1.52406849e-01 -6.57228491e-02 -2.41304112e-02\n",
      "  1.79207853e-01 -6.64964430e-01 -9.43008657e-01  4.82481281e-01\n",
      "  2.59523269e+00  1.04623659e-01  9.25847072e-02 -4.97397703e-01\n",
      " -8.11280367e-01  3.08935855e-01 -1.56456084e-01 -2.00363145e-01\n",
      " -1.80916735e-01 -8.39204665e-02  4.17020609e-02 -4.32598926e-02\n",
      " -5.96121250e-02 -8.29236293e-02 -1.15849861e-01 -1.68937663e-01\n",
      "  5.09193962e-01 -6.78986486e-02 -3.85221098e-01 -1.30096367e-01\n",
      "  2.36320908e-01  8.94218878e-02  1.17815605e-02 -4.35519476e-01\n",
      " -3.95668027e-01  1.13747802e-01 -1.17861098e-01 -3.62192069e-02\n",
      "  2.06360149e-02  2.84143730e-01  8.91651270e-02 -7.19051866e-02\n",
      " -5.25712880e-02  2.51609919e-02  1.72291765e-01  1.29953348e-01\n",
      " -9.48788553e-02 -6.16559700e-02 -3.86490627e-02  1.07380737e-01\n",
      "  2.53834890e-01 -3.58415494e-01 -1.07533956e+00 -1.28551700e+00\n",
      "  3.08530896e-01  2.40261177e+00  1.98148586e-02  2.67138590e-01\n",
      " -4.39913203e-01 -9.02233535e-01  2.38252309e-01  1.33563007e-02\n",
      " -2.18471307e-02  1.27602778e-01  4.55458349e-01  3.57757661e-01\n",
      " -7.96848746e-02 -1.00743177e-01 -9.68860515e-02 -5.20778505e-02\n",
      " -9.44147878e-02  5.92059483e-01 -1.40747040e-01 -6.25035114e-01\n",
      " -3.16188987e-01  1.73129852e-01 -3.81036202e-02 -4.81549913e-02\n",
      " -6.48672170e-02 -6.51288295e-02 -4.35295629e-02 -6.52536496e-01\n",
      " -6.66740456e-01 -6.25534512e-01 -5.85859271e-01 -6.71668279e-01\n",
      " -6.28054685e-01 -6.47448214e-01 -6.34983454e-01 -6.13106977e-01\n",
      " -6.58749675e-01 -6.28079625e-01 -6.58593399e-01 -6.49676599e-01\n",
      " -6.16459313e-01 -6.18218939e-01  9.99825050e-02 -9.83791747e-01\n",
      " -9.93465409e-01  5.80518110e-01  8.31531408e-01  3.24551520e-01\n",
      " -6.40915678e-03 -3.16480743e-01 -1.57112799e-01  4.11437847e-01\n",
      " -2.27712159e-01 -5.66648945e-01 -3.98336808e-01 -3.89217153e-01\n",
      " -1.58430595e-01 -1.83066850e-01 -2.76405170e-01 -2.51260591e-01\n",
      " -2.55958643e-01 -2.70591060e-01  1.56031109e+00  9.07470074e-01\n",
      "  3.47497675e-01  3.22917055e-01  7.37064306e-01  6.27453716e-01\n",
      " -9.99279854e-02 -6.15813146e-01 -4.15631416e-01  3.47757062e-01\n",
      "  1.40815442e-01  1.54113192e-01  1.99619243e-01  1.96335138e-01\n",
      "  4.76019426e-02  1.44596014e-01  1.58902736e-01  1.80614540e-01\n",
      "  1.84226847e-01  8.23757770e-02  1.42435082e-01  1.44512177e-01\n",
      "  1.74165704e-01  2.00008475e-01  1.42432744e-01 -1.17426641e-01\n",
      " -4.31695955e-01  4.77135539e-02  9.91531369e-01  4.21565509e-01\n",
      "  4.25704671e-02 -2.42458474e-01 -3.35306233e-01  2.45488443e-02\n",
      "  9.64623625e-01 -9.99360567e-02  8.88233678e-03  1.41972084e-02\n",
      " -1.56829046e-01  9.19908017e-02 -4.46156977e-02 -6.93448855e-02\n",
      " -9.48877492e-02 -1.57357874e-01 -2.02926646e-01 -1.57209939e-01\n",
      " -9.11458362e-01 -6.12746312e-01  1.05009332e-01  6.72986243e-01\n",
      "  8.52834153e-02 -2.70799414e-01 -3.77899513e-01  5.54862015e-02\n",
      "  1.18827780e+00 -4.66715676e-01 -4.76583379e-01 -4.79752231e-01\n",
      " -4.80290386e-01 -4.30852464e-01 -4.71395679e-01 -4.77753575e-01\n",
      " -4.83560769e-01 -4.81281716e-01 -4.58041269e-01 -4.67472086e-01\n",
      " -4.74163549e-01 -4.79503031e-01 -4.84591154e-01 -4.50170870e-01\n",
      " -1.92489670e-02 -1.63632576e-01 -1.07199540e+00 -1.39742539e+00\n",
      " -6.23180597e-01 -7.91330392e-03 -3.44633154e-05 -1.87831740e-02\n",
      " -6.60923707e-02 -1.33116495e-01 -4.48230014e-01 -5.01533714e-01\n",
      " -5.02294231e-01 -4.54409912e-01 -2.49303458e-01 -1.78078129e-01\n",
      " -1.92124812e-01 -2.24509674e-01 -2.51493832e-01 -2.66784948e-01\n",
      " -7.37375927e-01 -6.84038953e-01 -7.45506759e-01 -4.94470274e-01\n",
      " -1.30407579e-02 -1.89463263e-02 -1.93544140e-02 -2.07669429e-02\n",
      " -1.93990441e-02 -4.10841954e-02 -4.15514886e-01 -4.21249881e-01\n",
      " -4.33655551e-01 -3.99748435e-01 -4.85610551e-01 -4.14920650e-01\n",
      " -4.20406328e-01 -4.21028703e-01 -4.21076700e-01 -4.71436809e-01\n",
      " -4.14609471e-01 -4.17426126e-01 -4.26874542e-01 -4.16243926e-01\n",
      " -4.44486302e-01  6.08671422e-01 -2.34519327e-01 -6.32921355e-01\n",
      "  1.30252757e+00  2.44179172e+00  6.09629866e-03  1.85286096e-01\n",
      " -4.90773025e-02 -3.07913560e-01  2.41655155e-01 -2.71568217e-01\n",
      " -2.53262898e-01 -2.41803450e-01 -1.69151920e-01 -6.75519812e-02\n",
      " -1.55312834e-01 -1.93824177e-01 -2.10095792e-01 -1.99859434e-01\n",
      " -2.31152041e-01  7.38032092e-01  2.01860346e-01 -1.06578623e-01\n",
      "  2.09612784e-02  3.84218862e-01 -4.58712514e-02  8.02728608e-01\n",
      " -3.23155164e-01 -7.26863880e-01  1.59926671e+00]\n"
     ]
    }
   ],
   "source": [
    "#Normalizising Features\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "train_data = (X_train - mean) / std\n",
    "test_data = (X_test - mean) / std\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d55d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "538450a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               376832    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,225\n",
      "Trainable params: 556,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Let's build an MLP model. Here, we'll use a Sequential model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, build_model, since we'll create a second model, later on.\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),  \n",
    "    keras.layers.Dense(1)\n",
    "  ], name=\"MLP_model\")\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc747a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "70/70 [==============================] - 2s 15ms/step - loss: 2506434.5000 - mae: 641.7710 - val_loss: 405801.9688 - val_mae: 287.2433\n",
      "Epoch 2/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 327392.1250 - mae: 261.1508 - val_loss: 290565.4062 - val_mae: 254.1807\n",
      "Epoch 3/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 244600.8281 - mae: 224.3152 - val_loss: 192398.2188 - val_mae: 202.4490\n",
      "Epoch 4/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 191932.3438 - mae: 202.4015 - val_loss: 520213.2188 - val_mae: 349.1631\n",
      "Epoch 5/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 213765.0312 - mae: 201.9070 - val_loss: 127942.1094 - val_mae: 188.8039\n",
      "Epoch 6/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 168329.5938 - mae: 188.2585 - val_loss: 380846.7500 - val_mae: 316.2718\n",
      "Epoch 7/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 180167.4531 - mae: 170.2370 - val_loss: 212394.5000 - val_mae: 218.1349\n",
      "Epoch 8/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 171584.0625 - mae: 171.4242 - val_loss: 42120.1055 - val_mae: 105.5382\n",
      "Epoch 9/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 115331.1016 - mae: 145.2372 - val_loss: 421193.5312 - val_mae: 333.3001\n",
      "Epoch 10/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 180025.2812 - mae: 179.0448 - val_loss: 355094.1250 - val_mae: 309.0223\n",
      "Epoch 11/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 137544.0938 - mae: 156.7449 - val_loss: 94801.3359 - val_mae: 153.3132\n",
      "Epoch 12/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 158912.6094 - mae: 169.1630 - val_loss: 36114.1953 - val_mae: 91.8902\n",
      "Epoch 13/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 142211.2656 - mae: 150.8723 - val_loss: 22534.8887 - val_mae: 75.0968\n",
      "Epoch 14/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 152831.8594 - mae: 164.8150 - val_loss: 44496.5703 - val_mae: 92.0931\n",
      "Epoch 15/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 132287.4375 - mae: 137.0687 - val_loss: 32557.2930 - val_mae: 86.5580\n",
      "Epoch 16/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 135813.6406 - mae: 151.4206 - val_loss: 47967.7812 - val_mae: 91.3571\n",
      "Epoch 17/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 124167.0000 - mae: 153.4262 - val_loss: 96100.0938 - val_mae: 148.5107\n",
      "Epoch 18/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 110968.3047 - mae: 139.8886 - val_loss: 67540.0625 - val_mae: 127.3861\n",
      "Epoch 19/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 114632.0078 - mae: 137.8704 - val_loss: 198732.4688 - val_mae: 213.4190\n",
      "Epoch 20/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 120667.7969 - mae: 147.3062 - val_loss: 139972.5312 - val_mae: 194.9719\n",
      "Epoch 21/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 121898.3828 - mae: 136.3807 - val_loss: 217560.3594 - val_mae: 241.3468\n",
      "Epoch 22/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 95488.1641 - mae: 120.7890 - val_loss: 29525.1992 - val_mae: 79.3857\n",
      "Epoch 23/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 116962.0469 - mae: 138.3538 - val_loss: 49316.5781 - val_mae: 105.5367\n",
      "Epoch 24/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 115408.2891 - mae: 137.3931 - val_loss: 43185.6953 - val_mae: 106.9452\n",
      "Epoch 25/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 120544.9922 - mae: 141.3804 - val_loss: 102734.9609 - val_mae: 161.0499\n",
      "Epoch 26/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 107427.4688 - mae: 138.7775 - val_loss: 33859.2305 - val_mae: 76.5859\n",
      "Epoch 27/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 104775.2266 - mae: 129.3769 - val_loss: 186830.5625 - val_mae: 182.1495\n",
      "Epoch 28/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 90886.3359 - mae: 115.3625 - val_loss: 95305.4844 - val_mae: 169.7223\n",
      "Epoch 29/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 102950.8359 - mae: 128.2748 - val_loss: 64213.4141 - val_mae: 124.0081\n",
      "Epoch 30/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 97266.1484 - mae: 128.0664 - val_loss: 35816.6094 - val_mae: 87.0541\n",
      "Epoch 31/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 90469.2500 - mae: 121.9242 - val_loss: 21297.3691 - val_mae: 69.1400\n",
      "Epoch 32/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 107141.6562 - mae: 131.8279 - val_loss: 22314.5332 - val_mae: 72.0870\n",
      "Epoch 33/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 107809.3203 - mae: 122.0180 - val_loss: 34531.3242 - val_mae: 80.4649\n",
      "Epoch 34/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 95203.9688 - mae: 125.8810 - val_loss: 122233.4062 - val_mae: 182.6025\n",
      "Epoch 35/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 90071.1484 - mae: 117.6180 - val_loss: 22628.9102 - val_mae: 76.5332\n",
      "Epoch 36/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 72944.7422 - mae: 106.8310 - val_loss: 10874.3779 - val_mae: 53.0464\n",
      "Epoch 37/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 86294.7969 - mae: 127.2947 - val_loss: 25564.4453 - val_mae: 74.9861\n",
      "Epoch 38/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 93459.1875 - mae: 124.0259 - val_loss: 35727.5039 - val_mae: 84.2754\n",
      "Epoch 39/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 72190.2578 - mae: 102.3602 - val_loss: 455158.2812 - val_mae: 347.3884\n",
      "Epoch 40/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 90345.3438 - mae: 114.6005 - val_loss: 61265.3398 - val_mae: 121.7165\n",
      "Epoch 41/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 81275.8828 - mae: 108.0510 - val_loss: 17268.7500 - val_mae: 61.0166\n",
      "Epoch 42/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 81221.2578 - mae: 115.3616 - val_loss: 188982.5938 - val_mae: 230.2151\n",
      "Epoch 43/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 84018.7812 - mae: 107.5573 - val_loss: 164152.9688 - val_mae: 214.9809\n",
      "Epoch 44/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 77316.3047 - mae: 109.8569 - val_loss: 18325.6016 - val_mae: 67.1527\n",
      "Epoch 45/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 76252.0859 - mae: 109.6412 - val_loss: 104131.2578 - val_mae: 156.5439\n",
      "Epoch 46/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 75283.4922 - mae: 106.9400 - val_loss: 30113.7520 - val_mae: 76.1758\n",
      "Epoch 47/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 57978.5742 - mae: 87.8727 - val_loss: 657940.0625 - val_mae: 429.5529\n",
      "Epoch 48/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 90563.4844 - mae: 121.1259 - val_loss: 189118.3438 - val_mae: 229.7656\n",
      "Epoch 49/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 65848.5938 - mae: 103.7097 - val_loss: 19211.1113 - val_mae: 71.2247\n",
      "Epoch 50/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 74103.2266 - mae: 109.2181 - val_loss: 93000.3594 - val_mae: 152.7145\n",
      "Epoch 51/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 75968.7812 - mae: 104.2192 - val_loss: 409472.4062 - val_mae: 345.3297\n",
      "Epoch 52/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 73529.2812 - mae: 102.9324 - val_loss: 353063.0938 - val_mae: 305.6517\n",
      "Epoch 53/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 69090.6016 - mae: 106.9573 - val_loss: 17806.1250 - val_mae: 59.8192\n",
      "Epoch 54/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 74984.9219 - mae: 100.3967 - val_loss: 15544.8066 - val_mae: 57.9278\n",
      "Epoch 55/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 78025.3672 - mae: 85.9616 - val_loss: 21015.6465 - val_mae: 71.4962\n",
      "Epoch 56/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 73310.1328 - mae: 97.7800 - val_loss: 28253.7441 - val_mae: 72.0801\n",
      "Epoch 57/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 63546.1445 - mae: 98.5090 - val_loss: 74960.2656 - val_mae: 134.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 68850.2656 - mae: 105.2954 - val_loss: 39156.9922 - val_mae: 93.1336\n",
      "Epoch 59/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 79689.9609 - mae: 107.2665 - val_loss: 63619.1680 - val_mae: 139.1268\n",
      "Epoch 60/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 64474.5312 - mae: 100.9038 - val_loss: 80676.3281 - val_mae: 150.0677\n",
      "Epoch 61/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 87213.1484 - mae: 109.4082 - val_loss: 24965.1719 - val_mae: 74.7488\n",
      "Epoch 62/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 53712.1680 - mae: 93.5342 - val_loss: 24745.1074 - val_mae: 77.9153\n",
      "Epoch 63/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 57076.1289 - mae: 98.7596 - val_loss: 25243.5977 - val_mae: 66.1904\n",
      "Epoch 64/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 60626.1797 - mae: 96.5652 - val_loss: 31447.6738 - val_mae: 87.8802\n",
      "Epoch 65/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 63291.4062 - mae: 103.5993 - val_loss: 13526.4492 - val_mae: 56.5526\n",
      "Epoch 66/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60335.4609 - mae: 104.8090 - val_loss: 35828.9414 - val_mae: 77.7213\n",
      "Epoch 67/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 56181.6719 - mae: 98.1460 - val_loss: 50648.3242 - val_mae: 117.4070\n",
      "Epoch 68/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60690.1094 - mae: 98.7898 - val_loss: 201609.6562 - val_mae: 226.7821\n",
      "Epoch 69/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 58396.0469 - mae: 100.8579 - val_loss: 26640.1543 - val_mae: 69.7147\n",
      "Epoch 70/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 56873.1445 - mae: 102.4874 - val_loss: 56003.2422 - val_mae: 103.9721\n",
      "Epoch 71/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 76342.4453 - mae: 112.6751 - val_loss: 19439.9668 - val_mae: 64.6750\n",
      "Epoch 72/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 58008.4492 - mae: 96.7132 - val_loss: 11568.3350 - val_mae: 52.2920\n",
      "Epoch 73/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 59464.0664 - mae: 91.8096 - val_loss: 29704.5723 - val_mae: 82.4349\n",
      "Epoch 74/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 56798.5859 - mae: 84.5376 - val_loss: 13315.5156 - val_mae: 51.3273\n",
      "Epoch 75/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60717.8008 - mae: 99.7076 - val_loss: 18211.6387 - val_mae: 64.8455\n",
      "Epoch 76/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 64465.3750 - mae: 98.4956 - val_loss: 19171.4180 - val_mae: 56.7365\n",
      "Epoch 77/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 53554.7500 - mae: 83.0214 - val_loss: 22341.8652 - val_mae: 61.8172\n",
      "Epoch 78/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 71715.0547 - mae: 109.9630 - val_loss: 13945.3867 - val_mae: 54.1584\n",
      "Epoch 79/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 46900.6602 - mae: 91.5887 - val_loss: 66722.2031 - val_mae: 130.0356\n",
      "Epoch 80/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 52775.2500 - mae: 95.7880 - val_loss: 746174.8750 - val_mae: 447.2228\n",
      "Epoch 81/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60951.9766 - mae: 87.8902 - val_loss: 77010.2422 - val_mae: 143.2303\n",
      "Epoch 82/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60667.2773 - mae: 100.3808 - val_loss: 24354.0449 - val_mae: 72.5064\n",
      "Epoch 83/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 48146.1484 - mae: 84.0080 - val_loss: 17280.9805 - val_mae: 57.6887\n",
      "Epoch 84/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 55014.4531 - mae: 89.0303 - val_loss: 14921.3193 - val_mae: 57.4516\n",
      "Epoch 85/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 57384.1328 - mae: 94.4052 - val_loss: 30880.1836 - val_mae: 70.4681\n",
      "Epoch 86/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 49942.0547 - mae: 88.5171 - val_loss: 26113.6973 - val_mae: 73.3662\n",
      "Epoch 87/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 59311.0664 - mae: 88.8847 - val_loss: 41980.7031 - val_mae: 99.3148\n",
      "Epoch 88/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 59384.9062 - mae: 85.9624 - val_loss: 15023.2070 - val_mae: 55.5733\n",
      "Epoch 89/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 60733.3633 - mae: 90.9734 - val_loss: 45751.8906 - val_mae: 106.8518\n",
      "Epoch 90/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 56289.1680 - mae: 93.0889 - val_loss: 17652.4023 - val_mae: 63.5263\n",
      "Epoch 91/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 47356.0352 - mae: 86.4208 - val_loss: 35154.0078 - val_mae: 80.5890\n",
      "Epoch 92/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 48978.1367 - mae: 91.6470 - val_loss: 171208.8906 - val_mae: 211.7515\n",
      "Epoch 93/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 51819.7227 - mae: 96.1639 - val_loss: 64912.7031 - val_mae: 124.7224\n",
      "Epoch 94/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 53031.3516 - mae: 90.0158 - val_loss: 40482.0391 - val_mae: 103.9429\n",
      "Epoch 95/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39483.6797 - mae: 82.3958 - val_loss: 108022.1953 - val_mae: 169.2560\n",
      "Epoch 96/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 54378.0352 - mae: 91.4932 - val_loss: 17085.3633 - val_mae: 56.2328\n",
      "Epoch 97/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 47196.9180 - mae: 82.0521 - val_loss: 49675.7227 - val_mae: 111.6773\n",
      "Epoch 98/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 49823.6289 - mae: 87.2329 - val_loss: 14929.6895 - val_mae: 55.2168\n",
      "Epoch 99/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 46507.0430 - mae: 82.3187 - val_loss: 497344.1875 - val_mae: 378.8185\n",
      "Epoch 100/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 49679.1953 - mae: 80.1294 - val_loss: 15469.3926 - val_mae: 60.4700\n",
      "Epoch 101/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 58577.0234 - mae: 94.1446 - val_loss: 45974.4844 - val_mae: 105.9373\n",
      "Epoch 102/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 33165.9102 - mae: 76.7610 - val_loss: 52553.1289 - val_mae: 113.5703\n",
      "Epoch 103/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 45137.4336 - mae: 82.1033 - val_loss: 18659.1406 - val_mae: 53.7383\n",
      "Epoch 104/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 42592.3242 - mae: 79.0732 - val_loss: 32654.7676 - val_mae: 84.1129\n",
      "Epoch 105/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39000.9766 - mae: 78.8241 - val_loss: 543412.4375 - val_mae: 385.1009\n",
      "Epoch 106/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39781.9297 - mae: 79.8779 - val_loss: 23852.7344 - val_mae: 69.4296\n",
      "Epoch 107/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40679.5625 - mae: 84.7443 - val_loss: 22619.9961 - val_mae: 68.6321\n",
      "Epoch 108/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 49496.5820 - mae: 87.4140 - val_loss: 31946.2109 - val_mae: 89.3029\n",
      "Epoch 109/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41446.0508 - mae: 80.8515 - val_loss: 16725.9570 - val_mae: 55.4114\n",
      "Epoch 110/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41596.1211 - mae: 75.6956 - val_loss: 46974.6680 - val_mae: 106.1888\n",
      "Epoch 111/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 46374.4492 - mae: 90.8500 - val_loss: 21278.7266 - val_mae: 59.2929\n",
      "Epoch 112/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39443.6328 - mae: 78.1334 - val_loss: 28809.7715 - val_mae: 69.3557\n",
      "Epoch 113/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 48026.1289 - mae: 83.3328 - val_loss: 14911.6035 - val_mae: 56.9053\n",
      "Epoch 114/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 44926.9961 - mae: 81.0159 - val_loss: 113311.5312 - val_mae: 173.4474\n",
      "Epoch 115/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39346.7852 - mae: 82.5591 - val_loss: 10480.4424 - val_mae: 49.4947\n",
      "Epoch 116/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40096.5430 - mae: 75.8217 - val_loss: 18299.3750 - val_mae: 60.9650\n",
      "Epoch 117/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40692.0039 - mae: 82.8965 - val_loss: 16295.1074 - val_mae: 52.6265\n",
      "Epoch 118/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 44004.1055 - mae: 78.9502 - val_loss: 12377.7910 - val_mae: 44.4362\n",
      "Epoch 119/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41555.3477 - mae: 83.7873 - val_loss: 13644.7490 - val_mae: 48.2091\n",
      "Epoch 120/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41169.6719 - mae: 84.0086 - val_loss: 210191.6406 - val_mae: 226.5859\n",
      "Epoch 121/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 36854.0625 - mae: 75.0872 - val_loss: 17569.1543 - val_mae: 54.9280\n",
      "Epoch 122/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 48117.6016 - mae: 86.3194 - val_loss: 24358.2617 - val_mae: 68.3856\n",
      "Epoch 123/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32383.7637 - mae: 68.0182 - val_loss: 103850.1250 - val_mae: 166.3235\n",
      "Epoch 124/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41694.5430 - mae: 80.5380 - val_loss: 29507.4375 - val_mae: 78.1921\n",
      "Epoch 125/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 42446.3828 - mae: 88.8901 - val_loss: 28132.2051 - val_mae: 81.4281\n",
      "Epoch 126/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 33563.1719 - mae: 73.2109 - val_loss: 18198.0566 - val_mae: 53.6565\n",
      "Epoch 127/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39074.1836 - mae: 80.8160 - val_loss: 19240.0996 - val_mae: 58.4372\n",
      "Epoch 128/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41121.7852 - mae: 78.1105 - val_loss: 12306.3301 - val_mae: 50.1782\n",
      "Epoch 129/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 36106.9961 - mae: 76.1868 - val_loss: 26015.8281 - val_mae: 64.6385\n",
      "Epoch 130/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39654.9102 - mae: 74.1940 - val_loss: 170386.5312 - val_mae: 224.4782\n",
      "Epoch 131/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 37834.1875 - mae: 73.2938 - val_loss: 17380.9922 - val_mae: 57.7519\n",
      "Epoch 132/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 33118.6484 - mae: 67.9804 - val_loss: 18916.8984 - val_mae: 64.1159\n",
      "Epoch 133/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 44873.6094 - mae: 80.8949 - val_loss: 18653.6621 - val_mae: 61.0956\n",
      "Epoch 134/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35599.0898 - mae: 70.8788 - val_loss: 132385.7500 - val_mae: 178.3843\n",
      "Epoch 135/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39440.5117 - mae: 74.3500 - val_loss: 73701.6641 - val_mae: 137.3555\n",
      "Epoch 136/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31945.4297 - mae: 72.1882 - val_loss: 29755.1484 - val_mae: 79.8906\n",
      "Epoch 137/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40183.7148 - mae: 80.2281 - val_loss: 20874.5977 - val_mae: 62.2935\n",
      "Epoch 138/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 46529.7969 - mae: 79.6451 - val_loss: 30161.8359 - val_mae: 83.8764\n",
      "Epoch 139/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 42135.9883 - mae: 78.2136 - val_loss: 22771.2734 - val_mae: 69.0533\n",
      "Epoch 140/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24108.8359 - mae: 63.7384 - val_loss: 162999.6719 - val_mae: 200.3772\n",
      "Epoch 141/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39880.2656 - mae: 84.7528 - val_loss: 15155.1953 - val_mae: 46.0635\n",
      "Epoch 142/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 37081.5898 - mae: 79.2532 - val_loss: 14648.8535 - val_mae: 48.8080\n",
      "Epoch 143/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27984.4668 - mae: 67.6199 - val_loss: 14958.1641 - val_mae: 53.4236\n",
      "Epoch 144/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 42981.9375 - mae: 74.0624 - val_loss: 16336.8066 - val_mae: 48.9375\n",
      "Epoch 145/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28799.5156 - mae: 73.6465 - val_loss: 22344.7891 - val_mae: 60.3100\n",
      "Epoch 146/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 41280.7891 - mae: 80.0802 - val_loss: 12493.7510 - val_mae: 46.1869\n",
      "Epoch 147/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40280.3867 - mae: 69.8613 - val_loss: 16903.3398 - val_mae: 50.5280\n",
      "Epoch 148/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 36757.8750 - mae: 77.6475 - val_loss: 34162.1367 - val_mae: 94.4975\n",
      "Epoch 149/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 33795.1797 - mae: 72.4931 - val_loss: 34327.3711 - val_mae: 80.4274\n",
      "Epoch 150/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35249.6367 - mae: 76.9289 - val_loss: 16186.5664 - val_mae: 50.2222\n",
      "Epoch 151/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 34070.0664 - mae: 72.3400 - val_loss: 25918.1406 - val_mae: 74.3938\n",
      "Epoch 152/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 37873.9336 - mae: 75.2700 - val_loss: 28440.7598 - val_mae: 79.8137\n",
      "Epoch 153/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30239.9277 - mae: 67.5078 - val_loss: 16112.1992 - val_mae: 46.7288\n",
      "Epoch 154/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40981.1406 - mae: 81.3623 - val_loss: 10490.1338 - val_mae: 39.4377\n",
      "Epoch 155/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30027.8027 - mae: 69.9126 - val_loss: 13464.4971 - val_mae: 47.4757\n",
      "Epoch 156/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35952.4727 - mae: 69.7104 - val_loss: 52569.4258 - val_mae: 114.5341\n",
      "Epoch 157/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 39305.3164 - mae: 79.3672 - val_loss: 11264.8135 - val_mae: 42.9948\n",
      "Epoch 158/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 38681.6211 - mae: 72.9416 - val_loss: 92733.6406 - val_mae: 148.1798\n",
      "Epoch 159/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 40874.0430 - mae: 78.1413 - val_loss: 131434.0156 - val_mae: 180.8532\n",
      "Epoch 160/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35495.1094 - mae: 79.9778 - val_loss: 16945.0059 - val_mae: 58.1680\n",
      "Epoch 161/500\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 31144.3594 - mae: 70.7532 - val_loss: 19170.3516 - val_mae: 54.4695\n",
      "Epoch 162/500\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 32855.7578 - mae: 70.8530 - val_loss: 16885.6406 - val_mae: 53.2226\n",
      "Epoch 163/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 29476.2246 - mae: 75.4278 - val_loss: 81032.2812 - val_mae: 137.2121\n",
      "Epoch 164/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 33136.5469 - mae: 67.1598 - val_loss: 16610.0605 - val_mae: 48.6763\n",
      "Epoch 165/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 36414.4609 - mae: 70.6678 - val_loss: 16452.2715 - val_mae: 61.5785\n",
      "Epoch 166/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35065.2422 - mae: 67.3532 - val_loss: 21704.6230 - val_mae: 64.2009\n",
      "Epoch 167/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26633.7227 - mae: 67.7704 - val_loss: 13161.6279 - val_mae: 49.3370\n",
      "Epoch 168/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31725.5332 - mae: 64.1363 - val_loss: 69960.8594 - val_mae: 135.3319\n",
      "Epoch 169/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32764.9785 - mae: 66.8558 - val_loss: 20670.6289 - val_mae: 69.1396\n",
      "Epoch 170/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 33309.4531 - mae: 72.7085 - val_loss: 18480.0020 - val_mae: 60.0799\n",
      "Epoch 171/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29943.4355 - mae: 76.1771 - val_loss: 143046.4219 - val_mae: 190.9994\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: 35575.3281 - mae: 80.0423 - val_loss: 38015.4492 - val_mae: 95.9189\n",
      "Epoch 173/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27348.6914 - mae: 63.9760 - val_loss: 14855.2891 - val_mae: 58.2481\n",
      "Epoch 174/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 34286.3555 - mae: 67.1507 - val_loss: 101649.1719 - val_mae: 170.2888\n",
      "Epoch 175/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28432.4824 - mae: 67.7793 - val_loss: 54420.6523 - val_mae: 127.2636\n",
      "Epoch 176/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31460.2715 - mae: 70.0457 - val_loss: 32356.2051 - val_mae: 97.6552\n",
      "Epoch 177/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29774.4766 - mae: 67.2649 - val_loss: 13694.9678 - val_mae: 46.2261\n",
      "Epoch 178/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30578.9238 - mae: 71.4919 - val_loss: 103928.9219 - val_mae: 155.4062\n",
      "Epoch 179/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32537.0215 - mae: 62.4661 - val_loss: 86873.4375 - val_mae: 154.6434\n",
      "Epoch 180/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 35884.6758 - mae: 70.2955 - val_loss: 13792.1816 - val_mae: 54.7474\n",
      "Epoch 181/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32740.4336 - mae: 70.5542 - val_loss: 34100.1133 - val_mae: 94.0303\n",
      "Epoch 182/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28166.2207 - mae: 67.5204 - val_loss: 17838.1035 - val_mae: 57.7122\n",
      "Epoch 183/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32641.1035 - mae: 62.7150 - val_loss: 71904.5469 - val_mae: 136.9581\n",
      "Epoch 184/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29429.1016 - mae: 63.1885 - val_loss: 13141.8184 - val_mae: 46.0538\n",
      "Epoch 185/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 34028.6758 - mae: 64.6518 - val_loss: 41296.7031 - val_mae: 94.2314\n",
      "Epoch 186/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 33757.8828 - mae: 70.7468 - val_loss: 11674.7324 - val_mae: 39.7922\n",
      "Epoch 187/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28312.1738 - mae: 59.3990 - val_loss: 10910.0439 - val_mae: 45.5675\n",
      "Epoch 188/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30549.9922 - mae: 70.1716 - val_loss: 31583.9648 - val_mae: 88.5576\n",
      "Epoch 189/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28291.4375 - mae: 64.8209 - val_loss: 19552.5762 - val_mae: 49.8750\n",
      "Epoch 190/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25200.9414 - mae: 63.2055 - val_loss: 12706.7188 - val_mae: 44.7774\n",
      "Epoch 191/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31268.3477 - mae: 67.6972 - val_loss: 11073.0664 - val_mae: 41.1450\n",
      "Epoch 192/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23759.7070 - mae: 65.0849 - val_loss: 335877.3125 - val_mae: 304.1398\n",
      "Epoch 193/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30991.8203 - mae: 58.9318 - val_loss: 9919.2588 - val_mae: 41.8149\n",
      "Epoch 194/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29978.8867 - mae: 67.7114 - val_loss: 18075.5215 - val_mae: 55.0515\n",
      "Epoch 195/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26763.8848 - mae: 68.7295 - val_loss: 106606.1172 - val_mae: 178.9857\n",
      "Epoch 196/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30002.5820 - mae: 64.6983 - val_loss: 33023.8164 - val_mae: 88.7528\n",
      "Epoch 197/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23001.1387 - mae: 59.6660 - val_loss: 109635.8203 - val_mae: 167.8530\n",
      "Epoch 198/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30438.4121 - mae: 63.9227 - val_loss: 72539.5703 - val_mae: 128.6784\n",
      "Epoch 199/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30028.7891 - mae: 71.0213 - val_loss: 31033.3945 - val_mae: 75.9563\n",
      "Epoch 200/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25751.9023 - mae: 61.5059 - val_loss: 25366.2168 - val_mae: 64.8507\n",
      "Epoch 201/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30767.5371 - mae: 67.1716 - val_loss: 25509.3887 - val_mae: 68.5732\n",
      "Epoch 202/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25335.3965 - mae: 60.4846 - val_loss: 52909.2695 - val_mae: 114.4448\n",
      "Epoch 203/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28211.1562 - mae: 70.1987 - val_loss: 203416.2344 - val_mae: 228.5817\n",
      "Epoch 204/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28041.3945 - mae: 62.1935 - val_loss: 38157.4883 - val_mae: 99.6642\n",
      "Epoch 205/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 32941.4336 - mae: 73.6820 - val_loss: 27825.2285 - val_mae: 72.3413\n",
      "Epoch 206/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 23827.6582 - mae: 61.0157 - val_loss: 12040.7246 - val_mae: 44.6814\n",
      "Epoch 207/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31494.0820 - mae: 70.8590 - val_loss: 12976.0273 - val_mae: 50.9301\n",
      "Epoch 208/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25013.5703 - mae: 65.7740 - val_loss: 11328.4336 - val_mae: 40.9787\n",
      "Epoch 209/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31173.1543 - mae: 69.5903 - val_loss: 10564.2666 - val_mae: 42.1074\n",
      "Epoch 210/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23598.6582 - mae: 65.9021 - val_loss: 73869.8828 - val_mae: 136.7151\n",
      "Epoch 211/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26121.0371 - mae: 64.1672 - val_loss: 18677.5195 - val_mae: 58.8934\n",
      "Epoch 212/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25625.3652 - mae: 60.4464 - val_loss: 13709.5557 - val_mae: 56.1714\n",
      "Epoch 213/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 28032.5156 - mae: 63.0588 - val_loss: 11455.3311 - val_mae: 45.4195\n",
      "Epoch 214/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21326.6641 - mae: 58.5363 - val_loss: 26253.1406 - val_mae: 72.6194\n",
      "Epoch 215/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 30201.5195 - mae: 67.9570 - val_loss: 10598.2949 - val_mae: 43.5929\n",
      "Epoch 216/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 27498.4961 - mae: 61.8802 - val_loss: 11677.3672 - val_mae: 41.8514\n",
      "Epoch 217/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 21642.9727 - mae: 60.2859 - val_loss: 25086.3262 - val_mae: 69.4547\n",
      "Epoch 218/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25991.0117 - mae: 63.1857 - val_loss: 66027.9688 - val_mae: 127.0441\n",
      "Epoch 219/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29484.2383 - mae: 63.3773 - val_loss: 12121.6562 - val_mae: 42.0535\n",
      "Epoch 220/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23958.4238 - mae: 64.5567 - val_loss: 16619.5547 - val_mae: 51.1510\n",
      "Epoch 221/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23825.2598 - mae: 62.8383 - val_loss: 16246.4141 - val_mae: 47.9194\n",
      "Epoch 222/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 27304.7578 - mae: 65.8230 - val_loss: 22840.1621 - val_mae: 81.9021\n",
      "Epoch 223/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32416.6602 - mae: 77.7369 - val_loss: 24309.3691 - val_mae: 69.4005\n",
      "Epoch 224/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29787.3809 - mae: 65.0072 - val_loss: 16968.6523 - val_mae: 53.4987\n",
      "Epoch 225/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23349.4805 - mae: 58.0451 - val_loss: 20405.7012 - val_mae: 71.7889\n",
      "Epoch 226/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21847.7578 - mae: 60.2785 - val_loss: 115596.8203 - val_mae: 175.0653\n",
      "Epoch 227/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 29641.7480 - mae: 71.7431 - val_loss: 18775.6270 - val_mae: 45.5653\n",
      "Epoch 228/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25038.8145 - mae: 64.4001 - val_loss: 16105.9746 - val_mae: 56.2930\n",
      "Epoch 229/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25768.9570 - mae: 61.7019 - val_loss: 15063.1934 - val_mae: 48.0823\n",
      "Epoch 230/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26902.5312 - mae: 68.0639 - val_loss: 20709.7168 - val_mae: 58.9423\n",
      "Epoch 231/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23434.2852 - mae: 60.7110 - val_loss: 14833.4580 - val_mae: 45.5809\n",
      "Epoch 232/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21415.9434 - mae: 62.0914 - val_loss: 23133.5664 - val_mae: 67.5367\n",
      "Epoch 233/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27850.3203 - mae: 61.2779 - val_loss: 11698.9072 - val_mae: 41.0821\n",
      "Epoch 234/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20732.4062 - mae: 59.3609 - val_loss: 238299.9688 - val_mae: 246.2694\n",
      "Epoch 235/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31055.4082 - mae: 65.2942 - val_loss: 75514.9141 - val_mae: 145.0837\n",
      "Epoch 236/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20010.3906 - mae: 55.1043 - val_loss: 17164.4277 - val_mae: 55.0571\n",
      "Epoch 237/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27177.6367 - mae: 61.3741 - val_loss: 13307.2539 - val_mae: 48.6148\n",
      "Epoch 238/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22216.4316 - mae: 56.4713 - val_loss: 15619.3906 - val_mae: 44.8786\n",
      "Epoch 239/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 31129.3145 - mae: 70.3827 - val_loss: 17447.6328 - val_mae: 57.6087\n",
      "Epoch 240/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22068.6562 - mae: 59.2724 - val_loss: 10270.3711 - val_mae: 43.0881\n",
      "Epoch 241/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 20148.1406 - mae: 58.1821 - val_loss: 20311.4453 - val_mae: 61.4801\n",
      "Epoch 242/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27274.0352 - mae: 68.9823 - val_loss: 15896.2275 - val_mae: 52.2147\n",
      "Epoch 243/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23720.6934 - mae: 65.2037 - val_loss: 12345.8223 - val_mae: 47.6005\n",
      "Epoch 244/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24268.6211 - mae: 61.3308 - val_loss: 11058.4443 - val_mae: 44.6191\n",
      "Epoch 245/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23901.5488 - mae: 61.5319 - val_loss: 90937.3438 - val_mae: 157.3152\n",
      "Epoch 246/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24495.8398 - mae: 55.4067 - val_loss: 53143.1641 - val_mae: 116.6616\n",
      "Epoch 247/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 32344.6484 - mae: 64.9993 - val_loss: 12591.3330 - val_mae: 42.5461\n",
      "Epoch 248/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18516.8750 - mae: 52.2464 - val_loss: 14182.2773 - val_mae: 42.1883\n",
      "Epoch 249/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25048.9434 - mae: 61.7409 - val_loss: 82510.4297 - val_mae: 149.6357\n",
      "Epoch 250/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20825.5449 - mae: 53.2441 - val_loss: 44240.9727 - val_mae: 96.6861\n",
      "Epoch 251/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23914.0488 - mae: 62.2725 - val_loss: 42620.8438 - val_mae: 100.2085\n",
      "Epoch 252/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24494.9316 - mae: 61.6061 - val_loss: 16412.3457 - val_mae: 47.2900\n",
      "Epoch 253/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20013.9473 - mae: 55.3733 - val_loss: 18795.3613 - val_mae: 57.4478\n",
      "Epoch 254/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26110.8418 - mae: 64.8846 - val_loss: 88017.0312 - val_mae: 136.7390\n",
      "Epoch 255/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21350.7285 - mae: 61.9282 - val_loss: 26256.7598 - val_mae: 73.5086\n",
      "Epoch 256/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25796.7988 - mae: 57.1433 - val_loss: 17830.3770 - val_mae: 48.8148\n",
      "Epoch 257/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22345.8262 - mae: 58.9596 - val_loss: 47552.9062 - val_mae: 104.4548\n",
      "Epoch 258/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24824.0977 - mae: 58.2642 - val_loss: 51380.9727 - val_mae: 104.1248\n",
      "Epoch 259/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24988.4844 - mae: 58.5733 - val_loss: 183057.9375 - val_mae: 213.5361\n",
      "Epoch 260/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20176.4883 - mae: 55.2715 - val_loss: 29505.8887 - val_mae: 68.3837\n",
      "Epoch 261/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19116.7812 - mae: 53.2339 - val_loss: 44569.8203 - val_mae: 96.2910\n",
      "Epoch 262/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25262.4414 - mae: 59.2081 - val_loss: 19151.7070 - val_mae: 53.7599\n",
      "Epoch 263/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24155.4258 - mae: 62.5037 - val_loss: 30159.7344 - val_mae: 75.9177\n",
      "Epoch 264/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18265.2305 - mae: 54.4942 - val_loss: 16063.7100 - val_mae: 49.4621\n",
      "Epoch 265/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22079.7715 - mae: 53.2150 - val_loss: 10713.0117 - val_mae: 39.2208\n",
      "Epoch 266/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22347.3633 - mae: 59.3298 - val_loss: 15003.6162 - val_mae: 46.2487\n",
      "Epoch 267/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21429.5410 - mae: 57.1253 - val_loss: 16408.0918 - val_mae: 42.9150\n",
      "Epoch 268/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21723.2031 - mae: 57.1101 - val_loss: 25823.6875 - val_mae: 70.3249\n",
      "Epoch 269/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21460.2754 - mae: 56.7289 - val_loss: 112086.3047 - val_mae: 165.1929\n",
      "Epoch 270/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21779.1055 - mae: 61.4037 - val_loss: 15698.0684 - val_mae: 43.1401\n",
      "Epoch 271/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21467.1484 - mae: 58.9786 - val_loss: 24122.4727 - val_mae: 62.4282\n",
      "Epoch 272/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 26796.4141 - mae: 65.7383 - val_loss: 37468.2383 - val_mae: 90.1455\n",
      "Epoch 273/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22417.9375 - mae: 57.0678 - val_loss: 13941.8076 - val_mae: 41.9029\n",
      "Epoch 274/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22662.7773 - mae: 58.9566 - val_loss: 17054.1816 - val_mae: 48.3304\n",
      "Epoch 275/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17952.3516 - mae: 53.2973 - val_loss: 24696.7637 - val_mae: 69.5140\n",
      "Epoch 276/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22080.0723 - mae: 53.9593 - val_loss: 14926.9414 - val_mae: 53.4248\n",
      "Epoch 277/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 24376.2188 - mae: 60.1191 - val_loss: 36770.0859 - val_mae: 74.6059\n",
      "Epoch 278/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21886.1680 - mae: 56.2630 - val_loss: 52461.4648 - val_mae: 105.0031\n",
      "Epoch 279/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22009.2266 - mae: 58.8793 - val_loss: 21145.0801 - val_mae: 52.6825\n",
      "Epoch 280/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25426.8887 - mae: 61.0303 - val_loss: 76327.2812 - val_mae: 139.5365\n",
      "Epoch 281/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18654.7344 - mae: 54.9448 - val_loss: 20752.0059 - val_mae: 56.8948\n",
      "Epoch 282/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19454.1328 - mae: 55.8026 - val_loss: 108355.3750 - val_mae: 161.5606\n",
      "Epoch 283/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23605.5898 - mae: 58.4924 - val_loss: 52234.1367 - val_mae: 113.2077\n",
      "Epoch 284/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22350.0234 - mae: 53.2407 - val_loss: 89859.5469 - val_mae: 141.3053\n",
      "Epoch 285/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19711.1309 - mae: 58.5760 - val_loss: 18154.1582 - val_mae: 49.0023\n",
      "Epoch 286/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: 20027.3242 - mae: 57.1699 - val_loss: 15459.8027 - val_mae: 57.0770\n",
      "Epoch 287/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 27842.3262 - mae: 58.2519 - val_loss: 13535.8848 - val_mae: 45.1570\n",
      "Epoch 288/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18538.2109 - mae: 54.2299 - val_loss: 15525.9834 - val_mae: 46.7902\n",
      "Epoch 289/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23714.9336 - mae: 55.9896 - val_loss: 15575.8623 - val_mae: 49.2292\n",
      "Epoch 290/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19428.9961 - mae: 58.0317 - val_loss: 19225.8418 - val_mae: 51.3423\n",
      "Epoch 291/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23730.2969 - mae: 54.8227 - val_loss: 19253.3281 - val_mae: 61.1773\n",
      "Epoch 292/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22403.9453 - mae: 52.9228 - val_loss: 73738.6641 - val_mae: 133.2319\n",
      "Epoch 293/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25691.9082 - mae: 61.7069 - val_loss: 14962.7051 - val_mae: 45.9018\n",
      "Epoch 294/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17235.3633 - mae: 47.9235 - val_loss: 49234.7266 - val_mae: 102.8576\n",
      "Epoch 295/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25015.7012 - mae: 56.4771 - val_loss: 148878.7031 - val_mae: 199.4366\n",
      "Epoch 296/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18487.2480 - mae: 53.4454 - val_loss: 12533.9033 - val_mae: 42.6009\n",
      "Epoch 297/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18488.2402 - mae: 51.9101 - val_loss: 18723.9668 - val_mae: 49.7427\n",
      "Epoch 298/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19619.6465 - mae: 53.3852 - val_loss: 12462.3887 - val_mae: 42.4258\n",
      "Epoch 299/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21541.3535 - mae: 52.4116 - val_loss: 13225.2793 - val_mae: 42.9001\n",
      "Epoch 300/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19233.2168 - mae: 51.4796 - val_loss: 17615.2871 - val_mae: 64.8932\n",
      "Epoch 301/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18861.1250 - mae: 53.4543 - val_loss: 17306.5000 - val_mae: 62.0105\n",
      "Epoch 302/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21862.4844 - mae: 53.1693 - val_loss: 32432.5801 - val_mae: 89.5502\n",
      "Epoch 303/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22078.0957 - mae: 52.9566 - val_loss: 12661.8301 - val_mae: 41.5668\n",
      "Epoch 304/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18092.3086 - mae: 52.2392 - val_loss: 9921.4072 - val_mae: 40.4587\n",
      "Epoch 305/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22497.6465 - mae: 60.4317 - val_loss: 14942.2764 - val_mae: 47.8099\n",
      "Epoch 306/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25982.3027 - mae: 51.8747 - val_loss: 12313.0801 - val_mae: 42.3094\n",
      "Epoch 307/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19265.0098 - mae: 57.1916 - val_loss: 27353.5547 - val_mae: 81.0252\n",
      "Epoch 308/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 23814.2070 - mae: 56.4019 - val_loss: 11881.7139 - val_mae: 41.0224\n",
      "Epoch 309/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18850.3379 - mae: 55.2437 - val_loss: 30011.1680 - val_mae: 67.1815\n",
      "Epoch 310/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21269.3418 - mae: 54.1994 - val_loss: 14932.3350 - val_mae: 46.8857\n",
      "Epoch 311/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18075.8145 - mae: 49.5489 - val_loss: 23799.5000 - val_mae: 65.1405\n",
      "Epoch 312/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17612.0215 - mae: 48.3877 - val_loss: 26993.4062 - val_mae: 78.7870\n",
      "Epoch 313/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22419.2930 - mae: 54.2069 - val_loss: 31718.4121 - val_mae: 84.0749\n",
      "Epoch 314/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 22326.1035 - mae: 53.9659 - val_loss: 11773.2666 - val_mae: 39.3438\n",
      "Epoch 315/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 25277.9023 - mae: 62.9938 - val_loss: 14934.3926 - val_mae: 44.3568\n",
      "Epoch 316/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14757.1631 - mae: 47.4202 - val_loss: 33109.3984 - val_mae: 93.0124\n",
      "Epoch 317/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20271.8223 - mae: 51.4028 - val_loss: 13947.8066 - val_mae: 46.0040\n",
      "Epoch 318/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19148.9141 - mae: 52.5678 - val_loss: 11982.0225 - val_mae: 41.2001\n",
      "Epoch 319/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19236.9375 - mae: 49.9397 - val_loss: 17428.2246 - val_mae: 58.6958\n",
      "Epoch 320/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19335.9375 - mae: 55.3288 - val_loss: 12377.0410 - val_mae: 42.4562\n",
      "Epoch 321/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19613.6055 - mae: 57.1483 - val_loss: 43604.5117 - val_mae: 94.8360\n",
      "Epoch 322/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15719.2344 - mae: 45.3981 - val_loss: 13564.9492 - val_mae: 48.5625\n",
      "Epoch 323/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18735.6504 - mae: 54.0426 - val_loss: 19947.8984 - val_mae: 57.7355\n",
      "Epoch 324/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20910.3691 - mae: 47.9126 - val_loss: 11129.9355 - val_mae: 39.3743\n",
      "Epoch 325/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21977.6895 - mae: 58.2994 - val_loss: 14184.5420 - val_mae: 43.3978\n",
      "Epoch 326/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16516.3203 - mae: 52.6311 - val_loss: 85136.1641 - val_mae: 145.5815\n",
      "Epoch 327/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21991.2539 - mae: 59.8619 - val_loss: 10744.8789 - val_mae: 47.9943\n",
      "Epoch 328/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16791.1777 - mae: 51.1992 - val_loss: 14473.1631 - val_mae: 48.6458\n",
      "Epoch 329/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 16087.7988 - mae: 49.3329 - val_loss: 12483.4834 - val_mae: 46.4748\n",
      "Epoch 330/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 20875.5625 - mae: 52.7677 - val_loss: 179665.1875 - val_mae: 215.3074\n",
      "Epoch 331/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19300.4609 - mae: 51.8428 - val_loss: 28836.0918 - val_mae: 75.3846\n",
      "Epoch 332/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16246.1377 - mae: 51.9250 - val_loss: 20603.2051 - val_mae: 60.6266\n",
      "Epoch 333/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21021.6621 - mae: 49.1406 - val_loss: 14722.0830 - val_mae: 49.7477\n",
      "Epoch 334/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16241.1631 - mae: 56.5671 - val_loss: 16302.9082 - val_mae: 55.1838\n",
      "Epoch 335/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16856.5898 - mae: 49.0007 - val_loss: 11029.8174 - val_mae: 39.1552\n",
      "Epoch 336/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19141.3418 - mae: 51.3853 - val_loss: 14574.2051 - val_mae: 43.1219\n",
      "Epoch 337/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17630.0684 - mae: 46.1821 - val_loss: 11964.5381 - val_mae: 43.3685\n",
      "Epoch 338/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16052.8643 - mae: 52.6900 - val_loss: 12337.6953 - val_mae: 47.1699\n",
      "Epoch 339/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19978.0508 - mae: 52.2342 - val_loss: 15999.7256 - val_mae: 51.1262\n",
      "Epoch 340/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21591.7285 - mae: 56.3157 - val_loss: 54607.2461 - val_mae: 122.4276\n",
      "Epoch 341/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18868.2129 - mae: 55.4771 - val_loss: 74428.1484 - val_mae: 138.6373\n",
      "Epoch 342/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18274.4805 - mae: 54.0021 - val_loss: 28238.3340 - val_mae: 78.8538\n",
      "Epoch 343/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18249.1172 - mae: 55.7243 - val_loss: 12282.9727 - val_mae: 42.4920\n",
      "Epoch 344/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18501.4883 - mae: 52.7831 - val_loss: 92356.8047 - val_mae: 150.3778\n",
      "Epoch 345/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17863.5547 - mae: 54.7386 - val_loss: 12824.1797 - val_mae: 41.9377\n",
      "Epoch 346/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20824.5293 - mae: 52.1910 - val_loss: 57159.1406 - val_mae: 117.3135\n",
      "Epoch 347/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17403.3223 - mae: 48.7322 - val_loss: 10878.1611 - val_mae: 41.4037\n",
      "Epoch 348/500\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 16655.7598 - mae: 47.4977 - val_loss: 14641.1914 - val_mae: 48.3698\n",
      "Epoch 349/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18123.2285 - mae: 44.0847 - val_loss: 18438.8730 - val_mae: 49.9026\n",
      "Epoch 350/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14046.5117 - mae: 46.5273 - val_loss: 19347.0215 - val_mae: 64.6049\n",
      "Epoch 351/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17527.8594 - mae: 50.6598 - val_loss: 17335.9746 - val_mae: 56.6458\n",
      "Epoch 352/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16018.2236 - mae: 51.0527 - val_loss: 200930.3906 - val_mae: 232.2174\n",
      "Epoch 353/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20665.3672 - mae: 51.4081 - val_loss: 14560.1973 - val_mae: 42.9229\n",
      "Epoch 354/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18569.8262 - mae: 46.8155 - val_loss: 21599.2930 - val_mae: 54.4161\n",
      "Epoch 355/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18791.8789 - mae: 53.9101 - val_loss: 11723.5205 - val_mae: 44.0189\n",
      "Epoch 356/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14071.4512 - mae: 47.2589 - val_loss: 12846.2344 - val_mae: 46.9646\n",
      "Epoch 357/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19107.8145 - mae: 53.6773 - val_loss: 12566.6699 - val_mae: 42.2802\n",
      "Epoch 358/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 13571.7295 - mae: 47.0878 - val_loss: 123634.8672 - val_mae: 188.1469\n",
      "Epoch 359/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 18533.5312 - mae: 53.0735 - val_loss: 10065.7568 - val_mae: 40.9869\n",
      "Epoch 360/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 18044.0918 - mae: 53.0394 - val_loss: 16212.9590 - val_mae: 56.9467\n",
      "Epoch 361/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17026.7832 - mae: 51.6742 - val_loss: 13050.6748 - val_mae: 45.7188\n",
      "Epoch 362/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18409.3652 - mae: 53.9892 - val_loss: 16451.8359 - val_mae: 58.8388\n",
      "Epoch 363/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 14558.9414 - mae: 48.0738 - val_loss: 20898.3438 - val_mae: 68.9169\n",
      "Epoch 364/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16354.1270 - mae: 48.1787 - val_loss: 10284.9961 - val_mae: 44.6618\n",
      "Epoch 365/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19922.0312 - mae: 58.4051 - val_loss: 14128.2441 - val_mae: 48.6070\n",
      "Epoch 366/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15111.1885 - mae: 43.8780 - val_loss: 11614.2598 - val_mae: 44.4064\n",
      "Epoch 367/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16406.1367 - mae: 54.5827 - val_loss: 20732.6230 - val_mae: 64.8361\n",
      "Epoch 368/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16615.2969 - mae: 47.0656 - val_loss: 28839.6309 - val_mae: 84.3734\n",
      "Epoch 369/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14550.8438 - mae: 50.0251 - val_loss: 54602.5508 - val_mae: 120.8596\n",
      "Epoch 370/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17050.0293 - mae: 48.7978 - val_loss: 13203.6279 - val_mae: 46.8639\n",
      "Epoch 371/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19975.3281 - mae: 52.9057 - val_loss: 13976.8311 - val_mae: 44.2517\n",
      "Epoch 372/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19025.9570 - mae: 50.9891 - val_loss: 11305.0029 - val_mae: 39.9015\n",
      "Epoch 373/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15335.5645 - mae: 49.5479 - val_loss: 13340.4092 - val_mae: 41.5000\n",
      "Epoch 374/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18176.2891 - mae: 44.3251 - val_loss: 12738.6143 - val_mae: 41.5895\n",
      "Epoch 375/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18172.2773 - mae: 51.2059 - val_loss: 26978.3945 - val_mae: 70.1255\n",
      "Epoch 376/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14395.0986 - mae: 46.2702 - val_loss: 13554.5928 - val_mae: 41.1599\n",
      "Epoch 377/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15829.8047 - mae: 51.2783 - val_loss: 14467.8379 - val_mae: 44.8118\n",
      "Epoch 378/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14863.6582 - mae: 51.0235 - val_loss: 16315.8535 - val_mae: 49.7242\n",
      "Epoch 379/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18894.7500 - mae: 50.9874 - val_loss: 14510.2373 - val_mae: 46.7589\n",
      "Epoch 380/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15784.6240 - mae: 48.2990 - val_loss: 19300.6484 - val_mae: 53.4722\n",
      "Epoch 381/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 20238.2559 - mae: 55.8819 - val_loss: 31263.1797 - val_mae: 81.8592\n",
      "Epoch 382/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13172.2900 - mae: 49.2219 - val_loss: 45083.1094 - val_mae: 111.1097\n",
      "Epoch 383/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18624.1250 - mae: 51.5924 - val_loss: 38943.5508 - val_mae: 87.5444\n",
      "Epoch 384/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17629.0098 - mae: 50.0741 - val_loss: 15099.8330 - val_mae: 53.2037\n",
      "Epoch 385/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16517.5488 - mae: 46.0963 - val_loss: 13307.0703 - val_mae: 45.2532\n",
      "Epoch 386/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 21109.8438 - mae: 52.5442 - val_loss: 25603.5977 - val_mae: 80.6216\n",
      "Epoch 387/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14202.8340 - mae: 43.3828 - val_loss: 148794.1562 - val_mae: 194.9872\n",
      "Epoch 388/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 18825.9746 - mae: 52.2111 - val_loss: 38015.8906 - val_mae: 93.9045\n",
      "Epoch 389/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12823.9297 - mae: 44.9846 - val_loss: 13430.2178 - val_mae: 40.5059\n",
      "Epoch 390/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19569.4492 - mae: 51.5618 - val_loss: 12979.3174 - val_mae: 42.7177\n",
      "Epoch 391/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15790.5791 - mae: 45.9084 - val_loss: 15047.6455 - val_mae: 47.0531\n",
      "Epoch 392/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15076.0918 - mae: 49.0700 - val_loss: 22450.2012 - val_mae: 72.5511\n",
      "Epoch 393/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15338.7148 - mae: 51.3359 - val_loss: 29334.1426 - val_mae: 74.8101\n",
      "Epoch 394/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16397.5508 - mae: 49.9917 - val_loss: 230211.9688 - val_mae: 248.0090\n",
      "Epoch 395/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17037.5234 - mae: 46.8105 - val_loss: 11346.0117 - val_mae: 39.5713\n",
      "Epoch 396/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17512.8145 - mae: 55.0179 - val_loss: 18553.9941 - val_mae: 63.5945\n",
      "Epoch 397/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19257.3398 - mae: 50.7743 - val_loss: 53067.2578 - val_mae: 107.7060\n",
      "Epoch 398/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17957.1406 - mae: 43.7671 - val_loss: 22541.4531 - val_mae: 60.0250\n",
      "Epoch 399/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16206.8672 - mae: 46.6265 - val_loss: 22091.4844 - val_mae: 65.9960\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: 17273.0371 - mae: 51.7343 - val_loss: 10597.2588 - val_mae: 39.4863\n",
      "Epoch 401/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15540.0342 - mae: 47.4964 - val_loss: 90053.1484 - val_mae: 150.3379\n",
      "Epoch 402/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15713.3066 - mae: 47.0682 - val_loss: 20214.0000 - val_mae: 69.1206\n",
      "Epoch 403/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15057.9102 - mae: 47.7850 - val_loss: 18077.2715 - val_mae: 49.4493\n",
      "Epoch 404/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16493.3848 - mae: 48.8632 - val_loss: 161068.0469 - val_mae: 203.7448\n",
      "Epoch 405/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15593.7295 - mae: 49.8913 - val_loss: 66446.9375 - val_mae: 122.4259\n",
      "Epoch 406/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15339.3838 - mae: 43.5729 - val_loss: 11822.2061 - val_mae: 42.1304\n",
      "Epoch 407/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16883.0566 - mae: 47.0432 - val_loss: 17037.7559 - val_mae: 56.5465\n",
      "Epoch 408/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17078.5000 - mae: 54.1102 - val_loss: 27635.2754 - val_mae: 77.7611\n",
      "Epoch 409/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14567.9473 - mae: 49.0280 - val_loss: 21955.9941 - val_mae: 73.8437\n",
      "Epoch 410/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15408.4141 - mae: 49.1812 - val_loss: 12756.4619 - val_mae: 40.5662\n",
      "Epoch 411/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16647.6250 - mae: 48.4092 - val_loss: 10728.8389 - val_mae: 43.4285\n",
      "Epoch 412/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 19640.3184 - mae: 49.2966 - val_loss: 13933.7119 - val_mae: 49.2665\n",
      "Epoch 413/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14580.8643 - mae: 46.0409 - val_loss: 12366.5029 - val_mae: 46.0109\n",
      "Epoch 414/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16310.8096 - mae: 44.9170 - val_loss: 14622.7656 - val_mae: 44.3892\n",
      "Epoch 415/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14016.1699 - mae: 49.3426 - val_loss: 27720.4102 - val_mae: 71.2655\n",
      "Epoch 416/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15659.2764 - mae: 50.7284 - val_loss: 14190.7080 - val_mae: 46.8006\n",
      "Epoch 417/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16248.0752 - mae: 46.4243 - val_loss: 40605.2266 - val_mae: 101.7308\n",
      "Epoch 418/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16274.9189 - mae: 51.9472 - val_loss: 15390.7637 - val_mae: 47.5906\n",
      "Epoch 419/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16548.3164 - mae: 49.4774 - val_loss: 10590.0400 - val_mae: 40.1811\n",
      "Epoch 420/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15190.9873 - mae: 45.5380 - val_loss: 10326.4414 - val_mae: 39.8550\n",
      "Epoch 421/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15579.4248 - mae: 45.6261 - val_loss: 14192.7793 - val_mae: 46.7442\n",
      "Epoch 422/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14360.7168 - mae: 46.6492 - val_loss: 12023.9609 - val_mae: 40.1015\n",
      "Epoch 423/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15184.9834 - mae: 50.0169 - val_loss: 10220.8838 - val_mae: 39.4897\n",
      "Epoch 424/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15429.4834 - mae: 47.0270 - val_loss: 13987.5020 - val_mae: 48.6230\n",
      "Epoch 425/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13504.8174 - mae: 46.7078 - val_loss: 12673.8037 - val_mae: 46.7002\n",
      "Epoch 426/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16774.9707 - mae: 48.9563 - val_loss: 13551.3828 - val_mae: 46.4433\n",
      "Epoch 427/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16367.8965 - mae: 49.0658 - val_loss: 21510.2070 - val_mae: 70.7949\n",
      "Epoch 428/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15267.7988 - mae: 50.6004 - val_loss: 14383.6113 - val_mae: 45.9155\n",
      "Epoch 429/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13065.0361 - mae: 43.4864 - val_loss: 12114.5498 - val_mae: 43.2190\n",
      "Epoch 430/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16641.5645 - mae: 46.8853 - val_loss: 75191.0078 - val_mae: 127.8762\n",
      "Epoch 431/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14510.9893 - mae: 46.3697 - val_loss: 10838.2832 - val_mae: 41.9152\n",
      "Epoch 432/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15165.2080 - mae: 48.9269 - val_loss: 10061.4199 - val_mae: 41.4977\n",
      "Epoch 433/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14190.7803 - mae: 45.5806 - val_loss: 10561.1279 - val_mae: 40.3921\n",
      "Epoch 434/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14545.5293 - mae: 46.3820 - val_loss: 13426.5205 - val_mae: 43.0482\n",
      "Epoch 435/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16850.2227 - mae: 50.1130 - val_loss: 21296.5898 - val_mae: 64.1904\n",
      "Epoch 436/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16992.6211 - mae: 49.8382 - val_loss: 15841.9424 - val_mae: 56.6128\n",
      "Epoch 437/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15214.6162 - mae: 47.6451 - val_loss: 11173.5293 - val_mae: 42.6012\n",
      "Epoch 438/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17628.8672 - mae: 52.0629 - val_loss: 10658.1455 - val_mae: 42.1388\n",
      "Epoch 439/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13970.7568 - mae: 49.6015 - val_loss: 61021.8867 - val_mae: 123.2130\n",
      "Epoch 440/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14863.8965 - mae: 43.8470 - val_loss: 14181.0020 - val_mae: 47.6214\n",
      "Epoch 441/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15852.1221 - mae: 43.6928 - val_loss: 58835.3008 - val_mae: 121.6285\n",
      "Epoch 442/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12944.9756 - mae: 50.8109 - val_loss: 14597.8311 - val_mae: 47.8079\n",
      "Epoch 443/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15402.3496 - mae: 47.8669 - val_loss: 10386.6992 - val_mae: 37.9403\n",
      "Epoch 444/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15536.2041 - mae: 52.8992 - val_loss: 102745.3594 - val_mae: 164.1839\n",
      "Epoch 445/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16651.3965 - mae: 48.2448 - val_loss: 8420.9834 - val_mae: 40.0373\n",
      "Epoch 446/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13462.1357 - mae: 44.2774 - val_loss: 37794.7734 - val_mae: 92.2528\n",
      "Epoch 447/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16230.9355 - mae: 45.1587 - val_loss: 11650.2305 - val_mae: 49.3102\n",
      "Epoch 448/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14420.2188 - mae: 43.7288 - val_loss: 18784.4746 - val_mae: 59.0022\n",
      "Epoch 449/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17843.6992 - mae: 54.6659 - val_loss: 21994.2500 - val_mae: 63.2289\n",
      "Epoch 450/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14921.1104 - mae: 47.4974 - val_loss: 10611.3613 - val_mae: 43.3099\n",
      "Epoch 451/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14736.8164 - mae: 47.2373 - val_loss: 30507.2285 - val_mae: 81.1884\n",
      "Epoch 452/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15328.2383 - mae: 48.8876 - val_loss: 12123.4795 - val_mae: 48.3816\n",
      "Epoch 453/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17501.1523 - mae: 48.0449 - val_loss: 8440.8350 - val_mae: 38.9051\n",
      "Epoch 454/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17377.2969 - mae: 48.8694 - val_loss: 11436.1426 - val_mae: 42.4676\n",
      "Epoch 455/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13811.7168 - mae: 46.8867 - val_loss: 11380.1934 - val_mae: 49.0697\n",
      "Epoch 456/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16420.4316 - mae: 50.2461 - val_loss: 12684.5254 - val_mae: 42.8170\n",
      "Epoch 457/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13962.1826 - mae: 43.6819 - val_loss: 9087.1113 - val_mae: 39.3607\n",
      "Epoch 458/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17151.6699 - mae: 52.2783 - val_loss: 10100.0771 - val_mae: 43.0455\n",
      "Epoch 459/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13025.4834 - mae: 43.2870 - val_loss: 8750.5000 - val_mae: 39.0341\n",
      "Epoch 460/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14760.5869 - mae: 49.3681 - val_loss: 13981.2822 - val_mae: 50.3756\n",
      "Epoch 461/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15829.3174 - mae: 49.3995 - val_loss: 8517.3018 - val_mae: 39.4658\n",
      "Epoch 462/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14373.7471 - mae: 46.9169 - val_loss: 25815.2559 - val_mae: 80.4665\n",
      "Epoch 463/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15581.6953 - mae: 41.8163 - val_loss: 11682.9463 - val_mae: 44.6098\n",
      "Epoch 464/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12012.7881 - mae: 44.8941 - val_loss: 49206.1523 - val_mae: 107.7317\n",
      "Epoch 465/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13560.6465 - mae: 42.8836 - val_loss: 31048.7637 - val_mae: 79.4175\n",
      "Epoch 466/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16381.0498 - mae: 50.7553 - val_loss: 13281.3838 - val_mae: 48.7039\n",
      "Epoch 467/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15015.0703 - mae: 45.8152 - val_loss: 11018.7598 - val_mae: 40.8163\n",
      "Epoch 468/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15972.2617 - mae: 47.7670 - val_loss: 44410.0859 - val_mae: 91.1370\n",
      "Epoch 469/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12949.2588 - mae: 40.6804 - val_loss: 10466.4385 - val_mae: 41.1983\n",
      "Epoch 470/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14790.6260 - mae: 48.6344 - val_loss: 24282.0781 - val_mae: 61.2455\n",
      "Epoch 471/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14546.0371 - mae: 50.1720 - val_loss: 13845.7471 - val_mae: 44.6147\n",
      "Epoch 472/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13654.4688 - mae: 37.4110 - val_loss: 58291.1445 - val_mae: 116.8532\n",
      "Epoch 473/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13741.9785 - mae: 47.3310 - val_loss: 40932.2383 - val_mae: 96.1792\n",
      "Epoch 474/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12325.5732 - mae: 44.8290 - val_loss: 34486.2070 - val_mae: 91.6023\n",
      "Epoch 475/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 17074.0488 - mae: 48.6832 - val_loss: 10390.6377 - val_mae: 43.1182\n",
      "Epoch 476/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14267.0537 - mae: 46.3433 - val_loss: 13038.9590 - val_mae: 43.1036\n",
      "Epoch 477/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13319.2070 - mae: 39.0634 - val_loss: 17284.3145 - val_mae: 54.8324\n",
      "Epoch 478/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13883.9717 - mae: 39.8755 - val_loss: 12157.5342 - val_mae: 52.0372\n",
      "Epoch 479/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16491.7930 - mae: 44.8792 - val_loss: 15764.2529 - val_mae: 49.0163\n",
      "Epoch 480/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14950.3799 - mae: 45.3140 - val_loss: 9874.3457 - val_mae: 42.5026\n",
      "Epoch 481/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14533.5615 - mae: 45.6670 - val_loss: 13007.0166 - val_mae: 46.0040\n",
      "Epoch 482/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15332.6631 - mae: 43.7072 - val_loss: 12034.0166 - val_mae: 42.6225\n",
      "Epoch 483/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 10826.2012 - mae: 41.0652 - val_loss: 47662.0000 - val_mae: 115.7367\n",
      "Epoch 484/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13830.5098 - mae: 45.9925 - val_loss: 31753.0332 - val_mae: 72.4981\n",
      "Epoch 485/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16770.7441 - mae: 48.6767 - val_loss: 12269.6650 - val_mae: 48.3083\n",
      "Epoch 486/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 11915.4326 - mae: 43.8512 - val_loss: 59719.0117 - val_mae: 122.2441\n",
      "Epoch 487/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14262.4785 - mae: 49.3824 - val_loss: 11779.5293 - val_mae: 46.1617\n",
      "Epoch 488/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14794.4707 - mae: 49.2488 - val_loss: 10010.6426 - val_mae: 40.5395\n",
      "Epoch 489/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12954.4805 - mae: 40.9151 - val_loss: 126408.7734 - val_mae: 189.5559\n",
      "Epoch 490/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14266.5430 - mae: 44.6571 - val_loss: 35027.3711 - val_mae: 82.8167\n",
      "Epoch 491/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14407.7803 - mae: 52.7641 - val_loss: 41811.3711 - val_mae: 107.5903\n",
      "Epoch 492/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14624.1543 - mae: 48.9398 - val_loss: 10841.0059 - val_mae: 40.3846\n",
      "Epoch 493/500\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 13782.4326 - mae: 43.8079 - val_loss: 11454.7793 - val_mae: 41.5848\n",
      "Epoch 494/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 13514.7959 - mae: 43.3080 - val_loss: 10057.1465 - val_mae: 40.6477\n",
      "Epoch 495/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 15091.7148 - mae: 46.7340 - val_loss: 18055.5039 - val_mae: 51.7237\n",
      "Epoch 496/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 16282.8652 - mae: 46.2634 - val_loss: 9528.2158 - val_mae: 38.2157\n",
      "Epoch 497/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 11514.5615 - mae: 42.3048 - val_loss: 105534.4219 - val_mae: 176.9702\n",
      "Epoch 498/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 12765.2090 - mae: 42.3272 - val_loss: 44381.8320 - val_mae: 102.6874\n",
      "Epoch 499/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14585.2852 - mae: 45.6376 - val_loss: 13075.8369 - val_mae: 42.1044\n",
      "Epoch 500/500\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 14747.6465 - mae: 43.0266 - val_loss: 11123.0820 - val_mae: 47.9831\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "EPOCHS = 500\n",
    "# Store training stats\n",
    "history = model.fit(train_data, y_train, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba50f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 64)                47104     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,089\n",
      "Trainable params: 54,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),    \n",
    "    keras.layers.Dense(1)\n",
    "  ], name=\"MLP_model\")\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69b624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "70/70 [==============================] - 1s 4ms/step - loss: 14487346.0000 - mae: 2016.2659 - val_loss: 9818007.0000 - val_mae: 1687.6729\n",
      "Epoch 2/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2359860.7500 - mae: 741.9677 - val_loss: 932348.0625 - val_mae: 522.1579\n",
      "Epoch 3/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 529396.3750 - mae: 390.3079 - val_loss: 643789.3125 - val_mae: 388.5796\n",
      "Epoch 4/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 345822.1875 - mae: 297.6293 - val_loss: 534112.8125 - val_mae: 323.6420\n",
      "Epoch 5/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 249312.0000 - mae: 247.9372 - val_loss: 397526.8438 - val_mae: 264.2201\n",
      "Epoch 6/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 171034.0000 - mae: 206.6887 - val_loss: 328443.3125 - val_mae: 237.1592\n",
      "Epoch 7/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133006.8125 - mae: 182.0396 - val_loss: 257550.5312 - val_mae: 205.6986\n",
      "Epoch 8/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 104567.8750 - mae: 164.1315 - val_loss: 279794.7500 - val_mae: 196.1144\n",
      "Epoch 9/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 83091.0000 - mae: 145.6147 - val_loss: 182660.0312 - val_mae: 165.4331\n",
      "Epoch 10/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 68473.3516 - mae: 133.5647 - val_loss: 176878.0000 - val_mae: 169.1381\n",
      "Epoch 11/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 49233.2852 - mae: 114.6217 - val_loss: 100463.6172 - val_mae: 131.5193\n",
      "Epoch 12/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 43803.8477 - mae: 106.7484 - val_loss: 76777.4688 - val_mae: 113.9931\n",
      "Epoch 13/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 33171.3516 - mae: 95.6593 - val_loss: 50696.3086 - val_mae: 97.7949\n",
      "Epoch 14/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 28562.3613 - mae: 89.4364 - val_loss: 49295.9648 - val_mae: 106.7155\n",
      "Epoch 15/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 28361.1465 - mae: 85.2286 - val_loss: 30864.5625 - val_mae: 83.2570\n",
      "Epoch 16/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 26277.6152 - mae: 79.1853 - val_loss: 24910.9961 - val_mae: 79.1452\n",
      "Epoch 17/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 23540.4043 - mae: 78.5945 - val_loss: 47109.1250 - val_mae: 110.2107\n",
      "Epoch 18/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 22084.5840 - mae: 73.2751 - val_loss: 31731.6270 - val_mae: 87.3777\n",
      "Epoch 19/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 20353.6973 - mae: 71.1083 - val_loss: 66263.0000 - val_mae: 132.3590\n",
      "Epoch 20/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 22011.2422 - mae: 72.3325 - val_loss: 18532.5508 - val_mae: 65.6629\n",
      "Epoch 21/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 17917.8652 - mae: 66.1582 - val_loss: 26580.9766 - val_mae: 82.1037\n",
      "Epoch 22/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 15808.4941 - mae: 64.6413 - val_loss: 52274.1523 - val_mae: 121.1737\n",
      "Epoch 23/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 18416.7734 - mae: 66.3269 - val_loss: 38721.1445 - val_mae: 93.5194\n",
      "Epoch 24/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 16381.1914 - mae: 62.1278 - val_loss: 34323.6094 - val_mae: 94.6601\n",
      "Epoch 25/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 16361.9463 - mae: 60.5013 - val_loss: 19660.7461 - val_mae: 66.3963\n",
      "Epoch 26/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 14958.1074 - mae: 58.7535 - val_loss: 44025.6250 - val_mae: 105.2754\n",
      "Epoch 27/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 15276.7451 - mae: 59.2708 - val_loss: 127696.8047 - val_mae: 187.9982\n",
      "Epoch 28/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 16605.2500 - mae: 59.7258 - val_loss: 12975.6865 - val_mae: 57.2947\n",
      "Epoch 29/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 15106.2832 - mae: 58.2692 - val_loss: 31932.1426 - val_mae: 92.3156\n",
      "Epoch 30/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 14615.5488 - mae: 57.5229 - val_loss: 18063.2969 - val_mae: 60.4889\n",
      "Epoch 31/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 14983.3984 - mae: 58.2331 - val_loss: 17800.6816 - val_mae: 65.2383\n",
      "Epoch 32/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 15882.2227 - mae: 58.9855 - val_loss: 17416.6621 - val_mae: 62.7654\n",
      "Epoch 33/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12492.7627 - mae: 53.3409 - val_loss: 15334.9531 - val_mae: 57.3672\n",
      "Epoch 34/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 16050.6357 - mae: 57.7366 - val_loss: 16462.8887 - val_mae: 59.1395\n",
      "Epoch 35/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13122.0762 - mae: 52.9215 - val_loss: 18775.5000 - val_mae: 57.6984\n",
      "Epoch 36/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13115.2266 - mae: 51.3131 - val_loss: 17385.8652 - val_mae: 56.0003\n",
      "Epoch 37/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13145.2480 - mae: 53.8029 - val_loss: 23962.1191 - val_mae: 78.0861\n",
      "Epoch 38/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13162.9580 - mae: 54.7667 - val_loss: 57967.8477 - val_mae: 115.7164\n",
      "Epoch 39/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13936.1992 - mae: 53.9713 - val_loss: 14300.2188 - val_mae: 52.7586\n",
      "Epoch 40/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11625.7393 - mae: 51.1362 - val_loss: 15938.5605 - val_mae: 55.9141\n",
      "Epoch 41/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12522.3789 - mae: 51.4245 - val_loss: 95537.2578 - val_mae: 161.4026\n",
      "Epoch 42/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12094.9023 - mae: 52.5486 - val_loss: 14900.9355 - val_mae: 54.9735\n",
      "Epoch 43/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13124.1787 - mae: 52.9117 - val_loss: 15283.7578 - val_mae: 56.4117\n",
      "Epoch 44/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13567.6338 - mae: 52.5242 - val_loss: 19262.9531 - val_mae: 65.7862\n",
      "Epoch 45/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12315.4590 - mae: 52.5929 - val_loss: 15017.4883 - val_mae: 57.0939\n",
      "Epoch 46/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11408.9531 - mae: 49.6761 - val_loss: 15693.3730 - val_mae: 52.8063\n",
      "Epoch 47/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12014.1357 - mae: 52.2621 - val_loss: 15014.1504 - val_mae: 53.3237\n",
      "Epoch 48/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10920.5400 - mae: 46.6071 - val_loss: 17109.8535 - val_mae: 64.0189\n",
      "Epoch 49/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12386.8809 - mae: 51.8357 - val_loss: 32472.8848 - val_mae: 85.2686\n",
      "Epoch 50/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10846.4121 - mae: 49.3558 - val_loss: 31145.1797 - val_mae: 82.1001\n",
      "Epoch 51/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12841.9414 - mae: 49.4304 - val_loss: 12066.8730 - val_mae: 50.2602\n",
      "Epoch 52/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12794.8027 - mae: 51.4919 - val_loss: 14307.5488 - val_mae: 55.4539\n",
      "Epoch 53/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10405.2676 - mae: 47.4254 - val_loss: 21003.7734 - val_mae: 60.2406\n",
      "Epoch 54/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12033.0371 - mae: 48.7803 - val_loss: 15509.3096 - val_mae: 54.0106\n",
      "Epoch 55/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13759.1523 - mae: 52.0137 - val_loss: 14286.6348 - val_mae: 50.1049\n",
      "Epoch 56/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9545.1006 - mae: 45.3662 - val_loss: 19918.3750 - val_mae: 64.2613\n",
      "Epoch 57/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11128.3242 - mae: 48.1381 - val_loss: 74293.6328 - val_mae: 133.9961\n",
      "Epoch 58/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11854.8916 - mae: 50.1752 - val_loss: 21774.8262 - val_mae: 64.7259\n",
      "Epoch 59/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10519.7402 - mae: 47.5226 - val_loss: 61211.0195 - val_mae: 133.6806\n",
      "Epoch 60/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11078.0371 - mae: 48.9872 - val_loss: 24590.4590 - val_mae: 68.8466\n",
      "Epoch 61/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10595.9912 - mae: 47.7175 - val_loss: 15359.9375 - val_mae: 50.4447\n",
      "Epoch 62/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11138.5381 - mae: 46.8376 - val_loss: 36069.3828 - val_mae: 78.1577\n",
      "Epoch 63/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11773.3857 - mae: 45.0211 - val_loss: 21055.9199 - val_mae: 62.9508\n",
      "Epoch 64/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11745.6455 - mae: 50.0191 - val_loss: 13298.1992 - val_mae: 44.0629\n",
      "Epoch 65/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9221.6865 - mae: 41.9530 - val_loss: 63945.4180 - val_mae: 131.8300\n",
      "Epoch 66/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11318.5889 - mae: 48.1289 - val_loss: 28133.4980 - val_mae: 75.0057\n",
      "Epoch 67/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12060.1250 - mae: 48.1193 - val_loss: 15800.3408 - val_mae: 49.8596\n",
      "Epoch 68/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11183.4502 - mae: 48.1218 - val_loss: 24800.6973 - val_mae: 73.3327\n",
      "Epoch 69/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9167.9814 - mae: 43.1806 - val_loss: 16533.0762 - val_mae: 53.1737\n",
      "Epoch 70/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10672.1211 - mae: 44.5817 - val_loss: 17483.6621 - val_mae: 50.3918\n",
      "Epoch 71/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11532.5820 - mae: 47.1864 - val_loss: 19457.1562 - val_mae: 50.5324\n",
      "Epoch 72/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10494.3867 - mae: 42.7926 - val_loss: 16647.0762 - val_mae: 49.9269\n",
      "Epoch 73/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9936.5059 - mae: 47.2445 - val_loss: 17054.1484 - val_mae: 57.5295\n",
      "Epoch 74/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11210.6465 - mae: 46.0277 - val_loss: 17966.5664 - val_mae: 55.9684\n",
      "Epoch 75/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9411.9316 - mae: 46.0003 - val_loss: 14021.7100 - val_mae: 54.0382\n",
      "Epoch 76/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9978.3916 - mae: 46.3616 - val_loss: 15123.5791 - val_mae: 50.2743\n",
      "Epoch 77/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9921.7578 - mae: 43.7683 - val_loss: 18779.5195 - val_mae: 63.7676\n",
      "Epoch 78/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10751.7529 - mae: 45.9823 - val_loss: 13993.7852 - val_mae: 46.1738\n",
      "Epoch 79/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9710.9531 - mae: 48.1101 - val_loss: 73156.3047 - val_mae: 139.4819\n",
      "Epoch 80/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10352.8672 - mae: 47.4262 - val_loss: 39671.4570 - val_mae: 88.7774\n",
      "Epoch 81/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11635.6045 - mae: 46.4466 - val_loss: 15377.0557 - val_mae: 50.6794\n",
      "Epoch 82/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11730.8887 - mae: 42.8752 - val_loss: 15858.6035 - val_mae: 49.6378\n",
      "Epoch 83/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9543.1953 - mae: 43.0340 - val_loss: 20191.0000 - val_mae: 56.3639\n",
      "Epoch 84/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10321.4697 - mae: 43.7106 - val_loss: 25127.3438 - val_mae: 72.6541\n",
      "Epoch 85/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8869.2871 - mae: 40.1034 - val_loss: 37781.9805 - val_mae: 90.8423\n",
      "Epoch 86/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10248.7715 - mae: 46.5486 - val_loss: 87837.1094 - val_mae: 153.5747\n",
      "Epoch 87/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9940.8633 - mae: 44.5378 - val_loss: 38679.9102 - val_mae: 85.1050\n",
      "Epoch 88/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9594.5420 - mae: 43.2122 - val_loss: 17112.8320 - val_mae: 47.7655\n",
      "Epoch 89/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9646.6064 - mae: 39.9551 - val_loss: 16077.5234 - val_mae: 45.8641\n",
      "Epoch 90/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9918.6768 - mae: 41.4209 - val_loss: 16039.9248 - val_mae: 48.8864\n",
      "Epoch 91/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9362.0342 - mae: 42.8375 - val_loss: 23097.8203 - val_mae: 72.8368\n",
      "Epoch 92/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10571.0508 - mae: 46.3296 - val_loss: 25467.6094 - val_mae: 54.3867\n",
      "Epoch 93/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10059.5488 - mae: 43.5217 - val_loss: 17867.3574 - val_mae: 51.2727\n",
      "Epoch 94/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9817.6328 - mae: 44.4922 - val_loss: 27748.6797 - val_mae: 69.1771\n",
      "Epoch 95/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9468.7646 - mae: 42.6887 - val_loss: 19012.3125 - val_mae: 47.7741\n",
      "Epoch 96/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9948.4941 - mae: 42.0830 - val_loss: 69786.5625 - val_mae: 124.5712\n",
      "Epoch 97/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10590.0059 - mae: 40.5725 - val_loss: 17186.1914 - val_mae: 44.2679\n",
      "Epoch 98/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8561.7559 - mae: 41.7506 - val_loss: 16570.1953 - val_mae: 52.7251\n",
      "Epoch 99/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8298.3496 - mae: 41.3532 - val_loss: 44030.6055 - val_mae: 103.3621\n",
      "Epoch 100/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10198.0977 - mae: 44.6161 - val_loss: 14978.5537 - val_mae: 45.4392\n",
      "Epoch 101/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10866.0938 - mae: 46.8832 - val_loss: 18380.7324 - val_mae: 53.8930\n",
      "Epoch 102/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11689.5303 - mae: 45.0862 - val_loss: 16639.4043 - val_mae: 50.2451\n",
      "Epoch 103/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6903.6240 - mae: 37.8196 - val_loss: 32891.1406 - val_mae: 82.0970\n",
      "Epoch 104/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11108.6201 - mae: 45.0126 - val_loss: 35677.8047 - val_mae: 91.1164\n",
      "Epoch 105/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10457.7949 - mae: 46.1296 - val_loss: 23729.2559 - val_mae: 72.9082\n",
      "Epoch 106/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8410.5703 - mae: 39.2949 - val_loss: 41506.7344 - val_mae: 88.4748\n",
      "Epoch 107/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9902.8740 - mae: 46.9489 - val_loss: 19999.4902 - val_mae: 49.0769\n",
      "Epoch 108/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9158.8291 - mae: 42.2636 - val_loss: 15085.3135 - val_mae: 45.5581\n",
      "Epoch 109/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9412.3174 - mae: 42.0882 - val_loss: 20565.8359 - val_mae: 47.3535\n",
      "Epoch 110/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9664.7334 - mae: 41.0414 - val_loss: 16445.5938 - val_mae: 45.9773\n",
      "Epoch 111/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10475.2412 - mae: 42.4388 - val_loss: 68063.3281 - val_mae: 124.2840\n",
      "Epoch 112/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8186.8779 - mae: 39.4009 - val_loss: 17810.0156 - val_mae: 47.6401\n",
      "Epoch 113/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10660.8281 - mae: 40.7281 - val_loss: 17206.1953 - val_mae: 49.7219\n",
      "Epoch 114/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7746.1113 - mae: 40.3194 - val_loss: 100638.6484 - val_mae: 170.4221\n",
      "Epoch 115/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9437.5391 - mae: 44.1263 - val_loss: 20306.4883 - val_mae: 54.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12250.4648 - mae: 47.7724 - val_loss: 17047.6445 - val_mae: 43.0108\n",
      "Epoch 117/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9142.1240 - mae: 41.1457 - val_loss: 22683.9883 - val_mae: 65.2078\n",
      "Epoch 118/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8346.9297 - mae: 39.0641 - val_loss: 16310.9961 - val_mae: 50.5093\n",
      "Epoch 119/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9435.6465 - mae: 42.2334 - val_loss: 19264.6074 - val_mae: 45.4118\n",
      "Epoch 120/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9301.2041 - mae: 42.2890 - val_loss: 33824.3359 - val_mae: 88.8239\n",
      "Epoch 121/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8557.4209 - mae: 41.8453 - val_loss: 15858.7773 - val_mae: 42.9793\n",
      "Epoch 122/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9202.1963 - mae: 41.6037 - val_loss: 21064.1719 - val_mae: 59.0089\n",
      "Epoch 123/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10772.1816 - mae: 41.1117 - val_loss: 13409.5469 - val_mae: 43.4858\n",
      "Epoch 124/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7239.2046 - mae: 37.2525 - val_loss: 14957.6172 - val_mae: 46.4706\n",
      "Epoch 125/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9099.7676 - mae: 39.8251 - val_loss: 17158.6250 - val_mae: 47.8204\n",
      "Epoch 126/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8784.9609 - mae: 41.3974 - val_loss: 11941.4404 - val_mae: 40.8984\n",
      "Epoch 127/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7997.2446 - mae: 40.7819 - val_loss: 15125.2363 - val_mae: 49.5628\n",
      "Epoch 128/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9119.1445 - mae: 41.1817 - val_loss: 19735.2559 - val_mae: 57.5105\n",
      "Epoch 129/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9942.8652 - mae: 44.8159 - val_loss: 15207.6807 - val_mae: 52.2967\n",
      "Epoch 130/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8571.0273 - mae: 39.8998 - val_loss: 13516.0127 - val_mae: 40.7308\n",
      "Epoch 131/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8509.4209 - mae: 42.1014 - val_loss: 52482.1211 - val_mae: 114.4043\n",
      "Epoch 132/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9850.3486 - mae: 40.6176 - val_loss: 19809.4023 - val_mae: 66.3075\n",
      "Epoch 133/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9301.1025 - mae: 40.9759 - val_loss: 17017.5977 - val_mae: 51.8470\n",
      "Epoch 134/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9669.4785 - mae: 41.6712 - val_loss: 15269.7295 - val_mae: 42.7074\n",
      "Epoch 135/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9455.1465 - mae: 39.2978 - val_loss: 16446.9121 - val_mae: 50.2159\n",
      "Epoch 136/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7582.8110 - mae: 38.0136 - val_loss: 14414.5918 - val_mae: 40.5125\n",
      "Epoch 137/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8596.4316 - mae: 40.2265 - val_loss: 11803.5205 - val_mae: 40.5559\n",
      "Epoch 138/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9115.2881 - mae: 42.6779 - val_loss: 19859.6992 - val_mae: 58.9241\n",
      "Epoch 139/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9431.6836 - mae: 44.8644 - val_loss: 13921.3682 - val_mae: 41.8633\n",
      "Epoch 140/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8575.6064 - mae: 41.9937 - val_loss: 18989.2188 - val_mae: 62.5113\n",
      "Epoch 141/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8219.4404 - mae: 37.7543 - val_loss: 20977.2812 - val_mae: 51.2563\n",
      "Epoch 142/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9067.2412 - mae: 38.9797 - val_loss: 15090.0859 - val_mae: 40.6510\n",
      "Epoch 143/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8018.2349 - mae: 38.3875 - val_loss: 27949.5059 - val_mae: 79.4015\n",
      "Epoch 144/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9878.8682 - mae: 39.8022 - val_loss: 16702.9121 - val_mae: 42.5578\n",
      "Epoch 145/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9251.3135 - mae: 37.5242 - val_loss: 20971.9258 - val_mae: 64.2221\n",
      "Epoch 146/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10321.8867 - mae: 42.7211 - val_loss: 18044.8105 - val_mae: 47.3603\n",
      "Epoch 147/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8581.1416 - mae: 39.9361 - val_loss: 15002.7998 - val_mae: 43.6162\n",
      "Epoch 148/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9447.0957 - mae: 37.0578 - val_loss: 14149.7012 - val_mae: 48.6470\n",
      "Epoch 149/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8069.6113 - mae: 40.3171 - val_loss: 17440.8594 - val_mae: 48.8792\n",
      "Epoch 150/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9065.8672 - mae: 39.6320 - val_loss: 12667.5811 - val_mae: 43.0274\n",
      "Epoch 151/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9070.2217 - mae: 38.3542 - val_loss: 17619.8574 - val_mae: 51.7315\n",
      "Epoch 152/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8639.5537 - mae: 41.4018 - val_loss: 25670.1758 - val_mae: 74.5402\n",
      "Epoch 153/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9405.8809 - mae: 41.5793 - val_loss: 10455.6455 - val_mae: 39.3720\n",
      "Epoch 154/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11048.0977 - mae: 40.3153 - val_loss: 11957.7461 - val_mae: 40.5466\n",
      "Epoch 155/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7784.8057 - mae: 38.4971 - val_loss: 11571.3311 - val_mae: 40.7908\n",
      "Epoch 156/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10224.3750 - mae: 41.9570 - val_loss: 15092.9141 - val_mae: 46.8206\n",
      "Epoch 157/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7883.9551 - mae: 39.9580 - val_loss: 13486.8643 - val_mae: 42.7378\n",
      "Epoch 158/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10061.1533 - mae: 43.4175 - val_loss: 17527.5020 - val_mae: 55.1173\n",
      "Epoch 159/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8232.7012 - mae: 39.4926 - val_loss: 12852.1797 - val_mae: 46.9308\n",
      "Epoch 160/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8021.3091 - mae: 39.2746 - val_loss: 12319.9248 - val_mae: 46.6790\n",
      "Epoch 161/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8850.8857 - mae: 38.6214 - val_loss: 12268.6680 - val_mae: 43.4994\n",
      "Epoch 162/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8091.2583 - mae: 40.6159 - val_loss: 14818.4873 - val_mae: 43.8485\n",
      "Epoch 163/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8853.4512 - mae: 41.1119 - val_loss: 19121.0215 - val_mae: 51.7867\n",
      "Epoch 164/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7125.9019 - mae: 37.6326 - val_loss: 28077.7988 - val_mae: 79.5316\n",
      "Epoch 165/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10136.6152 - mae: 42.4161 - val_loss: 15944.0449 - val_mae: 46.4861\n",
      "Epoch 166/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8366.2588 - mae: 39.2410 - val_loss: 12126.0986 - val_mae: 38.0864\n",
      "Epoch 167/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9143.5488 - mae: 42.6832 - val_loss: 12272.0635 - val_mae: 42.0177\n",
      "Epoch 168/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8420.7588 - mae: 38.1345 - val_loss: 13228.3535 - val_mae: 45.3948\n",
      "Epoch 169/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11441.7139 - mae: 43.8372 - val_loss: 13180.3428 - val_mae: 43.0967\n",
      "Epoch 170/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7883.0298 - mae: 36.5083 - val_loss: 12525.8916 - val_mae: 48.1679\n",
      "Epoch 171/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8298.0596 - mae: 37.4126 - val_loss: 17763.8652 - val_mae: 62.8498\n",
      "Epoch 172/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8937.7715 - mae: 39.0073 - val_loss: 12222.7666 - val_mae: 38.7384\n",
      "Epoch 173/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9225.6855 - mae: 40.2880 - val_loss: 13469.6250 - val_mae: 47.5178\n",
      "Epoch 174/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7657.0010 - mae: 39.2862 - val_loss: 17124.0273 - val_mae: 47.5634\n",
      "Epoch 175/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9533.4512 - mae: 41.1304 - val_loss: 15921.8115 - val_mae: 45.3485\n",
      "Epoch 176/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9378.5508 - mae: 39.5866 - val_loss: 14926.8213 - val_mae: 41.3089\n",
      "Epoch 177/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7511.1929 - mae: 34.4612 - val_loss: 14855.4238 - val_mae: 55.0115\n",
      "Epoch 178/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8972.6133 - mae: 41.7614 - val_loss: 11523.6719 - val_mae: 43.1156\n",
      "Epoch 179/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7159.9272 - mae: 36.1273 - val_loss: 12704.8398 - val_mae: 39.8008\n",
      "Epoch 180/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8629.9951 - mae: 40.0913 - val_loss: 15137.9014 - val_mae: 47.6914\n",
      "Epoch 181/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8159.7188 - mae: 39.2278 - val_loss: 14244.1035 - val_mae: 44.7161\n",
      "Epoch 182/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9389.5898 - mae: 41.2109 - val_loss: 17917.7441 - val_mae: 49.3641\n",
      "Epoch 183/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7916.3594 - mae: 36.1238 - val_loss: 14174.9600 - val_mae: 42.4411\n",
      "Epoch 184/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9487.4639 - mae: 40.3497 - val_loss: 17256.7969 - val_mae: 52.0220\n",
      "Epoch 185/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7361.7231 - mae: 38.5104 - val_loss: 14721.6045 - val_mae: 49.5691\n",
      "Epoch 186/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10132.8887 - mae: 39.9350 - val_loss: 13482.0117 - val_mae: 40.6783\n",
      "Epoch 187/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7049.4971 - mae: 37.4228 - val_loss: 14909.5938 - val_mae: 53.4107\n",
      "Epoch 188/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8460.7861 - mae: 37.1235 - val_loss: 11174.8311 - val_mae: 41.2463\n",
      "Epoch 189/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8108.1265 - mae: 37.0566 - val_loss: 43711.7734 - val_mae: 97.5642\n",
      "Epoch 190/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8326.7559 - mae: 34.9958 - val_loss: 18722.2480 - val_mae: 56.1826\n",
      "Epoch 191/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7357.5635 - mae: 36.1219 - val_loss: 16879.5508 - val_mae: 57.1745\n",
      "Epoch 192/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8752.0273 - mae: 39.4480 - val_loss: 13132.2441 - val_mae: 39.5167\n",
      "Epoch 193/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7065.5620 - mae: 34.7591 - val_loss: 58053.3242 - val_mae: 124.7127\n",
      "Epoch 194/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8387.8750 - mae: 38.4092 - val_loss: 12942.3633 - val_mae: 41.8785\n",
      "Epoch 195/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7067.4595 - mae: 38.3030 - val_loss: 59102.5156 - val_mae: 118.4403\n",
      "Epoch 196/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7579.1567 - mae: 39.5111 - val_loss: 13507.1436 - val_mae: 42.8181\n",
      "Epoch 197/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7737.0728 - mae: 36.1385 - val_loss: 21149.8184 - val_mae: 52.7597\n",
      "Epoch 198/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8559.2334 - mae: 38.2038 - val_loss: 10723.1953 - val_mae: 37.9803\n",
      "Epoch 199/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7343.2983 - mae: 39.1755 - val_loss: 19332.2754 - val_mae: 51.2242\n",
      "Epoch 200/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8106.7974 - mae: 38.6625 - val_loss: 11798.6309 - val_mae: 43.1538\n",
      "Epoch 201/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6265.7202 - mae: 35.8709 - val_loss: 16607.3047 - val_mae: 46.9180\n",
      "Epoch 202/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9467.8516 - mae: 43.8012 - val_loss: 33863.5352 - val_mae: 79.9611\n",
      "Epoch 203/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7965.4453 - mae: 37.0116 - val_loss: 30886.3301 - val_mae: 87.7397\n",
      "Epoch 204/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7745.3145 - mae: 36.1418 - val_loss: 21564.4902 - val_mae: 63.0382\n",
      "Epoch 205/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9979.5674 - mae: 39.6047 - val_loss: 12567.3613 - val_mae: 40.2141\n",
      "Epoch 206/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8600.9023 - mae: 39.8957 - val_loss: 22150.0879 - val_mae: 54.1454\n",
      "Epoch 207/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6919.1309 - mae: 35.6413 - val_loss: 12995.9297 - val_mae: 39.1984\n",
      "Epoch 208/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7874.2178 - mae: 37.2420 - val_loss: 18970.2148 - val_mae: 46.8422\n",
      "Epoch 209/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8007.7744 - mae: 38.3145 - val_loss: 12637.8525 - val_mae: 39.5371\n",
      "Epoch 210/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7856.9971 - mae: 37.8615 - val_loss: 11794.1240 - val_mae: 39.9206\n",
      "Epoch 211/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8438.1016 - mae: 37.7258 - val_loss: 91704.5078 - val_mae: 152.6068\n",
      "Epoch 212/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7560.0234 - mae: 39.2230 - val_loss: 12344.7461 - val_mae: 37.8656\n",
      "Epoch 213/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7348.9438 - mae: 36.2368 - val_loss: 15608.0059 - val_mae: 47.6828\n",
      "Epoch 214/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8933.6191 - mae: 40.6170 - val_loss: 42768.3281 - val_mae: 102.5224\n",
      "Epoch 215/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7944.6030 - mae: 40.0270 - val_loss: 12079.5176 - val_mae: 42.3516\n",
      "Epoch 216/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7439.1167 - mae: 35.6554 - val_loss: 13477.5322 - val_mae: 40.9028\n",
      "Epoch 217/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6762.1875 - mae: 37.5897 - val_loss: 16775.5449 - val_mae: 57.6435\n",
      "Epoch 218/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8507.9717 - mae: 41.0347 - val_loss: 16557.4414 - val_mae: 49.8731\n",
      "Epoch 219/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8216.7988 - mae: 34.5717 - val_loss: 55499.4961 - val_mae: 116.6818\n",
      "Epoch 220/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7260.9810 - mae: 34.5339 - val_loss: 14222.3516 - val_mae: 41.2095\n",
      "Epoch 221/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8581.9951 - mae: 40.2455 - val_loss: 37889.7812 - val_mae: 93.9590\n",
      "Epoch 222/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7949.1211 - mae: 36.0712 - val_loss: 19263.8066 - val_mae: 65.6719\n",
      "Epoch 223/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7835.2251 - mae: 38.8800 - val_loss: 14773.7197 - val_mae: 40.4124\n",
      "Epoch 224/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7675.9282 - mae: 37.4487 - val_loss: 17287.3828 - val_mae: 44.4044\n",
      "Epoch 225/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7368.9897 - mae: 35.5205 - val_loss: 16241.6631 - val_mae: 44.3493\n",
      "Epoch 226/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8383.2363 - mae: 37.1014 - val_loss: 15405.9053 - val_mae: 48.7614\n",
      "Epoch 227/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7163.1128 - mae: 36.3206 - val_loss: 19039.7656 - val_mae: 62.9301\n",
      "Epoch 228/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7122.2139 - mae: 38.0086 - val_loss: 16000.6113 - val_mae: 48.5369\n",
      "Epoch 229/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7447.8213 - mae: 35.6032 - val_loss: 14502.6426 - val_mae: 43.2971\n",
      "Epoch 230/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7461.2578 - mae: 35.9712 - val_loss: 13069.2188 - val_mae: 39.2493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7789.0859 - mae: 37.8265 - val_loss: 12750.2314 - val_mae: 42.4669\n",
      "Epoch 232/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6434.9897 - mae: 33.8223 - val_loss: 16555.0449 - val_mae: 51.6567\n",
      "Epoch 233/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8119.0518 - mae: 39.2626 - val_loss: 12466.2939 - val_mae: 41.9265\n",
      "Epoch 234/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6979.1133 - mae: 34.2189 - val_loss: 14574.2852 - val_mae: 42.5846\n",
      "Epoch 235/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8204.5176 - mae: 36.4842 - val_loss: 13629.6611 - val_mae: 38.5938\n",
      "Epoch 236/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7375.8452 - mae: 37.0398 - val_loss: 61610.4805 - val_mae: 126.2253\n",
      "Epoch 237/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8643.4482 - mae: 37.4837 - val_loss: 13712.8447 - val_mae: 42.8922\n",
      "Epoch 238/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6631.1724 - mae: 37.1195 - val_loss: 17647.7227 - val_mae: 48.6993\n",
      "Epoch 239/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7067.3115 - mae: 37.2548 - val_loss: 38424.6914 - val_mae: 93.6848\n",
      "Epoch 240/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6525.9087 - mae: 32.5801 - val_loss: 85389.8438 - val_mae: 143.9548\n",
      "Epoch 241/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9051.8994 - mae: 36.5989 - val_loss: 13480.5205 - val_mae: 39.3538\n",
      "Epoch 242/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7955.0405 - mae: 36.0122 - val_loss: 13067.5342 - val_mae: 39.5446\n",
      "Epoch 243/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6726.8706 - mae: 32.5897 - val_loss: 28257.3047 - val_mae: 80.2297\n",
      "Epoch 244/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8549.3516 - mae: 36.5882 - val_loss: 17421.0977 - val_mae: 44.8064\n",
      "Epoch 245/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8400.5293 - mae: 37.2568 - val_loss: 13211.7354 - val_mae: 38.8976\n",
      "Epoch 246/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6633.1460 - mae: 32.7840 - val_loss: 15508.1777 - val_mae: 40.9833\n",
      "Epoch 247/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7853.9912 - mae: 36.8085 - val_loss: 17093.2344 - val_mae: 44.6821\n",
      "Epoch 248/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7773.1147 - mae: 35.3558 - val_loss: 44175.0352 - val_mae: 96.2903\n",
      "Epoch 249/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6851.0215 - mae: 35.4922 - val_loss: 16722.5117 - val_mae: 48.2403\n",
      "Epoch 250/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7200.0391 - mae: 36.7324 - val_loss: 29741.3047 - val_mae: 73.7617\n",
      "Epoch 251/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6760.8301 - mae: 34.6484 - val_loss: 15755.6914 - val_mae: 43.1188\n",
      "Epoch 252/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7940.9023 - mae: 38.0804 - val_loss: 13712.5010 - val_mae: 41.9204\n",
      "Epoch 253/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7539.8950 - mae: 37.2514 - val_loss: 13054.0488 - val_mae: 39.3371\n",
      "Epoch 254/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7107.8452 - mae: 35.4216 - val_loss: 15386.6143 - val_mae: 48.1591\n",
      "Epoch 255/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8262.8945 - mae: 39.2230 - val_loss: 26191.8438 - val_mae: 80.7554\n",
      "Epoch 256/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7038.6206 - mae: 36.1568 - val_loss: 16134.5381 - val_mae: 44.4802\n",
      "Epoch 257/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7027.0571 - mae: 32.7078 - val_loss: 13213.4697 - val_mae: 40.8574\n",
      "Epoch 258/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7621.5635 - mae: 36.1430 - val_loss: 35459.3086 - val_mae: 84.0756\n",
      "Epoch 259/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7384.2515 - mae: 37.5790 - val_loss: 19668.6406 - val_mae: 47.6794\n",
      "Epoch 260/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5564.6094 - mae: 33.4767 - val_loss: 14811.8027 - val_mae: 40.6439\n",
      "Epoch 261/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8572.9365 - mae: 38.2289 - val_loss: 17766.5586 - val_mae: 43.5813\n",
      "Epoch 262/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7376.9800 - mae: 38.1015 - val_loss: 23526.7383 - val_mae: 73.0451\n",
      "Epoch 263/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9044.9043 - mae: 37.6476 - val_loss: 16187.5273 - val_mae: 43.5056\n",
      "Epoch 264/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5923.0469 - mae: 33.8075 - val_loss: 16193.8096 - val_mae: 51.9427\n",
      "Epoch 265/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7784.8530 - mae: 38.0438 - val_loss: 14409.6064 - val_mae: 41.7982\n",
      "Epoch 266/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7738.9966 - mae: 34.4497 - val_loss: 26241.9141 - val_mae: 66.7981\n",
      "Epoch 267/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7806.9668 - mae: 34.3166 - val_loss: 32930.1836 - val_mae: 86.7946\n",
      "Epoch 268/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6286.1973 - mae: 35.3429 - val_loss: 14124.6719 - val_mae: 45.0732\n",
      "Epoch 269/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7952.2671 - mae: 36.5533 - val_loss: 15044.8496 - val_mae: 50.1628\n",
      "Epoch 270/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7472.1958 - mae: 37.9912 - val_loss: 45110.8047 - val_mae: 95.3299\n",
      "Epoch 271/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6598.4536 - mae: 35.9745 - val_loss: 17706.7188 - val_mae: 55.2118\n",
      "Epoch 272/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7170.2544 - mae: 37.2421 - val_loss: 14478.1133 - val_mae: 43.7587\n",
      "Epoch 273/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6584.0239 - mae: 34.3394 - val_loss: 17834.8496 - val_mae: 49.8186\n",
      "Epoch 274/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7273.9609 - mae: 35.6453 - val_loss: 15173.2559 - val_mae: 44.7304\n",
      "Epoch 275/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7901.3145 - mae: 35.2648 - val_loss: 13556.2666 - val_mae: 39.4815\n",
      "Epoch 276/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6080.7153 - mae: 31.8321 - val_loss: 12911.5840 - val_mae: 40.7901\n",
      "Epoch 277/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8258.4180 - mae: 36.2167 - val_loss: 19355.3867 - val_mae: 52.2191\n",
      "Epoch 278/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6179.6377 - mae: 34.2913 - val_loss: 12460.1826 - val_mae: 38.6278\n",
      "Epoch 279/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6161.4028 - mae: 33.2880 - val_loss: 45658.5977 - val_mae: 108.0953\n",
      "Epoch 280/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6786.7012 - mae: 34.1350 - val_loss: 10530.5059 - val_mae: 38.3291\n",
      "Epoch 281/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7315.1138 - mae: 36.0274 - val_loss: 55296.9219 - val_mae: 112.5010\n",
      "Epoch 282/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7138.8237 - mae: 33.7922 - val_loss: 13483.6953 - val_mae: 43.4356\n",
      "Epoch 283/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8004.2095 - mae: 36.0556 - val_loss: 23249.2930 - val_mae: 61.2378\n",
      "Epoch 284/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7508.7388 - mae: 36.7186 - val_loss: 10741.8496 - val_mae: 38.2251\n",
      "Epoch 285/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7391.2905 - mae: 34.9975 - val_loss: 12358.9111 - val_mae: 42.9867\n",
      "Epoch 286/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6797.6738 - mae: 34.3992 - val_loss: 12885.6943 - val_mae: 46.6532\n",
      "Epoch 287/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6271.9966 - mae: 32.8700 - val_loss: 14482.3330 - val_mae: 42.8969\n",
      "Epoch 288/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6891.3936 - mae: 34.9328 - val_loss: 17659.4121 - val_mae: 45.2462\n",
      "Epoch 289/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7007.4189 - mae: 36.4316 - val_loss: 18833.7207 - val_mae: 51.6465\n",
      "Epoch 290/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6992.5068 - mae: 36.7504 - val_loss: 15087.5107 - val_mae: 44.3872\n",
      "Epoch 291/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6915.5264 - mae: 35.1972 - val_loss: 12240.3916 - val_mae: 47.3547\n",
      "Epoch 292/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6747.3843 - mae: 34.1733 - val_loss: 13735.8809 - val_mae: 41.2675\n",
      "Epoch 293/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6950.9097 - mae: 35.9399 - val_loss: 14380.3115 - val_mae: 40.7216\n",
      "Epoch 294/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7106.7861 - mae: 37.2022 - val_loss: 19383.5996 - val_mae: 52.4594\n",
      "Epoch 295/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7273.9438 - mae: 38.2381 - val_loss: 62018.8906 - val_mae: 117.0921\n",
      "Epoch 296/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6956.6230 - mae: 35.9109 - val_loss: 13843.8096 - val_mae: 42.0425\n",
      "Epoch 297/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5710.6484 - mae: 31.5305 - val_loss: 17314.3516 - val_mae: 45.6187\n",
      "Epoch 298/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7373.6948 - mae: 35.7435 - val_loss: 17008.9648 - val_mae: 45.9124\n",
      "Epoch 299/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8585.8330 - mae: 35.4485 - val_loss: 14042.2881 - val_mae: 39.9381\n",
      "Epoch 300/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6103.6372 - mae: 31.2336 - val_loss: 26211.9375 - val_mae: 68.3292\n",
      "Epoch 301/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7086.6548 - mae: 36.6630 - val_loss: 63220.3164 - val_mae: 120.0153\n",
      "Epoch 302/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6888.1167 - mae: 33.6091 - val_loss: 18622.7793 - val_mae: 62.7797\n",
      "Epoch 303/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7201.5610 - mae: 34.7718 - val_loss: 22717.8379 - val_mae: 58.4543\n",
      "Epoch 304/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6170.9600 - mae: 34.3651 - val_loss: 31310.1406 - val_mae: 83.8796\n",
      "Epoch 305/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6844.2168 - mae: 35.9820 - val_loss: 17016.2559 - val_mae: 45.9318\n",
      "Epoch 306/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6364.7202 - mae: 35.0562 - val_loss: 35082.1328 - val_mae: 88.9663\n",
      "Epoch 307/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7151.8804 - mae: 35.1065 - val_loss: 15416.7129 - val_mae: 40.3394\n",
      "Epoch 308/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6388.1587 - mae: 34.5056 - val_loss: 22504.7500 - val_mae: 54.9881\n",
      "Epoch 309/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7918.5142 - mae: 36.1415 - val_loss: 12408.1875 - val_mae: 40.2604\n",
      "Epoch 310/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6130.6235 - mae: 30.2998 - val_loss: 57421.2812 - val_mae: 112.8953\n",
      "Epoch 311/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6055.0610 - mae: 33.7817 - val_loss: 23316.8535 - val_mae: 56.6872\n",
      "Epoch 312/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7319.1802 - mae: 36.8490 - val_loss: 14409.2676 - val_mae: 44.7929\n",
      "Epoch 313/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7095.1748 - mae: 37.7799 - val_loss: 21390.6738 - val_mae: 69.2703\n",
      "Epoch 314/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6083.7886 - mae: 32.7090 - val_loss: 14023.3115 - val_mae: 42.0761\n",
      "Epoch 315/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6661.3672 - mae: 36.8830 - val_loss: 18368.1289 - val_mae: 43.0707\n",
      "Epoch 316/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6940.2393 - mae: 34.5689 - val_loss: 19655.2812 - val_mae: 44.9703\n",
      "Epoch 317/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6906.8345 - mae: 35.3652 - val_loss: 11449.9639 - val_mae: 40.6304\n",
      "Epoch 318/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6539.1660 - mae: 32.7739 - val_loss: 14546.9121 - val_mae: 42.0027\n",
      "Epoch 319/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7467.4312 - mae: 35.7682 - val_loss: 27999.7246 - val_mae: 65.7214\n",
      "Epoch 320/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7126.1187 - mae: 34.7720 - val_loss: 17106.4961 - val_mae: 44.1559\n",
      "Epoch 321/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6235.8691 - mae: 32.3613 - val_loss: 12984.5879 - val_mae: 38.9071\n",
      "Epoch 322/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6249.6426 - mae: 30.9483 - val_loss: 18180.2148 - val_mae: 52.1935\n",
      "Epoch 323/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7127.2617 - mae: 34.6025 - val_loss: 19033.0391 - val_mae: 51.5997\n",
      "Epoch 324/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6568.8813 - mae: 35.4528 - val_loss: 15198.6309 - val_mae: 45.7997\n",
      "Epoch 325/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5891.8521 - mae: 34.0618 - val_loss: 11828.3604 - val_mae: 40.4794\n",
      "Epoch 326/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7089.4629 - mae: 33.0755 - val_loss: 11149.2734 - val_mae: 41.5395\n",
      "Epoch 327/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5780.9390 - mae: 34.8718 - val_loss: 21012.9883 - val_mae: 66.7278\n",
      "Epoch 328/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7043.1152 - mae: 35.9394 - val_loss: 11143.0820 - val_mae: 39.1762\n",
      "Epoch 329/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6242.2568 - mae: 31.5474 - val_loss: 13151.3135 - val_mae: 42.8960\n",
      "Epoch 330/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6624.6616 - mae: 34.7085 - val_loss: 14881.1025 - val_mae: 41.7626\n",
      "Epoch 331/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6051.3320 - mae: 34.1716 - val_loss: 47989.6992 - val_mae: 97.8406\n",
      "Epoch 332/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7225.0020 - mae: 36.6640 - val_loss: 16342.8242 - val_mae: 44.6348\n",
      "Epoch 333/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5754.6333 - mae: 33.3901 - val_loss: 81143.4141 - val_mae: 141.7690\n",
      "Epoch 334/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6423.4116 - mae: 32.1777 - val_loss: 11788.5215 - val_mae: 41.8802\n",
      "Epoch 335/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7225.3696 - mae: 35.4530 - val_loss: 11307.8955 - val_mae: 43.0724\n",
      "Epoch 336/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5709.2378 - mae: 30.8808 - val_loss: 14518.0127 - val_mae: 40.5785\n",
      "Epoch 337/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6864.1670 - mae: 36.6633 - val_loss: 40983.4531 - val_mae: 104.6355\n",
      "Epoch 338/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5892.2310 - mae: 32.9652 - val_loss: 15181.9961 - val_mae: 49.7963\n",
      "Epoch 339/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6219.5161 - mae: 33.0602 - val_loss: 13546.3359 - val_mae: 41.0985\n",
      "Epoch 340/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6906.1021 - mae: 34.2506 - val_loss: 50355.7578 - val_mae: 113.0158\n",
      "Epoch 341/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7903.0601 - mae: 35.6881 - val_loss: 11640.0117 - val_mae: 40.5242\n",
      "Epoch 342/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6379.9966 - mae: 32.4558 - val_loss: 11127.9170 - val_mae: 38.1697\n",
      "Epoch 343/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5922.7964 - mae: 31.4040 - val_loss: 22111.4102 - val_mae: 68.6698\n",
      "Epoch 344/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5889.8291 - mae: 32.0562 - val_loss: 11320.7227 - val_mae: 36.7703\n",
      "Epoch 345/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8535.5215 - mae: 37.2743 - val_loss: 11677.2529 - val_mae: 38.9542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5931.7471 - mae: 31.9787 - val_loss: 12311.5469 - val_mae: 43.5244\n",
      "Epoch 347/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5872.0459 - mae: 33.4162 - val_loss: 11277.5752 - val_mae: 40.0158\n",
      "Epoch 348/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6293.2085 - mae: 32.1553 - val_loss: 11317.7383 - val_mae: 41.2855\n",
      "Epoch 349/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6141.9326 - mae: 33.4912 - val_loss: 13094.8389 - val_mae: 42.1477\n",
      "Epoch 350/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6114.4556 - mae: 33.6752 - val_loss: 13743.8936 - val_mae: 43.3162\n",
      "Epoch 351/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6689.4146 - mae: 33.0273 - val_loss: 34282.0547 - val_mae: 95.5821\n",
      "Epoch 352/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6493.0830 - mae: 33.1279 - val_loss: 12916.1484 - val_mae: 38.8636\n",
      "Epoch 353/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5545.3579 - mae: 30.9611 - val_loss: 12010.3301 - val_mae: 41.2712\n",
      "Epoch 354/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6722.6279 - mae: 35.0731 - val_loss: 11523.8945 - val_mae: 40.1627\n",
      "Epoch 355/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7020.0522 - mae: 33.4716 - val_loss: 10170.4648 - val_mae: 39.1317\n",
      "Epoch 356/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5641.7744 - mae: 33.3231 - val_loss: 44538.9883 - val_mae: 101.1704\n",
      "Epoch 357/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6362.4639 - mae: 33.2379 - val_loss: 29401.7988 - val_mae: 75.8094\n",
      "Epoch 358/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6246.8979 - mae: 34.1258 - val_loss: 12888.7998 - val_mae: 49.5161\n",
      "Epoch 359/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6615.7056 - mae: 32.9541 - val_loss: 13141.1436 - val_mae: 40.0882\n",
      "Epoch 360/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6093.8843 - mae: 30.8803 - val_loss: 10223.0449 - val_mae: 39.9631\n",
      "Epoch 361/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7283.0518 - mae: 35.7651 - val_loss: 11408.3291 - val_mae: 40.2277\n",
      "Epoch 362/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5703.8208 - mae: 30.0464 - val_loss: 28464.3809 - val_mae: 85.2889\n",
      "Epoch 363/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6838.4292 - mae: 36.9312 - val_loss: 16373.5283 - val_mae: 47.7521\n",
      "Epoch 364/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6282.2217 - mae: 32.7372 - val_loss: 52957.1484 - val_mae: 111.2748\n",
      "Epoch 365/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5530.9790 - mae: 31.7234 - val_loss: 12430.1904 - val_mae: 40.8525\n",
      "Epoch 366/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5888.2837 - mae: 32.9314 - val_loss: 12974.1641 - val_mae: 41.1483\n",
      "Epoch 367/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5575.8604 - mae: 32.0407 - val_loss: 12711.4443 - val_mae: 39.8378\n",
      "Epoch 368/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6076.9727 - mae: 33.8453 - val_loss: 11200.1699 - val_mae: 45.3974\n",
      "Epoch 369/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7062.6670 - mae: 34.9138 - val_loss: 13926.4463 - val_mae: 43.6020\n",
      "Epoch 370/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5621.5723 - mae: 31.7065 - val_loss: 81051.6094 - val_mae: 140.8251\n",
      "Epoch 371/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5618.8838 - mae: 29.4888 - val_loss: 12095.9990 - val_mae: 46.1555\n",
      "Epoch 372/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6611.8086 - mae: 33.9830 - val_loss: 13943.6465 - val_mae: 43.0561\n",
      "Epoch 373/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6708.2256 - mae: 35.5265 - val_loss: 11116.2939 - val_mae: 40.7045\n",
      "Epoch 374/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5847.1284 - mae: 33.5443 - val_loss: 14456.2783 - val_mae: 45.1673\n",
      "Epoch 375/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6761.7959 - mae: 33.2469 - val_loss: 11424.1299 - val_mae: 44.8223\n",
      "Epoch 376/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5699.7607 - mae: 29.5350 - val_loss: 10566.9189 - val_mae: 46.0676\n",
      "Epoch 377/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6598.0928 - mae: 35.0761 - val_loss: 9995.7930 - val_mae: 40.1296\n",
      "Epoch 378/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7062.8779 - mae: 34.5674 - val_loss: 14672.8867 - val_mae: 57.7803\n",
      "Epoch 379/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5385.8867 - mae: 32.3983 - val_loss: 9930.5293 - val_mae: 38.4315\n",
      "Epoch 380/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5724.7935 - mae: 32.0703 - val_loss: 11937.1162 - val_mae: 41.7254\n",
      "Epoch 381/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8336.3105 - mae: 36.7126 - val_loss: 10181.4424 - val_mae: 39.9018\n",
      "Epoch 382/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5195.2622 - mae: 30.3998 - val_loss: 12812.2539 - val_mae: 43.7834\n",
      "Epoch 383/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6392.3203 - mae: 31.7200 - val_loss: 13328.6494 - val_mae: 40.0449\n",
      "Epoch 384/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6029.4971 - mae: 32.6014 - val_loss: 15409.6826 - val_mae: 60.6851\n",
      "Epoch 385/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6625.4390 - mae: 32.3702 - val_loss: 34130.6172 - val_mae: 88.8692\n",
      "Epoch 386/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6019.2148 - mae: 32.1111 - val_loss: 11239.6445 - val_mae: 39.4047\n",
      "Epoch 387/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6345.1211 - mae: 31.7622 - val_loss: 14752.1396 - val_mae: 56.2643\n",
      "Epoch 388/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5182.7021 - mae: 32.0773 - val_loss: 46581.2930 - val_mae: 106.1333\n",
      "Epoch 389/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6383.4849 - mae: 33.1783 - val_loss: 12704.1240 - val_mae: 52.1389\n",
      "Epoch 390/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6039.0557 - mae: 30.4735 - val_loss: 11369.2041 - val_mae: 39.9102\n",
      "Epoch 391/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5682.0825 - mae: 31.9523 - val_loss: 14267.6143 - val_mae: 53.2845\n",
      "Epoch 392/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5999.0503 - mae: 30.9296 - val_loss: 10575.2744 - val_mae: 40.1145\n",
      "Epoch 393/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6324.2979 - mae: 34.3145 - val_loss: 10488.5713 - val_mae: 39.8866\n",
      "Epoch 394/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8663.3340 - mae: 34.5360 - val_loss: 10389.4736 - val_mae: 38.8276\n",
      "Epoch 395/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4579.9355 - mae: 28.8439 - val_loss: 11780.9512 - val_mae: 39.0862\n",
      "Epoch 396/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5716.1226 - mae: 31.0836 - val_loss: 31907.5117 - val_mae: 83.5491\n",
      "Epoch 397/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5908.6069 - mae: 34.6145 - val_loss: 10247.3105 - val_mae: 41.5567\n",
      "Epoch 398/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7231.0249 - mae: 34.6993 - val_loss: 10358.2832 - val_mae: 37.1473\n",
      "Epoch 399/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5837.0244 - mae: 32.6674 - val_loss: 16700.5664 - val_mae: 57.3975\n",
      "Epoch 400/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7115.2480 - mae: 31.7413 - val_loss: 14668.4824 - val_mae: 51.7648\n",
      "Epoch 401/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6275.7485 - mae: 32.7137 - val_loss: 12200.6436 - val_mae: 39.9002\n",
      "Epoch 402/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7038.6001 - mae: 33.2151 - val_loss: 62969.4844 - val_mae: 124.4824\n",
      "Epoch 403/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6334.8936 - mae: 33.3103 - val_loss: 12793.6133 - val_mae: 50.3167\n",
      "Epoch 404/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6119.9009 - mae: 30.7596 - val_loss: 11563.7031 - val_mae: 49.6285\n",
      "Epoch 405/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5818.5645 - mae: 32.1683 - val_loss: 9763.9824 - val_mae: 36.6084\n",
      "Epoch 406/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6523.1714 - mae: 33.4676 - val_loss: 13595.3594 - val_mae: 43.2915\n",
      "Epoch 407/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5573.3560 - mae: 32.6940 - val_loss: 12711.4326 - val_mae: 44.7290\n",
      "Epoch 408/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8228.8477 - mae: 33.9535 - val_loss: 7357.5718 - val_mae: 35.8258\n",
      "Epoch 409/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5226.4692 - mae: 29.6630 - val_loss: 11708.3818 - val_mae: 40.7284\n",
      "Epoch 410/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6200.3506 - mae: 30.8945 - val_loss: 46380.1172 - val_mae: 102.1797\n",
      "Epoch 411/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5590.1699 - mae: 32.7815 - val_loss: 11150.6592 - val_mae: 42.9999\n",
      "Epoch 412/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6658.3818 - mae: 33.3664 - val_loss: 13177.5059 - val_mae: 42.0103\n",
      "Epoch 413/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6695.1714 - mae: 33.6920 - val_loss: 10779.9150 - val_mae: 42.0883\n",
      "Epoch 414/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5113.6230 - mae: 30.6098 - val_loss: 70928.1094 - val_mae: 130.9684\n",
      "Epoch 415/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7348.1797 - mae: 32.5177 - val_loss: 12943.9316 - val_mae: 45.4515\n",
      "Epoch 416/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6756.7632 - mae: 33.9638 - val_loss: 9457.8184 - val_mae: 37.1889\n",
      "Epoch 417/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5859.9355 - mae: 33.4331 - val_loss: 18327.4922 - val_mae: 62.0216\n",
      "Epoch 418/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6201.1313 - mae: 32.2636 - val_loss: 12173.1670 - val_mae: 45.0129\n",
      "Epoch 419/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5320.8286 - mae: 30.8464 - val_loss: 11454.0498 - val_mae: 39.8552\n",
      "Epoch 420/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6109.0386 - mae: 32.7790 - val_loss: 17161.9102 - val_mae: 53.1140\n",
      "Epoch 421/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6095.1196 - mae: 33.1965 - val_loss: 13397.4385 - val_mae: 43.2979\n",
      "Epoch 422/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5714.8359 - mae: 33.1753 - val_loss: 11102.4766 - val_mae: 40.6502\n",
      "Epoch 423/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5883.9761 - mae: 32.5483 - val_loss: 25515.6602 - val_mae: 70.5476\n",
      "Epoch 424/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6136.0332 - mae: 32.7079 - val_loss: 21643.1934 - val_mae: 63.9571\n",
      "Epoch 425/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5668.6855 - mae: 32.1119 - val_loss: 11634.5879 - val_mae: 41.2549\n",
      "Epoch 426/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5969.2998 - mae: 31.2155 - val_loss: 9691.0684 - val_mae: 40.0123\n",
      "Epoch 427/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6268.6216 - mae: 33.5903 - val_loss: 9527.2754 - val_mae: 42.4019\n",
      "Epoch 428/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5958.8774 - mae: 32.8964 - val_loss: 12999.8857 - val_mae: 42.7532\n",
      "Epoch 429/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6538.8193 - mae: 31.0570 - val_loss: 13123.4824 - val_mae: 42.3108\n",
      "Epoch 430/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5556.1606 - mae: 29.8253 - val_loss: 11983.5732 - val_mae: 41.2049\n",
      "Epoch 431/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6330.9897 - mae: 29.3651 - val_loss: 13640.4785 - val_mae: 43.8398\n",
      "Epoch 432/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6532.3809 - mae: 34.5549 - val_loss: 15874.4551 - val_mae: 58.4845\n",
      "Epoch 433/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5754.0640 - mae: 33.3526 - val_loss: 11720.5576 - val_mae: 41.5688\n",
      "Epoch 434/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5502.4761 - mae: 30.2173 - val_loss: 12982.8945 - val_mae: 43.9847\n",
      "Epoch 435/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5456.5659 - mae: 30.3996 - val_loss: 12797.7383 - val_mae: 40.6414\n",
      "Epoch 436/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6322.8350 - mae: 33.6820 - val_loss: 67221.1484 - val_mae: 125.8287\n",
      "Epoch 437/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6488.4512 - mae: 32.3032 - val_loss: 9571.7256 - val_mae: 38.2324\n",
      "Epoch 438/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5571.1626 - mae: 30.9844 - val_loss: 21420.3633 - val_mae: 75.5189\n",
      "Epoch 439/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6127.8315 - mae: 33.9052 - val_loss: 16968.3398 - val_mae: 60.8988\n",
      "Epoch 440/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6086.4800 - mae: 34.8029 - val_loss: 10151.8896 - val_mae: 38.5675\n",
      "Epoch 441/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5579.4824 - mae: 33.5185 - val_loss: 29842.4980 - val_mae: 83.0519\n",
      "Epoch 442/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5710.1494 - mae: 29.0682 - val_loss: 54611.1992 - val_mae: 114.2147\n",
      "Epoch 443/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6066.9360 - mae: 33.0390 - val_loss: 9212.3213 - val_mae: 38.7685\n",
      "Epoch 444/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6453.1831 - mae: 32.3636 - val_loss: 10733.4424 - val_mae: 41.4045\n",
      "Epoch 445/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4937.3062 - mae: 31.0883 - val_loss: 10998.4980 - val_mae: 42.0490\n",
      "Epoch 446/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4823.5044 - mae: 27.7129 - val_loss: 10535.5762 - val_mae: 39.1531\n",
      "Epoch 447/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5247.8638 - mae: 30.0412 - val_loss: 9400.3828 - val_mae: 44.0285\n",
      "Epoch 448/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6312.9214 - mae: 32.8990 - val_loss: 10423.0801 - val_mae: 38.3504\n",
      "Epoch 449/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6300.5454 - mae: 31.0379 - val_loss: 48905.5781 - val_mae: 118.2467\n",
      "Epoch 450/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6379.2612 - mae: 33.7851 - val_loss: 9885.5938 - val_mae: 38.7496\n",
      "Epoch 451/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5724.6797 - mae: 29.6613 - val_loss: 37739.3672 - val_mae: 95.4151\n",
      "Epoch 452/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5780.6294 - mae: 30.6817 - val_loss: 8566.1826 - val_mae: 37.6195\n",
      "Epoch 453/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5254.9604 - mae: 32.5036 - val_loss: 9077.4932 - val_mae: 36.2549\n",
      "Epoch 454/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6156.7275 - mae: 30.0276 - val_loss: 48292.4570 - val_mae: 104.0936\n",
      "Epoch 455/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5677.5215 - mae: 31.9092 - val_loss: 7384.6235 - val_mae: 37.9890\n",
      "Epoch 456/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6194.1255 - mae: 32.8781 - val_loss: 8666.4404 - val_mae: 36.5874\n",
      "Epoch 457/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4954.3687 - mae: 29.4282 - val_loss: 13709.4258 - val_mae: 46.9609\n",
      "Epoch 458/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5980.3926 - mae: 32.8004 - val_loss: 32945.0508 - val_mae: 93.9024\n",
      "Epoch 459/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4498.4814 - mae: 28.5995 - val_loss: 31923.2969 - val_mae: 87.1164\n",
      "Epoch 460/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6198.6816 - mae: 31.6701 - val_loss: 8565.9248 - val_mae: 36.5393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4446.2378 - mae: 28.9200 - val_loss: 36768.7070 - val_mae: 92.4692\n",
      "Epoch 462/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5522.0220 - mae: 31.5691 - val_loss: 45363.6914 - val_mae: 112.4778\n",
      "Epoch 463/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5644.0669 - mae: 28.9730 - val_loss: 46956.5234 - val_mae: 110.2891\n",
      "Epoch 464/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6244.3408 - mae: 29.7447 - val_loss: 9616.2285 - val_mae: 37.3557\n",
      "Epoch 465/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5041.9492 - mae: 29.7053 - val_loss: 42556.9102 - val_mae: 102.7037\n",
      "Epoch 466/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6123.0229 - mae: 30.9376 - val_loss: 20769.2051 - val_mae: 70.5662\n",
      "Epoch 467/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6120.1387 - mae: 32.6253 - val_loss: 10650.0752 - val_mae: 42.2395\n",
      "Epoch 468/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6815.5425 - mae: 34.3561 - val_loss: 21213.5996 - val_mae: 72.5872\n",
      "Epoch 469/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5990.1787 - mae: 32.0343 - val_loss: 10660.4316 - val_mae: 39.1311\n",
      "Epoch 470/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4465.8472 - mae: 28.2274 - val_loss: 10665.5400 - val_mae: 37.7330\n",
      "Epoch 471/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5427.6523 - mae: 30.5769 - val_loss: 10986.9414 - val_mae: 40.7955\n",
      "Epoch 472/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6193.8003 - mae: 33.0033 - val_loss: 9734.9912 - val_mae: 38.0623\n",
      "Epoch 473/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5720.1113 - mae: 30.6408 - val_loss: 14838.3672 - val_mae: 47.9498\n",
      "Epoch 474/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4824.9077 - mae: 28.0181 - val_loss: 9719.9307 - val_mae: 38.5491\n",
      "Epoch 475/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5939.9805 - mae: 33.1900 - val_loss: 13486.9258 - val_mae: 54.8731\n",
      "Epoch 476/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6033.0190 - mae: 31.5917 - val_loss: 19919.7266 - val_mae: 68.0397\n",
      "Epoch 477/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5681.6714 - mae: 31.5321 - val_loss: 30683.3867 - val_mae: 85.5236\n",
      "Epoch 478/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4993.8335 - mae: 30.3034 - val_loss: 9562.1582 - val_mae: 38.1619\n",
      "Epoch 479/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6468.5249 - mae: 32.0500 - val_loss: 16873.9023 - val_mae: 51.4033\n",
      "Epoch 480/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5877.5293 - mae: 31.6765 - val_loss: 12089.8789 - val_mae: 41.1966\n",
      "Epoch 481/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5095.5723 - mae: 30.5689 - val_loss: 12101.0273 - val_mae: 41.7547\n",
      "Epoch 482/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5826.4399 - mae: 30.0243 - val_loss: 16840.6367 - val_mae: 66.4628\n",
      "Epoch 483/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5239.4321 - mae: 30.1225 - val_loss: 9827.8008 - val_mae: 37.5248\n",
      "Epoch 484/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5505.4175 - mae: 30.5919 - val_loss: 13238.7100 - val_mae: 55.2764\n",
      "Epoch 485/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6227.5825 - mae: 29.6838 - val_loss: 11134.2637 - val_mae: 39.1240\n",
      "Epoch 486/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4782.7827 - mae: 27.6777 - val_loss: 9615.1230 - val_mae: 37.1884\n",
      "Epoch 487/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5409.2471 - mae: 30.4314 - val_loss: 13280.6270 - val_mae: 41.6662\n",
      "Epoch 488/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4854.7842 - mae: 27.9551 - val_loss: 32686.0078 - val_mae: 81.2770\n",
      "Epoch 489/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5923.1812 - mae: 27.8184 - val_loss: 72439.7812 - val_mae: 132.4677\n",
      "Epoch 490/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5643.4209 - mae: 32.1605 - val_loss: 19170.4004 - val_mae: 58.8672\n",
      "Epoch 491/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5378.7607 - mae: 29.9987 - val_loss: 12088.2383 - val_mae: 42.5342\n",
      "Epoch 492/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5856.1982 - mae: 31.8729 - val_loss: 49230.0117 - val_mae: 108.7572\n",
      "Epoch 493/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5295.4414 - mae: 30.7553 - val_loss: 9037.0879 - val_mae: 37.5362\n",
      "Epoch 494/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5101.7119 - mae: 28.3814 - val_loss: 10528.8428 - val_mae: 38.3706\n",
      "Epoch 495/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5907.4907 - mae: 31.8171 - val_loss: 18476.4668 - val_mae: 60.9226\n",
      "Epoch 496/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5046.1255 - mae: 30.4601 - val_loss: 29091.7734 - val_mae: 85.2149\n",
      "Epoch 497/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5582.8384 - mae: 29.6172 - val_loss: 11425.0488 - val_mae: 46.5398\n",
      "Epoch 498/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6190.9253 - mae: 31.6846 - val_loss: 32912.9336 - val_mae: 87.1574\n",
      "Epoch 499/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4698.9116 - mae: 28.1618 - val_loss: 16511.1543 - val_mae: 49.6107\n",
      "Epoch 500/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6267.7925 - mae: 33.0167 - val_loss: 11752.6572 - val_mae: 49.2951\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "EPOCHS = 500\n",
    "# Store training stats\n",
    "history = model.fit(train_data, y_train, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e68e70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 64)                47104     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,929\n",
      "Trainable params: 49,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),    \n",
    "    keras.layers.Dense(1)\n",
    "  ], name=\"MLP_model\")\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec1219e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "70/70 [==============================] - 1s 5ms/step - loss: 14650706.0000 - mae: 2034.1583 - val_loss: 12365372.0000 - val_mae: 1902.8831\n",
      "Epoch 2/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4696681.5000 - mae: 1071.6063 - val_loss: 1172287.0000 - val_mae: 586.7269\n",
      "Epoch 3/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 658371.8125 - mae: 443.6899 - val_loss: 726001.8125 - val_mae: 410.3457\n",
      "Epoch 4/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 389430.4375 - mae: 320.6393 - val_loss: 555515.1875 - val_mae: 338.3784\n",
      "Epoch 5/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 271805.7500 - mae: 255.7318 - val_loss: 470750.4375 - val_mae: 287.2606\n",
      "Epoch 6/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 198237.2656 - mae: 218.9335 - val_loss: 375175.4688 - val_mae: 254.4240\n",
      "Epoch 7/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 151619.6562 - mae: 189.8239 - val_loss: 367516.4062 - val_mae: 233.0702\n",
      "Epoch 8/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 120359.0703 - mae: 171.4285 - val_loss: 253990.5312 - val_mae: 198.7168\n",
      "Epoch 9/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 91760.0078 - mae: 149.7824 - val_loss: 282966.5938 - val_mae: 193.3365\n",
      "Epoch 10/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 73878.3047 - mae: 135.5886 - val_loss: 161967.0469 - val_mae: 157.5582\n",
      "Epoch 11/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 57242.5352 - mae: 119.4926 - val_loss: 126115.8984 - val_mae: 137.7850\n",
      "Epoch 12/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 44960.6250 - mae: 107.0027 - val_loss: 91433.1328 - val_mae: 125.9911\n",
      "Epoch 13/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 35937.1484 - mae: 96.3667 - val_loss: 69101.9531 - val_mae: 112.2362\n",
      "Epoch 14/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 32650.1973 - mae: 91.4469 - val_loss: 53685.2383 - val_mae: 100.6058\n",
      "Epoch 15/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 24801.7285 - mae: 81.4031 - val_loss: 40133.2422 - val_mae: 89.9617\n",
      "Epoch 16/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 22622.9844 - mae: 75.0357 - val_loss: 33550.4141 - val_mae: 81.4270\n",
      "Epoch 17/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 20255.5859 - mae: 70.8114 - val_loss: 27164.2988 - val_mae: 73.4005\n",
      "Epoch 18/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 19034.9531 - mae: 68.2597 - val_loss: 24014.2148 - val_mae: 68.8309\n",
      "Epoch 19/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 16906.1172 - mae: 64.6881 - val_loss: 25738.1426 - val_mae: 70.5664\n",
      "Epoch 20/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 14226.3193 - mae: 59.1182 - val_loss: 23451.5098 - val_mae: 69.9493\n",
      "Epoch 21/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 14826.0078 - mae: 59.2861 - val_loss: 33542.3672 - val_mae: 76.8939\n",
      "Epoch 22/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13345.0918 - mae: 56.1147 - val_loss: 22440.6309 - val_mae: 67.0298\n",
      "Epoch 23/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 13704.5859 - mae: 56.9155 - val_loss: 18987.0293 - val_mae: 59.2180\n",
      "Epoch 24/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12033.0166 - mae: 54.0023 - val_loss: 25738.8281 - val_mae: 74.8836\n",
      "Epoch 25/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11347.9785 - mae: 52.8101 - val_loss: 22574.9297 - val_mae: 68.2908\n",
      "Epoch 26/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11651.4766 - mae: 53.1666 - val_loss: 28075.7363 - val_mae: 80.2812\n",
      "Epoch 27/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11313.9395 - mae: 50.4924 - val_loss: 16516.5977 - val_mae: 61.4786\n",
      "Epoch 28/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10714.7109 - mae: 50.4888 - val_loss: 18979.8027 - val_mae: 61.9698\n",
      "Epoch 29/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10565.4365 - mae: 48.8289 - val_loss: 16653.5547 - val_mae: 62.5392\n",
      "Epoch 30/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10197.9219 - mae: 49.2188 - val_loss: 17838.1797 - val_mae: 59.3036\n",
      "Epoch 31/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9547.2227 - mae: 46.9632 - val_loss: 17394.7285 - val_mae: 55.1739\n",
      "Epoch 32/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9779.6523 - mae: 46.5949 - val_loss: 14813.6025 - val_mae: 53.5106\n",
      "Epoch 33/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9097.4072 - mae: 46.6251 - val_loss: 18048.6465 - val_mae: 64.6344\n",
      "Epoch 34/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9432.0225 - mae: 46.4289 - val_loss: 16703.0762 - val_mae: 55.6432\n",
      "Epoch 35/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9880.7314 - mae: 46.9378 - val_loss: 16481.5996 - val_mae: 54.8568\n",
      "Epoch 36/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7710.3682 - mae: 42.0901 - val_loss: 14421.7139 - val_mae: 51.6858\n",
      "Epoch 37/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9680.0381 - mae: 45.1337 - val_loss: 20334.9844 - val_mae: 62.6119\n",
      "Epoch 38/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7709.3081 - mae: 42.0685 - val_loss: 14233.7305 - val_mae: 49.5647\n",
      "Epoch 39/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8935.4053 - mae: 44.0499 - val_loss: 37032.0703 - val_mae: 77.8960\n",
      "Epoch 40/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7289.7842 - mae: 41.9709 - val_loss: 30178.9434 - val_mae: 80.9428\n",
      "Epoch 41/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9016.0293 - mae: 44.3444 - val_loss: 16959.4141 - val_mae: 53.3012\n",
      "Epoch 42/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8074.9658 - mae: 43.1038 - val_loss: 18623.1016 - val_mae: 58.3970\n",
      "Epoch 43/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7332.3262 - mae: 40.3625 - val_loss: 14490.0293 - val_mae: 49.1396\n",
      "Epoch 44/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8141.4541 - mae: 42.2060 - val_loss: 19992.6230 - val_mae: 59.3346\n",
      "Epoch 45/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8140.1147 - mae: 42.2550 - val_loss: 16854.4004 - val_mae: 53.2158\n",
      "Epoch 46/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7074.1582 - mae: 40.3784 - val_loss: 16409.7148 - val_mae: 49.9957\n",
      "Epoch 47/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6697.0430 - mae: 38.1598 - val_loss: 18479.7637 - val_mae: 53.2976\n",
      "Epoch 48/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7724.4624 - mae: 41.6041 - val_loss: 16672.2773 - val_mae: 51.5448\n",
      "Epoch 49/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7014.8037 - mae: 39.1825 - val_loss: 17183.0879 - val_mae: 52.4809\n",
      "Epoch 50/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7776.0303 - mae: 41.3688 - val_loss: 16572.6973 - val_mae: 50.9516\n",
      "Epoch 51/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7252.1548 - mae: 38.5187 - val_loss: 18335.3535 - val_mae: 50.8271\n",
      "Epoch 52/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7094.5391 - mae: 39.5965 - val_loss: 17148.2754 - val_mae: 50.8535\n",
      "Epoch 53/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6876.1206 - mae: 37.7246 - val_loss: 14533.1904 - val_mae: 49.1367\n",
      "Epoch 54/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7235.3018 - mae: 40.1930 - val_loss: 21393.9688 - val_mae: 56.1101\n",
      "Epoch 55/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7225.4580 - mae: 39.6995 - val_loss: 12571.9072 - val_mae: 46.2093\n",
      "Epoch 56/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6529.3276 - mae: 37.7901 - val_loss: 13914.0840 - val_mae: 46.6444\n",
      "Epoch 57/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6982.8174 - mae: 40.4207 - val_loss: 17138.1055 - val_mae: 47.9790\n",
      "Epoch 58/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5780.7617 - mae: 37.3184 - val_loss: 49198.4961 - val_mae: 108.8920\n",
      "Epoch 59/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6960.9600 - mae: 39.5631 - val_loss: 15336.7900 - val_mae: 49.4654\n",
      "Epoch 60/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7201.9111 - mae: 38.7088 - val_loss: 15773.2637 - val_mae: 50.8285\n",
      "Epoch 61/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6340.2646 - mae: 37.8351 - val_loss: 20443.5605 - val_mae: 57.6647\n",
      "Epoch 62/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7512.7554 - mae: 38.4718 - val_loss: 13069.4922 - val_mae: 47.0673\n",
      "Epoch 63/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5893.5269 - mae: 34.5607 - val_loss: 14036.4385 - val_mae: 51.2821\n",
      "Epoch 64/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5279.2720 - mae: 35.3014 - val_loss: 19430.0469 - val_mae: 55.4720\n",
      "Epoch 65/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6869.1646 - mae: 38.2317 - val_loss: 21425.2402 - val_mae: 58.3492\n",
      "Epoch 66/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7820.6030 - mae: 38.7693 - val_loss: 11824.6406 - val_mae: 44.4968\n",
      "Epoch 67/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5917.5522 - mae: 35.8884 - val_loss: 17018.9023 - val_mae: 55.3665\n",
      "Epoch 68/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5851.0898 - mae: 35.0668 - val_loss: 13171.1855 - val_mae: 49.8503\n",
      "Epoch 69/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6158.2900 - mae: 35.9342 - val_loss: 17425.6777 - val_mae: 53.6181\n",
      "Epoch 70/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6468.1152 - mae: 36.4526 - val_loss: 15432.7441 - val_mae: 50.6916\n",
      "Epoch 71/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6250.1753 - mae: 35.7209 - val_loss: 13956.0273 - val_mae: 50.5136\n",
      "Epoch 72/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6831.3135 - mae: 37.6777 - val_loss: 11928.7578 - val_mae: 42.7345\n",
      "Epoch 73/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5976.1172 - mae: 35.1104 - val_loss: 11415.9131 - val_mae: 43.0912\n",
      "Epoch 74/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6886.0605 - mae: 37.5091 - val_loss: 11744.9189 - val_mae: 42.5834\n",
      "Epoch 75/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5370.9507 - mae: 33.6603 - val_loss: 17375.3457 - val_mae: 46.5838\n",
      "Epoch 76/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6070.3120 - mae: 37.2361 - val_loss: 16183.5752 - val_mae: 50.3169\n",
      "Epoch 77/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6168.6958 - mae: 35.9661 - val_loss: 13532.1963 - val_mae: 42.8116\n",
      "Epoch 78/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5897.1006 - mae: 34.6782 - val_loss: 15739.7959 - val_mae: 48.5930\n",
      "Epoch 79/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6722.5728 - mae: 36.8811 - val_loss: 19444.7773 - val_mae: 52.8028\n",
      "Epoch 80/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5266.7783 - mae: 33.7084 - val_loss: 14783.0537 - val_mae: 50.3381\n",
      "Epoch 81/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5851.6553 - mae: 34.2322 - val_loss: 28450.8926 - val_mae: 64.5111\n",
      "Epoch 82/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6887.7749 - mae: 37.1895 - val_loss: 17252.1328 - val_mae: 50.1221\n",
      "Epoch 83/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5758.4712 - mae: 32.6449 - val_loss: 13585.4658 - val_mae: 44.1901\n",
      "Epoch 84/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6250.6792 - mae: 36.4215 - val_loss: 18093.7441 - val_mae: 56.3977\n",
      "Epoch 85/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6719.0029 - mae: 35.4802 - val_loss: 27241.1582 - val_mae: 78.3585\n",
      "Epoch 86/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5160.4390 - mae: 33.5824 - val_loss: 14719.9209 - val_mae: 43.1620\n",
      "Epoch 87/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6280.3242 - mae: 35.6026 - val_loss: 20081.0645 - val_mae: 57.6596\n",
      "Epoch 88/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5516.2080 - mae: 35.1466 - val_loss: 16181.0947 - val_mae: 48.8624\n",
      "Epoch 89/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5387.6641 - mae: 34.6021 - val_loss: 22223.0801 - val_mae: 74.2741\n",
      "Epoch 90/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6621.8911 - mae: 36.7723 - val_loss: 11510.1895 - val_mae: 44.8751\n",
      "Epoch 91/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6645.2007 - mae: 35.7783 - val_loss: 16538.8125 - val_mae: 48.5305\n",
      "Epoch 92/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5732.9316 - mae: 34.1680 - val_loss: 12119.8408 - val_mae: 39.9523\n",
      "Epoch 93/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6038.1548 - mae: 34.5098 - val_loss: 10557.2344 - val_mae: 39.2493\n",
      "Epoch 94/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4796.9595 - mae: 32.2840 - val_loss: 29211.2578 - val_mae: 72.3881\n",
      "Epoch 95/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6030.3789 - mae: 35.1042 - val_loss: 18713.8613 - val_mae: 48.8379\n",
      "Epoch 96/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5057.7324 - mae: 34.2415 - val_loss: 14068.3271 - val_mae: 49.4546\n",
      "Epoch 97/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5805.6382 - mae: 33.5783 - val_loss: 10883.5635 - val_mae: 42.3963\n",
      "Epoch 98/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4810.0435 - mae: 31.5047 - val_loss: 19772.3984 - val_mae: 54.7437\n",
      "Epoch 99/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5329.8540 - mae: 33.3171 - val_loss: 12590.7490 - val_mae: 44.1739\n",
      "Epoch 100/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5679.0884 - mae: 33.5437 - val_loss: 13085.7773 - val_mae: 45.2951\n",
      "Epoch 101/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5444.1440 - mae: 33.2237 - val_loss: 10034.3760 - val_mae: 42.3764\n",
      "Epoch 102/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4185.9834 - mae: 30.6776 - val_loss: 11927.5195 - val_mae: 43.8671\n",
      "Epoch 103/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6067.6489 - mae: 34.8277 - val_loss: 27270.8438 - val_mae: 78.1286\n",
      "Epoch 104/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4259.9321 - mae: 30.3846 - val_loss: 16210.7383 - val_mae: 53.0531\n",
      "Epoch 105/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5259.5981 - mae: 32.2833 - val_loss: 11570.4434 - val_mae: 40.5738\n",
      "Epoch 106/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4953.9624 - mae: 33.4814 - val_loss: 40408.3711 - val_mae: 88.8422\n",
      "Epoch 107/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5304.5464 - mae: 33.3418 - val_loss: 12674.0566 - val_mae: 43.5454\n",
      "Epoch 108/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5172.6128 - mae: 31.7766 - val_loss: 14824.5430 - val_mae: 47.9301\n",
      "Epoch 109/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6952.1729 - mae: 34.8564 - val_loss: 16193.1162 - val_mae: 50.5006\n",
      "Epoch 110/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4232.7573 - mae: 29.9139 - val_loss: 10365.5625 - val_mae: 42.6954\n",
      "Epoch 111/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6110.6743 - mae: 34.0182 - val_loss: 13746.8115 - val_mae: 43.5133\n",
      "Epoch 112/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4742.4736 - mae: 30.2301 - val_loss: 12551.7881 - val_mae: 46.7034\n",
      "Epoch 113/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5893.3022 - mae: 31.6155 - val_loss: 12976.0928 - val_mae: 46.1661\n",
      "Epoch 114/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4519.7749 - mae: 30.8826 - val_loss: 17571.7305 - val_mae: 54.6269\n",
      "Epoch 115/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6157.8271 - mae: 35.6694 - val_loss: 12606.6924 - val_mae: 43.3841\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 3ms/step - loss: 5187.9893 - mae: 30.5924 - val_loss: 12773.7617 - val_mae: 44.1445\n",
      "Epoch 117/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4753.0703 - mae: 31.1846 - val_loss: 14356.2646 - val_mae: 54.1845\n",
      "Epoch 118/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5318.4185 - mae: 31.7426 - val_loss: 10635.2109 - val_mae: 44.3750\n",
      "Epoch 119/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4946.6030 - mae: 32.1306 - val_loss: 28083.4219 - val_mae: 70.6276\n",
      "Epoch 120/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6174.5410 - mae: 30.7705 - val_loss: 12295.7402 - val_mae: 42.5214\n",
      "Epoch 121/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4483.7861 - mae: 30.6115 - val_loss: 10847.8750 - val_mae: 41.6217\n",
      "Epoch 122/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5902.4004 - mae: 34.3644 - val_loss: 25375.8242 - val_mae: 74.8985\n",
      "Epoch 123/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4680.4043 - mae: 32.1025 - val_loss: 11633.9102 - val_mae: 41.0931\n",
      "Epoch 124/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4554.3857 - mae: 31.1116 - val_loss: 14561.2998 - val_mae: 45.6799\n",
      "Epoch 125/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4746.0767 - mae: 31.1790 - val_loss: 12730.6562 - val_mae: 40.8626\n",
      "Epoch 126/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4429.7095 - mae: 29.9844 - val_loss: 18197.5742 - val_mae: 66.9823\n",
      "Epoch 127/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5517.8833 - mae: 33.0019 - val_loss: 11048.8174 - val_mae: 46.9551\n",
      "Epoch 128/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4259.8647 - mae: 28.3584 - val_loss: 11291.4424 - val_mae: 40.5318\n",
      "Epoch 129/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5457.9531 - mae: 33.0245 - val_loss: 12199.7705 - val_mae: 40.8076\n",
      "Epoch 130/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4918.3921 - mae: 28.4879 - val_loss: 10653.3750 - val_mae: 40.4616\n",
      "Epoch 131/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4624.7485 - mae: 31.1455 - val_loss: 9343.0352 - val_mae: 39.3595\n",
      "Epoch 132/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4870.2324 - mae: 31.8457 - val_loss: 10648.0508 - val_mae: 42.5563\n",
      "Epoch 133/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5064.9268 - mae: 30.2797 - val_loss: 11131.6064 - val_mae: 45.7302\n",
      "Epoch 134/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5231.4971 - mae: 31.4661 - val_loss: 12483.3330 - val_mae: 44.0621\n",
      "Epoch 135/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4173.8501 - mae: 30.5383 - val_loss: 14467.4150 - val_mae: 47.6496\n",
      "Epoch 136/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4252.0015 - mae: 29.8748 - val_loss: 40281.6133 - val_mae: 87.5394\n",
      "Epoch 137/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5113.3301 - mae: 33.0812 - val_loss: 12638.8926 - val_mae: 43.4685\n",
      "Epoch 138/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4994.9160 - mae: 31.0985 - val_loss: 12466.2246 - val_mae: 39.8083\n",
      "Epoch 139/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4462.4751 - mae: 29.5364 - val_loss: 10316.6338 - val_mae: 39.1386\n",
      "Epoch 140/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5454.9976 - mae: 29.7903 - val_loss: 13962.3779 - val_mae: 47.6487\n",
      "Epoch 141/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4916.1533 - mae: 30.5705 - val_loss: 15179.5518 - val_mae: 48.9314\n",
      "Epoch 142/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4836.1504 - mae: 32.0318 - val_loss: 22334.5879 - val_mae: 64.8690\n",
      "Epoch 143/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4742.8071 - mae: 30.8118 - val_loss: 17987.8945 - val_mae: 51.1255\n",
      "Epoch 144/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4460.6646 - mae: 29.5468 - val_loss: 10693.3154 - val_mae: 45.6346\n",
      "Epoch 145/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4934.8032 - mae: 31.7241 - val_loss: 16500.5703 - val_mae: 59.6547\n",
      "Epoch 146/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5198.7441 - mae: 31.3452 - val_loss: 32046.0430 - val_mae: 80.1305\n",
      "Epoch 147/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4791.5723 - mae: 29.9925 - val_loss: 10722.8223 - val_mae: 39.5003\n",
      "Epoch 148/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4516.1802 - mae: 28.7799 - val_loss: 15525.2119 - val_mae: 45.3493\n",
      "Epoch 149/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3796.4614 - mae: 29.6299 - val_loss: 46323.6797 - val_mae: 104.3915\n",
      "Epoch 150/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4893.3271 - mae: 30.1045 - val_loss: 10698.9297 - val_mae: 43.2493\n",
      "Epoch 151/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4593.6938 - mae: 31.2319 - val_loss: 15095.0469 - val_mae: 43.8235\n",
      "Epoch 152/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3925.8445 - mae: 28.8955 - val_loss: 10235.8584 - val_mae: 42.3005\n",
      "Epoch 153/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5453.6245 - mae: 30.9139 - val_loss: 11070.2373 - val_mae: 43.3207\n",
      "Epoch 154/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4284.7808 - mae: 28.6245 - val_loss: 15881.2988 - val_mae: 62.5855\n",
      "Epoch 155/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4797.2837 - mae: 31.1352 - val_loss: 28667.6816 - val_mae: 70.4546\n",
      "Epoch 156/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4988.8960 - mae: 30.0659 - val_loss: 25210.2500 - val_mae: 80.3699\n",
      "Epoch 157/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5351.4536 - mae: 30.5692 - val_loss: 10673.2373 - val_mae: 39.4879\n",
      "Epoch 158/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4591.9917 - mae: 29.9666 - val_loss: 26654.0527 - val_mae: 85.3365\n",
      "Epoch 159/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4690.0747 - mae: 30.5758 - val_loss: 11039.6543 - val_mae: 40.7821\n",
      "Epoch 160/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4210.4634 - mae: 30.2027 - val_loss: 12163.0615 - val_mae: 45.5813\n",
      "Epoch 161/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4052.7759 - mae: 28.8377 - val_loss: 11957.0703 - val_mae: 40.1489\n",
      "Epoch 162/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5046.6890 - mae: 30.9447 - val_loss: 10982.2666 - val_mae: 40.8534\n",
      "Epoch 163/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3940.7979 - mae: 27.5508 - val_loss: 13088.0332 - val_mae: 51.0838\n",
      "Epoch 164/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4714.4653 - mae: 29.9568 - val_loss: 9883.2949 - val_mae: 38.9228\n",
      "Epoch 165/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4183.1377 - mae: 29.1337 - val_loss: 13168.3848 - val_mae: 45.0553\n",
      "Epoch 166/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4541.6099 - mae: 31.5452 - val_loss: 12923.8105 - val_mae: 45.3371\n",
      "Epoch 167/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4021.7737 - mae: 28.4963 - val_loss: 15248.4697 - val_mae: 59.2349\n",
      "Epoch 168/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4845.4341 - mae: 28.7962 - val_loss: 9122.7490 - val_mae: 39.0117\n",
      "Epoch 169/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3962.4453 - mae: 29.5600 - val_loss: 12105.3818 - val_mae: 50.1917\n",
      "Epoch 170/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4812.9473 - mae: 31.2092 - val_loss: 10977.3223 - val_mae: 40.9639\n",
      "Epoch 171/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4415.9414 - mae: 28.5010 - val_loss: 10799.2900 - val_mae: 43.5437\n",
      "Epoch 172/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4244.5840 - mae: 29.5163 - val_loss: 10120.8096 - val_mae: 39.3338\n",
      "Epoch 173/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4211.8345 - mae: 28.8844 - val_loss: 10337.5781 - val_mae: 40.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3529.9958 - mae: 25.6906 - val_loss: 9620.6045 - val_mae: 42.8260\n",
      "Epoch 175/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5101.7886 - mae: 29.4272 - val_loss: 10003.5547 - val_mae: 40.3415\n",
      "Epoch 176/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3919.1021 - mae: 28.1140 - val_loss: 9728.9727 - val_mae: 38.9544\n",
      "Epoch 177/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4910.7202 - mae: 30.2043 - val_loss: 11985.3369 - val_mae: 44.4664\n",
      "Epoch 178/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5549.2397 - mae: 30.7852 - val_loss: 11179.9297 - val_mae: 40.0620\n",
      "Epoch 179/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4101.7139 - mae: 28.3797 - val_loss: 15165.6504 - val_mae: 49.9795\n",
      "Epoch 180/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4638.3926 - mae: 30.9576 - val_loss: 29903.5996 - val_mae: 85.7338\n",
      "Epoch 181/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4644.5405 - mae: 30.9656 - val_loss: 9442.6992 - val_mae: 41.7356\n",
      "Epoch 182/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4302.5654 - mae: 30.4502 - val_loss: 10558.7314 - val_mae: 38.6871\n",
      "Epoch 183/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4010.0515 - mae: 28.4539 - val_loss: 10724.5869 - val_mae: 45.4970\n",
      "Epoch 184/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5781.2012 - mae: 33.9597 - val_loss: 12016.0605 - val_mae: 39.7806\n",
      "Epoch 185/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3815.5847 - mae: 27.3100 - val_loss: 30116.7207 - val_mae: 72.2945\n",
      "Epoch 186/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4764.7944 - mae: 29.6292 - val_loss: 21823.0312 - val_mae: 74.2725\n",
      "Epoch 187/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4993.3706 - mae: 31.7063 - val_loss: 10491.2109 - val_mae: 40.6597\n",
      "Epoch 188/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4889.8950 - mae: 27.1039 - val_loss: 12878.8760 - val_mae: 42.6925\n",
      "Epoch 189/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4349.2603 - mae: 27.7635 - val_loss: 10099.5654 - val_mae: 38.1944\n",
      "Epoch 190/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5001.6045 - mae: 30.5543 - val_loss: 9857.0674 - val_mae: 39.0493\n",
      "Epoch 191/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3592.6509 - mae: 25.5381 - val_loss: 12311.7939 - val_mae: 41.5614\n",
      "Epoch 192/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5249.7964 - mae: 31.4975 - val_loss: 14889.4629 - val_mae: 47.1183\n",
      "Epoch 193/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3577.7434 - mae: 27.6311 - val_loss: 13080.0439 - val_mae: 40.1171\n",
      "Epoch 194/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4283.0513 - mae: 27.7924 - val_loss: 15437.8438 - val_mae: 56.4520\n",
      "Epoch 195/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4839.0659 - mae: 30.9835 - val_loss: 17497.9199 - val_mae: 50.0311\n",
      "Epoch 196/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3926.7544 - mae: 27.5851 - val_loss: 26341.0488 - val_mae: 77.4103\n",
      "Epoch 197/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4847.0083 - mae: 29.6844 - val_loss: 23397.4219 - val_mae: 60.7208\n",
      "Epoch 198/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4440.4478 - mae: 30.4222 - val_loss: 16313.4404 - val_mae: 47.7186\n",
      "Epoch 199/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4153.8472 - mae: 28.7293 - val_loss: 11177.9688 - val_mae: 39.4892\n",
      "Epoch 200/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3854.6663 - mae: 27.0457 - val_loss: 24783.1719 - val_mae: 65.0742\n",
      "Epoch 201/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4566.8560 - mae: 29.7330 - val_loss: 21272.4160 - val_mae: 70.0365\n",
      "Epoch 202/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4436.2500 - mae: 28.9184 - val_loss: 16105.5498 - val_mae: 61.0505\n",
      "Epoch 203/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4779.5356 - mae: 29.9015 - val_loss: 11576.9434 - val_mae: 38.9607\n",
      "Epoch 204/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3991.8777 - mae: 28.7838 - val_loss: 15295.0645 - val_mae: 50.8045\n",
      "Epoch 205/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4264.0293 - mae: 28.3657 - val_loss: 37831.3789 - val_mae: 90.3164\n",
      "Epoch 206/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3679.6228 - mae: 28.2629 - val_loss: 14102.2900 - val_mae: 46.1808\n",
      "Epoch 207/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4639.7090 - mae: 28.9245 - val_loss: 11950.4648 - val_mae: 40.2840\n",
      "Epoch 208/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4648.7573 - mae: 29.1150 - val_loss: 9742.4951 - val_mae: 38.6538\n",
      "Epoch 209/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4018.2383 - mae: 27.5138 - val_loss: 15639.6328 - val_mae: 46.9476\n",
      "Epoch 210/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5163.4756 - mae: 29.1964 - val_loss: 13427.2471 - val_mae: 44.3984\n",
      "Epoch 211/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3942.2205 - mae: 26.2965 - val_loss: 26523.2148 - val_mae: 76.8231\n",
      "Epoch 212/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4523.4741 - mae: 27.7344 - val_loss: 11485.8965 - val_mae: 41.4563\n",
      "Epoch 213/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3979.8064 - mae: 28.2675 - val_loss: 11270.7490 - val_mae: 41.1860\n",
      "Epoch 214/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4137.5801 - mae: 29.3937 - val_loss: 9468.8125 - val_mae: 40.5664\n",
      "Epoch 215/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5185.0024 - mae: 28.5297 - val_loss: 10077.6035 - val_mae: 41.4597\n",
      "Epoch 216/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4536.6606 - mae: 28.3237 - val_loss: 11471.6416 - val_mae: 45.9729\n",
      "Epoch 217/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3505.1475 - mae: 27.4539 - val_loss: 13690.7578 - val_mae: 43.2093\n",
      "Epoch 218/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4736.3662 - mae: 29.7872 - val_loss: 11485.8447 - val_mae: 47.1396\n",
      "Epoch 219/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4349.4077 - mae: 26.6754 - val_loss: 17035.3965 - val_mae: 53.2428\n",
      "Epoch 220/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3046.0793 - mae: 26.3033 - val_loss: 24761.5176 - val_mae: 77.3849\n",
      "Epoch 221/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4704.0537 - mae: 30.9746 - val_loss: 14190.5684 - val_mae: 44.8253\n",
      "Epoch 222/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3895.7832 - mae: 26.0594 - val_loss: 11866.1484 - val_mae: 41.1835\n",
      "Epoch 223/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4370.8545 - mae: 29.1741 - val_loss: 13789.4014 - val_mae: 44.1016\n",
      "Epoch 224/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5667.2944 - mae: 30.9853 - val_loss: 9533.4990 - val_mae: 38.9691\n",
      "Epoch 225/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2798.0847 - mae: 23.7706 - val_loss: 16243.4268 - val_mae: 49.5277\n",
      "Epoch 226/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5461.9146 - mae: 29.1958 - val_loss: 11493.9209 - val_mae: 43.7794\n",
      "Epoch 227/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4543.9648 - mae: 26.9965 - val_loss: 15695.9766 - val_mae: 46.5935\n",
      "Epoch 228/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4146.5703 - mae: 28.7476 - val_loss: 12494.2285 - val_mae: 41.5056\n",
      "Epoch 229/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3416.5269 - mae: 25.9731 - val_loss: 13656.2920 - val_mae: 51.7376\n",
      "Epoch 230/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4852.1318 - mae: 27.6751 - val_loss: 35848.2227 - val_mae: 86.7416\n",
      "Epoch 231/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4228.9946 - mae: 30.1652 - val_loss: 32617.1543 - val_mae: 97.3539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4400.1201 - mae: 27.1890 - val_loss: 18914.7676 - val_mae: 68.9982\n",
      "Epoch 233/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4395.2769 - mae: 26.5512 - val_loss: 11003.4199 - val_mae: 43.5924\n",
      "Epoch 234/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4506.8330 - mae: 28.4949 - val_loss: 14005.6250 - val_mae: 44.7635\n",
      "Epoch 235/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3177.7830 - mae: 24.4384 - val_loss: 12447.8857 - val_mae: 43.9877\n",
      "Epoch 236/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4549.8696 - mae: 27.9560 - val_loss: 10983.4619 - val_mae: 39.4404\n",
      "Epoch 237/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3930.7222 - mae: 27.1751 - val_loss: 9545.9404 - val_mae: 39.3304\n",
      "Epoch 238/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4652.6992 - mae: 27.6555 - val_loss: 13919.7783 - val_mae: 47.6768\n",
      "Epoch 239/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3623.6653 - mae: 25.2172 - val_loss: 13675.2842 - val_mae: 43.2820\n",
      "Epoch 240/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4433.9155 - mae: 28.3198 - val_loss: 10454.4033 - val_mae: 39.2067\n",
      "Epoch 241/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4681.1768 - mae: 28.6706 - val_loss: 13030.9639 - val_mae: 50.3011\n",
      "Epoch 242/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3581.5234 - mae: 26.1855 - val_loss: 16035.6719 - val_mae: 49.5947\n",
      "Epoch 243/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4999.4844 - mae: 31.7111 - val_loss: 9676.3604 - val_mae: 39.0185\n",
      "Epoch 244/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3681.7217 - mae: 27.9825 - val_loss: 13724.4619 - val_mae: 43.3809\n",
      "Epoch 245/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4150.6382 - mae: 28.4190 - val_loss: 12394.1904 - val_mae: 39.4835\n",
      "Epoch 246/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3931.5188 - mae: 28.5679 - val_loss: 14507.0225 - val_mae: 44.8209\n",
      "Epoch 247/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4991.3574 - mae: 27.7613 - val_loss: 11570.2256 - val_mae: 44.2907\n",
      "Epoch 248/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3891.7783 - mae: 28.9758 - val_loss: 15070.5498 - val_mae: 52.1997\n",
      "Epoch 249/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4399.5718 - mae: 29.3500 - val_loss: 11196.2480 - val_mae: 42.2072\n",
      "Epoch 250/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3846.0623 - mae: 26.9016 - val_loss: 16322.0430 - val_mae: 47.7215\n",
      "Epoch 251/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4243.9692 - mae: 28.0310 - val_loss: 10211.4521 - val_mae: 42.9649\n",
      "Epoch 252/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4308.9946 - mae: 30.4603 - val_loss: 12577.5068 - val_mae: 44.9955\n",
      "Epoch 253/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4117.9453 - mae: 26.5187 - val_loss: 10006.0889 - val_mae: 39.0686\n",
      "Epoch 254/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3754.0640 - mae: 26.5760 - val_loss: 9200.8457 - val_mae: 38.8436\n",
      "Epoch 255/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3581.8711 - mae: 24.8949 - val_loss: 16984.0938 - val_mae: 63.2867\n",
      "Epoch 256/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4196.1421 - mae: 29.2406 - val_loss: 10938.2666 - val_mae: 40.1817\n",
      "Epoch 257/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4123.1416 - mae: 27.0299 - val_loss: 10123.4619 - val_mae: 41.9198\n",
      "Epoch 258/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3973.0176 - mae: 28.7875 - val_loss: 13718.2148 - val_mae: 44.0721\n",
      "Epoch 259/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4044.5564 - mae: 27.9696 - val_loss: 10361.6680 - val_mae: 40.1518\n",
      "Epoch 260/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4158.2085 - mae: 28.0451 - val_loss: 12785.1885 - val_mae: 44.6343\n",
      "Epoch 261/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4544.6655 - mae: 28.0776 - val_loss: 10718.3828 - val_mae: 42.8328\n",
      "Epoch 262/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3459.8872 - mae: 24.4812 - val_loss: 10687.8711 - val_mae: 41.7267\n",
      "Epoch 263/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4118.2886 - mae: 27.1006 - val_loss: 9434.4199 - val_mae: 37.0301\n",
      "Epoch 264/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4204.4409 - mae: 28.8634 - val_loss: 17099.7246 - val_mae: 55.3198\n",
      "Epoch 265/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4314.3726 - mae: 26.2597 - val_loss: 17612.5703 - val_mae: 44.5089\n",
      "Epoch 266/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3524.9087 - mae: 25.1265 - val_loss: 11742.8936 - val_mae: 39.4552\n",
      "Epoch 267/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3879.5332 - mae: 26.5425 - val_loss: 42882.0117 - val_mae: 94.6339\n",
      "Epoch 268/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3584.1392 - mae: 25.3392 - val_loss: 12316.8311 - val_mae: 42.5185\n",
      "Epoch 269/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4453.1685 - mae: 28.0649 - val_loss: 11942.5420 - val_mae: 48.1541\n",
      "Epoch 270/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3444.1562 - mae: 26.6997 - val_loss: 9431.7188 - val_mae: 37.2327\n",
      "Epoch 271/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4372.2075 - mae: 25.9709 - val_loss: 10914.5234 - val_mae: 40.7962\n",
      "Epoch 272/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4604.7334 - mae: 27.9691 - val_loss: 11023.7129 - val_mae: 44.2365\n",
      "Epoch 273/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3612.6455 - mae: 26.3279 - val_loss: 15590.4482 - val_mae: 52.6625\n",
      "Epoch 274/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4187.2793 - mae: 28.1982 - val_loss: 13920.7773 - val_mae: 55.8714\n",
      "Epoch 275/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3155.8889 - mae: 25.1315 - val_loss: 12858.2939 - val_mae: 42.2226\n",
      "Epoch 276/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3744.0110 - mae: 26.7747 - val_loss: 10919.7061 - val_mae: 41.3986\n",
      "Epoch 277/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4402.0762 - mae: 27.5953 - val_loss: 10419.8506 - val_mae: 39.4183\n",
      "Epoch 278/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4286.3618 - mae: 28.4161 - val_loss: 9929.9658 - val_mae: 38.8747\n",
      "Epoch 279/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3490.5969 - mae: 23.6553 - val_loss: 58825.9570 - val_mae: 125.8412\n",
      "Epoch 280/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4743.4995 - mae: 26.9953 - val_loss: 10903.3057 - val_mae: 44.4980\n",
      "Epoch 281/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3618.5779 - mae: 25.6503 - val_loss: 11870.8223 - val_mae: 44.7766\n",
      "Epoch 282/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3978.7424 - mae: 27.1257 - val_loss: 10961.8740 - val_mae: 39.0061\n",
      "Epoch 283/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3983.3181 - mae: 28.7004 - val_loss: 15100.4297 - val_mae: 55.5361\n",
      "Epoch 284/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3342.7529 - mae: 26.7125 - val_loss: 9458.8906 - val_mae: 39.9271\n",
      "Epoch 285/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3627.6516 - mae: 27.9192 - val_loss: 13609.1426 - val_mae: 48.9695\n",
      "Epoch 286/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4006.8096 - mae: 27.2047 - val_loss: 9024.9004 - val_mae: 38.9987\n",
      "Epoch 287/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3561.6748 - mae: 25.3988 - val_loss: 9859.3301 - val_mae: 42.5470\n",
      "Epoch 288/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4189.7876 - mae: 29.2965 - val_loss: 14817.4238 - val_mae: 49.8833\n",
      "Epoch 289/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3923.6550 - mae: 27.9441 - val_loss: 9767.5205 - val_mae: 38.1335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4118.1777 - mae: 26.9307 - val_loss: 10521.6621 - val_mae: 38.6457\n",
      "Epoch 291/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3723.2734 - mae: 26.7992 - val_loss: 8622.2402 - val_mae: 36.8663\n",
      "Epoch 292/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4159.5190 - mae: 28.0730 - val_loss: 10716.9932 - val_mae: 41.2793\n",
      "Epoch 293/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3679.7925 - mae: 26.4457 - val_loss: 10505.9932 - val_mae: 38.1283\n",
      "Epoch 294/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4247.9497 - mae: 30.1597 - val_loss: 9679.8057 - val_mae: 41.2465\n",
      "Epoch 295/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3604.1074 - mae: 25.5487 - val_loss: 10357.7021 - val_mae: 38.8643\n",
      "Epoch 296/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4122.2886 - mae: 27.9798 - val_loss: 11149.7324 - val_mae: 42.8118\n",
      "Epoch 297/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4417.6025 - mae: 25.0736 - val_loss: 10508.7197 - val_mae: 38.2700\n",
      "Epoch 298/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3487.6584 - mae: 26.7163 - val_loss: 12099.3740 - val_mae: 41.3942\n",
      "Epoch 299/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3560.4666 - mae: 26.8835 - val_loss: 18110.1621 - val_mae: 65.2699\n",
      "Epoch 300/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3788.4131 - mae: 26.2110 - val_loss: 8894.9424 - val_mae: 41.8788\n",
      "Epoch 301/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4017.1013 - mae: 27.9957 - val_loss: 9874.1035 - val_mae: 45.9000\n",
      "Epoch 302/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4352.5640 - mae: 28.8228 - val_loss: 12299.8545 - val_mae: 42.2148\n",
      "Epoch 303/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2978.7100 - mae: 23.7396 - val_loss: 22491.4961 - val_mae: 73.4264\n",
      "Epoch 304/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4146.8882 - mae: 28.5055 - val_loss: 10556.0693 - val_mae: 48.5396\n",
      "Epoch 305/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3606.6079 - mae: 26.3845 - val_loss: 9984.5703 - val_mae: 39.5808\n",
      "Epoch 306/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4375.8594 - mae: 28.0510 - val_loss: 18070.8223 - val_mae: 58.1410\n",
      "Epoch 307/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3512.6453 - mae: 26.1300 - val_loss: 12065.5283 - val_mae: 40.5314\n",
      "Epoch 308/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3798.3191 - mae: 24.0431 - val_loss: 13547.3906 - val_mae: 46.6280\n",
      "Epoch 309/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3977.6169 - mae: 27.0413 - val_loss: 19384.4297 - val_mae: 52.2166\n",
      "Epoch 310/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3634.2341 - mae: 26.1636 - val_loss: 15679.0605 - val_mae: 54.4837\n",
      "Epoch 311/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3011.4951 - mae: 25.1519 - val_loss: 14101.3965 - val_mae: 41.5425\n",
      "Epoch 312/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4514.0244 - mae: 29.2998 - val_loss: 11575.7783 - val_mae: 39.3162\n",
      "Epoch 313/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3662.6357 - mae: 26.5877 - val_loss: 11572.0752 - val_mae: 52.2898\n",
      "Epoch 314/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3869.6169 - mae: 26.8262 - val_loss: 11260.8906 - val_mae: 39.2813\n",
      "Epoch 315/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4091.6299 - mae: 25.6319 - val_loss: 15330.6689 - val_mae: 45.5613\n",
      "Epoch 316/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3319.5012 - mae: 24.2719 - val_loss: 12822.4512 - val_mae: 41.9379\n",
      "Epoch 317/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3637.0715 - mae: 26.3336 - val_loss: 10157.0293 - val_mae: 41.0738\n",
      "Epoch 318/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3729.4021 - mae: 26.9835 - val_loss: 10078.2910 - val_mae: 36.6034\n",
      "Epoch 319/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4555.6250 - mae: 27.3877 - val_loss: 20684.7090 - val_mae: 72.6440\n",
      "Epoch 320/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3799.5972 - mae: 26.4458 - val_loss: 24574.2637 - val_mae: 68.8516\n",
      "Epoch 321/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3713.6780 - mae: 25.7040 - val_loss: 24919.5508 - val_mae: 76.5100\n",
      "Epoch 322/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3656.1069 - mae: 26.3326 - val_loss: 36728.4648 - val_mae: 85.1802\n",
      "Epoch 323/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4215.5767 - mae: 27.0677 - val_loss: 13439.8633 - val_mae: 45.8642\n",
      "Epoch 324/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3592.3604 - mae: 25.6977 - val_loss: 12064.0889 - val_mae: 41.3907\n",
      "Epoch 325/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3653.8313 - mae: 25.6067 - val_loss: 11517.2031 - val_mae: 41.5577\n",
      "Epoch 326/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3702.4934 - mae: 27.8105 - val_loss: 11326.2812 - val_mae: 39.5078\n",
      "Epoch 327/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3005.5847 - mae: 25.2254 - val_loss: 33986.5430 - val_mae: 83.4786\n",
      "Epoch 328/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4035.0015 - mae: 26.5850 - val_loss: 10357.7090 - val_mae: 37.7738\n",
      "Epoch 329/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3692.5942 - mae: 27.3503 - val_loss: 10204.2012 - val_mae: 36.8957\n",
      "Epoch 330/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4348.6411 - mae: 28.0614 - val_loss: 11954.5186 - val_mae: 46.4907\n",
      "Epoch 331/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3466.0498 - mae: 23.8274 - val_loss: 33320.6328 - val_mae: 78.8885\n",
      "Epoch 332/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4571.0166 - mae: 28.9461 - val_loss: 28014.3809 - val_mae: 70.8247\n",
      "Epoch 333/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3084.6318 - mae: 23.9676 - val_loss: 10574.9082 - val_mae: 39.0302\n",
      "Epoch 334/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3627.8723 - mae: 24.7786 - val_loss: 10339.3350 - val_mae: 42.8159\n",
      "Epoch 335/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4302.3398 - mae: 26.8012 - val_loss: 12307.8350 - val_mae: 48.6538\n",
      "Epoch 336/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3732.4038 - mae: 26.3773 - val_loss: 15969.0986 - val_mae: 48.9928\n",
      "Epoch 337/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3840.9490 - mae: 26.3362 - val_loss: 11533.5381 - val_mae: 39.5757\n",
      "Epoch 338/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3551.0828 - mae: 26.1968 - val_loss: 11748.7334 - val_mae: 44.5214\n",
      "Epoch 339/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3405.1609 - mae: 25.7332 - val_loss: 14129.5830 - val_mae: 41.7714\n",
      "Epoch 340/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3247.9607 - mae: 26.4174 - val_loss: 14214.0752 - val_mae: 54.1404\n",
      "Epoch 341/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3766.8647 - mae: 26.4194 - val_loss: 10827.0273 - val_mae: 38.7686\n",
      "Epoch 342/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3923.9812 - mae: 26.0193 - val_loss: 13592.8809 - val_mae: 43.1667\n",
      "Epoch 343/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3532.2900 - mae: 26.7178 - val_loss: 17355.8203 - val_mae: 48.1159\n",
      "Epoch 344/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3335.3269 - mae: 24.6238 - val_loss: 21701.7324 - val_mae: 59.4892\n",
      "Epoch 345/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5316.1021 - mae: 28.2760 - val_loss: 11933.7314 - val_mae: 39.7226\n",
      "Epoch 346/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2934.5327 - mae: 21.9978 - val_loss: 11268.6328 - val_mae: 40.5661\n",
      "Epoch 347/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3379.0938 - mae: 25.3038 - val_loss: 27474.9570 - val_mae: 61.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3497.5906 - mae: 26.6430 - val_loss: 13993.7129 - val_mae: 41.1180\n",
      "Epoch 349/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3293.0007 - mae: 25.0167 - val_loss: 10996.0566 - val_mae: 39.8070\n",
      "Epoch 350/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2848.7168 - mae: 23.5286 - val_loss: 28284.1895 - val_mae: 71.6764\n",
      "Epoch 351/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3819.2478 - mae: 26.8855 - val_loss: 55271.8047 - val_mae: 108.6861\n",
      "Epoch 352/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3486.5513 - mae: 27.0483 - val_loss: 13610.2539 - val_mae: 46.0305\n",
      "Epoch 353/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4163.3311 - mae: 27.0437 - val_loss: 15622.8281 - val_mae: 45.6163\n",
      "Epoch 354/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3571.3579 - mae: 25.7758 - val_loss: 10715.2461 - val_mae: 45.1246\n",
      "Epoch 355/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3389.5454 - mae: 25.3726 - val_loss: 10797.0469 - val_mae: 38.6080\n",
      "Epoch 356/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3182.4668 - mae: 24.4054 - val_loss: 20393.5254 - val_mae: 60.2541\n",
      "Epoch 357/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3632.9475 - mae: 25.9524 - val_loss: 10041.3135 - val_mae: 38.0706\n",
      "Epoch 358/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3689.6748 - mae: 25.4950 - val_loss: 9634.6553 - val_mae: 37.2611\n",
      "Epoch 359/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3493.1250 - mae: 25.7069 - val_loss: 13147.1318 - val_mae: 48.6180\n",
      "Epoch 360/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4225.8325 - mae: 27.6207 - val_loss: 9486.4102 - val_mae: 39.7474\n",
      "Epoch 361/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3015.6455 - mae: 24.0366 - val_loss: 16675.5137 - val_mae: 58.0019\n",
      "Epoch 362/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3416.1311 - mae: 26.8200 - val_loss: 15521.6035 - val_mae: 54.9788\n",
      "Epoch 363/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3753.7222 - mae: 26.0948 - val_loss: 9904.7393 - val_mae: 39.8081\n",
      "Epoch 364/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3083.3882 - mae: 23.7372 - val_loss: 12365.3604 - val_mae: 52.1317\n",
      "Epoch 365/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4040.8982 - mae: 25.8572 - val_loss: 10658.5391 - val_mae: 38.5585\n",
      "Epoch 366/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3236.6538 - mae: 25.4027 - val_loss: 9708.8389 - val_mae: 38.3330\n",
      "Epoch 367/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3161.2871 - mae: 23.5730 - val_loss: 13979.7490 - val_mae: 45.5052\n",
      "Epoch 368/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3848.6182 - mae: 25.1703 - val_loss: 15480.9229 - val_mae: 56.1182\n",
      "Epoch 369/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3514.3828 - mae: 25.0955 - val_loss: 21455.0840 - val_mae: 57.8936\n",
      "Epoch 370/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3315.9819 - mae: 22.7500 - val_loss: 11877.3672 - val_mae: 39.9129\n",
      "Epoch 371/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4023.8074 - mae: 27.6452 - val_loss: 14858.9590 - val_mae: 46.4259\n",
      "Epoch 372/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3505.5491 - mae: 25.1492 - val_loss: 11639.0156 - val_mae: 39.5993\n",
      "Epoch 373/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3120.9365 - mae: 25.4229 - val_loss: 12974.5225 - val_mae: 41.9954\n",
      "Epoch 374/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4037.5938 - mae: 27.5287 - val_loss: 11444.6631 - val_mae: 43.6720\n",
      "Epoch 375/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2980.5532 - mae: 23.6522 - val_loss: 12095.2744 - val_mae: 48.8750\n",
      "Epoch 376/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3369.0879 - mae: 23.4766 - val_loss: 8769.9971 - val_mae: 38.3424\n",
      "Epoch 377/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3315.7266 - mae: 23.8482 - val_loss: 12803.5215 - val_mae: 45.7644\n",
      "Epoch 378/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3813.1672 - mae: 25.1342 - val_loss: 10435.1543 - val_mae: 41.7547\n",
      "Epoch 379/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3587.9788 - mae: 25.6082 - val_loss: 9889.5273 - val_mae: 36.9606\n",
      "Epoch 380/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3421.0234 - mae: 25.7680 - val_loss: 11989.7158 - val_mae: 41.5664\n",
      "Epoch 381/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3890.5557 - mae: 26.8876 - val_loss: 12375.5605 - val_mae: 39.3544\n",
      "Epoch 382/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3471.4194 - mae: 24.0818 - val_loss: 9307.3643 - val_mae: 36.6883\n",
      "Epoch 383/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3304.6248 - mae: 23.1537 - val_loss: 11151.2773 - val_mae: 37.5966\n",
      "Epoch 384/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4086.3572 - mae: 25.0089 - val_loss: 11474.4609 - val_mae: 39.2574\n",
      "Epoch 385/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3809.2388 - mae: 27.2709 - val_loss: 14605.2988 - val_mae: 41.3786\n",
      "Epoch 386/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3236.4099 - mae: 24.7775 - val_loss: 26570.5664 - val_mae: 84.4770\n",
      "Epoch 387/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3984.9302 - mae: 26.4903 - val_loss: 13001.6240 - val_mae: 41.6573\n",
      "Epoch 388/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3268.8467 - mae: 25.4207 - val_loss: 11388.4209 - val_mae: 40.2249\n",
      "Epoch 389/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3537.2383 - mae: 25.9799 - val_loss: 11877.4375 - val_mae: 43.6555\n",
      "Epoch 390/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3290.8479 - mae: 24.4332 - val_loss: 14962.4072 - val_mae: 45.0604\n",
      "Epoch 391/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3766.4490 - mae: 25.5818 - val_loss: 11651.3594 - val_mae: 40.4310\n",
      "Epoch 392/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3841.8284 - mae: 26.2419 - val_loss: 11115.8955 - val_mae: 39.1249\n",
      "Epoch 393/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4079.6384 - mae: 28.2604 - val_loss: 10651.5576 - val_mae: 39.7278\n",
      "Epoch 394/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3288.8286 - mae: 25.9544 - val_loss: 13014.5293 - val_mae: 41.5946\n",
      "Epoch 395/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4008.8186 - mae: 26.1505 - val_loss: 12446.7510 - val_mae: 41.3330\n",
      "Epoch 396/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3025.4805 - mae: 23.3196 - val_loss: 17658.5195 - val_mae: 64.9403\n",
      "Epoch 397/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3824.9924 - mae: 24.9621 - val_loss: 11009.5088 - val_mae: 40.5599\n",
      "Epoch 398/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3152.7285 - mae: 25.3428 - val_loss: 14627.1816 - val_mae: 44.4348\n",
      "Epoch 399/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3896.1963 - mae: 24.4160 - val_loss: 11704.8350 - val_mae: 43.1221\n",
      "Epoch 400/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3230.6023 - mae: 24.3184 - val_loss: 14236.9629 - val_mae: 44.0533\n",
      "Epoch 401/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3323.5183 - mae: 24.9745 - val_loss: 10892.5566 - val_mae: 41.6571\n",
      "Epoch 402/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2688.1018 - mae: 22.8123 - val_loss: 10607.9785 - val_mae: 38.9164\n",
      "Epoch 403/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3158.5054 - mae: 24.2913 - val_loss: 12962.8867 - val_mae: 42.1480\n",
      "Epoch 404/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3558.1611 - mae: 25.6040 - val_loss: 13771.1738 - val_mae: 54.9855\n",
      "Epoch 405/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3738.5808 - mae: 25.5383 - val_loss: 13141.0557 - val_mae: 44.5159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3462.9277 - mae: 25.0706 - val_loss: 12517.1729 - val_mae: 39.6079\n",
      "Epoch 407/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3790.9275 - mae: 24.9644 - val_loss: 22767.0098 - val_mae: 59.6809\n",
      "Epoch 408/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3314.7747 - mae: 25.6611 - val_loss: 9496.7119 - val_mae: 37.4751\n",
      "Epoch 409/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3262.3198 - mae: 24.6344 - val_loss: 12781.0215 - val_mae: 45.8658\n",
      "Epoch 410/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3498.9309 - mae: 27.1637 - val_loss: 10431.7822 - val_mae: 38.2349\n",
      "Epoch 411/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2979.7837 - mae: 21.4789 - val_loss: 16453.7930 - val_mae: 48.1693\n",
      "Epoch 412/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4001.5156 - mae: 25.4190 - val_loss: 11742.1797 - val_mae: 38.5547\n",
      "Epoch 413/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4113.6694 - mae: 28.0592 - val_loss: 9786.9580 - val_mae: 37.0135\n",
      "Epoch 414/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2980.3257 - mae: 22.9918 - val_loss: 20397.0508 - val_mae: 69.9694\n",
      "Epoch 415/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3459.9954 - mae: 24.7002 - val_loss: 10529.6377 - val_mae: 38.8939\n",
      "Epoch 416/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2913.8582 - mae: 22.9711 - val_loss: 13155.5029 - val_mae: 40.5278\n",
      "Epoch 417/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4277.1035 - mae: 27.3484 - val_loss: 9497.3730 - val_mae: 38.7164\n",
      "Epoch 418/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3856.2925 - mae: 24.8316 - val_loss: 12468.9707 - val_mae: 40.5232\n",
      "Epoch 419/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3166.1475 - mae: 24.2605 - val_loss: 12818.8848 - val_mae: 42.6549\n",
      "Epoch 420/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3395.2051 - mae: 25.3522 - val_loss: 11325.2451 - val_mae: 39.3819\n",
      "Epoch 421/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2974.7859 - mae: 24.3295 - val_loss: 10006.9375 - val_mae: 36.8312\n",
      "Epoch 422/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3952.4141 - mae: 24.5132 - val_loss: 10968.6631 - val_mae: 37.6924\n",
      "Epoch 423/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3384.6155 - mae: 25.3265 - val_loss: 16611.4023 - val_mae: 59.7121\n",
      "Epoch 424/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3281.2241 - mae: 23.0119 - val_loss: 13541.1504 - val_mae: 48.4284\n",
      "Epoch 425/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3780.3379 - mae: 25.3116 - val_loss: 11553.7998 - val_mae: 46.0880\n",
      "Epoch 426/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3069.2385 - mae: 23.2427 - val_loss: 22650.0684 - val_mae: 65.1753\n",
      "Epoch 427/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3490.1384 - mae: 25.9773 - val_loss: 9902.0498 - val_mae: 36.6227\n",
      "Epoch 428/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3137.8384 - mae: 23.9434 - val_loss: 10045.7666 - val_mae: 39.3006\n",
      "Epoch 429/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3312.0464 - mae: 25.0645 - val_loss: 20132.7148 - val_mae: 61.7954\n",
      "Epoch 430/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4106.1289 - mae: 25.5203 - val_loss: 8565.6680 - val_mae: 37.7701\n",
      "Epoch 431/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3645.1001 - mae: 25.2596 - val_loss: 13610.9922 - val_mae: 41.7679\n",
      "Epoch 432/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3375.8206 - mae: 23.9005 - val_loss: 14291.1904 - val_mae: 44.9846\n",
      "Epoch 433/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2970.3428 - mae: 23.4926 - val_loss: 21724.5723 - val_mae: 59.2064\n",
      "Epoch 434/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3582.8203 - mae: 25.1552 - val_loss: 13701.2549 - val_mae: 44.6089\n",
      "Epoch 435/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3356.8008 - mae: 22.6697 - val_loss: 14366.2852 - val_mae: 42.1590\n",
      "Epoch 436/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3851.8845 - mae: 26.1320 - val_loss: 14125.8711 - val_mae: 40.9526\n",
      "Epoch 437/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2960.7415 - mae: 22.6146 - val_loss: 12787.2676 - val_mae: 41.8179\n",
      "Epoch 438/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3250.3198 - mae: 23.4713 - val_loss: 10703.6855 - val_mae: 40.2421\n",
      "Epoch 439/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3815.4373 - mae: 26.2017 - val_loss: 12094.6006 - val_mae: 40.8561\n",
      "Epoch 440/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2781.7290 - mae: 21.5889 - val_loss: 9887.5166 - val_mae: 38.3698\n",
      "Epoch 441/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3685.4578 - mae: 24.5100 - val_loss: 12385.3408 - val_mae: 46.1062\n",
      "Epoch 442/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3261.9094 - mae: 22.6777 - val_loss: 11196.4902 - val_mae: 39.3606\n",
      "Epoch 443/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3220.4407 - mae: 22.6480 - val_loss: 24643.6680 - val_mae: 67.6754\n",
      "Epoch 444/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3427.6599 - mae: 25.4177 - val_loss: 10994.1289 - val_mae: 41.1235\n",
      "Epoch 445/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3887.4417 - mae: 24.1434 - val_loss: 9475.4209 - val_mae: 38.8884\n",
      "Epoch 446/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2843.1941 - mae: 23.2256 - val_loss: 10916.9414 - val_mae: 40.3016\n",
      "Epoch 447/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3278.8484 - mae: 23.7773 - val_loss: 25008.2988 - val_mae: 64.8318\n",
      "Epoch 448/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3452.6794 - mae: 25.8987 - val_loss: 12477.3828 - val_mae: 38.9783\n",
      "Epoch 449/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3181.4988 - mae: 23.9269 - val_loss: 14888.9258 - val_mae: 42.2162\n",
      "Epoch 450/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3512.0513 - mae: 25.3098 - val_loss: 11440.2578 - val_mae: 44.2090\n",
      "Epoch 451/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3687.6580 - mae: 23.3101 - val_loss: 11168.2236 - val_mae: 38.9713\n",
      "Epoch 452/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3255.2937 - mae: 22.5150 - val_loss: 11025.9385 - val_mae: 38.4633\n",
      "Epoch 453/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3108.0171 - mae: 23.8684 - val_loss: 11593.1904 - val_mae: 41.5258\n",
      "Epoch 454/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3187.1765 - mae: 22.1326 - val_loss: 10653.8203 - val_mae: 39.5507\n",
      "Epoch 455/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3354.5581 - mae: 24.9436 - val_loss: 12961.9600 - val_mae: 43.5414\n",
      "Epoch 456/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3771.0740 - mae: 25.0207 - val_loss: 11212.0547 - val_mae: 39.6847\n",
      "Epoch 457/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3244.9490 - mae: 21.8568 - val_loss: 11301.6904 - val_mae: 41.1432\n",
      "Epoch 458/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3604.6704 - mae: 26.0083 - val_loss: 14351.7285 - val_mae: 56.2197\n",
      "Epoch 459/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3432.0049 - mae: 25.4082 - val_loss: 10814.6738 - val_mae: 39.2517\n",
      "Epoch 460/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3827.4937 - mae: 26.8648 - val_loss: 9045.9785 - val_mae: 41.5299\n",
      "Epoch 461/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2730.9463 - mae: 23.8250 - val_loss: 11550.2588 - val_mae: 41.9377\n",
      "Epoch 462/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3596.6780 - mae: 26.9406 - val_loss: 16059.7793 - val_mae: 51.6005\n",
      "Epoch 463/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3400.0144 - mae: 25.9807 - val_loss: 12693.1758 - val_mae: 46.5397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2997.5449 - mae: 25.2215 - val_loss: 12781.8467 - val_mae: 47.2413\n",
      "Epoch 465/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3229.4102 - mae: 24.1152 - val_loss: 12054.7373 - val_mae: 40.0555\n",
      "Epoch 466/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4296.0298 - mae: 25.9871 - val_loss: 9899.2979 - val_mae: 37.3648\n",
      "Epoch 467/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3073.0071 - mae: 22.9063 - val_loss: 11833.5107 - val_mae: 38.3148\n",
      "Epoch 468/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2829.4192 - mae: 23.8285 - val_loss: 11064.4941 - val_mae: 37.4948\n",
      "Epoch 469/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3717.9080 - mae: 24.8985 - val_loss: 9321.6250 - val_mae: 37.9301\n",
      "Epoch 470/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3227.6836 - mae: 23.7285 - val_loss: 11311.7012 - val_mae: 40.9324\n",
      "Epoch 471/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3108.4846 - mae: 23.8519 - val_loss: 11417.3691 - val_mae: 39.9162\n",
      "Epoch 472/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3323.5017 - mae: 24.6868 - val_loss: 12123.6064 - val_mae: 39.4656\n",
      "Epoch 473/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3332.9875 - mae: 23.6451 - val_loss: 10018.7617 - val_mae: 38.3804\n",
      "Epoch 474/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3021.4395 - mae: 23.2182 - val_loss: 9283.5732 - val_mae: 39.0061\n",
      "Epoch 475/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4299.0928 - mae: 27.0023 - val_loss: 18246.5645 - val_mae: 52.6667\n",
      "Epoch 476/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3329.2708 - mae: 25.9849 - val_loss: 11136.2646 - val_mae: 41.0040\n",
      "Epoch 477/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3282.1833 - mae: 22.7170 - val_loss: 16752.8574 - val_mae: 60.6213\n",
      "Epoch 478/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3256.6174 - mae: 24.4915 - val_loss: 11312.1621 - val_mae: 37.3574\n",
      "Epoch 479/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2631.7378 - mae: 22.2129 - val_loss: 9896.4922 - val_mae: 38.1649\n",
      "Epoch 480/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3234.2024 - mae: 24.2524 - val_loss: 20735.9961 - val_mae: 53.7174\n",
      "Epoch 481/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3955.6863 - mae: 24.1030 - val_loss: 11173.0059 - val_mae: 39.5851\n",
      "Epoch 482/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3723.2268 - mae: 24.4414 - val_loss: 11280.5039 - val_mae: 39.0777\n",
      "Epoch 483/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3417.8359 - mae: 25.3357 - val_loss: 11471.9453 - val_mae: 38.7580\n",
      "Epoch 484/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3603.9878 - mae: 25.1987 - val_loss: 12266.0684 - val_mae: 40.5939\n",
      "Epoch 485/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2695.6995 - mae: 21.4165 - val_loss: 14409.7471 - val_mae: 52.3775\n",
      "Epoch 486/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3692.5840 - mae: 25.8615 - val_loss: 13136.0586 - val_mae: 40.1015\n",
      "Epoch 487/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3350.8228 - mae: 23.6671 - val_loss: 13441.9844 - val_mae: 44.8047\n",
      "Epoch 488/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3061.3079 - mae: 23.4634 - val_loss: 13659.0674 - val_mae: 41.5906\n",
      "Epoch 489/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3079.5007 - mae: 22.7540 - val_loss: 19092.3184 - val_mae: 55.9515\n",
      "Epoch 490/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3701.7307 - mae: 25.7684 - val_loss: 13544.9180 - val_mae: 40.3738\n",
      "Epoch 491/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2758.7866 - mae: 22.4152 - val_loss: 16991.7324 - val_mae: 61.0336\n",
      "Epoch 492/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3405.4590 - mae: 25.3249 - val_loss: 14148.8184 - val_mae: 49.0729\n",
      "Epoch 493/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3941.3718 - mae: 23.4578 - val_loss: 12585.8896 - val_mae: 37.7597\n",
      "Epoch 494/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3613.4360 - mae: 23.9662 - val_loss: 12690.0605 - val_mae: 40.3763\n",
      "Epoch 495/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2814.7549 - mae: 22.3907 - val_loss: 14939.9619 - val_mae: 42.0787\n",
      "Epoch 496/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3068.8923 - mae: 23.9718 - val_loss: 11291.4365 - val_mae: 47.0553\n",
      "Epoch 497/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3273.5332 - mae: 23.4869 - val_loss: 30280.8789 - val_mae: 71.1330\n",
      "Epoch 498/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3158.0952 - mae: 24.3101 - val_loss: 13867.4893 - val_mae: 41.9191\n",
      "Epoch 499/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3477.0176 - mae: 23.3819 - val_loss: 11487.1436 - val_mae: 40.1665\n",
      "Epoch 500/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2788.5713 - mae: 22.0928 - val_loss: 15769.1865 - val_mae: 42.9156\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "EPOCHS = 500\n",
    "# Store training stats\n",
    "history = model.fit(train_data, y_train, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f5c2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 32)                23552     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,297\n",
      "Trainable params: 24,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),  \n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "      \n",
    "    keras.layers.Dense(8,activation=tf.nn.relu),\n",
    "      \n",
    "    keras.layers.Dense(8,activation=tf.nn.relu), \n",
    "      \n",
    "    keras.layers.Dense(1)\n",
    "  ], name=\"MLP_model\")\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14dd9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "70/70 [==============================] - 1s 4ms/step - loss: 15822017.0000 - mae: 2120.3918 - val_loss: 17359778.0000 - val_mae: 2274.6514\n",
      "Epoch 2/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 15180115.0000 - mae: 2072.7944 - val_loss: 15793490.0000 - val_mae: 2163.2783\n",
      "Epoch 3/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 12260189.0000 - mae: 1847.6461 - val_loss: 10455642.0000 - val_mae: 1736.3230\n",
      "Epoch 4/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5995543.5000 - mae: 1239.3322 - val_loss: 2654633.5000 - val_mae: 845.4451\n",
      "Epoch 5/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1210853.8750 - mae: 600.7048 - val_loss: 1071252.2500 - val_mae: 555.2159\n",
      "Epoch 6/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 689991.0625 - mae: 459.2953 - val_loss: 827616.2500 - val_mae: 472.2885\n",
      "Epoch 7/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 528225.1250 - mae: 392.7844 - val_loss: 697282.5625 - val_mae: 422.9678\n",
      "Epoch 8/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 411721.2500 - mae: 336.6982 - val_loss: 581193.4375 - val_mae: 358.8979\n",
      "Epoch 9/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 338266.2188 - mae: 293.0898 - val_loss: 524128.6875 - val_mae: 330.2026\n",
      "Epoch 10/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 277540.4062 - mae: 262.9328 - val_loss: 467267.4062 - val_mae: 297.7346\n",
      "Epoch 11/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 232741.4531 - mae: 237.7824 - val_loss: 423142.8750 - val_mae: 274.2059\n",
      "Epoch 12/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 195595.0469 - mae: 217.8421 - val_loss: 386678.1875 - val_mae: 254.4467\n",
      "Epoch 13/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 170456.2344 - mae: 203.3096 - val_loss: 350345.0625 - val_mae: 238.9745\n",
      "Epoch 14/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 145009.6094 - mae: 187.3081 - val_loss: 326303.7500 - val_mae: 231.4723\n",
      "Epoch 15/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 126997.5312 - mae: 176.0268 - val_loss: 309608.4062 - val_mae: 211.6040\n",
      "Epoch 16/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 111936.0938 - mae: 166.5740 - val_loss: 275247.8750 - val_mae: 200.6069\n",
      "Epoch 17/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 97516.1016 - mae: 155.2379 - val_loss: 259907.1562 - val_mae: 189.6523\n",
      "Epoch 18/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 84630.0234 - mae: 145.3600 - val_loss: 259843.6094 - val_mae: 187.5737\n",
      "Epoch 19/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 74466.3125 - mae: 137.0428 - val_loss: 197092.3906 - val_mae: 167.8667\n",
      "Epoch 20/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 66578.2812 - mae: 130.6095 - val_loss: 186156.2031 - val_mae: 157.8204\n",
      "Epoch 21/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 59000.8320 - mae: 122.2904 - val_loss: 156864.2656 - val_mae: 148.8074\n",
      "Epoch 22/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 51740.2266 - mae: 115.3175 - val_loss: 130452.5312 - val_mae: 141.5983\n",
      "Epoch 23/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 45236.5000 - mae: 108.4408 - val_loss: 112744.0156 - val_mae: 133.6066\n",
      "Epoch 24/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 40366.6680 - mae: 101.8185 - val_loss: 95429.9141 - val_mae: 126.6239\n",
      "Epoch 25/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 36779.8789 - mae: 97.2569 - val_loss: 83971.6094 - val_mae: 116.1842\n",
      "Epoch 26/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 32058.3867 - mae: 91.3369 - val_loss: 70964.3281 - val_mae: 109.5652\n",
      "Epoch 27/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 28390.9863 - mae: 86.9122 - val_loss: 59483.5898 - val_mae: 103.5936\n",
      "Epoch 28/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 25398.1680 - mae: 82.0689 - val_loss: 52996.3711 - val_mae: 100.4993\n",
      "Epoch 29/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 24248.9609 - mae: 79.2455 - val_loss: 43396.7109 - val_mae: 92.7389\n",
      "Epoch 30/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 21763.7461 - mae: 75.4341 - val_loss: 49046.7695 - val_mae: 103.4252\n",
      "Epoch 31/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 20064.9414 - mae: 72.3880 - val_loss: 35402.6289 - val_mae: 84.8344\n",
      "Epoch 32/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 19169.5898 - mae: 70.0393 - val_loss: 33677.0469 - val_mae: 82.3808\n",
      "Epoch 33/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 17566.5820 - mae: 67.4809 - val_loss: 28274.3262 - val_mae: 78.7503\n",
      "Epoch 34/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 15821.2920 - mae: 64.2428 - val_loss: 28304.3770 - val_mae: 77.8377\n",
      "Epoch 35/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 15333.8652 - mae: 61.6000 - val_loss: 27585.5449 - val_mae: 76.2296\n",
      "Epoch 36/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 14596.4951 - mae: 60.1536 - val_loss: 24393.3125 - val_mae: 71.2807\n",
      "Epoch 37/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 13702.1201 - mae: 59.5629 - val_loss: 23858.5605 - val_mae: 69.8857\n",
      "Epoch 38/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 13286.3896 - mae: 58.6951 - val_loss: 23899.8828 - val_mae: 67.5647\n",
      "Epoch 39/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12494.5723 - mae: 56.3942 - val_loss: 24001.7500 - val_mae: 71.5326\n",
      "Epoch 40/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 12212.5371 - mae: 54.9225 - val_loss: 21853.9062 - val_mae: 65.3526\n",
      "Epoch 41/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 11237.2373 - mae: 53.1371 - val_loss: 20277.5312 - val_mae: 64.3895\n",
      "Epoch 42/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 10512.5977 - mae: 51.1388 - val_loss: 20654.9023 - val_mae: 62.2443\n",
      "Epoch 43/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 10630.1719 - mae: 51.2193 - val_loss: 19202.6465 - val_mae: 64.7108\n",
      "Epoch 44/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9807.8096 - mae: 50.3426 - val_loss: 21826.5000 - val_mae: 63.1993\n",
      "Epoch 45/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 10201.8984 - mae: 49.5992 - val_loss: 18545.7051 - val_mae: 61.0280\n",
      "Epoch 46/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9475.7188 - mae: 48.1991 - val_loss: 20428.7266 - val_mae: 61.1000\n",
      "Epoch 47/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 9015.5986 - mae: 47.1945 - val_loss: 18723.2793 - val_mae: 60.8949\n",
      "Epoch 48/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 8757.8096 - mae: 46.4030 - val_loss: 17509.2070 - val_mae: 58.6922\n",
      "Epoch 49/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 8423.8906 - mae: 45.5666 - val_loss: 22297.0020 - val_mae: 69.5963\n",
      "Epoch 50/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7828.2305 - mae: 43.8564 - val_loss: 17362.2031 - val_mae: 60.3405\n",
      "Epoch 51/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7174.9175 - mae: 43.0397 - val_loss: 19845.8594 - val_mae: 62.1685\n",
      "Epoch 52/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7699.4497 - mae: 43.5091 - val_loss: 21079.8594 - val_mae: 60.3247\n",
      "Epoch 53/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7507.4028 - mae: 43.2254 - val_loss: 17198.3809 - val_mae: 59.1906\n",
      "Epoch 54/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 7626.1211 - mae: 42.0056 - val_loss: 16775.4219 - val_mae: 58.9374\n",
      "Epoch 55/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6992.2163 - mae: 41.7666 - val_loss: 35403.1289 - val_mae: 88.1220\n",
      "Epoch 56/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7317.4038 - mae: 41.7740 - val_loss: 18195.7754 - val_mae: 55.1107\n",
      "Epoch 57/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7071.4556 - mae: 41.3402 - val_loss: 18307.3320 - val_mae: 56.0878\n",
      "Epoch 58/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 2ms/step - loss: 6817.4971 - mae: 40.2442 - val_loss: 16241.1455 - val_mae: 54.7779\n",
      "Epoch 59/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 7034.7026 - mae: 40.8432 - val_loss: 16897.0586 - val_mae: 54.2748\n",
      "Epoch 60/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6262.3076 - mae: 38.3596 - val_loss: 27618.4023 - val_mae: 76.2715\n",
      "Epoch 61/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6460.7910 - mae: 39.8323 - val_loss: 26052.8555 - val_mae: 67.0004\n",
      "Epoch 62/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6947.3452 - mae: 40.1666 - val_loss: 15154.9824 - val_mae: 57.1638\n",
      "Epoch 63/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5908.0405 - mae: 37.9232 - val_loss: 16447.5703 - val_mae: 55.5511\n",
      "Epoch 64/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6241.9121 - mae: 38.8797 - val_loss: 15839.4854 - val_mae: 55.6990\n",
      "Epoch 65/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6111.9482 - mae: 37.3220 - val_loss: 18436.5742 - val_mae: 57.6615\n",
      "Epoch 66/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 6181.1387 - mae: 38.1057 - val_loss: 16650.9062 - val_mae: 56.2537\n",
      "Epoch 67/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5655.4048 - mae: 36.9409 - val_loss: 18497.9160 - val_mae: 55.3816\n",
      "Epoch 68/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5907.3179 - mae: 37.1978 - val_loss: 15651.4209 - val_mae: 52.5305\n",
      "Epoch 69/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5018.2671 - mae: 35.3644 - val_loss: 14950.5605 - val_mae: 53.4086\n",
      "Epoch 70/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5645.4629 - mae: 37.3370 - val_loss: 16164.8350 - val_mae: 57.3418\n",
      "Epoch 71/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 5302.9043 - mae: 36.0232 - val_loss: 17835.3301 - val_mae: 57.9187\n",
      "Epoch 72/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 6005.4165 - mae: 37.3611 - val_loss: 16353.7686 - val_mae: 53.9465\n",
      "Epoch 73/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5102.9570 - mae: 35.5474 - val_loss: 17398.6309 - val_mae: 57.4532\n",
      "Epoch 74/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5270.6406 - mae: 35.8176 - val_loss: 16749.6895 - val_mae: 54.0167\n",
      "Epoch 75/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5172.9702 - mae: 34.7752 - val_loss: 17657.1992 - val_mae: 57.5764\n",
      "Epoch 76/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4842.0303 - mae: 34.7399 - val_loss: 44363.6250 - val_mae: 94.9377\n",
      "Epoch 77/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5147.9976 - mae: 34.9113 - val_loss: 26507.9004 - val_mae: 75.1267\n",
      "Epoch 78/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5016.7676 - mae: 34.2708 - val_loss: 14805.6455 - val_mae: 52.5647\n",
      "Epoch 79/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4798.6030 - mae: 33.6853 - val_loss: 16804.2754 - val_mae: 52.5757\n",
      "Epoch 80/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 5249.6675 - mae: 34.3925 - val_loss: 14624.3984 - val_mae: 49.0653\n",
      "Epoch 81/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4565.3062 - mae: 33.3162 - val_loss: 15109.7207 - val_mae: 50.6738\n",
      "Epoch 82/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4567.1074 - mae: 33.0107 - val_loss: 17034.3555 - val_mae: 55.6407\n",
      "Epoch 83/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4749.6870 - mae: 33.5293 - val_loss: 15068.4932 - val_mae: 49.7391\n",
      "Epoch 84/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4678.8477 - mae: 33.3683 - val_loss: 15470.7812 - val_mae: 50.6571\n",
      "Epoch 85/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4740.0010 - mae: 33.1616 - val_loss: 14049.7314 - val_mae: 49.1702\n",
      "Epoch 86/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4248.3960 - mae: 32.0894 - val_loss: 16412.8184 - val_mae: 49.1895\n",
      "Epoch 87/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4515.7422 - mae: 32.7300 - val_loss: 30543.8359 - val_mae: 70.5492\n",
      "Epoch 88/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4562.0288 - mae: 33.1607 - val_loss: 20479.1836 - val_mae: 62.7239\n",
      "Epoch 89/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4479.5479 - mae: 31.7192 - val_loss: 18939.1543 - val_mae: 52.4036\n",
      "Epoch 90/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4012.5198 - mae: 30.5592 - val_loss: 15215.4336 - val_mae: 54.8946\n",
      "Epoch 91/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4247.1875 - mae: 31.4132 - val_loss: 18060.0098 - val_mae: 52.6108\n",
      "Epoch 92/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4359.2495 - mae: 32.0100 - val_loss: 15537.9639 - val_mae: 48.8020\n",
      "Epoch 93/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3967.1797 - mae: 31.3169 - val_loss: 15328.9873 - val_mae: 52.6110\n",
      "Epoch 94/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4222.8438 - mae: 31.4615 - val_loss: 16091.4512 - val_mae: 49.4259\n",
      "Epoch 95/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4108.0317 - mae: 31.6709 - val_loss: 16954.3652 - val_mae: 50.0020\n",
      "Epoch 96/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4031.4055 - mae: 31.0375 - val_loss: 19238.2539 - val_mae: 52.4331\n",
      "Epoch 97/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4039.2729 - mae: 30.6285 - val_loss: 17989.5508 - val_mae: 57.5317\n",
      "Epoch 98/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3640.6453 - mae: 29.9681 - val_loss: 16463.3594 - val_mae: 49.8173\n",
      "Epoch 99/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4181.7842 - mae: 31.8594 - val_loss: 14223.7275 - val_mae: 48.3573\n",
      "Epoch 100/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4052.7769 - mae: 30.6914 - val_loss: 18086.1738 - val_mae: 54.0047\n",
      "Epoch 101/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4183.3696 - mae: 31.2906 - val_loss: 15554.0283 - val_mae: 52.1215\n",
      "Epoch 102/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4047.7222 - mae: 30.6294 - val_loss: 15457.7764 - val_mae: 48.6137\n",
      "Epoch 103/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3918.5559 - mae: 29.6880 - val_loss: 15675.0254 - val_mae: 48.3050\n",
      "Epoch 104/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3602.0964 - mae: 29.6557 - val_loss: 15120.6377 - val_mae: 46.6333\n",
      "Epoch 105/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4083.6277 - mae: 29.5887 - val_loss: 16572.3262 - val_mae: 49.5851\n",
      "Epoch 106/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 4120.5996 - mae: 30.3171 - val_loss: 13906.2139 - val_mae: 49.1545\n",
      "Epoch 107/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3927.7864 - mae: 30.5136 - val_loss: 15518.8818 - val_mae: 47.0974\n",
      "Epoch 108/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3854.7935 - mae: 30.1206 - val_loss: 13439.2959 - val_mae: 46.5558\n",
      "Epoch 109/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3814.5269 - mae: 29.7927 - val_loss: 15554.6807 - val_mae: 49.5731\n",
      "Epoch 110/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3521.6860 - mae: 29.0032 - val_loss: 13959.5059 - val_mae: 45.8286\n",
      "Epoch 111/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3536.6035 - mae: 28.6625 - val_loss: 14121.0830 - val_mae: 47.1825\n",
      "Epoch 112/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3777.9834 - mae: 30.0815 - val_loss: 14227.9082 - val_mae: 48.2009\n",
      "Epoch 113/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 4212.9448 - mae: 29.9355 - val_loss: 16182.0273 - val_mae: 50.9831\n",
      "Epoch 114/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3494.7068 - mae: 28.4945 - val_loss: 17558.5586 - val_mae: 55.5325\n",
      "Epoch 115/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3522.0173 - mae: 29.0089 - val_loss: 14469.6846 - val_mae: 48.7423\n",
      "Epoch 116/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 2ms/step - loss: 4142.0762 - mae: 30.6312 - val_loss: 13472.2979 - val_mae: 44.2216\n",
      "Epoch 117/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3170.7625 - mae: 27.6271 - val_loss: 24276.0234 - val_mae: 62.3692\n",
      "Epoch 118/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3907.8357 - mae: 29.7409 - val_loss: 15039.3086 - val_mae: 47.4349\n",
      "Epoch 119/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3752.2595 - mae: 29.4451 - val_loss: 15267.2227 - val_mae: 46.5058\n",
      "Epoch 120/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3291.5474 - mae: 27.5537 - val_loss: 13847.3643 - val_mae: 45.8939\n",
      "Epoch 121/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3683.6372 - mae: 29.0325 - val_loss: 13598.8096 - val_mae: 45.4177\n",
      "Epoch 122/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3285.8901 - mae: 27.7947 - val_loss: 15109.4854 - val_mae: 47.8410\n",
      "Epoch 123/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3445.7568 - mae: 28.1646 - val_loss: 17027.3242 - val_mae: 51.0540\n",
      "Epoch 124/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3548.9709 - mae: 28.2461 - val_loss: 16227.4053 - val_mae: 50.6336\n",
      "Epoch 125/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3548.1921 - mae: 28.8015 - val_loss: 17068.7988 - val_mae: 50.2544\n",
      "Epoch 126/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3163.0955 - mae: 27.8097 - val_loss: 16952.2832 - val_mae: 48.1748\n",
      "Epoch 127/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3827.0237 - mae: 28.1658 - val_loss: 21402.5117 - val_mae: 55.1021\n",
      "Epoch 128/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3094.8850 - mae: 27.1293 - val_loss: 17762.1562 - val_mae: 50.7554\n",
      "Epoch 129/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3209.4297 - mae: 27.2980 - val_loss: 17107.8750 - val_mae: 49.8409\n",
      "Epoch 130/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3264.0212 - mae: 27.5596 - val_loss: 14043.4131 - val_mae: 44.1472\n",
      "Epoch 131/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3280.4578 - mae: 27.3667 - val_loss: 13788.8008 - val_mae: 47.0000\n",
      "Epoch 132/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3463.5935 - mae: 28.0657 - val_loss: 14147.5479 - val_mae: 47.0168\n",
      "Epoch 133/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3441.9199 - mae: 28.2273 - val_loss: 15793.7881 - val_mae: 45.3298\n",
      "Epoch 134/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3470.1709 - mae: 27.3044 - val_loss: 21762.9453 - val_mae: 57.0690\n",
      "Epoch 135/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3325.4719 - mae: 27.7518 - val_loss: 15308.3154 - val_mae: 46.9427\n",
      "Epoch 136/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3446.1265 - mae: 28.1311 - val_loss: 13793.7764 - val_mae: 44.2193\n",
      "Epoch 137/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2770.8916 - mae: 25.2569 - val_loss: 24714.2676 - val_mae: 73.7283\n",
      "Epoch 138/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3636.2683 - mae: 27.9138 - val_loss: 16473.6426 - val_mae: 47.5147\n",
      "Epoch 139/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3427.4333 - mae: 27.1939 - val_loss: 14344.5908 - val_mae: 48.4971\n",
      "Epoch 140/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3185.3435 - mae: 27.1295 - val_loss: 13441.4189 - val_mae: 45.5805\n",
      "Epoch 141/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3165.6611 - mae: 26.4784 - val_loss: 15507.5518 - val_mae: 52.9964\n",
      "Epoch 142/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3009.7866 - mae: 26.2504 - val_loss: 13307.4922 - val_mae: 45.6081\n",
      "Epoch 143/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3101.6152 - mae: 26.5568 - val_loss: 14101.1475 - val_mae: 45.9571\n",
      "Epoch 144/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2994.6978 - mae: 25.9502 - val_loss: 14460.4316 - val_mae: 44.6724\n",
      "Epoch 145/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3009.2075 - mae: 25.9063 - val_loss: 13339.3984 - val_mae: 44.5511\n",
      "Epoch 146/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2860.8296 - mae: 26.6588 - val_loss: 15413.8242 - val_mae: 45.7983\n",
      "Epoch 147/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3010.7080 - mae: 25.5646 - val_loss: 16512.9180 - val_mae: 54.0938\n",
      "Epoch 148/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3354.1213 - mae: 26.0488 - val_loss: 15182.6934 - val_mae: 44.2962\n",
      "Epoch 149/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3220.3215 - mae: 26.8503 - val_loss: 14263.5234 - val_mae: 43.5171\n",
      "Epoch 150/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3054.0588 - mae: 26.5442 - val_loss: 17987.2305 - val_mae: 57.1670\n",
      "Epoch 151/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3110.5857 - mae: 26.8498 - val_loss: 14603.4707 - val_mae: 44.9804\n",
      "Epoch 152/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2603.2146 - mae: 25.0914 - val_loss: 15388.1992 - val_mae: 45.5486\n",
      "Epoch 153/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2842.6208 - mae: 25.3355 - val_loss: 13716.0039 - val_mae: 43.7444\n",
      "Epoch 154/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2903.4099 - mae: 25.3804 - val_loss: 15079.6543 - val_mae: 44.2674\n",
      "Epoch 155/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3158.3696 - mae: 26.4840 - val_loss: 14340.0332 - val_mae: 44.7420\n",
      "Epoch 156/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2978.9126 - mae: 26.2312 - val_loss: 13997.6699 - val_mae: 45.4668\n",
      "Epoch 157/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2866.1804 - mae: 25.3965 - val_loss: 14973.0527 - val_mae: 51.6735\n",
      "Epoch 158/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3045.8728 - mae: 26.2689 - val_loss: 26793.4980 - val_mae: 69.0741\n",
      "Epoch 159/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3013.9033 - mae: 26.6021 - val_loss: 13454.5010 - val_mae: 42.0242\n",
      "Epoch 160/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2527.6665 - mae: 24.6509 - val_loss: 16075.2422 - val_mae: 46.8345\n",
      "Epoch 161/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2991.0767 - mae: 26.4898 - val_loss: 15583.7666 - val_mae: 47.0862\n",
      "Epoch 162/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2865.0415 - mae: 25.5919 - val_loss: 16216.2363 - val_mae: 50.2097\n",
      "Epoch 163/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3314.1206 - mae: 26.8133 - val_loss: 13325.0762 - val_mae: 45.3300\n",
      "Epoch 164/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2718.9341 - mae: 25.3852 - val_loss: 13923.0166 - val_mae: 42.5832\n",
      "Epoch 165/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2649.6570 - mae: 25.4518 - val_loss: 14310.7441 - val_mae: 47.2435\n",
      "Epoch 166/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2812.2410 - mae: 25.5060 - val_loss: 13193.2451 - val_mae: 43.3920\n",
      "Epoch 167/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2543.6477 - mae: 25.2565 - val_loss: 13068.1367 - val_mae: 42.9515\n",
      "Epoch 168/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 3080.6362 - mae: 26.4075 - val_loss: 16615.4434 - val_mae: 50.3415\n",
      "Epoch 169/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2867.0962 - mae: 25.0405 - val_loss: 13676.2539 - val_mae: 43.7557\n",
      "Epoch 170/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2504.0308 - mae: 24.0650 - val_loss: 14693.8125 - val_mae: 44.2257\n",
      "Epoch 171/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2902.8687 - mae: 25.5021 - val_loss: 23245.6777 - val_mae: 60.4284\n",
      "Epoch 172/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2861.9915 - mae: 25.9307 - val_loss: 13351.6650 - val_mae: 45.7234\n",
      "Epoch 173/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2711.2878 - mae: 24.2289 - val_loss: 12971.8789 - val_mae: 43.4646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3108.1316 - mae: 26.2748 - val_loss: 27880.1328 - val_mae: 70.7655\n",
      "Epoch 175/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2717.1521 - mae: 25.0785 - val_loss: 13244.7227 - val_mae: 41.7602\n",
      "Epoch 176/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2907.0325 - mae: 25.6065 - val_loss: 22964.4023 - val_mae: 58.2986\n",
      "Epoch 177/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2594.8572 - mae: 24.5200 - val_loss: 15389.7852 - val_mae: 53.4731\n",
      "Epoch 178/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2745.8857 - mae: 24.2168 - val_loss: 14234.5820 - val_mae: 43.5327\n",
      "Epoch 179/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3190.1094 - mae: 25.5819 - val_loss: 13501.3789 - val_mae: 41.9046\n",
      "Epoch 180/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2602.4524 - mae: 23.9898 - val_loss: 12747.4570 - val_mae: 41.8140\n",
      "Epoch 181/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2923.3203 - mae: 25.5086 - val_loss: 14036.4180 - val_mae: 48.0573\n",
      "Epoch 182/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2909.3484 - mae: 25.2981 - val_loss: 14859.7119 - val_mae: 44.3193\n",
      "Epoch 183/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2593.5615 - mae: 23.9878 - val_loss: 21702.4980 - val_mae: 59.7282\n",
      "Epoch 184/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 3006.1196 - mae: 24.8346 - val_loss: 12342.5352 - val_mae: 41.5972\n",
      "Epoch 185/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2722.0439 - mae: 24.5420 - val_loss: 14155.7783 - val_mae: 42.8528\n",
      "Epoch 186/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2509.6345 - mae: 23.8224 - val_loss: 12361.9844 - val_mae: 39.6087\n",
      "Epoch 187/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2635.9773 - mae: 24.4935 - val_loss: 19991.6621 - val_mae: 54.8017\n",
      "Epoch 188/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2874.4121 - mae: 24.5842 - val_loss: 14818.9590 - val_mae: 49.3912\n",
      "Epoch 189/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2486.4478 - mae: 24.5710 - val_loss: 13536.6533 - val_mae: 44.3673\n",
      "Epoch 190/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2757.6699 - mae: 25.3206 - val_loss: 13010.5645 - val_mae: 39.6842\n",
      "Epoch 191/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2778.8438 - mae: 23.8799 - val_loss: 16068.8516 - val_mae: 47.2305\n",
      "Epoch 192/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2590.1113 - mae: 24.2979 - val_loss: 12383.4277 - val_mae: 42.1366\n",
      "Epoch 193/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2616.7441 - mae: 24.5166 - val_loss: 19619.8848 - val_mae: 62.9793\n",
      "Epoch 194/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2810.8682 - mae: 23.3085 - val_loss: 13516.4453 - val_mae: 43.1722\n",
      "Epoch 195/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2693.3628 - mae: 24.2797 - val_loss: 16645.0176 - val_mae: 56.5007\n",
      "Epoch 196/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2593.9023 - mae: 24.1785 - val_loss: 13261.4268 - val_mae: 47.5547\n",
      "Epoch 197/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2605.0005 - mae: 24.3528 - val_loss: 14016.3203 - val_mae: 43.5629\n",
      "Epoch 198/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2647.8354 - mae: 24.4159 - val_loss: 11821.1465 - val_mae: 40.7347\n",
      "Epoch 199/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2817.7988 - mae: 23.9492 - val_loss: 12589.1592 - val_mae: 40.5497\n",
      "Epoch 200/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2420.9929 - mae: 23.3922 - val_loss: 16457.4688 - val_mae: 57.9916\n",
      "Epoch 201/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2612.6047 - mae: 23.8631 - val_loss: 12402.3311 - val_mae: 41.5052\n",
      "Epoch 202/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2893.6277 - mae: 25.6519 - val_loss: 14030.8096 - val_mae: 47.7928\n",
      "Epoch 203/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2404.4373 - mae: 23.1803 - val_loss: 10939.4189 - val_mae: 43.4124\n",
      "Epoch 204/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2394.4795 - mae: 23.4287 - val_loss: 20569.7754 - val_mae: 69.8114\n",
      "Epoch 205/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2689.6155 - mae: 24.5340 - val_loss: 13706.1602 - val_mae: 42.7287\n",
      "Epoch 206/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2759.7249 - mae: 23.7484 - val_loss: 14503.1387 - val_mae: 46.5583\n",
      "Epoch 207/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2559.3625 - mae: 24.0368 - val_loss: 13603.5869 - val_mae: 41.2539\n",
      "Epoch 208/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2821.3530 - mae: 24.2602 - val_loss: 12259.0850 - val_mae: 40.3105\n",
      "Epoch 209/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2506.6155 - mae: 22.9830 - val_loss: 13676.7686 - val_mae: 40.7960\n",
      "Epoch 210/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2712.8381 - mae: 23.9004 - val_loss: 11876.3193 - val_mae: 41.9550\n",
      "Epoch 211/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2483.4636 - mae: 23.6392 - val_loss: 25136.6191 - val_mae: 61.3068\n",
      "Epoch 212/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2533.2146 - mae: 24.1374 - val_loss: 15648.7012 - val_mae: 44.0883\n",
      "Epoch 213/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2602.7034 - mae: 23.8076 - val_loss: 13949.6816 - val_mae: 45.1784\n",
      "Epoch 214/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2294.6606 - mae: 22.7883 - val_loss: 14638.5527 - val_mae: 45.3320\n",
      "Epoch 215/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2661.2964 - mae: 23.6832 - val_loss: 16778.0254 - val_mae: 47.2321\n",
      "Epoch 216/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2393.4741 - mae: 23.7396 - val_loss: 15901.6807 - val_mae: 47.4000\n",
      "Epoch 217/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2615.6721 - mae: 23.6748 - val_loss: 12611.5674 - val_mae: 42.3184\n",
      "Epoch 218/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2763.5818 - mae: 24.0353 - val_loss: 12394.7939 - val_mae: 45.0900\n",
      "Epoch 219/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1980.6870 - mae: 20.8891 - val_loss: 23419.5195 - val_mae: 62.2375\n",
      "Epoch 220/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2566.7268 - mae: 23.5157 - val_loss: 14445.3965 - val_mae: 46.8278\n",
      "Epoch 221/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2283.9810 - mae: 22.7513 - val_loss: 12426.6689 - val_mae: 43.3538\n",
      "Epoch 222/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2557.9878 - mae: 23.7925 - val_loss: 17676.9531 - val_mae: 49.3210\n",
      "Epoch 223/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2613.4802 - mae: 23.7852 - val_loss: 17218.9648 - val_mae: 48.0799\n",
      "Epoch 224/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2017.7578 - mae: 21.7955 - val_loss: 13930.9844 - val_mae: 42.4326\n",
      "Epoch 225/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2786.5364 - mae: 24.3981 - val_loss: 14328.4521 - val_mae: 42.8735\n",
      "Epoch 226/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2467.2957 - mae: 23.6429 - val_loss: 17375.0469 - val_mae: 50.8577\n",
      "Epoch 227/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2595.6997 - mae: 23.8456 - val_loss: 16227.0381 - val_mae: 44.3979\n",
      "Epoch 228/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2419.1975 - mae: 23.4967 - val_loss: 13732.4941 - val_mae: 42.4605\n",
      "Epoch 229/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2353.7090 - mae: 23.0297 - val_loss: 12934.6328 - val_mae: 43.3113\n",
      "Epoch 230/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2206.1792 - mae: 22.4392 - val_loss: 21768.3672 - val_mae: 68.0738\n",
      "Epoch 231/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2124.9119 - mae: 22.0965 - val_loss: 15774.6396 - val_mae: 43.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2342.6543 - mae: 22.7868 - val_loss: 13179.3379 - val_mae: 42.0615\n",
      "Epoch 233/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2295.5950 - mae: 23.2710 - val_loss: 16589.6133 - val_mae: 44.4225\n",
      "Epoch 234/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2172.9573 - mae: 22.5297 - val_loss: 16193.7451 - val_mae: 43.6107\n",
      "Epoch 235/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2387.9851 - mae: 23.0003 - val_loss: 17989.3359 - val_mae: 46.4152\n",
      "Epoch 236/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2373.6035 - mae: 23.2654 - val_loss: 14650.7617 - val_mae: 41.3289\n",
      "Epoch 237/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2569.4939 - mae: 23.3438 - val_loss: 13338.6738 - val_mae: 45.0707\n",
      "Epoch 238/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2404.7134 - mae: 21.6845 - val_loss: 23525.9746 - val_mae: 71.1928\n",
      "Epoch 239/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2370.4417 - mae: 22.7154 - val_loss: 27077.5664 - val_mae: 67.4324\n",
      "Epoch 240/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2552.8523 - mae: 22.7148 - val_loss: 14014.0127 - val_mae: 41.9838\n",
      "Epoch 241/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2760.0674 - mae: 24.1901 - val_loss: 16391.8711 - val_mae: 57.1758\n",
      "Epoch 242/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2241.3618 - mae: 21.9739 - val_loss: 25181.8457 - val_mae: 63.8233\n",
      "Epoch 243/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2562.5625 - mae: 23.4482 - val_loss: 18134.6348 - val_mae: 48.8165\n",
      "Epoch 244/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2178.9143 - mae: 22.3028 - val_loss: 13099.2666 - val_mae: 41.6364\n",
      "Epoch 245/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2586.0471 - mae: 24.6118 - val_loss: 21367.5625 - val_mae: 58.7452\n",
      "Epoch 246/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2377.4285 - mae: 23.3809 - val_loss: 15428.4551 - val_mae: 46.7271\n",
      "Epoch 247/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2463.0598 - mae: 22.4259 - val_loss: 33927.8359 - val_mae: 75.7664\n",
      "Epoch 248/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2393.7737 - mae: 22.9255 - val_loss: 19621.5586 - val_mae: 52.3113\n",
      "Epoch 249/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2220.7964 - mae: 22.0387 - val_loss: 12714.9258 - val_mae: 40.5457\n",
      "Epoch 250/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2290.3638 - mae: 22.1718 - val_loss: 12699.0898 - val_mae: 41.8658\n",
      "Epoch 251/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2561.0759 - mae: 22.8347 - val_loss: 13285.4004 - val_mae: 42.3046\n",
      "Epoch 252/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2232.6921 - mae: 22.2871 - val_loss: 32001.0781 - val_mae: 77.0511\n",
      "Epoch 253/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2359.3120 - mae: 22.2321 - val_loss: 13503.0361 - val_mae: 40.9021\n",
      "Epoch 254/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2235.7083 - mae: 21.8890 - val_loss: 13441.5752 - val_mae: 41.5512\n",
      "Epoch 255/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2334.2449 - mae: 23.0620 - val_loss: 17233.4238 - val_mae: 49.4432\n",
      "Epoch 256/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2046.6776 - mae: 22.1919 - val_loss: 19919.9062 - val_mae: 53.0465\n",
      "Epoch 257/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2490.4465 - mae: 22.5151 - val_loss: 15245.3750 - val_mae: 43.6183\n",
      "Epoch 258/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2517.4128 - mae: 23.3718 - val_loss: 13516.5859 - val_mae: 42.3839\n",
      "Epoch 259/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2090.5569 - mae: 22.3079 - val_loss: 12505.2266 - val_mae: 44.9774\n",
      "Epoch 260/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2369.5869 - mae: 22.3384 - val_loss: 13819.2275 - val_mae: 41.2608\n",
      "Epoch 261/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2004.9640 - mae: 20.8768 - val_loss: 11907.0254 - val_mae: 38.1167\n",
      "Epoch 262/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2231.3894 - mae: 22.8068 - val_loss: 15579.4014 - val_mae: 41.5288\n",
      "Epoch 263/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2225.1384 - mae: 22.0677 - val_loss: 12123.0312 - val_mae: 39.3284\n",
      "Epoch 264/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2324.3848 - mae: 22.5714 - val_loss: 16663.9023 - val_mae: 46.8113\n",
      "Epoch 265/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1951.5327 - mae: 21.4409 - val_loss: 31242.1621 - val_mae: 74.1586\n",
      "Epoch 266/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2224.8799 - mae: 22.1421 - val_loss: 18763.1797 - val_mae: 54.1612\n",
      "Epoch 267/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2341.7031 - mae: 23.3003 - val_loss: 13230.4980 - val_mae: 40.4112\n",
      "Epoch 268/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2212.3132 - mae: 22.5124 - val_loss: 21511.1406 - val_mae: 53.4878\n",
      "Epoch 269/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2569.5703 - mae: 21.9669 - val_loss: 13769.8711 - val_mae: 40.5696\n",
      "Epoch 270/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2260.5017 - mae: 22.7956 - val_loss: 14911.2041 - val_mae: 42.8919\n",
      "Epoch 271/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2122.4272 - mae: 20.5817 - val_loss: 12799.1260 - val_mae: 40.1292\n",
      "Epoch 272/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2033.3728 - mae: 21.6631 - val_loss: 12681.5469 - val_mae: 41.7749\n",
      "Epoch 273/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2484.3752 - mae: 23.1079 - val_loss: 14979.4365 - val_mae: 43.1108\n",
      "Epoch 274/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2051.4407 - mae: 21.9581 - val_loss: 12894.3672 - val_mae: 39.8520\n",
      "Epoch 275/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2540.3579 - mae: 22.4708 - val_loss: 13995.9961 - val_mae: 41.7443\n",
      "Epoch 276/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2072.7969 - mae: 21.3102 - val_loss: 12321.7549 - val_mae: 41.1510\n",
      "Epoch 277/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2046.0724 - mae: 21.9582 - val_loss: 11982.6416 - val_mae: 40.9393\n",
      "Epoch 278/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1971.9857 - mae: 21.3496 - val_loss: 14750.6035 - val_mae: 42.9591\n",
      "Epoch 279/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2442.7397 - mae: 23.2139 - val_loss: 22192.0273 - val_mae: 51.9549\n",
      "Epoch 280/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2705.2854 - mae: 23.2640 - val_loss: 14976.9717 - val_mae: 50.6017\n",
      "Epoch 281/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1907.8766 - mae: 21.0198 - val_loss: 13065.8818 - val_mae: 41.6580\n",
      "Epoch 282/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2258.6370 - mae: 21.1287 - val_loss: 12842.0293 - val_mae: 39.9562\n",
      "Epoch 283/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2145.4253 - mae: 22.0154 - val_loss: 13582.2686 - val_mae: 40.8254\n",
      "Epoch 284/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2017.6285 - mae: 21.3262 - val_loss: 16164.2832 - val_mae: 52.4160\n",
      "Epoch 285/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2331.5410 - mae: 22.9037 - val_loss: 13864.9316 - val_mae: 44.6637\n",
      "Epoch 286/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2386.1726 - mae: 22.0105 - val_loss: 15777.4248 - val_mae: 43.4917\n",
      "Epoch 287/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2113.0693 - mae: 21.7022 - val_loss: 37887.3164 - val_mae: 83.2161\n",
      "Epoch 288/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2170.7097 - mae: 21.6521 - val_loss: 12949.5029 - val_mae: 41.0329\n",
      "Epoch 289/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2113.6873 - mae: 22.0009 - val_loss: 13410.6123 - val_mae: 40.4290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2284.8247 - mae: 21.8908 - val_loss: 11526.8193 - val_mae: 40.0301\n",
      "Epoch 291/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2478.7019 - mae: 22.2145 - val_loss: 12416.4512 - val_mae: 43.7127\n",
      "Epoch 292/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2127.3081 - mae: 21.2915 - val_loss: 13461.6299 - val_mae: 41.9982\n",
      "Epoch 293/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2177.0696 - mae: 22.3101 - val_loss: 12615.7393 - val_mae: 43.8105\n",
      "Epoch 294/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2486.9058 - mae: 22.3856 - val_loss: 11678.0430 - val_mae: 40.3383\n",
      "Epoch 295/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2151.9990 - mae: 21.5410 - val_loss: 12362.2266 - val_mae: 46.2845\n",
      "Epoch 296/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2275.9915 - mae: 22.3379 - val_loss: 12894.9834 - val_mae: 42.1788\n",
      "Epoch 297/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2446.6763 - mae: 22.0976 - val_loss: 12594.6553 - val_mae: 42.7037\n",
      "Epoch 298/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2222.3713 - mae: 20.7623 - val_loss: 13850.0840 - val_mae: 53.5781\n",
      "Epoch 299/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2149.2751 - mae: 22.0358 - val_loss: 15515.4248 - val_mae: 42.0014\n",
      "Epoch 300/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1893.7047 - mae: 21.4422 - val_loss: 11199.3867 - val_mae: 39.2924\n",
      "Epoch 301/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2123.2073 - mae: 22.4922 - val_loss: 19356.2422 - val_mae: 52.7687\n",
      "Epoch 302/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2141.6165 - mae: 21.4841 - val_loss: 15117.4014 - val_mae: 45.7783\n",
      "Epoch 303/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2024.2717 - mae: 21.5375 - val_loss: 14564.3467 - val_mae: 43.8527\n",
      "Epoch 304/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2257.8916 - mae: 22.5066 - val_loss: 12260.0420 - val_mae: 40.4251\n",
      "Epoch 305/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1918.2424 - mae: 20.5830 - val_loss: 12497.9512 - val_mae: 42.8267\n",
      "Epoch 306/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2077.1042 - mae: 20.9717 - val_loss: 12832.8857 - val_mae: 42.3625\n",
      "Epoch 307/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2018.4917 - mae: 20.9561 - val_loss: 11664.4541 - val_mae: 41.8609\n",
      "Epoch 308/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2259.2510 - mae: 21.6349 - val_loss: 14545.0146 - val_mae: 41.6514\n",
      "Epoch 309/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1965.9434 - mae: 20.4343 - val_loss: 13825.5781 - val_mae: 40.7081\n",
      "Epoch 310/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2280.5530 - mae: 22.4797 - val_loss: 14768.5049 - val_mae: 42.0595\n",
      "Epoch 311/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1840.2889 - mae: 20.4577 - val_loss: 12622.9727 - val_mae: 45.6200\n",
      "Epoch 312/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2261.8599 - mae: 22.0149 - val_loss: 13076.3730 - val_mae: 40.8646\n",
      "Epoch 313/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2193.1992 - mae: 21.9249 - val_loss: 14728.4883 - val_mae: 43.8402\n",
      "Epoch 314/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2135.9070 - mae: 22.3698 - val_loss: 11348.9463 - val_mae: 38.5440\n",
      "Epoch 315/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1890.3624 - mae: 21.2273 - val_loss: 17776.4961 - val_mae: 51.5278\n",
      "Epoch 316/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2482.3589 - mae: 22.4749 - val_loss: 11281.0430 - val_mae: 38.6198\n",
      "Epoch 317/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2164.0879 - mae: 21.2065 - val_loss: 12928.0723 - val_mae: 44.3461\n",
      "Epoch 318/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2211.8872 - mae: 22.2173 - val_loss: 13180.5684 - val_mae: 40.6820\n",
      "Epoch 319/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1851.1135 - mae: 21.1333 - val_loss: 13391.1865 - val_mae: 47.0947\n",
      "Epoch 320/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2254.7278 - mae: 21.6524 - val_loss: 16141.0068 - val_mae: 46.1447\n",
      "Epoch 321/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2079.2461 - mae: 21.4582 - val_loss: 15417.0684 - val_mae: 42.9689\n",
      "Epoch 322/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2150.2639 - mae: 21.3787 - val_loss: 13304.8975 - val_mae: 43.7011\n",
      "Epoch 323/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1884.0276 - mae: 19.8307 - val_loss: 11137.4121 - val_mae: 40.1078\n",
      "Epoch 324/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2079.3552 - mae: 21.3974 - val_loss: 15379.4912 - val_mae: 42.9807\n",
      "Epoch 325/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2303.3445 - mae: 21.9712 - val_loss: 13775.3887 - val_mae: 42.0346\n",
      "Epoch 326/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1954.5616 - mae: 20.3550 - val_loss: 12936.3994 - val_mae: 41.2522\n",
      "Epoch 327/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2040.7709 - mae: 21.5848 - val_loss: 20559.0332 - val_mae: 51.7312\n",
      "Epoch 328/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1883.4045 - mae: 20.2723 - val_loss: 34995.5078 - val_mae: 81.0053\n",
      "Epoch 329/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2328.3179 - mae: 22.1547 - val_loss: 13394.7930 - val_mae: 44.0815\n",
      "Epoch 330/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1804.4153 - mae: 20.4743 - val_loss: 17065.5957 - val_mae: 53.1095\n",
      "Epoch 331/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2145.8318 - mae: 21.1891 - val_loss: 12073.7959 - val_mae: 40.5707\n",
      "Epoch 332/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2151.1064 - mae: 21.8437 - val_loss: 10823.9102 - val_mae: 39.0722\n",
      "Epoch 333/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2203.0723 - mae: 22.0157 - val_loss: 12318.4072 - val_mae: 38.2972\n",
      "Epoch 334/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1801.4775 - mae: 20.6252 - val_loss: 11505.4619 - val_mae: 40.0233\n",
      "Epoch 335/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1928.6080 - mae: 20.1357 - val_loss: 13741.4404 - val_mae: 43.7999\n",
      "Epoch 336/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2098.4226 - mae: 21.1526 - val_loss: 13375.8203 - val_mae: 46.9056\n",
      "Epoch 337/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1884.5939 - mae: 20.6249 - val_loss: 23944.7480 - val_mae: 56.6310\n",
      "Epoch 338/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2226.2556 - mae: 22.5588 - val_loss: 12240.6006 - val_mae: 40.3571\n",
      "Epoch 339/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1936.0206 - mae: 20.9280 - val_loss: 13701.3857 - val_mae: 41.9365\n",
      "Epoch 340/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1956.7251 - mae: 21.6677 - val_loss: 11688.8906 - val_mae: 40.5443\n",
      "Epoch 341/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2095.3818 - mae: 21.4249 - val_loss: 32283.1719 - val_mae: 72.5363\n",
      "Epoch 342/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2201.6577 - mae: 21.9741 - val_loss: 13099.4893 - val_mae: 41.2463\n",
      "Epoch 343/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2169.9897 - mae: 21.3638 - val_loss: 14461.1318 - val_mae: 42.5861\n",
      "Epoch 344/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1895.5853 - mae: 19.8732 - val_loss: 15414.3350 - val_mae: 52.1286\n",
      "Epoch 345/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2266.7727 - mae: 21.9672 - val_loss: 16592.6367 - val_mae: 46.1797\n",
      "Epoch 346/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1860.4144 - mae: 20.0778 - val_loss: 13875.3115 - val_mae: 43.3389\n",
      "Epoch 347/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1941.6422 - mae: 19.6812 - val_loss: 13540.2461 - val_mae: 40.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1869.4042 - mae: 19.7929 - val_loss: 15046.3047 - val_mae: 45.3413\n",
      "Epoch 349/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1847.2928 - mae: 21.0140 - val_loss: 15955.8428 - val_mae: 48.2820\n",
      "Epoch 350/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1753.1544 - mae: 20.5432 - val_loss: 13389.1357 - val_mae: 39.5183\n",
      "Epoch 351/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1855.3724 - mae: 20.7965 - val_loss: 12153.4072 - val_mae: 39.3409\n",
      "Epoch 352/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2032.0201 - mae: 20.9826 - val_loss: 13175.7578 - val_mae: 44.0510\n",
      "Epoch 353/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2020.1306 - mae: 21.3243 - val_loss: 13266.7510 - val_mae: 41.8976\n",
      "Epoch 354/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1790.1990 - mae: 19.9692 - val_loss: 14104.2080 - val_mae: 49.2288\n",
      "Epoch 355/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1955.2479 - mae: 20.0243 - val_loss: 22275.3379 - val_mae: 62.5957\n",
      "Epoch 356/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2011.7623 - mae: 20.3751 - val_loss: 11990.4189 - val_mae: 40.0801\n",
      "Epoch 357/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1705.9081 - mae: 19.4724 - val_loss: 23166.0977 - val_mae: 57.6345\n",
      "Epoch 358/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2032.0000 - mae: 21.1644 - val_loss: 11621.3486 - val_mae: 45.6579\n",
      "Epoch 359/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2311.5439 - mae: 20.7228 - val_loss: 11790.2637 - val_mae: 40.3851\n",
      "Epoch 360/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1759.7748 - mae: 19.6984 - val_loss: 11984.9619 - val_mae: 38.8410\n",
      "Epoch 361/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2289.9851 - mae: 21.7587 - val_loss: 11617.5352 - val_mae: 40.1940\n",
      "Epoch 362/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2038.9458 - mae: 20.2698 - val_loss: 11098.4990 - val_mae: 39.5100\n",
      "Epoch 363/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2202.6206 - mae: 21.6033 - val_loss: 12807.0674 - val_mae: 41.2430\n",
      "Epoch 364/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2056.9822 - mae: 20.4263 - val_loss: 18245.6582 - val_mae: 65.1132\n",
      "Epoch 365/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1917.9066 - mae: 20.7909 - val_loss: 14032.0195 - val_mae: 42.0478\n",
      "Epoch 366/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1935.1991 - mae: 20.0438 - val_loss: 11035.9355 - val_mae: 38.7042\n",
      "Epoch 367/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1942.9185 - mae: 20.9321 - val_loss: 12417.1572 - val_mae: 39.3387\n",
      "Epoch 368/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2240.2217 - mae: 20.5529 - val_loss: 11639.9648 - val_mae: 42.1522\n",
      "Epoch 369/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1561.1711 - mae: 19.1154 - val_loss: 24598.5801 - val_mae: 58.3004\n",
      "Epoch 370/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2157.5427 - mae: 21.4655 - val_loss: 31800.9570 - val_mae: 75.3699\n",
      "Epoch 371/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2178.7102 - mae: 20.8505 - val_loss: 11212.1465 - val_mae: 40.9667\n",
      "Epoch 372/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2053.8752 - mae: 20.6460 - val_loss: 12438.3525 - val_mae: 38.0493\n",
      "Epoch 373/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2074.9343 - mae: 21.3165 - val_loss: 13126.3242 - val_mae: 40.8994\n",
      "Epoch 374/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1857.3579 - mae: 20.2659 - val_loss: 11557.9697 - val_mae: 38.6474\n",
      "Epoch 375/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2431.0715 - mae: 21.3537 - val_loss: 16243.5283 - val_mae: 45.0904\n",
      "Epoch 376/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1835.7870 - mae: 19.9610 - val_loss: 14168.5449 - val_mae: 42.5742\n",
      "Epoch 377/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2160.5159 - mae: 21.2880 - val_loss: 15756.1094 - val_mae: 45.1486\n",
      "Epoch 378/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1920.3457 - mae: 19.7371 - val_loss: 21058.6270 - val_mae: 53.1866\n",
      "Epoch 379/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1907.3812 - mae: 19.6152 - val_loss: 12833.1729 - val_mae: 38.8768\n",
      "Epoch 380/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2046.8715 - mae: 20.1013 - val_loss: 23327.8047 - val_mae: 65.6304\n",
      "Epoch 381/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2096.6624 - mae: 20.9027 - val_loss: 11669.6074 - val_mae: 38.5732\n",
      "Epoch 382/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1778.2373 - mae: 20.4419 - val_loss: 15180.6562 - val_mae: 42.4548\n",
      "Epoch 383/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1954.9767 - mae: 20.0579 - val_loss: 10933.9004 - val_mae: 39.2128\n",
      "Epoch 384/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2234.9453 - mae: 21.2683 - val_loss: 12140.4492 - val_mae: 43.0113\n",
      "Epoch 385/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1703.3813 - mae: 19.9226 - val_loss: 10643.0801 - val_mae: 41.0375\n",
      "Epoch 386/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1905.6309 - mae: 21.0368 - val_loss: 11262.7705 - val_mae: 41.4181\n",
      "Epoch 387/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1888.2229 - mae: 20.9739 - val_loss: 13360.9727 - val_mae: 41.6566\n",
      "Epoch 388/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1702.6517 - mae: 19.8766 - val_loss: 20173.6348 - val_mae: 58.5011\n",
      "Epoch 389/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1862.2190 - mae: 20.6164 - val_loss: 16127.4248 - val_mae: 46.6841\n",
      "Epoch 390/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2146.5679 - mae: 21.4772 - val_loss: 11465.0801 - val_mae: 38.7192\n",
      "Epoch 391/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1623.6415 - mae: 19.4292 - val_loss: 12610.2656 - val_mae: 46.3016\n",
      "Epoch 392/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1962.3508 - mae: 20.7296 - val_loss: 14482.3428 - val_mae: 57.0189\n",
      "Epoch 393/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1933.1038 - mae: 20.5243 - val_loss: 14521.1396 - val_mae: 55.6104\n",
      "Epoch 394/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1979.3658 - mae: 21.0675 - val_loss: 9731.6455 - val_mae: 38.2749\n",
      "Epoch 395/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1896.6138 - mae: 20.7081 - val_loss: 11658.6953 - val_mae: 39.5730\n",
      "Epoch 396/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1876.9766 - mae: 19.3255 - val_loss: 10990.3154 - val_mae: 42.6860\n",
      "Epoch 397/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1903.4351 - mae: 19.8323 - val_loss: 12481.7783 - val_mae: 46.7401\n",
      "Epoch 398/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2040.7836 - mae: 21.0498 - val_loss: 11886.4072 - val_mae: 39.6797\n",
      "Epoch 399/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1983.6180 - mae: 20.1869 - val_loss: 13007.0342 - val_mae: 48.1432\n",
      "Epoch 400/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1922.1595 - mae: 20.6654 - val_loss: 12131.2461 - val_mae: 40.9023\n",
      "Epoch 401/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1820.2566 - mae: 18.8826 - val_loss: 16850.4258 - val_mae: 44.0925\n",
      "Epoch 402/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2188.4390 - mae: 22.3010 - val_loss: 20472.3379 - val_mae: 63.9881\n",
      "Epoch 403/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1414.5374 - mae: 18.3010 - val_loss: 13623.8984 - val_mae: 43.7658\n",
      "Epoch 404/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1904.3154 - mae: 21.1651 - val_loss: 11668.8408 - val_mae: 40.6210\n",
      "Epoch 405/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1992.0905 - mae: 21.0054 - val_loss: 11496.1387 - val_mae: 44.4905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1818.0763 - mae: 19.3828 - val_loss: 11775.3193 - val_mae: 39.3139\n",
      "Epoch 407/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1942.8351 - mae: 20.3663 - val_loss: 11212.1143 - val_mae: 39.1081\n",
      "Epoch 408/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1925.7126 - mae: 20.5549 - val_loss: 20588.4648 - val_mae: 68.3783\n",
      "Epoch 409/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1903.7711 - mae: 20.4991 - val_loss: 15723.2061 - val_mae: 44.1544\n",
      "Epoch 410/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2040.0410 - mae: 20.8880 - val_loss: 15979.7402 - val_mae: 45.8622\n",
      "Epoch 411/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2199.1467 - mae: 20.6232 - val_loss: 20701.0000 - val_mae: 57.6024\n",
      "Epoch 412/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1796.3286 - mae: 20.2274 - val_loss: 12340.9834 - val_mae: 40.4212\n",
      "Epoch 413/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1895.4557 - mae: 19.8887 - val_loss: 13726.2334 - val_mae: 41.7934\n",
      "Epoch 414/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1961.7928 - mae: 20.8023 - val_loss: 13398.2090 - val_mae: 41.1365\n",
      "Epoch 415/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1656.5588 - mae: 20.1337 - val_loss: 11956.4238 - val_mae: 41.7881\n",
      "Epoch 416/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1861.4414 - mae: 19.4533 - val_loss: 14075.1914 - val_mae: 50.7799\n",
      "Epoch 417/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2243.7202 - mae: 21.3439 - val_loss: 12297.6211 - val_mae: 39.9557\n",
      "Epoch 418/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1875.0306 - mae: 20.5177 - val_loss: 13401.9941 - val_mae: 41.7725\n",
      "Epoch 419/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1898.9966 - mae: 20.1260 - val_loss: 11380.0186 - val_mae: 39.1282\n",
      "Epoch 420/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1733.4581 - mae: 19.8554 - val_loss: 13070.1357 - val_mae: 50.8476\n",
      "Epoch 421/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2047.8383 - mae: 19.7012 - val_loss: 24632.7598 - val_mae: 63.4800\n",
      "Epoch 422/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2366.2903 - mae: 21.7458 - val_loss: 12079.0811 - val_mae: 39.4564\n",
      "Epoch 423/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1871.7280 - mae: 19.3528 - val_loss: 11724.3291 - val_mae: 41.5335\n",
      "Epoch 424/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1641.4419 - mae: 19.1378 - val_loss: 11208.0742 - val_mae: 43.1649\n",
      "Epoch 425/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2000.2484 - mae: 20.3304 - val_loss: 12465.0762 - val_mae: 42.5355\n",
      "Epoch 426/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1897.4482 - mae: 19.7943 - val_loss: 11217.5205 - val_mae: 38.3881\n",
      "Epoch 427/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1567.0723 - mae: 19.0100 - val_loss: 17261.7344 - val_mae: 48.5003\n",
      "Epoch 428/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1986.1918 - mae: 20.5063 - val_loss: 11045.0684 - val_mae: 40.6033\n",
      "Epoch 429/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1698.3060 - mae: 19.8436 - val_loss: 12190.7803 - val_mae: 39.9922\n",
      "Epoch 430/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2020.4136 - mae: 20.3054 - val_loss: 13175.7520 - val_mae: 40.0934\n",
      "Epoch 431/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1778.8445 - mae: 19.6024 - val_loss: 15513.1328 - val_mae: 57.3944\n",
      "Epoch 432/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1857.4873 - mae: 20.2865 - val_loss: 12401.8643 - val_mae: 41.0662\n",
      "Epoch 433/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1788.6194 - mae: 19.8167 - val_loss: 13947.0059 - val_mae: 42.8727\n",
      "Epoch 434/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1570.0682 - mae: 18.7072 - val_loss: 19604.5254 - val_mae: 55.6374\n",
      "Epoch 435/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1889.9464 - mae: 20.1389 - val_loss: 12190.8965 - val_mae: 39.6408\n",
      "Epoch 436/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1847.4739 - mae: 20.4585 - val_loss: 11493.4795 - val_mae: 43.0288\n",
      "Epoch 437/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1778.4948 - mae: 19.8769 - val_loss: 12446.4346 - val_mae: 41.3202\n",
      "Epoch 438/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2043.6671 - mae: 20.4226 - val_loss: 12315.2598 - val_mae: 40.2360\n",
      "Epoch 439/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1743.5483 - mae: 19.4378 - val_loss: 11507.8848 - val_mae: 38.5553\n",
      "Epoch 440/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1664.1606 - mae: 19.5135 - val_loss: 11619.5312 - val_mae: 40.3327\n",
      "Epoch 441/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1828.4932 - mae: 19.4614 - val_loss: 12081.8711 - val_mae: 38.8779\n",
      "Epoch 442/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1941.6814 - mae: 20.2839 - val_loss: 11044.8359 - val_mae: 38.5024\n",
      "Epoch 443/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1645.9269 - mae: 19.0641 - val_loss: 11861.6523 - val_mae: 42.5510\n",
      "Epoch 444/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1715.3101 - mae: 19.2538 - val_loss: 16861.6934 - val_mae: 59.8623\n",
      "Epoch 445/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1971.9810 - mae: 20.4792 - val_loss: 12030.5693 - val_mae: 45.1248\n",
      "Epoch 446/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1687.6649 - mae: 19.1391 - val_loss: 12536.5400 - val_mae: 39.7545\n",
      "Epoch 447/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1600.0338 - mae: 18.6978 - val_loss: 12421.4131 - val_mae: 40.2636\n",
      "Epoch 448/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1891.7426 - mae: 20.9558 - val_loss: 15338.7275 - val_mae: 44.1343\n",
      "Epoch 449/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1581.3572 - mae: 18.9591 - val_loss: 17005.7676 - val_mae: 50.5502\n",
      "Epoch 450/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2102.1353 - mae: 21.1832 - val_loss: 15692.8496 - val_mae: 43.6976\n",
      "Epoch 451/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1824.1039 - mae: 17.8059 - val_loss: 14974.3701 - val_mae: 44.0606\n",
      "Epoch 452/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1917.8281 - mae: 19.9112 - val_loss: 12118.1377 - val_mae: 41.4699\n",
      "Epoch 453/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1543.8138 - mae: 19.0483 - val_loss: 12227.7363 - val_mae: 38.5639\n",
      "Epoch 454/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1645.2150 - mae: 19.3032 - val_loss: 15227.5215 - val_mae: 43.2369\n",
      "Epoch 455/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1865.9288 - mae: 19.7695 - val_loss: 10664.6885 - val_mae: 41.2374\n",
      "Epoch 456/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1561.3716 - mae: 19.3039 - val_loss: 14149.9619 - val_mae: 42.8138\n",
      "Epoch 457/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1708.1318 - mae: 19.0772 - val_loss: 10860.4463 - val_mae: 41.8798\n",
      "Epoch 458/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1641.1416 - mae: 19.4947 - val_loss: 12289.8125 - val_mae: 40.4477\n",
      "Epoch 459/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1633.1458 - mae: 19.5803 - val_loss: 12954.5137 - val_mae: 48.4126\n",
      "Epoch 460/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1852.8610 - mae: 19.6515 - val_loss: 11784.0625 - val_mae: 40.9460\n",
      "Epoch 461/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1740.1073 - mae: 19.5957 - val_loss: 11797.2441 - val_mae: 38.3941\n",
      "Epoch 462/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1729.1569 - mae: 19.3685 - val_loss: 14419.7510 - val_mae: 43.5075\n",
      "Epoch 463/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1679.0482 - mae: 20.2081 - val_loss: 11703.1523 - val_mae: 41.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1812.7419 - mae: 18.7041 - val_loss: 15509.9141 - val_mae: 47.2660\n",
      "Epoch 465/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1905.6086 - mae: 20.8484 - val_loss: 12250.2334 - val_mae: 41.3348\n",
      "Epoch 466/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1531.6543 - mae: 18.7953 - val_loss: 12144.5898 - val_mae: 44.3726\n",
      "Epoch 467/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1832.1525 - mae: 20.1885 - val_loss: 12803.3359 - val_mae: 42.6950\n",
      "Epoch 468/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1848.4763 - mae: 18.6307 - val_loss: 13032.7598 - val_mae: 40.6522\n",
      "Epoch 469/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2005.0861 - mae: 20.5408 - val_loss: 12506.3467 - val_mae: 39.2790\n",
      "Epoch 470/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1554.3429 - mae: 18.8137 - val_loss: 12074.2061 - val_mae: 39.4987\n",
      "Epoch 471/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1953.8774 - mae: 19.7060 - val_loss: 19229.8809 - val_mae: 53.1373\n",
      "Epoch 472/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1605.2369 - mae: 19.1613 - val_loss: 11222.7441 - val_mae: 38.8692\n",
      "Epoch 473/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1504.6753 - mae: 18.8076 - val_loss: 18162.8848 - val_mae: 48.2750\n",
      "Epoch 474/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1494.3243 - mae: 19.1875 - val_loss: 12586.3584 - val_mae: 39.3586\n",
      "Epoch 475/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1734.2931 - mae: 19.0602 - val_loss: 12384.3594 - val_mae: 44.9756\n",
      "Epoch 476/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1865.0294 - mae: 19.9676 - val_loss: 13150.2256 - val_mae: 40.8095\n",
      "Epoch 477/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1781.0795 - mae: 18.6521 - val_loss: 13661.5059 - val_mae: 51.2810\n",
      "Epoch 478/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1521.0500 - mae: 19.1594 - val_loss: 10860.3438 - val_mae: 39.0683\n",
      "Epoch 479/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1531.9207 - mae: 18.7246 - val_loss: 13133.2490 - val_mae: 44.9060\n",
      "Epoch 480/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1998.8811 - mae: 19.9594 - val_loss: 13102.3486 - val_mae: 44.9294\n",
      "Epoch 481/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1941.1929 - mae: 19.6486 - val_loss: 12953.9775 - val_mae: 40.0953\n",
      "Epoch 482/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1488.4247 - mae: 18.6132 - val_loss: 13611.8193 - val_mae: 47.7487\n",
      "Epoch 483/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2030.7441 - mae: 20.4098 - val_loss: 12204.5430 - val_mae: 40.1145\n",
      "Epoch 484/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1598.6149 - mae: 18.1313 - val_loss: 20081.0645 - val_mae: 69.1930\n",
      "Epoch 485/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1654.8287 - mae: 19.3421 - val_loss: 12098.2764 - val_mae: 39.5761\n",
      "Epoch 486/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1855.4802 - mae: 19.4537 - val_loss: 11379.3379 - val_mae: 38.9175\n",
      "Epoch 487/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1564.0785 - mae: 18.8880 - val_loss: 11607.1592 - val_mae: 40.7790\n",
      "Epoch 488/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1810.5037 - mae: 19.3886 - val_loss: 12536.0342 - val_mae: 39.1850\n",
      "Epoch 489/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1617.7151 - mae: 18.9406 - val_loss: 11790.7344 - val_mae: 41.3010\n",
      "Epoch 490/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1911.7294 - mae: 19.1862 - val_loss: 13555.0010 - val_mae: 41.4164\n",
      "Epoch 491/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1817.9084 - mae: 20.8428 - val_loss: 11536.6924 - val_mae: 38.9257\n",
      "Epoch 492/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1377.9731 - mae: 17.5829 - val_loss: 12143.3662 - val_mae: 39.1389\n",
      "Epoch 493/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1845.3000 - mae: 19.4874 - val_loss: 11927.8223 - val_mae: 41.1676\n",
      "Epoch 494/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1935.0376 - mae: 20.5339 - val_loss: 11855.7227 - val_mae: 43.1880\n",
      "Epoch 495/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1616.5444 - mae: 19.2592 - val_loss: 12955.0586 - val_mae: 47.7292\n",
      "Epoch 496/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1837.3063 - mae: 20.2226 - val_loss: 12412.9863 - val_mae: 40.5386\n",
      "Epoch 497/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1856.6566 - mae: 19.0586 - val_loss: 12776.0215 - val_mae: 44.0207\n",
      "Epoch 498/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1892.7074 - mae: 20.2668 - val_loss: 13037.8477 - val_mae: 42.8582\n",
      "Epoch 499/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1649.3915 - mae: 19.3197 - val_loss: 11113.4521 - val_mae: 40.6666\n",
      "Epoch 500/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1775.7366 - mae: 19.0455 - val_loss: 14866.6963 - val_mae: 56.2827\n",
      "Epoch 501/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1650.9236 - mae: 18.9339 - val_loss: 12734.6982 - val_mae: 39.6587\n",
      "Epoch 502/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1691.5029 - mae: 19.3962 - val_loss: 11439.2666 - val_mae: 39.9475\n",
      "Epoch 503/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1440.4708 - mae: 17.6849 - val_loss: 17334.7793 - val_mae: 57.9434\n",
      "Epoch 504/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1707.8147 - mae: 18.4188 - val_loss: 11821.7236 - val_mae: 39.0362\n",
      "Epoch 505/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1638.9476 - mae: 18.7440 - val_loss: 13756.6406 - val_mae: 41.3116\n",
      "Epoch 506/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1633.0693 - mae: 19.0093 - val_loss: 14032.1484 - val_mae: 45.5131\n",
      "Epoch 507/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1808.9570 - mae: 19.0122 - val_loss: 11347.2559 - val_mae: 41.1414\n",
      "Epoch 508/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1750.7133 - mae: 19.1807 - val_loss: 11300.3418 - val_mae: 38.7607\n",
      "Epoch 509/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1952.9805 - mae: 20.2128 - val_loss: 11468.0635 - val_mae: 41.5218\n",
      "Epoch 510/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1650.7588 - mae: 18.3481 - val_loss: 13778.4932 - val_mae: 40.1172\n",
      "Epoch 511/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1989.5024 - mae: 20.2986 - val_loss: 11847.9736 - val_mae: 42.4438\n",
      "Epoch 512/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1403.9686 - mae: 17.9669 - val_loss: 18747.8770 - val_mae: 54.3337\n",
      "Epoch 513/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1819.7267 - mae: 20.0496 - val_loss: 10781.5664 - val_mae: 37.3255\n",
      "Epoch 514/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1705.3018 - mae: 19.5949 - val_loss: 11456.4014 - val_mae: 44.4428\n",
      "Epoch 515/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1544.2164 - mae: 18.9382 - val_loss: 11472.2646 - val_mae: 38.5211\n",
      "Epoch 516/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1649.1500 - mae: 19.1908 - val_loss: 13609.9219 - val_mae: 40.8365\n",
      "Epoch 517/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1748.7665 - mae: 19.0422 - val_loss: 13669.0898 - val_mae: 40.0610\n",
      "Epoch 518/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1507.3300 - mae: 18.5350 - val_loss: 23616.7031 - val_mae: 56.8438\n",
      "Epoch 519/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1631.1100 - mae: 18.9676 - val_loss: 11372.3467 - val_mae: 40.3429\n",
      "Epoch 520/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1679.9368 - mae: 18.7166 - val_loss: 20659.3223 - val_mae: 69.3811\n",
      "Epoch 521/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1694.8302 - mae: 18.4792 - val_loss: 13814.7227 - val_mae: 43.5904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1923.2283 - mae: 19.0639 - val_loss: 14344.0117 - val_mae: 41.6919\n",
      "Epoch 523/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1550.5653 - mae: 17.8216 - val_loss: 12921.6836 - val_mae: 47.4570\n",
      "Epoch 524/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1659.2740 - mae: 19.0830 - val_loss: 12638.5410 - val_mae: 38.4854\n",
      "Epoch 525/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1668.9368 - mae: 19.1117 - val_loss: 11571.9893 - val_mae: 39.8380\n",
      "Epoch 526/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1618.0256 - mae: 19.4458 - val_loss: 12351.2959 - val_mae: 41.6386\n",
      "Epoch 527/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1453.0861 - mae: 18.0737 - val_loss: 13260.1680 - val_mae: 40.8421\n",
      "Epoch 528/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1657.3973 - mae: 17.9018 - val_loss: 18464.4473 - val_mae: 47.8975\n",
      "Epoch 529/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1806.6002 - mae: 19.5279 - val_loss: 13389.1543 - val_mae: 39.2138\n",
      "Epoch 530/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1517.7046 - mae: 17.9096 - val_loss: 13028.6357 - val_mae: 49.0416\n",
      "Epoch 531/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1643.1887 - mae: 20.1087 - val_loss: 14262.2607 - val_mae: 42.7472\n",
      "Epoch 532/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2009.9512 - mae: 18.8541 - val_loss: 13008.2666 - val_mae: 39.0774\n",
      "Epoch 533/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1811.6216 - mae: 19.2485 - val_loss: 17650.4766 - val_mae: 45.5605\n",
      "Epoch 534/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1685.5612 - mae: 19.4922 - val_loss: 16377.2344 - val_mae: 59.3202\n",
      "Epoch 535/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1773.6150 - mae: 19.1362 - val_loss: 11968.6865 - val_mae: 40.3366\n",
      "Epoch 536/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1285.6207 - mae: 16.4181 - val_loss: 20516.9453 - val_mae: 68.9691\n",
      "Epoch 537/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1776.0647 - mae: 20.3065 - val_loss: 13464.7090 - val_mae: 45.6384\n",
      "Epoch 538/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1744.1450 - mae: 19.5220 - val_loss: 12630.4824 - val_mae: 38.9869\n",
      "Epoch 539/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1623.0746 - mae: 19.0233 - val_loss: 12244.5322 - val_mae: 39.2092\n",
      "Epoch 540/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1545.8383 - mae: 19.1490 - val_loss: 13385.9385 - val_mae: 40.8406\n",
      "Epoch 541/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1410.5278 - mae: 17.5693 - val_loss: 11938.7031 - val_mae: 43.8641\n",
      "Epoch 542/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1807.5427 - mae: 18.7580 - val_loss: 12397.5381 - val_mae: 40.8846\n",
      "Epoch 543/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2196.3086 - mae: 20.0957 - val_loss: 11951.4746 - val_mae: 38.2665\n",
      "Epoch 544/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1412.6818 - mae: 17.1880 - val_loss: 22100.3027 - val_mae: 55.1095\n",
      "Epoch 545/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1992.2460 - mae: 19.8640 - val_loss: 12177.9316 - val_mae: 41.1937\n",
      "Epoch 546/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1503.2404 - mae: 18.9190 - val_loss: 12281.1270 - val_mae: 39.5338\n",
      "Epoch 547/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2212.2297 - mae: 20.2683 - val_loss: 12411.1211 - val_mae: 42.7649\n",
      "Epoch 548/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1347.0836 - mae: 17.0194 - val_loss: 17472.3359 - val_mae: 48.2488\n",
      "Epoch 549/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1525.5320 - mae: 16.9674 - val_loss: 13799.0127 - val_mae: 51.6831\n",
      "Epoch 550/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2071.7622 - mae: 21.1373 - val_loss: 12996.8760 - val_mae: 40.3216\n",
      "Epoch 551/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1403.1243 - mae: 17.6821 - val_loss: 11050.3809 - val_mae: 38.9059\n",
      "Epoch 552/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1603.8154 - mae: 19.0520 - val_loss: 16781.3770 - val_mae: 48.0757\n",
      "Epoch 553/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1626.3323 - mae: 19.6915 - val_loss: 10666.3818 - val_mae: 39.0441\n",
      "Epoch 554/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1710.1992 - mae: 19.1392 - val_loss: 15465.5859 - val_mae: 48.0629\n",
      "Epoch 555/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1720.7667 - mae: 18.8053 - val_loss: 11878.0381 - val_mae: 42.2062\n",
      "Epoch 556/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1365.0703 - mae: 18.0050 - val_loss: 11367.5361 - val_mae: 41.3524\n",
      "Epoch 557/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1531.1058 - mae: 17.9289 - val_loss: 12510.2695 - val_mae: 39.4568\n",
      "Epoch 558/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1615.8367 - mae: 19.5281 - val_loss: 20193.0605 - val_mae: 55.3942\n",
      "Epoch 559/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1878.4460 - mae: 19.7089 - val_loss: 20449.3027 - val_mae: 67.4531\n",
      "Epoch 560/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1638.2471 - mae: 18.1162 - val_loss: 12124.1748 - val_mae: 38.7155\n",
      "Epoch 561/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1459.7664 - mae: 17.8777 - val_loss: 17374.6172 - val_mae: 46.7047\n",
      "Epoch 562/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1735.2858 - mae: 19.7171 - val_loss: 10920.9707 - val_mae: 37.3550\n",
      "Epoch 563/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1401.3447 - mae: 17.6499 - val_loss: 14225.8047 - val_mae: 42.9208\n",
      "Epoch 564/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1827.3179 - mae: 19.5453 - val_loss: 12745.9629 - val_mae: 39.1200\n",
      "Epoch 565/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1544.6748 - mae: 18.5768 - val_loss: 11764.4941 - val_mae: 39.2238\n",
      "Epoch 566/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1625.9530 - mae: 18.5747 - val_loss: 14511.2520 - val_mae: 49.1187\n",
      "Epoch 567/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1552.3767 - mae: 18.2285 - val_loss: 11971.6992 - val_mae: 39.3575\n",
      "Epoch 568/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1354.8226 - mae: 18.2769 - val_loss: 13336.2119 - val_mae: 43.3073\n",
      "Epoch 569/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1518.2484 - mae: 17.7696 - val_loss: 13312.1514 - val_mae: 40.1025\n",
      "Epoch 570/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1853.4744 - mae: 18.4199 - val_loss: 17055.2305 - val_mae: 49.1089\n",
      "Epoch 571/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1787.0417 - mae: 19.9132 - val_loss: 11787.7773 - val_mae: 41.1268\n",
      "Epoch 572/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1575.9583 - mae: 18.5070 - val_loss: 12116.2598 - val_mae: 38.1343\n",
      "Epoch 573/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1651.9778 - mae: 18.7394 - val_loss: 11818.5850 - val_mae: 39.8889\n",
      "Epoch 574/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1581.6404 - mae: 18.4807 - val_loss: 11736.1533 - val_mae: 39.8066\n",
      "Epoch 575/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1750.1396 - mae: 18.8364 - val_loss: 12958.6611 - val_mae: 41.9854\n",
      "Epoch 576/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1856.7246 - mae: 18.8011 - val_loss: 11153.7373 - val_mae: 37.8986\n",
      "Epoch 577/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1564.7473 - mae: 18.0830 - val_loss: 13483.7646 - val_mae: 45.4993\n",
      "Epoch 578/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1475.1514 - mae: 17.7073 - val_loss: 11034.8330 - val_mae: 37.3400\n",
      "Epoch 579/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1448.4922 - mae: 18.4834 - val_loss: 16724.0176 - val_mae: 58.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1700.1185 - mae: 18.5526 - val_loss: 13345.9912 - val_mae: 41.5796\n",
      "Epoch 581/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1747.9349 - mae: 19.3658 - val_loss: 13508.0312 - val_mae: 42.6709\n",
      "Epoch 582/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1647.5396 - mae: 18.1678 - val_loss: 11866.8496 - val_mae: 45.9357\n",
      "Epoch 583/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1676.5867 - mae: 18.9683 - val_loss: 12037.3545 - val_mae: 40.3818\n",
      "Epoch 584/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1722.1464 - mae: 18.6963 - val_loss: 13116.9570 - val_mae: 47.0914\n",
      "Epoch 585/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1573.2181 - mae: 18.6432 - val_loss: 21300.3867 - val_mae: 55.7566\n",
      "Epoch 586/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1725.7142 - mae: 18.4867 - val_loss: 12717.9434 - val_mae: 39.9495\n",
      "Epoch 587/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1756.9552 - mae: 19.0250 - val_loss: 16384.8105 - val_mae: 58.3483\n",
      "Epoch 588/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1495.9714 - mae: 18.7505 - val_loss: 11290.2998 - val_mae: 38.3526\n",
      "Epoch 589/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1577.5953 - mae: 18.1094 - val_loss: 11526.8613 - val_mae: 43.6185\n",
      "Epoch 590/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1725.9928 - mae: 19.2668 - val_loss: 11983.9678 - val_mae: 42.1182\n",
      "Epoch 591/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1516.9828 - mae: 17.8208 - val_loss: 11503.2061 - val_mae: 39.9188\n",
      "Epoch 592/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1652.7527 - mae: 19.7673 - val_loss: 14185.6357 - val_mae: 51.4357\n",
      "Epoch 593/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1725.0175 - mae: 19.1942 - val_loss: 20685.5254 - val_mae: 56.4612\n",
      "Epoch 594/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1601.9431 - mae: 18.0505 - val_loss: 11413.7461 - val_mae: 42.1540\n",
      "Epoch 595/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1767.2192 - mae: 17.8288 - val_loss: 16804.4512 - val_mae: 49.6281\n",
      "Epoch 596/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1668.2621 - mae: 18.8064 - val_loss: 13532.1826 - val_mae: 42.1867\n",
      "Epoch 597/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1417.8857 - mae: 17.8294 - val_loss: 12144.2119 - val_mae: 41.4943\n",
      "Epoch 598/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1632.8761 - mae: 18.8796 - val_loss: 11055.0381 - val_mae: 40.3125\n",
      "Epoch 599/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1527.3469 - mae: 17.6617 - val_loss: 18519.0742 - val_mae: 65.5926\n",
      "Epoch 600/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1677.7865 - mae: 18.9103 - val_loss: 11874.0449 - val_mae: 46.7932\n",
      "Epoch 601/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1551.2307 - mae: 19.2377 - val_loss: 12970.1602 - val_mae: 49.0566\n",
      "Epoch 602/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1587.9030 - mae: 18.1448 - val_loss: 12555.5391 - val_mae: 40.7207\n",
      "Epoch 603/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1550.0278 - mae: 18.8265 - val_loss: 11126.3818 - val_mae: 41.1383\n",
      "Epoch 604/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1676.6052 - mae: 17.8433 - val_loss: 10626.4424 - val_mae: 39.3370\n",
      "Epoch 605/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1578.6963 - mae: 19.2910 - val_loss: 21671.4473 - val_mae: 65.1169\n",
      "Epoch 606/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1816.2792 - mae: 19.2703 - val_loss: 14648.0107 - val_mae: 47.9111\n",
      "Epoch 607/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1395.1473 - mae: 17.7331 - val_loss: 11870.5488 - val_mae: 38.5881\n",
      "Epoch 608/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1585.1500 - mae: 18.6869 - val_loss: 12392.7695 - val_mae: 40.1429\n",
      "Epoch 609/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1497.9384 - mae: 18.0699 - val_loss: 13790.4834 - val_mae: 41.7374\n",
      "Epoch 610/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1404.7628 - mae: 18.2473 - val_loss: 12850.5127 - val_mae: 39.5161\n",
      "Epoch 611/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1609.7684 - mae: 18.4622 - val_loss: 14557.8418 - val_mae: 47.8644\n",
      "Epoch 612/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1493.7731 - mae: 18.1586 - val_loss: 13216.9346 - val_mae: 40.8432\n",
      "Epoch 613/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1731.7634 - mae: 18.7315 - val_loss: 12344.6191 - val_mae: 40.9100\n",
      "Epoch 614/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1546.1925 - mae: 18.2651 - val_loss: 12183.6953 - val_mae: 41.6486\n",
      "Epoch 615/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1711.6310 - mae: 17.4233 - val_loss: 12927.9648 - val_mae: 40.5097\n",
      "Epoch 616/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1709.4349 - mae: 18.2193 - val_loss: 12015.1562 - val_mae: 39.2512\n",
      "Epoch 617/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1670.2507 - mae: 17.9011 - val_loss: 13487.9893 - val_mae: 39.5600\n",
      "Epoch 618/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1624.5608 - mae: 19.5888 - val_loss: 11580.0205 - val_mae: 46.0671\n",
      "Epoch 619/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1428.5265 - mae: 17.9426 - val_loss: 18616.2402 - val_mae: 63.9214\n",
      "Epoch 620/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1732.3884 - mae: 19.1560 - val_loss: 11432.0303 - val_mae: 38.2309\n",
      "Epoch 621/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1345.8406 - mae: 17.9735 - val_loss: 11108.1357 - val_mae: 37.5657\n",
      "Epoch 622/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1762.3098 - mae: 18.8132 - val_loss: 12070.7041 - val_mae: 37.9970\n",
      "Epoch 623/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1367.8121 - mae: 17.8980 - val_loss: 12984.4531 - val_mae: 44.0400\n",
      "Epoch 624/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1737.0468 - mae: 19.1880 - val_loss: 11863.3623 - val_mae: 40.2219\n",
      "Epoch 625/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1639.8927 - mae: 18.3907 - val_loss: 12908.5322 - val_mae: 40.3988\n",
      "Epoch 626/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1679.5710 - mae: 19.0173 - val_loss: 12707.3730 - val_mae: 41.5317\n",
      "Epoch 627/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1547.7839 - mae: 17.7282 - val_loss: 13234.9492 - val_mae: 38.9285\n",
      "Epoch 628/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1592.7118 - mae: 18.8656 - val_loss: 12124.8418 - val_mae: 40.0204\n",
      "Epoch 629/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1444.5164 - mae: 17.8501 - val_loss: 26502.6133 - val_mae: 69.9025\n",
      "Epoch 630/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1900.1956 - mae: 20.9771 - val_loss: 12979.1523 - val_mae: 49.2777\n",
      "Epoch 631/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1395.7444 - mae: 17.6171 - val_loss: 10191.5479 - val_mae: 38.0695\n",
      "Epoch 632/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1669.1349 - mae: 18.3465 - val_loss: 11953.8311 - val_mae: 39.2194\n",
      "Epoch 633/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1622.0798 - mae: 17.3313 - val_loss: 11197.4053 - val_mae: 38.9630\n",
      "Epoch 634/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1665.9910 - mae: 18.8329 - val_loss: 12783.7852 - val_mae: 40.7484\n",
      "Epoch 635/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1556.7568 - mae: 17.1365 - val_loss: 11920.4580 - val_mae: 39.6165\n",
      "Epoch 636/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1481.7574 - mae: 18.4274 - val_loss: 12038.9775 - val_mae: 38.0107\n",
      "Epoch 637/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1730.6613 - mae: 19.2354 - val_loss: 12084.5742 - val_mae: 38.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1401.9205 - mae: 17.0889 - val_loss: 11577.0244 - val_mae: 42.3330\n",
      "Epoch 639/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1781.6368 - mae: 18.6154 - val_loss: 12140.0713 - val_mae: 39.4418\n",
      "Epoch 640/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1354.6277 - mae: 17.9266 - val_loss: 18000.3848 - val_mae: 46.3261\n",
      "Epoch 641/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1773.0612 - mae: 19.6327 - val_loss: 13677.3096 - val_mae: 42.4590\n",
      "Epoch 642/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1620.0718 - mae: 17.9519 - val_loss: 13148.9287 - val_mae: 40.3706\n",
      "Epoch 643/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1375.6749 - mae: 17.5494 - val_loss: 12477.7109 - val_mae: 39.3696\n",
      "Epoch 644/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1489.8844 - mae: 17.6592 - val_loss: 14496.8320 - val_mae: 41.6127\n",
      "Epoch 645/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1507.1619 - mae: 18.5328 - val_loss: 12210.4297 - val_mae: 38.9782\n",
      "Epoch 646/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1456.2318 - mae: 17.4225 - val_loss: 12257.9844 - val_mae: 40.3086\n",
      "Epoch 647/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1689.5720 - mae: 19.2154 - val_loss: 11155.3076 - val_mae: 38.1496\n",
      "Epoch 648/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1375.5969 - mae: 17.8221 - val_loss: 11772.8125 - val_mae: 38.8345\n",
      "Epoch 649/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1624.3003 - mae: 17.8358 - val_loss: 13073.3535 - val_mae: 40.6012\n",
      "Epoch 650/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1476.5132 - mae: 18.1915 - val_loss: 11648.7422 - val_mae: 41.7900\n",
      "Epoch 651/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1352.9979 - mae: 17.4208 - val_loss: 19690.3750 - val_mae: 67.8823\n",
      "Epoch 652/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1474.4354 - mae: 18.2760 - val_loss: 12608.9873 - val_mae: 39.3929\n",
      "Epoch 653/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1670.8435 - mae: 18.8329 - val_loss: 12269.1191 - val_mae: 41.3817\n",
      "Epoch 654/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1605.7850 - mae: 18.4668 - val_loss: 12787.6787 - val_mae: 45.0283\n",
      "Epoch 655/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1408.4867 - mae: 16.9444 - val_loss: 12422.9248 - val_mae: 39.2022\n",
      "Epoch 656/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1633.0165 - mae: 17.9046 - val_loss: 12199.8398 - val_mae: 38.4873\n",
      "Epoch 657/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1283.7432 - mae: 16.5566 - val_loss: 11776.5381 - val_mae: 40.8029\n",
      "Epoch 658/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1479.3319 - mae: 18.5840 - val_loss: 14063.4277 - val_mae: 42.5200\n",
      "Epoch 659/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1635.9164 - mae: 18.3763 - val_loss: 11347.1953 - val_mae: 39.9767\n",
      "Epoch 660/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1476.2648 - mae: 18.2075 - val_loss: 15607.2773 - val_mae: 42.4917\n",
      "Epoch 661/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1437.7524 - mae: 18.4544 - val_loss: 13120.1973 - val_mae: 39.6948\n",
      "Epoch 662/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1522.0135 - mae: 17.9245 - val_loss: 13418.0166 - val_mae: 39.6754\n",
      "Epoch 663/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1642.2017 - mae: 18.1951 - val_loss: 14317.6504 - val_mae: 42.0198\n",
      "Epoch 664/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1595.8101 - mae: 18.7772 - val_loss: 12765.8203 - val_mae: 39.3893\n",
      "Epoch 665/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1264.1857 - mae: 16.7202 - val_loss: 11680.0186 - val_mae: 40.8255\n",
      "Epoch 666/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1802.8066 - mae: 19.4425 - val_loss: 14151.6553 - val_mae: 43.5748\n",
      "Epoch 667/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1241.8997 - mae: 16.4820 - val_loss: 11972.1328 - val_mae: 40.5041\n",
      "Epoch 668/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1614.3853 - mae: 17.8947 - val_loss: 12940.6904 - val_mae: 40.1781\n",
      "Epoch 669/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1301.8615 - mae: 17.0628 - val_loss: 11348.3838 - val_mae: 38.2047\n",
      "Epoch 670/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1720.0822 - mae: 18.4748 - val_loss: 12168.2842 - val_mae: 43.7977\n",
      "Epoch 671/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1533.7307 - mae: 17.2656 - val_loss: 13610.3408 - val_mae: 41.5602\n",
      "Epoch 672/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1482.5040 - mae: 17.4617 - val_loss: 11409.3857 - val_mae: 38.8592\n",
      "Epoch 673/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1701.0796 - mae: 18.0235 - val_loss: 11437.1895 - val_mae: 39.7976\n",
      "Epoch 674/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1545.5284 - mae: 18.8515 - val_loss: 14923.9365 - val_mae: 44.8611\n",
      "Epoch 675/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1531.0211 - mae: 18.3357 - val_loss: 11189.0830 - val_mae: 39.2973\n",
      "Epoch 676/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1372.6815 - mae: 16.7842 - val_loss: 11413.7129 - val_mae: 38.6364\n",
      "Epoch 677/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1502.9788 - mae: 17.6693 - val_loss: 11822.0928 - val_mae: 41.4770\n",
      "Epoch 678/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1638.5112 - mae: 17.5956 - val_loss: 12169.1064 - val_mae: 38.9122\n",
      "Epoch 679/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1591.5636 - mae: 17.3883 - val_loss: 13705.1855 - val_mae: 41.5713\n",
      "Epoch 680/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1386.7683 - mae: 17.5771 - val_loss: 12095.2100 - val_mae: 41.8341\n",
      "Epoch 681/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1517.4139 - mae: 17.4991 - val_loss: 15874.2871 - val_mae: 45.0249\n",
      "Epoch 682/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1335.6836 - mae: 18.0873 - val_loss: 17040.7578 - val_mae: 49.7768\n",
      "Epoch 683/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1592.0702 - mae: 18.7720 - val_loss: 17448.2070 - val_mae: 46.1559\n",
      "Epoch 684/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1689.2061 - mae: 18.9992 - val_loss: 15607.3477 - val_mae: 42.7953\n",
      "Epoch 685/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1348.8232 - mae: 16.8243 - val_loss: 13184.5801 - val_mae: 40.5282\n",
      "Epoch 686/700\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1509.2748 - mae: 18.3793 - val_loss: 12836.4258 - val_mae: 39.5422\n",
      "Epoch 687/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1524.6726 - mae: 17.2027 - val_loss: 12773.6250 - val_mae: 39.3751\n",
      "Epoch 688/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1427.6188 - mae: 17.5020 - val_loss: 13493.4580 - val_mae: 39.6361\n",
      "Epoch 689/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1595.5392 - mae: 18.5398 - val_loss: 12939.4443 - val_mae: 39.4590\n",
      "Epoch 690/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1444.7141 - mae: 17.4971 - val_loss: 15124.2988 - val_mae: 44.4610\n",
      "Epoch 691/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1652.9288 - mae: 18.4609 - val_loss: 12947.8643 - val_mae: 45.2257\n",
      "Epoch 692/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1345.7600 - mae: 17.1568 - val_loss: 13428.8516 - val_mae: 37.8532\n",
      "Epoch 693/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1551.4875 - mae: 18.6401 - val_loss: 12872.7910 - val_mae: 39.8404\n",
      "Epoch 694/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1537.1160 - mae: 17.8289 - val_loss: 11846.3291 - val_mae: 39.6467\n",
      "Epoch 695/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1342.5613 - mae: 17.3311 - val_loss: 12268.3535 - val_mae: 39.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1666.0757 - mae: 17.8356 - val_loss: 11853.9023 - val_mae: 40.1475\n",
      "Epoch 697/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1307.6364 - mae: 17.3598 - val_loss: 12052.5977 - val_mae: 41.0655\n",
      "Epoch 698/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1492.2430 - mae: 17.3698 - val_loss: 12489.6631 - val_mae: 40.9276\n",
      "Epoch 699/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1441.2582 - mae: 17.8295 - val_loss: 12838.2871 - val_mae: 41.1441\n",
      "Epoch 700/700\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1509.9100 - mae: 18.6467 - val_loss: 14445.3770 - val_mae: 42.6851\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "EPOCHS = 700\n",
    "# Store training stats\n",
    "history = model.fit(train_data, y_train, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bfef3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(history.history['mae'], label='train')\n",
    "plt.plot(history.history['val_mae'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f00bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: $48618.64\n"
     ]
    }
   ],
   "source": [
    "[loss, mae] = model.evaluate(test_data, y_test, verbose=0)\n",
    "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b00008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
