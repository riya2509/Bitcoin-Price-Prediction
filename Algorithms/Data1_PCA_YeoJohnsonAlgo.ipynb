{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_1776\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23463a8e",
   "metadata": {},
   "source": [
    "### Reading the YeoJohnson PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0         1          2          3         4          5  \\\n",
       "0           0  32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1           1  32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2           2  33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3           3  32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4           4  32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "\n",
       "           6         7         8  ...        89        90        91        92  \\\n",
       "0  16.524812  0.166351 -8.700498  ...  1.923946  3.832444 -2.257067  2.835188   \n",
       "1  17.966608 -0.569542 -9.306701  ...  1.593726  0.604879  0.335266  1.183815   \n",
       "2  16.543319  0.781871 -8.695417  ...  0.497217 -0.891250  2.450366  2.249480   \n",
       "3  17.856147  1.884261 -6.869309  ... -0.687552 -0.829605 -5.461876  0.345240   \n",
       "4  16.420547  3.158366 -8.634797  ... -0.422376  1.025973  1.077336  0.491024   \n",
       "\n",
       "         93        94        95        96        97  priceUSD  \n",
       "0 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201    0.0495  \n",
       "1 -0.294895 -1.473127 -0.657472  0.007406 -2.294048    0.0726  \n",
       "2 -1.947763 -2.079104  1.532892  1.893578 -0.800749    0.0859  \n",
       "3 -0.446096 -0.270433  6.035264  4.706512 -1.654442    0.0783  \n",
       "4  0.339590 -0.503155  3.711262  1.314670 -0.031391    0.0767  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_YeoJohnson_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>10.438027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>9.018383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>8.221800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>6.376521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>5.447760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>-19.315494</td>\n",
       "      <td>0.236167</td>\n",
       "      <td>-2.750750</td>\n",
       "      <td>-5.370912</td>\n",
       "      <td>-0.186745</td>\n",
       "      <td>4.678685</td>\n",
       "      <td>1.096600</td>\n",
       "      <td>3.019217</td>\n",
       "      <td>2.146403</td>\n",
       "      <td>3.662000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429743</td>\n",
       "      <td>1.624900</td>\n",
       "      <td>1.085748</td>\n",
       "      <td>-0.379536</td>\n",
       "      <td>-0.537552</td>\n",
       "      <td>-0.248166</td>\n",
       "      <td>-0.836404</td>\n",
       "      <td>1.001076</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-19.318940</td>\n",
       "      <td>0.733044</td>\n",
       "      <td>-0.889637</td>\n",
       "      <td>-5.979197</td>\n",
       "      <td>-1.170327</td>\n",
       "      <td>4.752099</td>\n",
       "      <td>-1.059497</td>\n",
       "      <td>4.918116</td>\n",
       "      <td>1.074642</td>\n",
       "      <td>2.816077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>-0.073998</td>\n",
       "      <td>-0.315707</td>\n",
       "      <td>1.726772</td>\n",
       "      <td>0.086268</td>\n",
       "      <td>-0.590934</td>\n",
       "      <td>-1.087419</td>\n",
       "      <td>0.384172</td>\n",
       "      <td>0.323270</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-19.018647</td>\n",
       "      <td>0.730092</td>\n",
       "      <td>-4.161934</td>\n",
       "      <td>-3.696162</td>\n",
       "      <td>2.779836</td>\n",
       "      <td>1.157445</td>\n",
       "      <td>-1.148338</td>\n",
       "      <td>4.904417</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>3.601954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613840</td>\n",
       "      <td>-0.938060</td>\n",
       "      <td>0.686956</td>\n",
       "      <td>2.921627</td>\n",
       "      <td>1.419180</td>\n",
       "      <td>-0.648111</td>\n",
       "      <td>-1.180782</td>\n",
       "      <td>-0.634334</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-19.091961</td>\n",
       "      <td>-1.767811</td>\n",
       "      <td>0.812909</td>\n",
       "      <td>-4.477929</td>\n",
       "      <td>-1.827579</td>\n",
       "      <td>-0.380548</td>\n",
       "      <td>-2.042414</td>\n",
       "      <td>3.578432</td>\n",
       "      <td>-0.707056</td>\n",
       "      <td>4.743335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276470</td>\n",
       "      <td>-0.493735</td>\n",
       "      <td>0.480427</td>\n",
       "      <td>1.565258</td>\n",
       "      <td>-0.317555</td>\n",
       "      <td>-1.248186</td>\n",
       "      <td>-0.791837</td>\n",
       "      <td>-0.580324</td>\n",
       "      <td>0.377241</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>-18.978473</td>\n",
       "      <td>-4.552622</td>\n",
       "      <td>1.547258</td>\n",
       "      <td>-2.263347</td>\n",
       "      <td>-0.054753</td>\n",
       "      <td>-3.135464</td>\n",
       "      <td>-2.699181</td>\n",
       "      <td>3.506751</td>\n",
       "      <td>-0.261364</td>\n",
       "      <td>5.744565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037892</td>\n",
       "      <td>-0.282042</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>1.032256</td>\n",
       "      <td>-0.721593</td>\n",
       "      <td>-2.401458</td>\n",
       "      <td>-0.049565</td>\n",
       "      <td>-0.425631</td>\n",
       "      <td>1.137282</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2          3         4          5  \\\n",
       "0     32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1     32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2     33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3     32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4     32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "3483 -19.315494  0.236167  -2.750750  -5.370912 -0.186745   4.678685   \n",
       "3484 -19.318940  0.733044  -0.889637  -5.979197 -1.170327   4.752099   \n",
       "3485 -19.018647  0.730092  -4.161934  -3.696162  2.779836   1.157445   \n",
       "3486 -19.091961 -1.767811   0.812909  -4.477929 -1.827579  -0.380548   \n",
       "3487 -18.978473 -4.552622   1.547258  -2.263347 -0.054753  -3.135464   \n",
       "\n",
       "              6         7         8          9  ...        89        90  \\\n",
       "0     16.524812  0.166351 -8.700498  10.438027  ...  1.923946  3.832444   \n",
       "1     17.966608 -0.569542 -9.306701   9.018383  ...  1.593726  0.604879   \n",
       "2     16.543319  0.781871 -8.695417   8.221800  ...  0.497217 -0.891250   \n",
       "3     17.856147  1.884261 -6.869309   6.376521  ... -0.687552 -0.829605   \n",
       "4     16.420547  3.158366 -8.634797   5.447760  ... -0.422376  1.025973   \n",
       "...         ...       ...       ...        ...  ...       ...       ...   \n",
       "3483   1.096600  3.019217  2.146403   3.662000  ... -0.429743  1.624900   \n",
       "3484  -1.059497  4.918116  1.074642   2.816077  ... -0.004836 -0.073998   \n",
       "3485  -1.148338  4.904417 -0.041506   3.601954  ... -0.613840 -0.938060   \n",
       "3486  -2.042414  3.578432 -0.707056   4.743335  ...  0.276470 -0.493735   \n",
       "3487  -2.699181  3.506751 -0.261364   5.744565  ... -0.037892 -0.282042   \n",
       "\n",
       "            91        92        93        94        95        96        97  \\\n",
       "0    -2.257067  2.835188 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201   \n",
       "1     0.335266  1.183815 -0.294895 -1.473127 -0.657472  0.007406 -2.294048   \n",
       "2     2.450366  2.249480 -1.947763 -2.079104  1.532892  1.893578 -0.800749   \n",
       "3    -5.461876  0.345240 -0.446096 -0.270433  6.035264  4.706512 -1.654442   \n",
       "4     1.077336  0.491024  0.339590 -0.503155  3.711262  1.314670 -0.031391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  1.085748 -0.379536 -0.537552 -0.248166 -0.836404  1.001076  0.001219   \n",
       "3484 -0.315707  1.726772  0.086268 -0.590934 -1.087419  0.384172  0.323270   \n",
       "3485  0.686956  2.921627  1.419180 -0.648111 -1.180782 -0.634334  0.133916   \n",
       "3486  0.480427  1.565258 -0.317555 -1.248186 -0.791837 -0.580324  0.377241   \n",
       "3487  0.909180  1.032256 -0.721593 -2.401458 -0.049565 -0.425631  1.137282   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 99 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14234118490774\n",
      "Test score of trained model: 94.02823354757119\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b667d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3538a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>858605.503644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>926.609682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.247982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>24122.446463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  858605.503644\n",
       "1    RMSE     926.609682\n",
       "2     MAE     670.247982\n",
       "3    MAPE   24122.446463\n",
       "4      r2       0.940282\n",
       "5  adj_r2       0.930512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576bfb2a",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78a8217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14224300146029\n",
      "Test score of trained model: 94.02074116036616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9793ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>859682.740160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>927.190779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.376568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  859682.740160\n",
       "1    RMSE     927.190779\n",
       "2     MAE     670.376568\n",
       "3      r2       0.940207\n",
       "4  adj_r2       0.930425"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7fcbe",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713ad932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14233880334643\n",
      "Test score of trained model: 94.02710187901044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ecd4262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>858768.212092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>926.697476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.263321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  858768.212092\n",
       "1    RMSE     926.697476\n",
       "2     MAE     670.263321\n",
       "3      r2       0.940271\n",
       "4  adj_r2       0.930499"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90fc8997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.98613775300879\n",
      "Test score of trained model: 98.87146560496448\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96666852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>162257.826113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>402.812396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>197.654321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.988715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.986868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  162257.826113\n",
       "1    RMSE     402.812396\n",
       "2     MAE     197.654321\n",
       "3      r2       0.988715\n",
       "4  adj_r2       0.986868"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=4, n_estimators=1500,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.983156832699998\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 1500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df10153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.977424705444053\n",
      "   Metric          Score\n",
      "0     MSE  324581.885553\n",
      "1    RMSE     569.720884\n",
      "2     MAE     254.796397\n",
      "3      r2       0.977425\n",
      "4  adj_r2       0.973731\n",
      "Best Score: 0.9754744870529732\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 20}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9795566061664265\n",
      "   Metric          Score\n",
      "0     MSE  293929.955206\n",
      "1    RMSE     542.153074\n",
      "2     MAE     239.832744\n",
      "3      r2       0.979557\n",
      "4  adj_r2       0.976212\n",
      "Best Score: 0.9746023395439201\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 20}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.979273127293828\n",
      "   Metric          Score\n",
      "0     MSE  298005.742867\n",
      "1    RMSE     545.899023\n",
      "2     MAE     237.691284\n",
      "3      r2       0.979273\n",
      "4  adj_r2       0.975882\n",
      "Best Score: 0.974616171503371\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9788592233058061\n",
      "   Metric          Score\n",
      "0     MSE  303956.749909\n",
      "1    RMSE     551.322728\n",
      "2     MAE     238.053668\n",
      "3      r2       0.978859\n",
      "4  adj_r2       0.975400\n",
      "Best Score: 0.9755353103360204\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9779729155355789\n",
      "   Metric          Score\n",
      "0     MSE  316699.859263\n",
      "1    RMSE     562.760925\n",
      "2     MAE     247.716171\n",
      "3      r2       0.977973\n",
      "4  adj_r2       0.974369\n",
      "Best Score: 0.9746339645494556\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b58b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d62e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a707d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 2075.9734 - mean_absolute_error: 2070.8970 - val_loss: 1778.1779 - val_mean_absolute_error: 1762.2402\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 751.5843 - mean_absolute_error: 726.3957 - val_loss: 419.2788 - val_mean_absolute_error: 391.6981\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 349.5955 - mean_absolute_error: 321.6591 - val_loss: 349.3987 - val_mean_absolute_error: 321.2832\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 287.3476 - mean_absolute_error: 258.7935 - val_loss: 294.8294 - val_mean_absolute_error: 265.8369\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 242.7664 - mean_absolute_error: 213.3580 - val_loss: 259.9649 - val_mean_absolute_error: 230.3202\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 202.5309 - mean_absolute_error: 172.4560 - val_loss: 225.3735 - val_mean_absolute_error: 194.9042\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 184.1765 - mean_absolute_error: 153.3572 - val_loss: 208.3751 - val_mean_absolute_error: 177.3968\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 158.8346 - mean_absolute_error: 127.7330 - val_loss: 192.0647 - val_mean_absolute_error: 160.8311\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 144.0778 - mean_absolute_error: 113.0327 - val_loss: 174.2645 - val_mean_absolute_error: 143.3703\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 140.3949 - mean_absolute_error: 109.4619 - val_loss: 167.6046 - val_mean_absolute_error: 136.7590\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 128.9045 - mean_absolute_error: 98.0002 - val_loss: 147.7926 - val_mean_absolute_error: 116.9856\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 120.2071 - mean_absolute_error: 89.4542 - val_loss: 153.0959 - val_mean_absolute_error: 122.5331\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 110.7386 - mean_absolute_error: 80.1504 - val_loss: 138.5098 - val_mean_absolute_error: 108.0105\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 107.8621 - mean_absolute_error: 77.6039 - val_loss: 141.1331 - val_mean_absolute_error: 110.9177\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 102.0436 - mean_absolute_error: 72.1097 - val_loss: 132.6985 - val_mean_absolute_error: 102.8521\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 98.9952 - mean_absolute_error: 69.2076 - val_loss: 131.2780 - val_mean_absolute_error: 101.7572\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.5768 - mean_absolute_error: 67.1971 - val_loss: 120.8625 - val_mean_absolute_error: 91.6274\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.7150 - mean_absolute_error: 67.5112 - val_loss: 133.2635 - val_mean_absolute_error: 104.1884\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 87.6720 - mean_absolute_error: 58.6898 - val_loss: 123.9468 - val_mean_absolute_error: 95.1066\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.3336 - mean_absolute_error: 61.6781 - val_loss: 119.2672 - val_mean_absolute_error: 90.8529\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.7942 - mean_absolute_error: 55.3743 - val_loss: 116.9577 - val_mean_absolute_error: 88.7151\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.1102 - mean_absolute_error: 54.8970 - val_loss: 116.8024 - val_mean_absolute_error: 88.7643\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.2587 - mean_absolute_error: 54.3013 - val_loss: 119.7162 - val_mean_absolute_error: 91.8914\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 80.7959 - mean_absolute_error: 53.1050 - val_loss: 123.3796 - val_mean_absolute_error: 95.8235\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.9994 - mean_absolute_error: 50.5865 - val_loss: 117.0756 - val_mean_absolute_error: 89.8471\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 78.9069 - mean_absolute_error: 51.7779 - val_loss: 117.8644 - val_mean_absolute_error: 90.9605\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.5519 - mean_absolute_error: 46.6302 - val_loss: 138.2760 - val_mean_absolute_error: 111.3448\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.5170 - mean_absolute_error: 50.8601 - val_loss: 113.0203 - val_mean_absolute_error: 86.4722\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.8262 - mean_absolute_error: 46.3291 - val_loss: 120.1357 - val_mean_absolute_error: 93.7621\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 80.5950 - mean_absolute_error: 54.3259 - val_loss: 114.7934 - val_mean_absolute_error: 88.5075\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.0279 - mean_absolute_error: 41.9777 - val_loss: 112.0232 - val_mean_absolute_error: 86.1796\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 71.3761 - mean_absolute_error: 45.5575 - val_loss: 106.2384 - val_mean_absolute_error: 80.4820\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.6904 - mean_absolute_error: 45.1101 - val_loss: 112.0941 - val_mean_absolute_error: 86.7278\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.3461 - mean_absolute_error: 42.0074 - val_loss: 105.6257 - val_mean_absolute_error: 80.3366\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.7791 - mean_absolute_error: 40.5925 - val_loss: 109.3541 - val_mean_absolute_error: 84.2945\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.9488 - mean_absolute_error: 42.0153 - val_loss: 111.2477 - val_mean_absolute_error: 86.2971\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.9321 - mean_absolute_error: 40.1433 - val_loss: 106.6066 - val_mean_absolute_error: 81.9851\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.4199 - mean_absolute_error: 38.8666 - val_loss: 111.9005 - val_mean_absolute_error: 87.3150\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.7418 - mean_absolute_error: 37.3697 - val_loss: 108.0025 - val_mean_absolute_error: 83.6786\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.1964 - mean_absolute_error: 40.0454 - val_loss: 101.2081 - val_mean_absolute_error: 77.1775\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.9196 - mean_absolute_error: 34.9794 - val_loss: 111.5960 - val_mean_absolute_error: 87.6779\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.7116 - mean_absolute_error: 43.9856 - val_loss: 101.7439 - val_mean_absolute_error: 78.1855\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.5374 - mean_absolute_error: 36.9841 - val_loss: 102.6490 - val_mean_absolute_error: 79.1719\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.2184 - mean_absolute_error: 37.8335 - val_loss: 106.0490 - val_mean_absolute_error: 82.8279\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.9700 - mean_absolute_error: 36.7889 - val_loss: 99.1806 - val_mean_absolute_error: 76.1069\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4117 - mean_absolute_error: 38.4250 - val_loss: 96.9421 - val_mean_absolute_error: 74.0806\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.6767 - mean_absolute_error: 33.8654 - val_loss: 98.0519 - val_mean_absolute_error: 75.2885\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.7120 - mean_absolute_error: 31.0415 - val_loss: 99.6642 - val_mean_absolute_error: 77.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.5453 - mean_absolute_error: 35.0672 - val_loss: 100.4368 - val_mean_absolute_error: 78.0621\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.3051 - mean_absolute_error: 36.9651 - val_loss: 94.4070 - val_mean_absolute_error: 72.1838\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0130 - mean_absolute_error: 33.8700 - val_loss: 107.1437 - val_mean_absolute_error: 85.1599\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.4210 - mean_absolute_error: 32.4088 - val_loss: 97.3990 - val_mean_absolute_error: 75.4268\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.9797 - mean_absolute_error: 33.1151 - val_loss: 100.4978 - val_mean_absolute_error: 78.6623\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1227 - mean_absolute_error: 31.4477 - val_loss: 97.1023 - val_mean_absolute_error: 75.5048\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.8985 - mean_absolute_error: 31.3885 - val_loss: 94.6682 - val_mean_absolute_error: 73.2131\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1105 - mean_absolute_error: 29.7627 - val_loss: 100.1385 - val_mean_absolute_error: 78.9571\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.5980 - mean_absolute_error: 34.4092 - val_loss: 93.1958 - val_mean_absolute_error: 72.1198\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.1247 - mean_absolute_error: 31.1106 - val_loss: 101.7058 - val_mean_absolute_error: 80.8566\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.7468 - mean_absolute_error: 31.8491 - val_loss: 95.8858 - val_mean_absolute_error: 75.0479\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.5841 - mean_absolute_error: 33.7619 - val_loss: 104.1782 - val_mean_absolute_error: 83.3146\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.5661 - mean_absolute_error: 32.9315 - val_loss: 103.1079 - val_mean_absolute_error: 82.5849\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1380 - mean_absolute_error: 32.6979 - val_loss: 93.8000 - val_mean_absolute_error: 73.4405\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.7062 - mean_absolute_error: 29.3996 - val_loss: 98.1754 - val_mean_absolute_error: 77.8895\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.8163 - mean_absolute_error: 27.6986 - val_loss: 102.5628 - val_mean_absolute_error: 82.4702\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.1897 - mean_absolute_error: 30.1914 - val_loss: 93.8666 - val_mean_absolute_error: 73.8783\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.8932 - mean_absolute_error: 33.9968 - val_loss: 100.9767 - val_mean_absolute_error: 81.1603\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.9376 - mean_absolute_error: 32.1900 - val_loss: 94.9020 - val_mean_absolute_error: 75.2163\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4319 - mean_absolute_error: 32.8126 - val_loss: 97.0874 - val_mean_absolute_error: 77.5299\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.3274 - mean_absolute_error: 28.8689 - val_loss: 92.5840 - val_mean_absolute_error: 73.2351\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0394 - mean_absolute_error: 27.7076 - val_loss: 95.8254 - val_mean_absolute_error: 76.5558\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.1386 - mean_absolute_error: 32.9172 - val_loss: 93.4864 - val_mean_absolute_error: 74.3726\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1985 - mean_absolute_error: 30.1088 - val_loss: 100.8253 - val_mean_absolute_error: 81.7018\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.8124 - mean_absolute_error: 29.8160 - val_loss: 90.9235 - val_mean_absolute_error: 72.0073\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1680 - mean_absolute_error: 30.2724 - val_loss: 97.1724 - val_mean_absolute_error: 78.3298\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.2731 - mean_absolute_error: 29.5199 - val_loss: 95.8904 - val_mean_absolute_error: 77.1784\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8855 - mean_absolute_error: 27.2328 - val_loss: 91.4839 - val_mean_absolute_error: 72.8758\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.7184 - mean_absolute_error: 30.1905 - val_loss: 93.2249 - val_mean_absolute_error: 74.7348\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1317 - mean_absolute_error: 27.7348 - val_loss: 97.5288 - val_mean_absolute_error: 79.2006\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9983 - mean_absolute_error: 28.6864 - val_loss: 95.8598 - val_mean_absolute_error: 77.6043\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.9559 - mean_absolute_error: 31.7489 - val_loss: 97.3415 - val_mean_absolute_error: 79.1429\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8139 - mean_absolute_error: 28.7312 - val_loss: 95.4632 - val_mean_absolute_error: 77.3962\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3568 - mean_absolute_error: 28.4181 - val_loss: 93.5814 - val_mean_absolute_error: 75.7373\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8604 - mean_absolute_error: 28.0631 - val_loss: 95.8668 - val_mean_absolute_error: 78.1556\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6237 - mean_absolute_error: 25.9209 - val_loss: 96.1111 - val_mean_absolute_error: 78.4656\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.5502 - mean_absolute_error: 28.9689 - val_loss: 101.1060 - val_mean_absolute_error: 83.6450\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3057 - mean_absolute_error: 28.7800 - val_loss: 94.6470 - val_mean_absolute_error: 77.0930\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2513 - mean_absolute_error: 25.8289 - val_loss: 86.7052 - val_mean_absolute_error: 69.3895\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.6739 - mean_absolute_error: 30.3758 - val_loss: 90.4700 - val_mean_absolute_error: 73.2015\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.7364 - mean_absolute_error: 27.5052 - val_loss: 94.1489 - val_mean_absolute_error: 76.9299\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.5010 - mean_absolute_error: 28.3796 - val_loss: 93.2006 - val_mean_absolute_error: 76.0774\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.4842 - mean_absolute_error: 33.4409 - val_loss: 92.3460 - val_mean_absolute_error: 75.4195\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7423 - mean_absolute_error: 25.8065 - val_loss: 90.9678 - val_mean_absolute_error: 74.0037\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.3263 - mean_absolute_error: 25.4782 - val_loss: 91.0577 - val_mean_absolute_error: 74.2863\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.5162 - mean_absolute_error: 28.7588 - val_loss: 90.7666 - val_mean_absolute_error: 74.0222\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5978 - mean_absolute_error: 26.9126 - val_loss: 93.5674 - val_mean_absolute_error: 76.9322\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.0430 - mean_absolute_error: 25.4651 - val_loss: 91.1613 - val_mean_absolute_error: 74.6449\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7675 - mean_absolute_error: 25.2796 - val_loss: 89.0280 - val_mean_absolute_error: 72.5206\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8215 - mean_absolute_error: 29.4093 - val_loss: 89.0940 - val_mean_absolute_error: 72.7076\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9165 - mean_absolute_error: 26.5894 - val_loss: 90.8620 - val_mean_absolute_error: 74.5073\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2509 - mean_absolute_error: 26.9520 - val_loss: 95.1758 - val_mean_absolute_error: 78.9203\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8fb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd03b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyQElEQVR4nO3deZxdVZXo8d+6c81zpqqEBAhDCBIgQGiQRnlCiMqgLQ2Kom0T7Vaa7rZReO3ss5ueHHjd4gONCipIg0paUYnMtgRIQhoCCSQhCanKUJVUVWq+43p/7H0rN5WqpOaK967v53M/de8+0z7n3Fpnn3X2PUdUFWOMMYUhMNUVMMYYM3ks6BtjTAGxoG+MMQXEgr4xxhQQC/rGGFNALOgbY0wBsaBv/uCJiIrIieM8zydF5M/Hc57GHAss6JtDiMh2EUmISO2A8hd9cJ07RfWaJyIZEblzKpZ/JGM9QPjp+0SkK+f1X+NZx2HU4fsi8n8mc5lmaljQN4PZBlyX/SAipwPFU1cdAD4EtAF/KiLRKa7LRPikqpbmvN492EgiEhpO2ZGMdHyTXyzom8HciwuyWTcA9+SOICJREflXEXlTRPaKyLdFpMgPqxKRX4hIi4i0+fcNOdM+KSJfEZH/FpFOEXl04JnFgGWJr89ngSQwWEBcJiJviMg+EfkXEQn4aU8UkadE5IAf9pOc+f6RiLzgh70gIn80xPK/KCI/zPk815/1hETkq8BbgX/3LfR/9+OcIiKrRKRVRF4TkWuGWr8jEZGLRaRRRD4jInuA7/n6PCgiPxSRDuDDIjJLRFb65W0RkRsH1P+Q8UdYhxv9PFv9Mmb5chGRr4tIs4h0iMjLIrLQD1smIq/6/dskIn83mvU348+CvhnMaqBcRE4VkSBwLfDDAePcDpwELAJOBOqBz/thAeB7wHHAHKAX+PcB078f+AgwDYgARwoKFwINwP3AA7iD0EBXA4uBs4ArgT/z5V8BHgWq/Dz+L4CIVAO/BO4AaoCvAb8UkZoj1OMwqvr3wDMcbKl/UkRKgFXAj/36XQt8S0QWjGTeOWYA1bjtudyXXQk8CFQCP8Jtm0ZgFvAnwD+IyNtz5jFw/GHx8/hH4BpgJrDDLwvgUuAi3Pegwo+z3w/7LvAxVS0DFgKPD3eZZmJZ0DdDybb23wFsBJqyA3zLeznwN6raqqqdwD/gghuqul9VH1LVHj/sq8AfD5j/91T1dVXtxQXyRUeoyw3Ar1S1DRdIl4rItAHj/JOvy5vANziYnkriguUsVe1T1d/58ncCm1X1XlVNqep9wCYGP4sYqXcB21X1e37eLwIPAe87wjR3iEh7zusrOcMywBdUNe63F8CzqvpzVc0AtcAFwGf8Oq4HvsOhZ2v94+fMYzg+AKxQ1XWqGgduA87313aSQBlwCiCqulFVd/vpksACESlX1TZVXTeCZZoJZEHfDOVeXGv8wwxI7QB1uBz/2myQAn7tyxGRYhH5fyKyw6cTngYq/VlD1p6c9z1A6WCV8Cmj9+Fbp6r6LPCmr1uunTnvd+BavACfBgR4XkReEZHsGcAsPx4DpqsfrB4jdBxwXm4QxwXPGUeY5q9UtTLn9bmcYS2q2jdg/Nz1nQVkD75ZA9cld/yROGQ7qWoXrjVfr6qP487g/gNoFpG7RKTcj/peYBmww6fXzh/l8s04s6BvBqWqO3AXdJcBPx0weB8uZXNaTpCqUNVs4P4UcDJwnqqW41IA4ILvSF0NlOPSI3t8Xruew1M8s3PezwF2+fXYo6o3quos4GN+Pif64ccNmMcccs5ocnRz6IXsgcF74K1qdwJPDQjipar6F0dc06ENdivc3LJdQLWIlOWUDVyX0d5O95Dt5FNXNdl5q+odqno2sACX5rnFl7+gqlfi0ls/x53NmWOABX1zJB8F3q6q3bmFPqVwN/D1bJpFROpF5DI/ShnuoNDuc+dfGEMdbgBWAKfjUkCLcKmMM8T1Ksq6xV9Ang3cDPzE1+t9OReR23DBLwM8ApwkIu/3F2T/FBe4fjFIHdYDF4nIHBGpwKU4cu0Fjs/5/As/7w+KSNi/zhGRU0e3CY5MVXcCvwf+UURiIvIW3L4beB3maIJ++uwrAtwHfEREFonrNfUPwHOqut2v03kiEsYdGPuAjIhEROQDIlKhqkmgA7fNzTHAgr4ZkqpuVdU1Qwz+DLAFWO1TOL/Fte7B5dSLcGcEq3GpnxETkXrgEuAbvsWefa3188xt7T8MrMUF6F/iLiQCnAM8JyJdwErgZlV9Q1X343Lvn8KlKz4NvEtV9w2sh6quwh1EXvLLGHhg+CbwJ+J6Kt3h0yyX4q5x7MKlsv4JOFJX02zvn+xr7XC2UY7rgLl+eT/DXQP47QjncSvuYJ19Pe7n8TncNYndwAn4aze4M7C7cQfTHbjt+C9+2AeB7f678XFcesscA8QeomKMMYXDWvrGGFNALOgbY0wBsaBvjDEFxIK+McYUkGP+xku1tbU6d+7cqa6GMcb8wVi7du0+Va0bbNgxH/Tnzp3LmjVD9Ro0xhgzkIgM/LV5P0vvGGNMAbGgb4wxBcSCvjHGFJBjPqdvjDEjlUwmaWxspK9v4M1J80ssFqOhoYFwODzsaSzoG2PyTmNjI2VlZcydOxf3+If8o6rs37+fxsZG5s2bN+zpLL1jjMk7fX191NTU5G3ABxARampqRnw2Y0HfGJOX8jngZ41mHfM26N/x2Gaeer1lqqthjDHHlLwN+t9+aiu/22xB3xgz+drb2/nWt7414umWLVtGe3v7+FcoR94G/UgoQDJtzwowxky+oYJ+KpU64nSPPPIIlZWVE1QrJ29774SDARJpe0KbMWby3XrrrWzdupVFixYRDoeJxWJUVVWxadMmXn/9da666ip27txJX18fN998M8uXLwcO3namq6uLyy+/nAsvvJDf//731NfX8/DDD1NUVDTmuuVt0I8EAyRTFvSNKXRf+q9XeHVXx7jOc8Gscr7w7tOGHH777bezYcMG1q9fz5NPPsk73/lONmzY0N+1csWKFVRXV9Pb28s555zDe9/7Xmpqag6Zx+bNm7nvvvu4++67ueaaa3jooYe4/vrrx1z3o6Z3RGS2iDwhIq+KyCsicrMvrxaRVSKy2f+t8uUiIneIyBYReUlEzsqZ1w1+/M0icsNQyxwP4aCQtJa+MeYYcO655x7Sl/6OO+7gjDPOYMmSJezcuZPNmzcfNs28efNYtGgRAGeffTbbt28fl7oMp6WfAj6lqutEpAxYKyKrgA8Dj6nq7SJyK+6hyp8BLgfm+9d5wJ3AeSJSDXwBWAyon89KVW0blzUZIBy0nL4xhiO2yCdLSUlJ//snn3yS3/72tzz77LMUFxdz8cUXD9rXPhqN9r8PBoP09vaOS12O2tJX1d2qus6/7wQ2AvXAlcAP/Gg/AK7y768E7lFnNVApIjOBy4BVqtrqA/0qYOm4rMUgwsEAcUvvGGOmQFlZGZ2dnYMOO3DgAFVVVRQXF7Np0yZWr149qXUbUU5fROYCZwLPAdNVdbcftAeY7t/XAztzJmv0ZUOVT4hwKGDpHWPMlKipqeGCCy5g4cKFFBUVMX369P5hS5cu5dvf/jannnoqJ598MkuWLJnUug076ItIKfAQ8Neq2pH7SzBVVREZt1yKiCwHlgPMmTNnVPOIWE7fGDOFfvzjHw9aHo1G+dWvfjXosGzevra2lg0bNvSX/93f/d241WtY/fRFJIwL+D9S1Z/64r0+bYP/2+zLm4DZOZM3+LKhyg+jqnep6mJVXVxXN+gTv47K5fQt6BtjTK7h9N4R4LvARlX9Ws6glUC2B84NwMM55R/yvXiWAAd8Gug3wKUiUuV7+lzqyyZEJBQgYRdyjTHmEMNJ71wAfBB4WUTW+7L/DdwOPCAiHwV2ANf4YY8Ay4AtQA/wEQBVbRWRrwAv+PG+rKqt47ESgwlbP31jjDnMUYO+qv4OGOpWbpcMMr4CnxhiXiuAFSOp4GhFLL1jjDGHydt779iPs4wx5nB5HPTtx1nGGDNQ/gb9kP04yxgzNUZ7a2WAb3zjG/T09IxzjQ7K26BvOX1jzFQ5loN+3t5l03L6xpipkntr5Xe84x1MmzaNBx54gHg8ztVXX82XvvQluru7ueaaa2hsbCSdTvO5z32OvXv3smvXLt72trdRW1vLE088Me51y+Ogby19Ywzwq1thz8vjO88Zp8Pltw85OPfWyo8++igPPvggzz//PKrKFVdcwdNPP01LSwuzZs3il7/8JeDuyVNRUcHXvvY1nnjiCWpra8e3zl7+pnf8k7NcD1JjjJkajz76KI8++ihnnnkmZ511Fps2bWLz5s2cfvrprFq1is985jM888wzVFRUTEp98rqlD5BMK5HQyJ8Yb4zJE0dokU8GVeW2227jYx/72GHD1q1bxyOPPMJnP/tZLrnkEj7/+c9PeH3yt6XfH/QtxWOMmVy5t1a+7LLLWLFiBV1dXQA0NTXR3NzMrl27KC4u5vrrr+eWW25h3bp1h007EfK4pe9a9xb0jTGTLffWypdffjnvf//7Of/88wEoLS3lhz/8IVu2bOGWW24hEAgQDoe58847AVi+fDlLly5l1qxZdiF3JMIh19JPWF99Y8wUGHhr5ZtvvvmQzyeccAKXXXbZYdPddNNN3HTTTRNWr7xN72Rz+glr6RtjTL+8DfqRnAu5xhhjnLwN+mG7kGtMQSuE7tqjWcc8DvruQq7l9I0pPLFYjP379+d14FdV9u/fTywWG9F0eXsh99SX/5lLA+Uk03801VUxxkyyhoYGGhsbaWlpmeqqTKhYLEZDQ8OIpjlq0BeRFcC7gGZVXejLfgKc7EepBNpVdZGIzAU2Aq/5YatV9eN+mrOB7wNFuKdr3awTeBieteV+zgn8seX0jSlA4XCYefPmTXU1jknDael/H/h34J5sgar+afa9iPwbcCBn/K2qumiQ+dwJ3Ag8hwv6S4HBHwk/DjQYJkzKcvrGGJPjqDl9VX0aGPRZtv6h6dcA9x1pHiIyEyhX1dW+dX8PcNWIazsCGggTIWU5fWOMyTHWC7lvBfaq6uacsnki8qKIPCUib/Vl9UBjzjiNvmxQIrJcRNaIyJrR5uQ0GCFMyvrpG2NMjrEG/es4tJW/G5ijqmcCfwv8WETKRzpTVb1LVRer6uK6urrR1SwYJiyW3jHGmFyj7r0jIiHgPcDZ2TJVjQNx/36tiGwFTgKagNxLzA2+bOJYS98YYw4zlpb+/wI2qWp/2kZE6kQk6N8fD8wH3lDV3UCHiCzx1wE+BDw8hmUfXSBMhDTJlPXeMcaYrKMGfRG5D3gWOFlEGkXko37QtRx+Afci4CURWQ88CHxcVbMXgf8S+A6wBdjKBPbcAZBQ2Fr6xhgzwFHTO6p63RDlHx6k7CHgoSHGXwMsHGH9Rk2CUcJ0WU7fGGNy5O1tGCRkF3KNMWagPA76USKk7Be5xhiTI3+Dvv9Fbtx+nGWMMf3yOOhHCEva0jvGGJMjb4M+wYjvsmlB3xhjsvI76NuFXGOMOUQeB/1sP327kGuMMVl5HPQjdmtlY4wZwIK+McYUkDwO+vYQFWOMGSiPg36EECkSyfRU18QYY44ZeR30AyiptAV9Y4zJyuOgHwZAk/Eprogxxhw78jjoRwDQdGKKK2KMMceOPA76rqWPBX1jjOk3nIeorBCRZhHZkFP2RRFpEpH1/rUsZ9htIrJFRF4Tkctyypf6si0icuv4r8oA/S395IQvyhhj/lAMp6X/fWDpIOVfV9VF/vUIgIgswD1R6zQ/zbdEJOgfofgfwOXAAuA6P+7E8UHfWvrGGHPQcJ6c9bSIzB3m/K4E7vcPSN8mIluAc/2wLar6BoCI3O/HfXXkVR4mS+8YY8xhxpLT/6SIvOTTP1W+rB7YmTNOoy8bqnxQIrJcRNaIyJqWlpbR1S6b3klZ0DfGmKzRBv07gROARcBu4N/Gq0IAqnqXqi5W1cV1dXWjm4kP+pKxoG+MMVlHTe8MRlX3Zt+LyN3AL/zHJmB2zqgNvowjlE+MoF81u5BrjDH9RtXSF5GZOR+vBrI9e1YC14pIVETmAfOB54EXgPkiMk9EIriLvStHX+1hyLb0LegbY0y/o7b0ReQ+4GKgVkQagS8AF4vIIkCB7cDHAFT1FRF5AHeBNgV8QlXTfj6fBH4DBIEVqvrKeK/MIXzQD2Qs6BtjTNZweu9cN0jxd48w/leBrw5S/gjwyIhqNxa+905Ak2QySiAgk7ZoY4w5VuXxL3JdSz9MimTGbq9sjDFQEEE/TdIemWiMMUBeB32X3gmTIpmylr4xxkBeB33f0pcUCXt6ljHGAAUQ9COkSFhL3xhjgLwO+jnpHWvpG2MMkNdBP6f3jl3INcYYoCCCftpa+sYY4+Vv0A+4351F7EKuMcb0y9+gL0ImELEum8YYkyN/gz6ggbDl9I0xJkd+B/2gC/qJdHqqq2KMMceE/A76gYjvp28tfWOMgTwP+gTD1k/fGGNy5HnQjxAWC/rGGJN11KDvH3zeLCIbcsr+RUQ2+Qej/0xEKn35XBHpFZH1/vXtnGnOFpGXRWSLiNwhIhN/g3tr6RtjzCGG09L/PrB0QNkqYKGqvgV4HbgtZ9hWVV3kXx/PKb8TuBH3CMX5g8xz/AUjREiTsN47xhgDDCPoq+rTQOuAskdVNeU/rsY96HxI/pm65aq6WlUVuAe4alQ1HgEJWT99Y4zJNR45/T8DfpXzeZ6IvCgiT4nIW31ZPdCYM06jL5tQEoxYescYY3Ic9Rm5RyIif497APqPfNFuYI6q7heRs4Gfi8hpo5jvcmA5wJw5c0Zfv1DYLuQaY0yOUbf0ReTDwLuAD/iUDaoaV9X9/v1aYCtwEtDEoSmgBl82KFW9S1UXq+riurq60VYRCUbsfvrGGJNjVEFfRJYCnwauUNWenPI6EQn698fjLti+oaq7gQ4RWeJ77XwIeHjMtT9aPYMRImIXco0xJuuo6R0RuQ+4GKgVkUbgC7jeOlFgle95udr31LkI+LKIJIEM8HFVzV4E/ktcT6Ai3DWA3OsAEyMYJmI5fWOM6XfUoK+q1w1S/N0hxn0IeGiIYWuAhSOq3VgFI0Qsp2+MMf3y/he5IXuIijHG9MvzoB+2G64ZY0yOPA/61k/fGGNy5X3QD1nQN8aYfnke9P1DVKyfvjHGAHkf9F1LP5GyJ2cZYwwUQNAPoKTTqaOPa4wxBSDPg34YAE0nprgixhhzbMjzoB9xf1MW9I0xBvI+6LuWfsaCvjHGAHkf9H1L39I7xhgDFEzQT05tPYwx5hiR50HfpXespW+MMU6eB31L7xhjTK7CCPoZS+8YYwzkfdB36Z2AtfSNMQYYZtAXkRUi0iwiG3LKqkVklYhs9n+rfLmIyB0iskVEXhKRs3KmucGPv1lEbhj/1RnAt/QlY7/INcYYGH5L//vA0gFltwKPqep84DH/GeBy3LNx5wPLgTvBHSRwj1o8DzgX+EL2QDFhfNAPapJ0xu6pb4wxwwr6qvo00Dqg+ErgB/79D4CrcsrvUWc1UCkiM4HLgFWq2qqqbcAqDj+QjK+gexqk3VPfGGOcseT0p6vqbv9+DzDdv68HduaM1+jLhio/jIgsF5E1IrKmpaVl9DX0LX0L+sYY44zLhVxVVWDc8ieqepeqLlbVxXV1daOfkQ/6EVIk05beMcaYsQT9vT5tg//b7MubgNk54zX4sqHKJ47vvWMPUjHGGGcsQX8lkO2BcwPwcE75h3wvniXAAZ8G+g1wqYhU+Qu4l/qyieNb+iFJW3rHGGOA0HBGEpH7gIuBWhFpxPXCuR14QEQ+CuwArvGjPwIsA7YAPcBHAFS1VUS+Arzgx/uyqg68ODy+ctI7CQv6xhgzvKCvqtcNMeiSQcZV4BNDzGcFsGLYtRurnPSOtfSNMSbvf5Gb03snZRdyjTGmQIJ+2tI7xhhDvgf9gMteRcTSO8YYA/ke9EXIBCKW0zfGGC+/gz6gwbD10zfGGC//g34gbC19Y4zx8j7oE4z4fvrWe8cYYwog6PuWvqV3jDGmEIJ+hLD13jHGGKBQgr7l9I0xBiiAoC/BCBHSltM3xhgKIeiHrPeOMcZk5X/Q9+kd66dvjDEFEPQJRew2DMYY4+V90JegC/p2wzVjjBlD0BeRk0Vkfc6rQ0T+WkS+KCJNOeXLcqa5TUS2iMhrInLZ+KzCUQTCREjbrZWNMYZhPkRlMKr6GrAIQESCuOfd/gz3pKyvq+q/5o4vIguAa4HTgFnAb0XkJFVNj7YOwxIMW3rHGGO88UrvXAJsVdUdRxjnSuB+VY2r6jbc4xTPHaflDy17Gwa7kGuMMeMW9K8F7sv5/EkReUlEVviHoAPUAztzxmn0ZYcRkeUiskZE1rS0tIytZsEIEUnTFU+NbT7GGJMHxhz0RSQCXAH8py+6EzgBl/rZDfzbSOepqnep6mJVXVxXVze2Cvr0Tmt3YmzzMcaYPDAeLf3LgXWquhdAVfeqalpVM8DdHEzhNAGzc6Zr8GUTKxghRJq2Hgv6xhgzHkH/OnJSOyIyM2fY1cAG/34lcK2IREVkHjAfeH4cln9k/sdZ1tI3xpgx9N4BEJES4B3Ax3KK/1lEFgEKbM8OU9VXROQB4FUgBXxiwnvuAATDhDRFW08CVUVEJnyRxhhzrBpT0FfVbqBmQNkHjzD+V4GvjmWZIxaMENQkyXSGrniKslh4UhdvjDHHkrz/RS7BCIISJGMpHmNMwSuAoO9a9pbXN8aYggj6EQAipKwHjzGm4BVA0M9t6SenuDLGGDO1CiDou5Z+mBRtlt4xxhS4ggn6xcE0rZbeMcYUuAII+i69U1MktHZZ0DfGFLYCCPqupV9bJNbSN8YUvIIJ+tVRsZy+MabgFUDQd+mdqhjW0jfGFLwCCPqupV8VVWvpG2MKXsEE/cqo0N6bJJ2xZ+UaYwpXAQR9l96piCiqcKDXfqBljClcBRD0XUu/POJa+K3d8amsjTHGTKkCCPqupV8ezgZ9a+kbYwrXeDwjd7uIvCwi60VkjS+rFpFVIrLZ/63y5SIid4jIFv/g9LPGuvyj8kG/NJQBsDttGmMK2ni19N+mqotUdbH/fCvwmKrOBx7zn8E9T3e+fy3HPUR9Yvn0Tqlv6dudNo0xhWyi0jtXAj/w738AXJVTfo86q4HKAc/UHX8+6JcEraVvjDHjEfQVeFRE1orIcl82XVV3+/d7gOn+fT2wM2faRl92CBFZLiJrRGRNS0vL2GqXvbWypCmOBK2vvjGmoI3pGbneharaJCLTgFUisil3oKqqiIyoc7yq3gXcBbB48eKxdaz3LX3SCaqKI9bSN8YUtDG39FW1yf9tBn4GnAvszaZt/N9mP3oTMDtn8gZfNnFygn51ScRuxWCMKWhjCvoiUiIiZdn3wKXABmAlcIMf7QbgYf9+JfAh34tnCXAgJw00MQL+ZCadpKokYukdY0xBG2t6ZzrwMxHJzuvHqvprEXkBeEBEPgrsAK7x4z8CLAO2AD3AR8a4/KMTca39dILq4jDb9nVN+CKNMeZYNaagr6pvAGcMUr4fuGSQcgU+MZZljkowAukk1SVR2uzHWcaYApb/v8gF14MnnaC6JExXPEU8lZ7qGhljzJQokKDv0jtVJe6ibnuPtfaNMYWpMIJ+2QxoXEt1keuzv9+elWuMKVCFEfTP+XPY+zLHda4B7FYMxpjCVRhB//RroGQax236LmC3YjDGFK7CCPrhGJy3nJKdT3KS7LSWvjGmYBVG0AdY/FE0XMyNwV9aS98YU7AKJ+gXVyNnXs9Vof8m1T6xd34wxphjVeEEfYAlf0EA5S1N9091TYwxZkoUVtCvPp4Xyy/hotaHaG3aMtW1McaYSVdYQR+ovfKrKMLehz491VUxxphJV3BBf+4JJ/NU3Qc4tfUx2l59bKqrY4wxk6rggj7AKe/9e5q0lvh/fRoydh8eY0zhKMigP3dmHY/PvokZvVvo+O+7p7o6xhgzaQoy6ANcfPWNPJtZQNHjn4M3n5vq6hhjzKQo2KA/u6aEZ874F3amq0n+8H3QvHGqq2SMMRNu1EFfRGaLyBMi8qqIvCIiN/vyL4pIk4is969lOdPcJiJbROQ1EblsPFZgLG569/l8tuzLtCcCZO59DxxonOoqGWPMhBpLSz8FfEpVFwBLgE+IyAI/7Ouqusi/HgHww64FTgOWAt8SkeAYlj9mRZEg//v9S/lI8jPEuw+g914N3funskrGGDOhRh30VXW3qq7z7zuBjUD9ESa5ErhfVeOqug33nNxzR7v88bKwvoJ3X3opN/T+LZnW7fDj90HcnqNrjMlP45LTF5G5wJlA9oroJ0XkJRFZISJVvqwe2JkzWSNDHCREZLmIrBGRNS0tLeNRxSO68a3HE5x3ITcl/wrd9SI88EFI2U3ZjDH5Z8xBX0RKgYeAv1bVDuBO4ARgEbAb+LeRzlNV71LVxaq6uK6ubqxVPKpAQPjmdYtYEzuffw7/JWx9HP7zBujYNeHLNsaYyTSmoC8iYVzA/5Gq/hRAVfeqalpVM8DdHEzhNAGzcyZv8GXHhGllMe68/iy+030B91X9Bbp5FdxxFvz2i9DbPtXVM8aYcTGW3jsCfBfYqKpfyymfmTPa1cAG/34lcK2IREVkHjAfeH60y58IZx9XzefetYDbdr+Vu97yE/SUd8Hvvg7fPAOe+Rokuqe6isYYMyZjaelfAHwQePuA7pn/LCIvi8hLwNuAvwFQ1VeAB4BXgV8Dn1DVY+4eCB9cchzvO7uBf1zdx5V7PsyrV/wCZp8Hj33JBf/Vd1q+3xjzB0tUdarrcESLFy/WNWvWTOoyVZWH1+/iH3+1kb0dcd5zVj1fPbuXot/9A2x7GqrmwTu+DKe+G0QmtW7GGHM0IrJWVRcPOsyC/tC64ym+9eQW7nxyKydOK+WuDy5mbtuz8OhnoWUjNJwDJ74D6s+C+rOhuHpK6mmMMbks6I/R7zbv45P3rSOTUb557Zm8bX41vHgPPHcXtGwCFCQIS/4CLr4NoqVTWl9jTGGzoD8Odrb2sPzetWzc3cEFJ9bw8T8+gQtPrEUSXbBrPbz8AKy7Bypmu9RPMOLOBtrfdGcDp7wTAlP6A2RjTIGwoD9OehNp7l29ne88s43mzjjzp5Vy8owy6iuLmF1dzLKKHVQ/fotv/XvRcoh3QPUJcP5fQtlM6N4Hva2ubN5boahq6IVOlfadUDYDguGprokxZoQs6I+zeCrNz19sYuX/7KKprZdd7X0k0hkCAhedUMGNs7Zz+kknUj77NAgXw8aV8LtvwO71h89MAjDrTKg+HiIlEC6B6Qvg5GUHrxHsfRVe/CH0HYATL4ET3g5FlRO0cl3w2Jfh+bvcdYo/vRfKZ03MsowxE8KC/gTLZJQ39nWzcn0TP1vfxM7WXkTg9PoKLppfx9tOmcaihgqCzS+DZqC4FmIVsPcVeONJ1yOoczckeyDe6f4GQjDvIujrgKY1Ll0ULoa+djds5hlQexLUnOB6ExVVuVeswvcoEvdUsO4W6NrrXgcaoaPJnWnUnOgONjMWunmn4tC+Ax79PBzYCQvfA6/92l2fuOYeaDgX9m+Gxhfc+HWnuOWHY1O89Y0xA1nQn0Sqyvqd7Tz9+j6e2dzCizvbSWeU6pIIF59Ux4nTS6ktjVJXFuWE2lIaqooIBCR3Bu6M4NWHYeN/uQB75vXwlmtd677xBXj9N+7v/q3QOYJbRQSjUFHvDg4tr0Oi8/Bxak+CK/4vzFninjFw//vddYlIqTvg5JIAlM6A0joomQaVs2H6QphxOoSisGcD7N3gDmQzz4BZZ7lxOna5A1Dnbnf20ncA0kmoOs6lvMpmQNt2lyZr2w7FNVA5x71mvAXK/e//Mml481m3Pcrr4ZRlbpzBJHvdwXI801WqbttUNNj1GnNMsaA/hQ70Jnnq9RYe37iXpzfvo7X70B92lUZDnDKjjDnVxdSVR6krjVJbGqWqJEJVcZiicBDFxZfa0gg1pdFDFxDvcq333jboaXUBFnVnFBI8GJBLp0NJ7cHfFWQy0PoGNL/qxg9GXat9zvkuYGf1trt0TyYFs8913VQ14w4IzRv9mUMLdDVD6zaIHzi0fqEiCBe5axhDCUYgEIbkIL94Lp3h1i0dP1hWXu8OLrvWuWUHQq5+4A4KlXPcmUuqz22Tzl1uHsGoO/g0nAPTToGiancADMUg1QvJPneWlehy2zHR7Q5G6YQL6nWnuOljlfDS/bD2+7DvdSipg5MucxfsNePOqrpb3FlX2SyXHiupc+m6WKUb3rzRXeiPlrv61J3i6vvm793ZX7IXpp8G009389z2FLzxlNtnoajbpiW1LtU3/zKYdqo7eLa+AW3b3L5o3ebqUX+2SwvOOtOdxe18Hnb/j9uOM89wZ3uI20Z97W67lNdDIOe3m/Eu9z2JlLrvULLPNU7eXO3KT7oc6k4++P3q3AsdjW7/R4rdehZVDf67lkzan4XucusWLXOpzlSf2weJHvfdjJa7bRoth2AoZ/qM+96l4m5bacYtf9/r7gVu3Wed6Q7Qfwi/rVF138FY+agmt6B/DOlJpNjXmaC5s48tzV1s3N3Bxt2dNLX30tIZJ5HOHHH60+sruPjkOk6aXkZbT4L9Xe4gsrC+gjMaKphWPoXpFlUXVPZscP+w0xe69JME3D/1rhfdP3ZFvfvnK5vpgmA45qbt3getW904VXNdEImUuH/q7mbX6t/1ojvL2fMyTFsAC66E+Ze6QLrpl/D6r92BKhRxQb642i2nfKYrb1zjglWqb/jrJUEXSBjwv9JwDpx6hZvf5lXugn3/NAE/zTBFytzBJR13B8FQ7ND5Ie4MavpCN16qD9p2wN6X3eBwsTtg5Sqd7s/qXnN1D4Qhk3TDct8PJhh1+0Az0Lnn4FlhIOy2aW+bq0eu6hPc/t7zsjuLGyhW4VKR5bMOpjJ721yngSPVZTDhEhcQU3F3oBpqWwf8wSHbKCidAXMvdK/q410923e6721u+jMYOfgd6v8bcwfbSInb3iLuewvuvQTcq68dulrcATcUdfuguDonBVvp5oW66dNxty3inW5bt22D1u1ue/3tKyPbLmSrY0H/D4KqcqA3yf7uBO09CVq7k8RTaQTXMnmjpYsnX2/hxTfbyOTstoDQ/7myOEw0FCAcdK9IMEAk5F7FkSAlkRAl0RA1pRFqSiJUl0RcoyKVJplW6quKOGm6O/NIpjM0tffS1NZLWSzE8bWlVBSH6YqnWLujjRe2tVJZHOY9ZzVQXRKZgi02Sumk+2fvbXOvVPzgP3S4yLVms63NYMS18lNx1zrf85I7KJ3yTheEs1IJ13qOFLvAUlTlzhg6d7vxe/b7V6troU9b4FrnvW2u5d20xtXh+LfBcX/k6tH+pkuPZdIuSA32478DTbD5UXfGVjEbque5wFo19+DvRbr3wxtPQNNaF5Rnn+eW373Prc/eV1xwLKp0gSZ78G3d5srLZkLZdBfQelrdWVuswp0Vzj7Pbc/XHoFNv3BBa8bpMHORq0Oqz5219La6g3brNjdOpMRt41iFOzOrnucaAumkO6tIdLntkQ2wqV53fSvekfO33Y2TDabhIldHxKUE6052dcik3TruWgc7n4Ntz0DXnkO3Y3GtSz2W17uzskzq4NliOuEPtHF35pHsceukevD6mWZA0+5vrNLNo6TGrU92m/W2uYbHYAc4CbrtUVLr9l/1PHcQXfLxUX3FLejnmfaeBHs6+qguiVBdHCGZVl7ZdYD/aTzAtn1dJFNKMpMhmVYSqTSJVIZ4KkNPIk1vIk1XPMW+rjjx1NAt0UgwMOhZR2VxmM6+FOmM9h9sIsEAl542nTMaKtnb0ceejj6646n+A09xJMiMihjTy2PUlUUpjboDTyQYIJ5K05fMkMpkKIuFKY+FKIuFKY2GiIUDyBCn4qp62LCeRIo129soiQY5bVYFsbDl2c0gVN31sI5GKG9wZ57hoslbdqL74FmSyMFOGuOYdrKgbw6jqnTFU7R1JwkGhUgwQDAgvNnaw+t7O9na0kVpJERDdRGzKoro7EuxbV83b+zrpqYkwnnHV3PWnCoa23q57/k3+em6Rjr6UsTCAWaUxyiLhUmmMyTTGbriKVo644ecnQyHCJREQv4gEaQ4EqI7nqK1J8GB3iTTy2LMn17K8bUlbGnp4oVtbf0HqkgwwML6cqaVxUj5A2AwIBSFg/0Hg55Eip5EmnBQmFtTwvF1pcypLmaav7YSCwfZdaCXXe297DnQR2dfiq54ingqTU1JlOnlMaaXRymLhSmJurOojCrpjJLKKEXhIGWxEKHgke9rmM4ou9p7AZheHiMSOnx8VaU36Q7g0VCQaChwaAeAERrsoGnyhwV9M+HiqTR9iQzlRaFBg0kqnWFfV4J9XXG64ym6E6n+ABYLBwkFha6+FB19SQ70JumOp+lJuCDbHU/RHU/TnUhRGg1RVRyhvCjE7vY+Njd3sbWli9lVxVx0Ui1vnV9HbzLNuh1trN3RxoHepD/jEDIKvUl3tgNQHAlSHAnSl8ywfX/3Ec98cgUDQnoER7CicJBwUAgEhIC4A09pNERpLER7T4Kdrb39BysRqC11Z0PJdIZUWulLpfvPrnKFAkLQv2LhINPKou6MqixGRXGYsmiIokiQjr6UTxcm2H2gj13tvezt6CMcDFBeFKYsFkJwB5+0KtUlUWZXuR8cVhdHKIoEKQoH2d8dZ0tzF1uau0ikM9T5XmhlsTBBv24irgtztq7RcIBIMEhRJEBlcYSq4gjFkSCt3e67cKA3SUVRmOqSCJXFETIZJZ7KEE+lae1O0NIZZ39XgtJYiOnlUaaVxdz3JWfdQwEh5M8oK4vDVBZH/PctTnNnnN5Eur9uReEgdWVRppXHCIpr5OzY3017T5Ka0gh1ZVEqisKkMuoaLH0p3tjXzdbmLvZ09LFgZjnnHV/DabPKCecczDMZpa0nQUtXnHAwQFksRHnMpVqHOrh2x1M0tvWSymSoK4tSXRw5agNhuCzoG3MUmYyyu6OPna09tHTGaemM05tMM7MiRn1lETMriqgoci36YEBo60myt6OP5s44XX2p/gNZQIRQUAiK0JNwwbqzL0kqo6i6oNqbyNAVT9LZl6I8Fua42mLm1pQQENh9oI/d7X30JN0ZSDgQIBp2QaQsFu5Pu/X5Vn9alXTanQXs7Yizp6OX5o44HX1J+pIHD2LZwDqjPMasyiKml0dJZZSOXlcPwAdu2N+d4M3WHpraekkNONDUlkY4cVopsXCQfV1uO3X1pUirksmAogTEHQAAEunMiA6QA4UCQlVJhK6+FL3JqbsTeyQYoKY0wu4DrgNANBSgJBrqP5i09yRIpg9fz1BAKImGKIkEiYQCbrsItPckD+vJlz0oZfy2rCmN8Oxtl4yqvkcK+qHBCo0pNIGAUF9ZRH3l8HK71f4i+Kkzjz7uVEmkMvQm0pTGQgRHkQpKZ5SeRKr/7Kg8FqZqFBfsU+kMvck07T1J2noS9CTSVJdEqC2NUh4L0dGXorU7TntPkmBAiIQCRENBakoiVBSFCQSkPx3Z3BmnL5kmk4FUJtOfSkulle5EigN+GcGAUFfmzkRKIiEUyKjS7VONzZ1xUukMc2pKOK66mOqSCPu7E+zrjNPemyTsU56xSJB5NSXMri4mGBCaO/t4YVsb63e2+WtR7mBeVRJhelmU2rIo6YzS0Zeiozfpz1JTdMXTpDIZMuoaGOVFIRqqipldXUwkKLR0ubOanniKYEAQEcpiExOeJ72lLyJLgW8CQeA7qnr7kca3lr4xxozMkVr645NAGn5FgsB/AJcDC4DrRGTBZNbBGGMK2aQGfdxD0reo6huqmgDuB66c5DoYY0zBmuygXw/szPnc6MsOISLLRWSNiKxpaWmZtMoZY0y+m+ygPyyqepeqLlbVxXV1dVNdHWOMyRuTHfSbgNk5nxt8mTHGmEkw2UH/BWC+iMwTkQhwLbBykutgjDEFa1L76atqSkQ+CfwG12VzhaqO7jZyxhhjRmzSf5ylqo8Aj0z2co0xxvwB3IZBRFqAHaOcvBbYN47V+UNQiOsMhbnehbjOUJjrPdJ1Pk5VB+0Fc8wH/bEQkTVD/SotXxXiOkNhrnchrjMU5nqP5zofk102jTHGTAwL+sYYU0DyPejfNdUVmAKFuM5QmOtdiOsMhbne47bOeZ3TN8YYc6h8b+kbY4zJYUHfGGMKSF4GfRFZKiKvicgWEbl1quszUURktog8ISKvisgrInKzL68WkVUistn/rZrquo43EQmKyIsi8gv/eZ6IPOf3+U/8bT7yiohUisiDIrJJRDaKyPn5vq9F5G/8d3uDiNwnIrF83NciskJEmkVkQ07ZoPtWnDv8+r8kImeNZFl5F/QL7EEtKeBTqroAWAJ8wq/rrcBjqjofeMx/zjc3AxtzPv8T8HVVPRFoAz46JbWaWN8Efq2qpwBn4NY/b/e1iNQDfwUsVtWFuFu3XEt+7uvvA0sHlA21by8H5vvXcuDOkSwo74I+BfSgFlXdrarr/PtOXBCox63vD/xoPwCumpIKThARaQDeCXzHfxbg7cCDfpR8XOcK4CLguwCqmlDVdvJ8X+NuFVMkIiGgGNhNHu5rVX0aaB1QPNS+vRK4R53VQKWIDPtpzfkY9If1oJZ8IyJzgTOB54DpqrrbD9oDTJ+qek2QbwCfBjL+cw3Qrqop/zkf9/k8oAX4nk9rfUdESsjjfa2qTcC/Am/igv0BYC35v6+zhtq3Y4px+Rj0C46IlAIPAX+tqh25w9T1yc2bfrki8i6gWVXXTnVdJlkIOAu4U1XPBLoZkMrJw31dhWvVzgNmASUcngIpCOO5b/Mx6BfUg1pEJIwL+D9S1Z/64r3Z0z3/t3mq6jcBLgCuEJHtuNTd23G57kqfAoD83OeNQKOqPuc/P4g7COTzvv5fwDZVbVHVJPBT3P7P932dNdS+HVOMy8egXzAPavG57O8CG1X1azmDVgI3+Pc3AA9Pdt0miqrepqoNqjoXt28fV9UPAE8Af+JHy6t1BlDVPcBOETnZF10CvEoe72tcWmeJiBT773p2nfN6X+cYat+uBD7ke/EsAQ7kpIGOTlXz7gUsA14HtgJ/P9X1mcD1vBB3yvcSsN6/luFy3I8Bm4HfAtVTXdcJWv+LgV/498cDzwNbgP8EolNdvwlY30XAGr+/fw5U5fu+Br4EbAI2APcC0Xzc18B9uOsWSdxZ3UeH2reA4HoobgVexvVuGvay7DYMxhhTQPIxvWOMMWYIFvSNMaaAWNA3xpgCYkHfGGMKiAV9Y4wpIBb0jTGmgFjQN8aYAvL/AQINfHJa7rwPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0fd797",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e607a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bc4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9aba8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 4ms/step - loss: 2113.7139 - mean_absolute_error: 2110.8538 - val_loss: 2123.1658 - val_mean_absolute_error: 2118.9543\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 915.7376 - mean_absolute_error: 902.7892 - val_loss: 432.6602 - val_mean_absolute_error: 416.5581\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 336.8755 - mean_absolute_error: 320.3271 - val_loss: 320.6676 - val_mean_absolute_error: 303.7600\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 260.4955 - mean_absolute_error: 243.2380 - val_loss: 266.5805 - val_mean_absolute_error: 248.7284\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 208.2431 - mean_absolute_error: 190.1080 - val_loss: 217.8300 - val_mean_absolute_error: 199.1928\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 176.7948 - mean_absolute_error: 157.9678 - val_loss: 187.3139 - val_mean_absolute_error: 168.3144\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 144.0632 - mean_absolute_error: 124.8444 - val_loss: 174.3139 - val_mean_absolute_error: 154.9573\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 128.8039 - mean_absolute_error: 109.3882 - val_loss: 155.4385 - val_mean_absolute_error: 136.0737\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 121.7314 - mean_absolute_error: 102.3147 - val_loss: 142.8868 - val_mean_absolute_error: 123.5262\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 111.7279 - mean_absolute_error: 92.3697 - val_loss: 134.6988 - val_mean_absolute_error: 115.2962\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 101.4463 - mean_absolute_error: 82.1339 - val_loss: 132.7108 - val_mean_absolute_error: 113.4083\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 99.8489 - mean_absolute_error: 80.5111 - val_loss: 133.5042 - val_mean_absolute_error: 114.1770\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 93.0943 - mean_absolute_error: 73.8666 - val_loss: 120.2195 - val_mean_absolute_error: 101.0302\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 89.7239 - mean_absolute_error: 70.5895 - val_loss: 123.4125 - val_mean_absolute_error: 104.2551\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.7561 - mean_absolute_error: 66.6413 - val_loss: 108.4748 - val_mean_absolute_error: 89.4306\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.6200 - mean_absolute_error: 64.6045 - val_loss: 115.9371 - val_mean_absolute_error: 96.9666\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.4939 - mean_absolute_error: 62.5951 - val_loss: 115.2714 - val_mean_absolute_error: 96.3448\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 80.9389 - mean_absolute_error: 62.0446 - val_loss: 108.5435 - val_mean_absolute_error: 89.7778\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 78.2658 - mean_absolute_error: 59.5292 - val_loss: 116.6348 - val_mean_absolute_error: 97.9985\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.3784 - mean_absolute_error: 55.7584 - val_loss: 115.5802 - val_mean_absolute_error: 96.9715\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.3525 - mean_absolute_error: 55.8150 - val_loss: 108.3648 - val_mean_absolute_error: 89.8509\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.5369 - mean_absolute_error: 55.0874 - val_loss: 98.7765 - val_mean_absolute_error: 80.3891\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.7035 - mean_absolute_error: 55.3346 - val_loss: 107.3823 - val_mean_absolute_error: 89.0483\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.5857 - mean_absolute_error: 51.3196 - val_loss: 104.8286 - val_mean_absolute_error: 86.6522\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.7658 - mean_absolute_error: 51.6143 - val_loss: 106.4823 - val_mean_absolute_error: 88.3723\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.3808 - mean_absolute_error: 50.2955 - val_loss: 109.9955 - val_mean_absolute_error: 91.9173\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.1508 - mean_absolute_error: 44.1269 - val_loss: 102.0619 - val_mean_absolute_error: 84.1441\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.1856 - mean_absolute_error: 45.2523 - val_loss: 97.0679 - val_mean_absolute_error: 79.1681\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.5642 - mean_absolute_error: 46.7262 - val_loss: 104.3384 - val_mean_absolute_error: 86.5053\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.1514 - mean_absolute_error: 45.3965 - val_loss: 103.1164 - val_mean_absolute_error: 85.4119\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.7399 - mean_absolute_error: 44.0051 - val_loss: 101.9465 - val_mean_absolute_error: 84.2566\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.7214 - mean_absolute_error: 47.0820 - val_loss: 93.0439 - val_mean_absolute_error: 75.5248\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.3815 - mean_absolute_error: 43.8321 - val_loss: 95.9022 - val_mean_absolute_error: 78.4244\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.5154 - mean_absolute_error: 42.0995 - val_loss: 95.7901 - val_mean_absolute_error: 78.4358\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0713 - mean_absolute_error: 38.7518 - val_loss: 98.5299 - val_mean_absolute_error: 81.2118\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.5761 - mean_absolute_error: 40.3503 - val_loss: 104.1142 - val_mean_absolute_error: 86.8858\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.1876 - mean_absolute_error: 39.0278 - val_loss: 104.7997 - val_mean_absolute_error: 87.6291\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.8098 - mean_absolute_error: 40.7623 - val_loss: 100.9970 - val_mean_absolute_error: 83.8877\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.2739 - mean_absolute_error: 38.2702 - val_loss: 94.3882 - val_mean_absolute_error: 77.4205\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.2404 - mean_absolute_error: 41.3298 - val_loss: 103.4233 - val_mean_absolute_error: 86.5491\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.9382 - mean_absolute_error: 36.1121 - val_loss: 99.3432 - val_mean_absolute_error: 82.4987\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.9866 - mean_absolute_error: 42.2234 - val_loss: 97.4680 - val_mean_absolute_error: 80.8043\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.9232 - mean_absolute_error: 34.2730 - val_loss: 92.6109 - val_mean_absolute_error: 76.0250\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.7036 - mean_absolute_error: 34.1233 - val_loss: 93.9718 - val_mean_absolute_error: 77.4592\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.6351 - mean_absolute_error: 38.1542 - val_loss: 96.3830 - val_mean_absolute_error: 79.9088\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.8057 - mean_absolute_error: 35.3960 - val_loss: 102.2151 - val_mean_absolute_error: 85.9157\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.5238 - mean_absolute_error: 36.1864 - val_loss: 99.5678 - val_mean_absolute_error: 83.3372\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.8019 - mean_absolute_error: 36.5633 - val_loss: 91.8099 - val_mean_absolute_error: 75.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.8923 - mean_absolute_error: 34.7365 - val_loss: 96.5030 - val_mean_absolute_error: 80.3899\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.4113 - mean_absolute_error: 33.3205 - val_loss: 93.4321 - val_mean_absolute_error: 77.3966\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.2878 - mean_absolute_error: 34.2725 - val_loss: 97.2002 - val_mean_absolute_error: 81.2312\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.3897 - mean_absolute_error: 36.4956 - val_loss: 95.3471 - val_mean_absolute_error: 79.4961\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.5796 - mean_absolute_error: 40.7521 - val_loss: 105.1656 - val_mean_absolute_error: 89.3751\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.4660 - mean_absolute_error: 35.6861 - val_loss: 95.1084 - val_mean_absolute_error: 79.3783\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.5787 - mean_absolute_error: 31.9124 - val_loss: 93.1204 - val_mean_absolute_error: 77.4404\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4069 - mean_absolute_error: 31.7875 - val_loss: 98.4492 - val_mean_absolute_error: 82.8115\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.6514 - mean_absolute_error: 33.0835 - val_loss: 92.6761 - val_mean_absolute_error: 77.1764\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4911 - mean_absolute_error: 37.0059 - val_loss: 92.3739 - val_mean_absolute_error: 76.9059\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4249 - mean_absolute_error: 37.0125 - val_loss: 98.3224 - val_mean_absolute_error: 82.9708\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.0823 - mean_absolute_error: 33.7556 - val_loss: 105.1936 - val_mean_absolute_error: 89.9202\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.6087 - mean_absolute_error: 37.3329 - val_loss: 93.8966 - val_mean_absolute_error: 78.6779\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.5159 - mean_absolute_error: 32.3297 - val_loss: 89.8427 - val_mean_absolute_error: 74.6920\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.6253 - mean_absolute_error: 32.4959 - val_loss: 85.7448 - val_mean_absolute_error: 70.6270\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.2839 - mean_absolute_error: 34.1967 - val_loss: 88.1792 - val_mean_absolute_error: 73.1417\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1197 - mean_absolute_error: 31.1262 - val_loss: 92.0055 - val_mean_absolute_error: 77.0195\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.4275 - mean_absolute_error: 31.4833 - val_loss: 88.1395 - val_mean_absolute_error: 73.2104\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.1518 - mean_absolute_error: 32.2564 - val_loss: 87.5622 - val_mean_absolute_error: 72.7613\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4281 - mean_absolute_error: 32.6214 - val_loss: 101.1051 - val_mean_absolute_error: 86.2944\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9868 - mean_absolute_error: 34.2508 - val_loss: 94.3536 - val_mean_absolute_error: 79.6329\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.6960 - mean_absolute_error: 32.0497 - val_loss: 89.4300 - val_mean_absolute_error: 74.8539\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.6978 - mean_absolute_error: 35.1311 - val_loss: 90.5325 - val_mean_absolute_error: 75.9982\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.5618 - mean_absolute_error: 32.0351 - val_loss: 110.1721 - val_mean_absolute_error: 95.6413\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.7049 - mean_absolute_error: 32.2211 - val_loss: 92.0352 - val_mean_absolute_error: 77.6228\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8480 - mean_absolute_error: 32.4464 - val_loss: 87.5762 - val_mean_absolute_error: 73.2060\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.7763 - mean_absolute_error: 34.4098 - val_loss: 99.3307 - val_mean_absolute_error: 84.8742\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.8057 - mean_absolute_error: 28.4620 - val_loss: 88.2051 - val_mean_absolute_error: 73.8730\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.4007 - mean_absolute_error: 32.1098 - val_loss: 87.2539 - val_mean_absolute_error: 72.9752\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.7425 - mean_absolute_error: 31.4779 - val_loss: 89.4929 - val_mean_absolute_error: 75.2334\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9372 - mean_absolute_error: 30.7470 - val_loss: 94.8100 - val_mean_absolute_error: 80.6872\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.9451 - mean_absolute_error: 37.8264 - val_loss: 101.7780 - val_mean_absolute_error: 87.6504\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.9004 - mean_absolute_error: 27.8951 - val_loss: 88.4618 - val_mean_absolute_error: 74.4840\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7458 - mean_absolute_error: 28.7863 - val_loss: 87.4186 - val_mean_absolute_error: 73.4538\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2895 - mean_absolute_error: 29.4078 - val_loss: 87.6402 - val_mean_absolute_error: 73.7802\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.4070 - mean_absolute_error: 25.5600 - val_loss: 90.4561 - val_mean_absolute_error: 76.6149\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.2033 - mean_absolute_error: 28.3961 - val_loss: 85.5766 - val_mean_absolute_error: 71.7578\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.5620 - mean_absolute_error: 27.8153 - val_loss: 87.2932 - val_mean_absolute_error: 73.6055\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.6071 - mean_absolute_error: 30.9171 - val_loss: 95.8864 - val_mean_absolute_error: 82.2637\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6462 - mean_absolute_error: 32.0109 - val_loss: 85.6160 - val_mean_absolute_error: 72.0029\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.3761 - mean_absolute_error: 35.7862 - val_loss: 88.0591 - val_mean_absolute_error: 74.5384\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1722 - mean_absolute_error: 32.6380 - val_loss: 90.8609 - val_mean_absolute_error: 77.3267\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.9745 - mean_absolute_error: 34.5003 - val_loss: 91.2758 - val_mean_absolute_error: 77.8886\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9076 - mean_absolute_error: 31.4739 - val_loss: 87.8018 - val_mean_absolute_error: 74.3710\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1928 - mean_absolute_error: 29.8278 - val_loss: 94.3945 - val_mean_absolute_error: 81.0250\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.9675 - mean_absolute_error: 28.6188 - val_loss: 102.1654 - val_mean_absolute_error: 88.7724\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6050 - mean_absolute_error: 32.3460 - val_loss: 100.1429 - val_mean_absolute_error: 86.8813\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2173 - mean_absolute_error: 27.9914 - val_loss: 86.6245 - val_mean_absolute_error: 73.4126\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.7795 - mean_absolute_error: 31.5985 - val_loss: 112.0532 - val_mean_absolute_error: 98.8201\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9075 - mean_absolute_error: 33.7483 - val_loss: 88.4414 - val_mean_absolute_error: 75.3664\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.2851 - mean_absolute_error: 29.1949 - val_loss: 87.0673 - val_mean_absolute_error: 73.9618\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2844 - mean_absolute_error: 28.2147 - val_loss: 85.8817 - val_mean_absolute_error: 72.8289\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fad7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953d19d",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862f815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4f909ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6b0cab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 23.6977 - mse: 15658966.0000 - val_loss: 9.6334 - val_mse: 16725431.0000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 6.4417 - mse: 14215364.0000 - val_loss: 4.6204 - val_mse: 14698508.0000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.5475 - mse: 12347175.0000 - val_loss: 2.8877 - val_mse: 12701615.0000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3290 - mse: 10511649.0000 - val_loss: 2.0186 - val_mse: 10689137.0000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6703 - mse: 8771491.0000 - val_loss: 1.5042 - val_mse: 8897519.0000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3425 - mse: 7274620.5000 - val_loss: 1.2842 - val_mse: 7556412.5000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1908 - mse: 6220188.0000 - val_loss: 1.1493 - val_mse: 6415204.5000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0980 - mse: 5321716.5000 - val_loss: 1.0164 - val_mse: 5720772.0000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9493 - mse: 4713451.5000 - val_loss: 0.9342 - val_mse: 4807969.5000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8560 - mse: 4082088.2500 - val_loss: 0.8496 - val_mse: 4212244.0000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8271 - mse: 3635785.0000 - val_loss: 0.7838 - val_mse: 3921766.2500\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7282 - mse: 3268932.2500 - val_loss: 0.7339 - val_mse: 3506879.5000\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6724 - mse: 2973678.0000 - val_loss: 0.6468 - val_mse: 3196178.7500\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6191 - mse: 2712741.7500 - val_loss: 0.6233 - val_mse: 2830819.2500\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6067 - mse: 2495946.7500 - val_loss: 0.6506 - val_mse: 2670914.5000\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5535 - mse: 2319740.2500 - val_loss: 0.5226 - val_mse: 2617050.5000\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4979 - mse: 2204731.7500 - val_loss: 0.5041 - val_mse: 2369974.2500\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4851 - mse: 2080790.2500 - val_loss: 0.4746 - val_mse: 2232225.5000\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4561 - mse: 1951014.7500 - val_loss: 0.4600 - val_mse: 2181838.2500\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4356 - mse: 1923222.2500 - val_loss: 0.4618 - val_mse: 2070315.8750\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4445 - mse: 1784769.0000 - val_loss: 0.4335 - val_mse: 1979930.6250\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4165 - mse: 1786309.2500 - val_loss: 0.4050 - val_mse: 1923668.6250\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3928 - mse: 1629703.1250 - val_loss: 0.3896 - val_mse: 1951705.0000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3765 - mse: 1642072.2500 - val_loss: 0.3810 - val_mse: 1774741.6250\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3670 - mse: 1502324.8750 - val_loss: 0.3665 - val_mse: 1746721.7500\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3738 - mse: 1515081.3750 - val_loss: 0.3631 - val_mse: 1751134.1250\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3505 - mse: 1463797.7500 - val_loss: 0.3493 - val_mse: 1668435.5000\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3409 - mse: 1427551.7500 - val_loss: 0.3429 - val_mse: 1629241.1250\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3327 - mse: 1367866.7500 - val_loss: 0.3333 - val_mse: 1647388.8750\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3258 - mse: 1356862.6250 - val_loss: 0.3253 - val_mse: 1576551.6250\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3173 - mse: 1339407.7500 - val_loss: 0.3189 - val_mse: 1574182.0000\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3091 - mse: 1314075.2500 - val_loss: 0.3094 - val_mse: 1452617.8750\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3007 - mse: 1272436.5000 - val_loss: 0.3011 - val_mse: 1456534.7500\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2931 - mse: 1242561.1250 - val_loss: 0.2941 - val_mse: 1424774.5000\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2853 - mse: 1217431.6250 - val_loss: 0.2878 - val_mse: 1410360.1250\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3221 - mse: 1244725.0000 - val_loss: 0.3255 - val_mse: 1592607.3750\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2951 - mse: 1296687.7500 - val_loss: 0.2822 - val_mse: 1395143.5000\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2718 - mse: 1168155.1250 - val_loss: 0.2708 - val_mse: 1407628.2500\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2624 - mse: 1161465.0000 - val_loss: 0.2640 - val_mse: 1405479.6250\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2559 - mse: 1148624.7500 - val_loss: 0.2568 - val_mse: 1356900.6250\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2504 - mse: 1132221.7500 - val_loss: 0.2525 - val_mse: 1329566.1250\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2461 - mse: 1101370.6250 - val_loss: 0.2477 - val_mse: 1326844.7500\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2415 - mse: 1111552.7500 - val_loss: 0.2435 - val_mse: 1279133.3750\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2373 - mse: 1070196.1250 - val_loss: 0.2401 - val_mse: 1314972.5000\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2332 - mse: 1088626.7500 - val_loss: 0.2362 - val_mse: 1220075.0000\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2297 - mse: 1029910.3750 - val_loss: 0.2323 - val_mse: 1232430.0000\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2262 - mse: 1037774.1250 - val_loss: 0.2306 - val_mse: 1220473.8750\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2223 - mse: 1014418.3750 - val_loss: 0.2243 - val_mse: 1237340.3750\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2183 - mse: 1025186.8750 - val_loss: 0.2209 - val_mse: 1203247.1250\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2136 - mse: 1015533.4375 - val_loss: 0.2149 - val_mse: 1151853.2500\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2077 - mse: 996924.5625 - val_loss: 0.2099 - val_mse: 1129859.2500\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2040 - mse: 966977.7500 - val_loss: 0.2055 - val_mse: 1113838.8750\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1956 - mse: 959917.0000 - val_loss: 0.1972 - val_mse: 1091587.2500\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1917 - mse: 925904.9375 - val_loss: 0.1950 - val_mse: 1202619.2500\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1891 - mse: 948606.5625 - val_loss: 0.1916 - val_mse: 1103716.2500\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1871 - mse: 928718.1250 - val_loss: 0.1897 - val_mse: 1095556.2500\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1861 - mse: 917048.6875 - val_loss: 0.1876 - val_mse: 1127063.1250\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1879 - mse: 931890.6875 - val_loss: 0.2220 - val_mse: 984236.5000\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2013 - mse: 908721.6250 - val_loss: 0.1972 - val_mse: 1101215.1250\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1838 - mse: 926575.2500 - val_loss: 0.1866 - val_mse: 1083728.3750\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1752 - mse: 910277.4375 - val_loss: 0.1762 - val_mse: 1041438.2500\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1708 - mse: 900907.5000 - val_loss: 0.1716 - val_mse: 1003693.4375\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1647 - mse: 854095.6250 - val_loss: 0.1695 - val_mse: 1088241.3750\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1631 - mse: 875641.0000 - val_loss: 0.1669 - val_mse: 1042325.5625\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1610 - mse: 875110.4375 - val_loss: 0.1637 - val_mse: 1024401.0000\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1590 - mse: 859507.8750 - val_loss: 0.1749 - val_mse: 1020430.6875\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1730 - mse: 877161.9375 - val_loss: 0.1714 - val_mse: 1017882.0625\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1582 - mse: 844657.2500 - val_loss: 0.1608 - val_mse: 1012592.8750\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1580 - mse: 855657.0625 - val_loss: 0.1559 - val_mse: 1059229.5000\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1486 - mse: 835594.2500 - val_loss: 0.1517 - val_mse: 1021000.6250\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1468 - mse: 832790.7500 - val_loss: 0.1519 - val_mse: 991870.6250\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1462 - mse: 813449.9375 - val_loss: 0.1509 - val_mse: 1027681.0625\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1454 - mse: 809596.9375 - val_loss: 0.1499 - val_mse: 1005137.6875\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1445 - mse: 819448.5625 - val_loss: 0.1509 - val_mse: 971581.5625\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1605 - mse: 818054.5625 - val_loss: 0.1569 - val_mse: 1006154.4375\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1479 - mse: 819529.3750 - val_loss: 0.1491 - val_mse: 956164.2500\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1428 - mse: 800095.9375 - val_loss: 0.1474 - val_mse: 934702.6250\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1432 - mse: 800552.0625 - val_loss: 0.1458 - val_mse: 940152.6875\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1399 - mse: 791921.1875 - val_loss: 0.1449 - val_mse: 918653.9375\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1389 - mse: 775012.3750 - val_loss: 0.1440 - val_mse: 968233.6250\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1381 - mse: 794189.5625 - val_loss: 0.1429 - val_mse: 933304.6250\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1373 - mse: 783507.9375 - val_loss: 0.1452 - val_mse: 902469.0625\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1369 - mse: 768589.5625 - val_loss: 0.1445 - val_mse: 944330.3750\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1364 - mse: 760940.3125 - val_loss: 0.1449 - val_mse: 944372.4375\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1357 - mse: 783347.6250 - val_loss: 0.1489 - val_mse: 859580.4375\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1374 - mse: 755936.5625 - val_loss: 0.1452 - val_mse: 940832.4375\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1336 - mse: 763363.8750 - val_loss: 0.1443 - val_mse: 917347.5625\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1412 - mse: 754321.7500 - val_loss: 0.1521 - val_mse: 930675.7500\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1420 - mse: 775132.0000 - val_loss: 0.1396 - val_mse: 930590.6875\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1340 - mse: 765856.5625 - val_loss: 0.1363 - val_mse: 892008.4375\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1310 - mse: 754720.1875 - val_loss: 0.1348 - val_mse: 903910.6250\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1299 - mse: 746815.8125 - val_loss: 0.1349 - val_mse: 889257.0000\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1288 - mse: 738905.2500 - val_loss: 0.1338 - val_mse: 886618.9375\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1301 - mse: 746158.3750 - val_loss: 0.1401 - val_mse: 886820.6250\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1279 - mse: 740110.5625 - val_loss: 0.1316 - val_mse: 899266.4375\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1273 - mse: 741833.9375 - val_loss: 0.1308 - val_mse: 888440.3750\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1247 - mse: 727267.8750 - val_loss: 0.1289 - val_mse: 904279.6250\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1236 - mse: 737816.1250 - val_loss: 0.1278 - val_mse: 875524.6875\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1258 - mse: 733905.4375 - val_loss: 0.1278 - val_mse: 913174.0625\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1216 - mse: 727279.5000 - val_loss: 0.1257 - val_mse: 920903.0625\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621e5fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57275db",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "237cbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4053ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79433751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10892470.0000 - mse: 10892453.0000 - val_loss: 1026498.1875 - val_mse: 1026461.5625\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 625842.9375 - mse: 625805.6875 - val_loss: 459726.5000 - val_mse: 459688.3750\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 304942.8125 - mse: 304904.0000 - val_loss: 343976.5625 - val_mse: 343937.0312\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 206829.5781 - mse: 206789.3281 - val_loss: 214649.3438 - val_mse: 214608.3594\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 146413.2656 - mse: 146371.8125 - val_loss: 188956.4531 - val_mse: 188914.5156\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 108047.0859 - mse: 108004.6953 - val_loss: 129429.0312 - val_mse: 129386.2188\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 84453.6875 - mse: 84410.4531 - val_loss: 104500.2812 - val_mse: 104456.6875\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 63267.8633 - mse: 63223.9062 - val_loss: 86650.9766 - val_mse: 86606.6875\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 52204.9062 - mse: 52160.3984 - val_loss: 82595.1406 - val_mse: 82550.3281\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 42413.4336 - mse: 42368.4805 - val_loss: 74996.3047 - val_mse: 74951.1406\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 35013.9180 - mse: 34968.6836 - val_loss: 70754.8438 - val_mse: 70709.4922\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 31606.5547 - mse: 31561.0723 - val_loss: 46130.8438 - val_mse: 46085.2227\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 28384.0488 - mse: 28338.3223 - val_loss: 48758.3906 - val_mse: 48712.6289\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 23549.7109 - mse: 23503.8340 - val_loss: 44800.9727 - val_mse: 44755.0547\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 21410.5312 - mse: 21364.4785 - val_loss: 48587.9414 - val_mse: 48541.8008\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19839.3379 - mse: 19793.1113 - val_loss: 55462.3398 - val_mse: 55415.9766\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 20242.3281 - mse: 20195.9453 - val_loss: 62114.6680 - val_mse: 62068.1016\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 29606.7344 - mse: 29560.1133 - val_loss: 53948.0820 - val_mse: 53901.3359\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 21184.0820 - mse: 21137.3379 - val_loss: 50799.4844 - val_mse: 50752.6133\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17786.0391 - mse: 17739.1621 - val_loss: 42414.3945 - val_mse: 42367.4648\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16725.6191 - mse: 16678.6133 - val_loss: 42233.8945 - val_mse: 42186.8242\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17736.7676 - mse: 17689.7012 - val_loss: 46621.3398 - val_mse: 46574.2188\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 22722.7812 - mse: 22675.6230 - val_loss: 40023.4141 - val_mse: 39976.1523\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15667.5146 - mse: 15620.1699 - val_loss: 40866.3555 - val_mse: 40818.9883\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13439.8730 - mse: 13392.4268 - val_loss: 53958.7734 - val_mse: 53911.2617\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11006.4512 - mse: 10958.9512 - val_loss: 36374.4766 - val_mse: 36326.9023\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9795.9619 - mse: 9748.3564 - val_loss: 49861.8477 - val_mse: 49814.2539\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 32862.2930 - mse: 32814.5859 - val_loss: 45905.6367 - val_mse: 45857.8438\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 18592.0996 - mse: 18544.2930 - val_loss: 61572.9375 - val_mse: 61525.0820\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10206.0293 - mse: 10158.1572 - val_loss: 33096.6562 - val_mse: 33048.7188\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7511.5332 - mse: 7463.5684 - val_loss: 43835.7188 - val_mse: 43787.7383\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7461.1968 - mse: 7413.1533 - val_loss: 31319.7891 - val_mse: 31271.7520\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7960.6738 - mse: 7912.5503 - val_loss: 39441.3164 - val_mse: 39393.1523\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7534.9668 - mse: 7486.7642 - val_loss: 41605.3320 - val_mse: 41556.9922\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11742.3701 - mse: 11694.0713 - val_loss: 37481.7188 - val_mse: 37433.4805\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 18191.9238 - mse: 18143.6172 - val_loss: 33417.3242 - val_mse: 33369.0859\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10303.2461 - mse: 10254.8037 - val_loss: 52421.8477 - val_mse: 52373.2891\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9083.6484 - mse: 9035.1201 - val_loss: 35922.6758 - val_mse: 35874.1289\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8141.4829 - mse: 8092.8628 - val_loss: 56832.5820 - val_mse: 56783.8750\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8741.7510 - mse: 8693.0830 - val_loss: 30931.5020 - val_mse: 30882.7676\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19073.6367 - mse: 19024.9219 - val_loss: 58318.7891 - val_mse: 58269.9883\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11869.0674 - mse: 11820.2227 - val_loss: 46775.1641 - val_mse: 46726.3281\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12559.9844 - mse: 12511.1582 - val_loss: 43487.4258 - val_mse: 43438.5273\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12386.8135 - mse: 12337.9600 - val_loss: 33709.8867 - val_mse: 33660.9297\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7364.1768 - mse: 7315.2456 - val_loss: 38562.9336 - val_mse: 38514.0039\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5532.2275 - mse: 5483.2471 - val_loss: 35502.4023 - val_mse: 35453.3828\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5464.0469 - mse: 5415.0005 - val_loss: 38607.7773 - val_mse: 38558.7188\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7108.9424 - mse: 7059.8848 - val_loss: 38960.6758 - val_mse: 38911.5391\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8475.9688 - mse: 8426.8789 - val_loss: 49247.3125 - val_mse: 49198.3125\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10559.0215 - mse: 10509.9219 - val_loss: 45871.4766 - val_mse: 45822.3477\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8474.6924 - mse: 8425.4932 - val_loss: 39576.7734 - val_mse: 39527.5547\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6769.5391 - mse: 6720.3398 - val_loss: 38194.2266 - val_mse: 38145.0195\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10613.8223 - mse: 10564.5508 - val_loss: 43961.8750 - val_mse: 43912.6133\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16673.1035 - mse: 16623.7715 - val_loss: 31181.1621 - val_mse: 31131.6621\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14627.5742 - mse: 14578.1084 - val_loss: 65742.3750 - val_mse: 65693.0000\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10299.6660 - mse: 10250.1982 - val_loss: 32915.9414 - val_mse: 32866.3984\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5872.7275 - mse: 5823.1885 - val_loss: 35065.2891 - val_mse: 35015.7617\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7468.4429 - mse: 7418.8511 - val_loss: 46850.7344 - val_mse: 46801.1602\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10083.8486 - mse: 10034.1914 - val_loss: 40782.5820 - val_mse: 40732.8438\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5805.8765 - mse: 5756.1777 - val_loss: 35545.3750 - val_mse: 35495.6992\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4651.4277 - mse: 4601.7246 - val_loss: 53447.9414 - val_mse: 53398.1172\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6643.4453 - mse: 6593.6875 - val_loss: 29817.6348 - val_mse: 29767.8379\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6878.3564 - mse: 6828.5986 - val_loss: 43292.9414 - val_mse: 43243.1523\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6939.6235 - mse: 6889.8438 - val_loss: 38829.6523 - val_mse: 38779.7305\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7417.8442 - mse: 7367.9731 - val_loss: 36718.3672 - val_mse: 36668.4531\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7783.6665 - mse: 7733.7158 - val_loss: 34735.0078 - val_mse: 34685.1094\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7514.3774 - mse: 7464.4771 - val_loss: 48844.0898 - val_mse: 48794.0547\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8535.0117 - mse: 8485.0273 - val_loss: 28425.7305 - val_mse: 28375.6953\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6864.8174 - mse: 6814.7886 - val_loss: 35653.1172 - val_mse: 35603.1562\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17575.6230 - mse: 17525.6211 - val_loss: 42645.5117 - val_mse: 42595.3789\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6073.5806 - mse: 6023.4961 - val_loss: 38519.4844 - val_mse: 38469.4297\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6129.7202 - mse: 6079.5957 - val_loss: 43437.5391 - val_mse: 43387.4141\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9488.3525 - mse: 9438.2383 - val_loss: 37563.1953 - val_mse: 37513.0820\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7018.3018 - mse: 6968.1416 - val_loss: 35820.0430 - val_mse: 35769.7266\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 35838.7734 - mse: 35788.5859 - val_loss: 69429.1953 - val_mse: 69378.9297\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10319.8018 - mse: 10269.5752 - val_loss: 31553.4590 - val_mse: 31503.1641\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4195.4307 - mse: 4145.0952 - val_loss: 33497.7773 - val_mse: 33447.4570\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2740.2000 - mse: 2689.7996 - val_loss: 28136.7500 - val_mse: 28086.3242\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4082.5698 - mse: 4032.1313 - val_loss: 31225.4121 - val_mse: 31174.9922\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3250.1460 - mse: 3199.6602 - val_loss: 31419.3047 - val_mse: 31368.7383\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4122.5391 - mse: 4072.0042 - val_loss: 29724.5508 - val_mse: 29674.0215\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5718.1343 - mse: 5667.5981 - val_loss: 31619.1074 - val_mse: 31568.6484\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9566.5488 - mse: 9515.9688 - val_loss: 35244.7656 - val_mse: 35194.0898\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6838.5303 - mse: 6787.8950 - val_loss: 28680.2148 - val_mse: 28629.5977\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7542.9355 - mse: 7492.3159 - val_loss: 30835.2578 - val_mse: 30784.5879\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8828.2539 - mse: 8777.5029 - val_loss: 33630.8438 - val_mse: 33579.9883\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5615.9370 - mse: 5565.1475 - val_loss: 37772.9492 - val_mse: 37722.0703\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5061.9619 - mse: 5011.1729 - val_loss: 32865.3281 - val_mse: 32814.5430\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9162.7021 - mse: 9111.8447 - val_loss: 32500.2715 - val_mse: 32449.3301\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8383.3408 - mse: 8332.4404 - val_loss: 29747.8594 - val_mse: 29696.8945\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7620.2520 - mse: 7569.2788 - val_loss: 40042.9844 - val_mse: 39991.9766\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3488.4724 - mse: 3437.4866 - val_loss: 31577.5762 - val_mse: 31526.6621\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4030.1594 - mse: 3979.1318 - val_loss: 37369.6250 - val_mse: 37318.6016\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5766.7607 - mse: 5715.7188 - val_loss: 32825.2578 - val_mse: 32774.0859\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6837.7646 - mse: 6786.7178 - val_loss: 35819.1953 - val_mse: 35768.2031\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4838.3428 - mse: 4787.2896 - val_loss: 30829.6738 - val_mse: 30778.6133\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7121.5884 - mse: 7070.4868 - val_loss: 39490.6406 - val_mse: 39439.4258\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6262.3291 - mse: 6211.2344 - val_loss: 37230.6602 - val_mse: 37179.5977\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10616.7549 - mse: 10565.6357 - val_loss: 30910.7930 - val_mse: 30859.5918\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10922.8301 - mse: 10871.6162 - val_loss: 26954.6875 - val_mse: 26903.4492\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe963eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6854842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
