{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_17332\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e96089",
   "metadata": {},
   "source": [
    "### Reading the StandardScaler Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0  priceUSD\n",
       "0           0  0.0    0.0495\n",
       "1           1  0.0    0.0726\n",
       "2           2  0.0    0.0859\n",
       "3           3  0.0    0.0783\n",
       "4           4  0.0    0.0767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_StandardScaler_data2.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>393.7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>386.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>0.0</td>\n",
       "      <td>379.4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0.0</td>\n",
       "      <td>384.7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>388.4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1556 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  priceUSD\n",
       "0     0.0    0.0495\n",
       "1     0.0    0.0726\n",
       "2     0.0    0.0859\n",
       "3     0.0    0.0783\n",
       "4     0.0    0.0767\n",
       "...   ...       ...\n",
       "1551  0.0  393.7880\n",
       "1552  0.0  386.2650\n",
       "1553  0.0  379.4510\n",
       "1554  0.0  384.7020\n",
       "1555  0.0  388.4040\n",
       "\n",
       "[1556 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.0\n",
      "Test score of trained model: -1.410867103973401\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "434d9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a0092b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50923.393871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.662123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>182.096993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>23821.436613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.017380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50923.393871\n",
       "1    RMSE    225.662123\n",
       "2     MAE    182.096993\n",
       "3    MAPE  23821.436613\n",
       "4      r2     -0.014109\n",
       "5  adj_r2     -0.017380"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92098bc0",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87d78217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.0\n",
      "Test score of trained model: -1.410867103973401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38125380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50923.393871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.662123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>182.096993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.017380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50923.393871\n",
       "1    RMSE    225.662123\n",
       "2     MAE    182.096993\n",
       "3      r2     -0.014109\n",
       "4  adj_r2     -0.017380"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d463bf",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f3c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.0\n",
      "Test score of trained model: -1.410867103973401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6eef51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50923.393871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.662123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>182.096993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.017380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50923.393871\n",
       "1    RMSE    225.662123\n",
       "2     MAE    182.096993\n",
       "3      r2     -0.014109\n",
       "4  adj_r2     -0.017380"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3534a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: -0.003502861950011038\n",
      "Test score of trained model: -1.256555812160176\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf6adfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50845.906567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.490369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>181.199069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.015832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50845.906567\n",
       "1    RMSE    225.490369\n",
       "2     MAE    181.199069\n",
       "3      r2     -0.012566\n",
       "4  adj_r2     -0.015832"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=10, n_estimators=500,\n",
      "                          subsample=0.1)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -0.002596298604877534\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 10, 'n_estimators': 500, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84cdd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: -0.015676619986858764\n",
      "   Metric         Score\n",
      "0     MSE  51002.128315\n",
      "1    RMSE    225.836508\n",
      "2     MAE    182.964726\n",
      "3      r2     -0.015677\n",
      "4  adj_r2     -0.018953\n",
      "Best Score: -0.010173248752887387\n",
      "Best params: {'bootstrap': True, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: -0.013270607082012775\n",
      "   Metric         Score\n",
      "0     MSE  50881.310550\n",
      "1    RMSE    225.568860\n",
      "2     MAE    181.613455\n",
      "3      r2     -0.013271\n",
      "4  adj_r2     -0.016539\n",
      "Best Score: -0.010410463562367989\n",
      "Best params: {'bootstrap': True, 'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 20}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: -0.013330132989183507\n",
      "   Metric         Score\n",
      "0     MSE  50884.299639\n",
      "1    RMSE    225.575485\n",
      "2     MAE    181.648200\n",
      "3      r2     -0.013330\n",
      "4  adj_r2     -0.016599\n",
      "Best Score: -0.009558065703564855\n",
      "Best params: {'bootstrap': True, 'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 10}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: -0.014518222316533658\n",
      "   Metric         Score\n",
      "0     MSE  50943.959459\n",
      "1    RMSE    225.707686\n",
      "2     MAE    182.328112\n",
      "3      r2     -0.014518\n",
      "4  adj_r2     -0.017791\n",
      "Best Score: -0.009629542751438657\n",
      "Best params: {'bootstrap': True, 'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: -0.013290572447068882\n",
      "   Metric         Score\n",
      "0     MSE  50882.313109\n",
      "1    RMSE    225.571082\n",
      "2     MAE    181.625050\n",
      "3      r2     -0.013291\n",
      "4  adj_r2     -0.016559\n",
      "Best Score: -0.009032229686705228\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b21c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0a4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55c5de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 170.0533 - mean_absolute_error: 165.5803 - val_loss: 129.3730 - val_mean_absolute_error: 128.1022\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.9844 - mean_absolute_error: 165.5221 - val_loss: 128.1405 - val_mean_absolute_error: 128.0503\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.5159 - mean_absolute_error: 165.4697 - val_loss: 128.0308 - val_mean_absolute_error: 128.0004\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.4467 - mean_absolute_error: 165.4171 - val_loss: 127.9806 - val_mean_absolute_error: 127.9509\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3972 - mean_absolute_error: 165.3678 - val_loss: 127.9350 - val_mean_absolute_error: 127.9057\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3520 - mean_absolute_error: 165.3226 - val_loss: 127.8940 - val_mean_absolute_error: 127.8646\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3086 - mean_absolute_error: 165.2792 - val_loss: 127.8522 - val_mean_absolute_error: 127.8231\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.2655 - mean_absolute_error: 165.2361 - val_loss: 127.8111 - val_mean_absolute_error: 127.7816\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.2227 - mean_absolute_error: 165.1933 - val_loss: 127.7704 - val_mean_absolute_error: 127.7410\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1798 - mean_absolute_error: 165.1504 - val_loss: 127.7295 - val_mean_absolute_error: 127.6996\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1366 - mean_absolute_error: 165.1072 - val_loss: 127.6870 - val_mean_absolute_error: 127.6575\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0933 - mean_absolute_error: 165.0638 - val_loss: 127.6456 - val_mean_absolute_error: 127.6160\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0495 - mean_absolute_error: 165.0201 - val_loss: 127.6037 - val_mean_absolute_error: 127.5744\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0075 - mean_absolute_error: 164.9781 - val_loss: 127.5645 - val_mean_absolute_error: 127.5350\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.9660 - mean_absolute_error: 164.9366 - val_loss: 127.5251 - val_mean_absolute_error: 127.4959\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.9258 - mean_absolute_error: 164.8963 - val_loss: 127.4873 - val_mean_absolute_error: 127.4578\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8884 - mean_absolute_error: 164.8590 - val_loss: 127.4520 - val_mean_absolute_error: 127.4226\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8517 - mean_absolute_error: 164.8223 - val_loss: 127.4171 - val_mean_absolute_error: 127.3872\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8151 - mean_absolute_error: 164.7857 - val_loss: 127.3822 - val_mean_absolute_error: 127.3529\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7787 - mean_absolute_error: 164.7493 - val_loss: 127.3491 - val_mean_absolute_error: 127.3195\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7425 - mean_absolute_error: 164.7132 - val_loss: 127.3162 - val_mean_absolute_error: 127.2868\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7060 - mean_absolute_error: 164.6765 - val_loss: 127.2829 - val_mean_absolute_error: 127.2533\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.6690 - mean_absolute_error: 164.6396 - val_loss: 127.2491 - val_mean_absolute_error: 127.2198\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.6318 - mean_absolute_error: 164.6024 - val_loss: 127.2162 - val_mean_absolute_error: 127.1866\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5949 - mean_absolute_error: 164.5655 - val_loss: 127.1823 - val_mean_absolute_error: 127.1529\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5574 - mean_absolute_error: 164.5280 - val_loss: 127.1488 - val_mean_absolute_error: 127.1191\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5197 - mean_absolute_error: 164.4903 - val_loss: 127.1137 - val_mean_absolute_error: 127.0844\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4822 - mean_absolute_error: 164.4529 - val_loss: 127.0802 - val_mean_absolute_error: 127.0507\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4454 - mean_absolute_error: 164.4160 - val_loss: 127.0467 - val_mean_absolute_error: 127.0174\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4085 - mean_absolute_error: 164.3791 - val_loss: 127.0135 - val_mean_absolute_error: 126.9838\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.3712 - mean_absolute_error: 164.3418 - val_loss: 126.9796 - val_mean_absolute_error: 126.9501\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.3341 - mean_absolute_error: 164.3047 - val_loss: 126.9452 - val_mean_absolute_error: 126.9157\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2962 - mean_absolute_error: 164.2668 - val_loss: 126.9106 - val_mean_absolute_error: 126.8812\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2586 - mean_absolute_error: 164.2292 - val_loss: 126.8759 - val_mean_absolute_error: 126.8462\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2206 - mean_absolute_error: 164.1912 - val_loss: 126.8408 - val_mean_absolute_error: 126.8114\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1827 - mean_absolute_error: 164.1533 - val_loss: 126.8061 - val_mean_absolute_error: 126.7767\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1447 - mean_absolute_error: 164.1153 - val_loss: 126.7710 - val_mean_absolute_error: 126.7418\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1068 - mean_absolute_error: 164.0774 - val_loss: 126.7368 - val_mean_absolute_error: 126.7072\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.0691 - mean_absolute_error: 164.0397 - val_loss: 126.7009 - val_mean_absolute_error: 126.6717\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.0319 - mean_absolute_error: 164.0025 - val_loss: 126.6676 - val_mean_absolute_error: 126.6380\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9950 - mean_absolute_error: 163.9656 - val_loss: 126.6324 - val_mean_absolute_error: 126.6029\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9577 - mean_absolute_error: 163.9283 - val_loss: 126.5984 - val_mean_absolute_error: 126.5686\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9207 - mean_absolute_error: 163.8913 - val_loss: 126.5639 - val_mean_absolute_error: 126.5345\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8838 - mean_absolute_error: 163.8544 - val_loss: 126.5298 - val_mean_absolute_error: 126.5002\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8478 - mean_absolute_error: 163.8184 - val_loss: 126.4964 - val_mean_absolute_error: 126.4671\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8122 - mean_absolute_error: 163.7829 - val_loss: 126.4630 - val_mean_absolute_error: 126.4332\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7763 - mean_absolute_error: 163.7469 - val_loss: 126.4299 - val_mean_absolute_error: 126.4007\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7407 - mean_absolute_error: 163.7113 - val_loss: 126.3962 - val_mean_absolute_error: 126.3666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7050 - mean_absolute_error: 163.6756 - val_loss: 126.3634 - val_mean_absolute_error: 126.3341\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6698 - mean_absolute_error: 163.6404 - val_loss: 126.3305 - val_mean_absolute_error: 126.3007\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6349 - mean_absolute_error: 163.6055 - val_loss: 126.2969 - val_mean_absolute_error: 126.2673\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5995 - mean_absolute_error: 163.5701 - val_loss: 126.2636 - val_mean_absolute_error: 126.2340\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5645 - mean_absolute_error: 163.5352 - val_loss: 126.2302 - val_mean_absolute_error: 126.2008\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5310 - mean_absolute_error: 163.5016 - val_loss: 126.1989 - val_mean_absolute_error: 126.1692\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4980 - mean_absolute_error: 163.4686 - val_loss: 126.1667 - val_mean_absolute_error: 126.1374\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4656 - mean_absolute_error: 163.4362 - val_loss: 126.1344 - val_mean_absolute_error: 126.1049\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4339 - mean_absolute_error: 163.4045 - val_loss: 126.1041 - val_mean_absolute_error: 126.0748\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4041 - mean_absolute_error: 163.3747 - val_loss: 126.0744 - val_mean_absolute_error: 126.0446\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3741 - mean_absolute_error: 163.3447 - val_loss: 126.0428 - val_mean_absolute_error: 126.0135\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3440 - mean_absolute_error: 163.3146 - val_loss: 126.0141 - val_mean_absolute_error: 125.9845\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3141 - mean_absolute_error: 163.2847 - val_loss: 125.9841 - val_mean_absolute_error: 125.9547\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2854 - mean_absolute_error: 163.2560 - val_loss: 125.9560 - val_mean_absolute_error: 125.9262\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2554 - mean_absolute_error: 163.2260 - val_loss: 125.9259 - val_mean_absolute_error: 125.8967\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2256 - mean_absolute_error: 163.1962 - val_loss: 125.8975 - val_mean_absolute_error: 125.8679\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1957 - mean_absolute_error: 163.1664 - val_loss: 125.8667 - val_mean_absolute_error: 125.8372\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1657 - mean_absolute_error: 163.1363 - val_loss: 125.8375 - val_mean_absolute_error: 125.8079\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1356 - mean_absolute_error: 163.1062 - val_loss: 125.8080 - val_mean_absolute_error: 125.7787\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1057 - mean_absolute_error: 163.0763 - val_loss: 125.7782 - val_mean_absolute_error: 125.7486\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0757 - mean_absolute_error: 163.0463 - val_loss: 125.7480 - val_mean_absolute_error: 125.7189\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0460 - mean_absolute_error: 163.0167 - val_loss: 125.7203 - val_mean_absolute_error: 125.6906\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0167 - mean_absolute_error: 162.9873 - val_loss: 125.6907 - val_mean_absolute_error: 125.6613\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9876 - mean_absolute_error: 162.9582 - val_loss: 125.6613 - val_mean_absolute_error: 125.6316\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9585 - mean_absolute_error: 162.9291 - val_loss: 125.6333 - val_mean_absolute_error: 125.6038\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9308 - mean_absolute_error: 162.9014 - val_loss: 125.6056 - val_mean_absolute_error: 125.5758\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9028 - mean_absolute_error: 162.8734 - val_loss: 125.5788 - val_mean_absolute_error: 125.5494\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8748 - mean_absolute_error: 162.8454 - val_loss: 125.5511 - val_mean_absolute_error: 125.5215\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8465 - mean_absolute_error: 162.8171 - val_loss: 125.5230 - val_mean_absolute_error: 125.4939\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8187 - mean_absolute_error: 162.7893 - val_loss: 125.4953 - val_mean_absolute_error: 125.4657\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7909 - mean_absolute_error: 162.7615 - val_loss: 125.4673 - val_mean_absolute_error: 125.4382\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7641 - mean_absolute_error: 162.7347 - val_loss: 125.4406 - val_mean_absolute_error: 125.4112\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7366 - mean_absolute_error: 162.7072 - val_loss: 125.4133 - val_mean_absolute_error: 125.3837\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7093 - mean_absolute_error: 162.6798 - val_loss: 125.3858 - val_mean_absolute_error: 125.3560\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6823 - mean_absolute_error: 162.6529 - val_loss: 125.3581 - val_mean_absolute_error: 125.3286\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6555 - mean_absolute_error: 162.6261 - val_loss: 125.3312 - val_mean_absolute_error: 125.3017\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6293 - mean_absolute_error: 162.5999 - val_loss: 125.3040 - val_mean_absolute_error: 125.2747\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6032 - mean_absolute_error: 162.5737 - val_loss: 125.2777 - val_mean_absolute_error: 125.2481\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5779 - mean_absolute_error: 162.5486 - val_loss: 125.2509 - val_mean_absolute_error: 125.2218\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5538 - mean_absolute_error: 162.5244 - val_loss: 125.2275 - val_mean_absolute_error: 125.1979\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5328 - mean_absolute_error: 162.5034 - val_loss: 125.2056 - val_mean_absolute_error: 125.1763\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5127 - mean_absolute_error: 162.4833 - val_loss: 125.1872 - val_mean_absolute_error: 125.1573\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4943 - mean_absolute_error: 162.4649 - val_loss: 125.1688 - val_mean_absolute_error: 125.1393\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4766 - mean_absolute_error: 162.4472 - val_loss: 125.1511 - val_mean_absolute_error: 125.1214\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4602 - mean_absolute_error: 162.4308 - val_loss: 125.1344 - val_mean_absolute_error: 125.1051\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4445 - mean_absolute_error: 162.4151 - val_loss: 125.1184 - val_mean_absolute_error: 125.0888\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4291 - mean_absolute_error: 162.3997 - val_loss: 125.1021 - val_mean_absolute_error: 125.0729\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4142 - mean_absolute_error: 162.3847 - val_loss: 125.0870 - val_mean_absolute_error: 125.0575\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3987 - mean_absolute_error: 162.3694 - val_loss: 125.0721 - val_mean_absolute_error: 125.0427\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3839 - mean_absolute_error: 162.3545 - val_loss: 125.0571 - val_mean_absolute_error: 125.0273\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3691 - mean_absolute_error: 162.3397 - val_loss: 125.0416 - val_mean_absolute_error: 125.0122\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3547 - mean_absolute_error: 162.3254 - val_loss: 125.0277 - val_mean_absolute_error: 124.9981\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408396ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665f078",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b36805",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd327e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af18071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 170.1572 - mean_absolute_error: 165.5802 - val_loss: 129.4146 - val_mean_absolute_error: 128.1022\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.9969 - mean_absolute_error: 165.5220 - val_loss: 128.1393 - val_mean_absolute_error: 128.0504\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.5158 - mean_absolute_error: 165.4695 - val_loss: 128.0317 - val_mean_absolute_error: 128.0006\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.4473 - mean_absolute_error: 165.4172 - val_loss: 127.9809 - val_mean_absolute_error: 127.9508\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3977 - mean_absolute_error: 165.3678 - val_loss: 127.9360 - val_mean_absolute_error: 127.9062\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3528 - mean_absolute_error: 165.3229 - val_loss: 127.8946 - val_mean_absolute_error: 127.8644\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.3091 - mean_absolute_error: 165.2792 - val_loss: 127.8527 - val_mean_absolute_error: 127.8231\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.2665 - mean_absolute_error: 165.2366 - val_loss: 127.8121 - val_mean_absolute_error: 127.7821\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.2238 - mean_absolute_error: 165.1939 - val_loss: 127.7714 - val_mean_absolute_error: 127.7416\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1810 - mean_absolute_error: 165.1512 - val_loss: 127.7304 - val_mean_absolute_error: 127.7001\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1381 - mean_absolute_error: 165.1082 - val_loss: 127.6885 - val_mean_absolute_error: 127.6588\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0946 - mean_absolute_error: 165.0647 - val_loss: 127.6466 - val_mean_absolute_error: 127.6166\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0511 - mean_absolute_error: 165.0212 - val_loss: 127.6054 - val_mean_absolute_error: 127.5758\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.0083 - mean_absolute_error: 164.9785 - val_loss: 127.5655 - val_mean_absolute_error: 127.5354\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.9668 - mean_absolute_error: 164.9370 - val_loss: 127.5259 - val_mean_absolute_error: 127.4963\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.9264 - mean_absolute_error: 164.8966 - val_loss: 127.4886 - val_mean_absolute_error: 127.4585\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8892 - mean_absolute_error: 164.8593 - val_loss: 127.4529 - val_mean_absolute_error: 127.4229\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8532 - mean_absolute_error: 164.8234 - val_loss: 127.4188 - val_mean_absolute_error: 127.3886\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8168 - mean_absolute_error: 164.7870 - val_loss: 127.3840 - val_mean_absolute_error: 127.3545\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7810 - mean_absolute_error: 164.7511 - val_loss: 127.3511 - val_mean_absolute_error: 127.3212\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7449 - mean_absolute_error: 164.7150 - val_loss: 127.3183 - val_mean_absolute_error: 127.2884\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.7084 - mean_absolute_error: 164.6786 - val_loss: 127.2849 - val_mean_absolute_error: 127.2547\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.6718 - mean_absolute_error: 164.6419 - val_loss: 127.2518 - val_mean_absolute_error: 127.2222\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.6353 - mean_absolute_error: 164.6055 - val_loss: 127.2187 - val_mean_absolute_error: 127.1886\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5980 - mean_absolute_error: 164.5681 - val_loss: 127.1851 - val_mean_absolute_error: 127.1551\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5604 - mean_absolute_error: 164.5306 - val_loss: 127.1517 - val_mean_absolute_error: 127.1215\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.5228 - mean_absolute_error: 164.4930 - val_loss: 127.1171 - val_mean_absolute_error: 127.0875\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4855 - mean_absolute_error: 164.4557 - val_loss: 127.0830 - val_mean_absolute_error: 127.0530\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4477 - mean_absolute_error: 164.4179 - val_loss: 127.0486 - val_mean_absolute_error: 127.0189\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.4103 - mean_absolute_error: 164.3804 - val_loss: 127.0156 - val_mean_absolute_error: 126.9854\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.3727 - mean_absolute_error: 164.3428 - val_loss: 126.9804 - val_mean_absolute_error: 126.9507\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.3354 - mean_absolute_error: 164.3056 - val_loss: 126.9463 - val_mean_absolute_error: 126.9163\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2981 - mean_absolute_error: 164.2683 - val_loss: 126.9123 - val_mean_absolute_error: 126.8824\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2606 - mean_absolute_error: 164.2307 - val_loss: 126.8780 - val_mean_absolute_error: 126.8479\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.2237 - mean_absolute_error: 164.1938 - val_loss: 126.8435 - val_mean_absolute_error: 126.8138\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1859 - mean_absolute_error: 164.1560 - val_loss: 126.8093 - val_mean_absolute_error: 126.7793\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1483 - mean_absolute_error: 164.1184 - val_loss: 126.7748 - val_mean_absolute_error: 126.7451\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.1106 - mean_absolute_error: 164.0807 - val_loss: 126.7403 - val_mean_absolute_error: 126.7101\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.0727 - mean_absolute_error: 164.0429 - val_loss: 126.7047 - val_mean_absolute_error: 126.6752\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.0349 - mean_absolute_error: 164.0051 - val_loss: 126.6699 - val_mean_absolute_error: 126.6401\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9972 - mean_absolute_error: 163.9674 - val_loss: 126.6354 - val_mean_absolute_error: 126.6054\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9602 - mean_absolute_error: 163.9304 - val_loss: 126.6001 - val_mean_absolute_error: 126.5698\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.9232 - mean_absolute_error: 163.8934 - val_loss: 126.5660 - val_mean_absolute_error: 126.5362\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8863 - mean_absolute_error: 163.8565 - val_loss: 126.5321 - val_mean_absolute_error: 126.5020\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8502 - mean_absolute_error: 163.8203 - val_loss: 126.4990 - val_mean_absolute_error: 126.4691\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.8141 - mean_absolute_error: 163.7843 - val_loss: 126.4653 - val_mean_absolute_error: 126.4352\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7781 - mean_absolute_error: 163.7483 - val_loss: 126.4310 - val_mean_absolute_error: 126.4015\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7430 - mean_absolute_error: 163.7132 - val_loss: 126.3991 - val_mean_absolute_error: 126.3691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.7074 - mean_absolute_error: 163.6775 - val_loss: 126.3649 - val_mean_absolute_error: 126.3351\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6718 - mean_absolute_error: 163.6420 - val_loss: 126.3326 - val_mean_absolute_error: 126.3025\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6365 - mean_absolute_error: 163.6066 - val_loss: 126.2986 - val_mean_absolute_error: 126.2688\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6010 - mean_absolute_error: 163.5712 - val_loss: 126.2656 - val_mean_absolute_error: 126.2356\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5665 - mean_absolute_error: 163.5366 - val_loss: 126.2325 - val_mean_absolute_error: 126.2027\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5331 - mean_absolute_error: 163.5033 - val_loss: 126.2012 - val_mean_absolute_error: 126.1710\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.5006 - mean_absolute_error: 163.4708 - val_loss: 126.1686 - val_mean_absolute_error: 126.1390\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4684 - mean_absolute_error: 163.4385 - val_loss: 126.1376 - val_mean_absolute_error: 126.1077\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4377 - mean_absolute_error: 163.4079 - val_loss: 126.1074 - val_mean_absolute_error: 126.0775\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.4078 - mean_absolute_error: 163.3779 - val_loss: 126.0774 - val_mean_absolute_error: 126.0472\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3776 - mean_absolute_error: 163.3477 - val_loss: 126.0464 - val_mean_absolute_error: 126.0169\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3474 - mean_absolute_error: 163.3176 - val_loss: 126.0169 - val_mean_absolute_error: 125.9869\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.3179 - mean_absolute_error: 163.2880 - val_loss: 125.9873 - val_mean_absolute_error: 125.9574\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2879 - mean_absolute_error: 163.2580 - val_loss: 125.9589 - val_mean_absolute_error: 125.9286\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2580 - mean_absolute_error: 163.2281 - val_loss: 125.9286 - val_mean_absolute_error: 125.8990\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.2279 - mean_absolute_error: 163.1980 - val_loss: 125.8994 - val_mean_absolute_error: 125.8694\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1978 - mean_absolute_error: 163.1680 - val_loss: 125.8694 - val_mean_absolute_error: 125.8394\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1683 - mean_absolute_error: 163.1385 - val_loss: 125.8406 - val_mean_absolute_error: 125.8105\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1388 - mean_absolute_error: 163.1090 - val_loss: 125.8110 - val_mean_absolute_error: 125.7812\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.1089 - mean_absolute_error: 163.0791 - val_loss: 125.7819 - val_mean_absolute_error: 125.7518\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0796 - mean_absolute_error: 163.0497 - val_loss: 125.7516 - val_mean_absolute_error: 125.7220\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0499 - mean_absolute_error: 163.0201 - val_loss: 125.7236 - val_mean_absolute_error: 125.6934\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0210 - mean_absolute_error: 162.9912 - val_loss: 125.6941 - val_mean_absolute_error: 125.6646\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9919 - mean_absolute_error: 162.9621 - val_loss: 125.6663 - val_mean_absolute_error: 125.6363\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9634 - mean_absolute_error: 162.9336 - val_loss: 125.6382 - val_mean_absolute_error: 125.6082\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9351 - mean_absolute_error: 162.9053 - val_loss: 125.6101 - val_mean_absolute_error: 125.5797\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.9068 - mean_absolute_error: 162.8769 - val_loss: 125.5822 - val_mean_absolute_error: 125.5524\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8790 - mean_absolute_error: 162.8492 - val_loss: 125.5549 - val_mean_absolute_error: 125.5248\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8512 - mean_absolute_error: 162.8213 - val_loss: 125.5273 - val_mean_absolute_error: 125.4974\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.8232 - mean_absolute_error: 162.7933 - val_loss: 125.4998 - val_mean_absolute_error: 125.4697\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7957 - mean_absolute_error: 162.7659 - val_loss: 125.4715 - val_mean_absolute_error: 125.4421\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7684 - mean_absolute_error: 162.7385 - val_loss: 125.4446 - val_mean_absolute_error: 125.4147\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7414 - mean_absolute_error: 162.7115 - val_loss: 125.4180 - val_mean_absolute_error: 125.3880\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7143 - mean_absolute_error: 162.6844 - val_loss: 125.3912 - val_mean_absolute_error: 125.3609\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6877 - mean_absolute_error: 162.6578 - val_loss: 125.3634 - val_mean_absolute_error: 125.3336\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6611 - mean_absolute_error: 162.6313 - val_loss: 125.3367 - val_mean_absolute_error: 125.3067\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6341 - mean_absolute_error: 162.6042 - val_loss: 125.3089 - val_mean_absolute_error: 125.2790\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.6079 - mean_absolute_error: 162.5781 - val_loss: 125.2828 - val_mean_absolute_error: 125.2525\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5827 - mean_absolute_error: 162.5528 - val_loss: 125.2561 - val_mean_absolute_error: 125.2266\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5590 - mean_absolute_error: 162.5291 - val_loss: 125.2327 - val_mean_absolute_error: 125.2027\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5372 - mean_absolute_error: 162.5074 - val_loss: 125.2097 - val_mean_absolute_error: 125.1800\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.5166 - mean_absolute_error: 162.4868 - val_loss: 125.1899 - val_mean_absolute_error: 125.1597\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4978 - mean_absolute_error: 162.4680 - val_loss: 125.1714 - val_mean_absolute_error: 125.1416\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4793 - mean_absolute_error: 162.4495 - val_loss: 125.1530 - val_mean_absolute_error: 125.1228\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4621 - mean_absolute_error: 162.4322 - val_loss: 125.1356 - val_mean_absolute_error: 125.1059\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4462 - mean_absolute_error: 162.4164 - val_loss: 125.1202 - val_mean_absolute_error: 125.0901\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4312 - mean_absolute_error: 162.4014 - val_loss: 125.1041 - val_mean_absolute_error: 125.0746\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4158 - mean_absolute_error: 162.3860 - val_loss: 125.0893 - val_mean_absolute_error: 125.0592\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.4009 - mean_absolute_error: 162.3710 - val_loss: 125.0736 - val_mean_absolute_error: 125.0436\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3862 - mean_absolute_error: 162.3564 - val_loss: 125.0589 - val_mean_absolute_error: 125.0286\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3712 - mean_absolute_error: 162.3414 - val_loss: 125.0441 - val_mean_absolute_error: 125.0146\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.3566 - mean_absolute_error: 162.3268 - val_loss: 125.0296 - val_mean_absolute_error: 124.9997\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d632a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11b04f",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bd6001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8964f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8f9f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 19.8536 - mse: 94895.2109 - val_loss: 14.7174 - val_mse: 65642.4688\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.7657 - mse: 94895.2266 - val_loss: 13.5170 - val_mse: 65642.4688\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3510 - mse: 94895.2188 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2266 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4636 - val_mse: 65642.4688\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4636 - val_mse: 65642.4688\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2188 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4622 - val_mse: 65642.4688\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2266 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1797 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1797 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2266 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4636 - val_mse: 65642.4688\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4637 - val_mse: 65642.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2188 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2188 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2266 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4622 - val_mse: 65642.4688\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1797 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2031 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1797 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1953 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2266 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.2109 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3368 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae7ffefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f29b9",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da7e37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f7ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313b6748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 94882.9688 - mse: 94879.8906 - val_loss: 65618.8984 - val_mse: 65618.6406\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94849.2188 - mse: 94849.1484 - val_loss: 65594.8203 - val_mse: 65594.7812\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94819.1562 - mse: 94819.1172 - val_loss: 65571.5078 - val_mse: 65571.4688\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94789.3594 - mse: 94789.3125 - val_loss: 65548.5156 - val_mse: 65548.4844\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94759.4766 - mse: 94759.4375 - val_loss: 65525.7734 - val_mse: 65525.7539\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94729.6250 - mse: 94729.6094 - val_loss: 65502.5195 - val_mse: 65502.4844\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94699.9141 - mse: 94699.9062 - val_loss: 65479.8008 - val_mse: 65479.7695\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94670.2969 - mse: 94670.2578 - val_loss: 65457.1836 - val_mse: 65457.1602\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94640.5234 - mse: 94640.4922 - val_loss: 65434.2812 - val_mse: 65434.2578\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94611.1406 - mse: 94611.1172 - val_loss: 65410.9805 - val_mse: 65410.9453\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94581.5859 - mse: 94581.5547 - val_loss: 65388.6562 - val_mse: 65388.6211\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94552.2109 - mse: 94552.2031 - val_loss: 65366.1172 - val_mse: 65366.0742\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94522.8906 - mse: 94522.8594 - val_loss: 65342.8359 - val_mse: 65342.8125\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94493.4922 - mse: 94493.4844 - val_loss: 65320.2266 - val_mse: 65320.1875\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94464.1797 - mse: 94464.1250 - val_loss: 65297.7422 - val_mse: 65297.7148\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94434.6406 - mse: 94434.5859 - val_loss: 65274.6992 - val_mse: 65274.6680\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94405.0859 - mse: 94405.0469 - val_loss: 65252.4023 - val_mse: 65252.3828\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94375.9219 - mse: 94375.8828 - val_loss: 65229.3750 - val_mse: 65229.3359\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94346.4844 - mse: 94346.4609 - val_loss: 65207.4023 - val_mse: 65207.3750\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94317.3516 - mse: 94317.3125 - val_loss: 65184.2266 - val_mse: 65184.1992\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94288.1797 - mse: 94288.1562 - val_loss: 65161.9414 - val_mse: 65161.9102\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94258.9531 - mse: 94258.9297 - val_loss: 65139.5586 - val_mse: 65139.5430\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94229.8906 - mse: 94229.8438 - val_loss: 65117.1523 - val_mse: 65117.1250\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94200.6250 - mse: 94200.5938 - val_loss: 65094.4805 - val_mse: 65094.4531\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94171.3828 - mse: 94171.3672 - val_loss: 65072.2305 - val_mse: 65072.1992\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94142.3672 - mse: 94142.3281 - val_loss: 65049.5508 - val_mse: 65049.5195\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94113.2891 - mse: 94113.2656 - val_loss: 65027.6289 - val_mse: 65027.5938\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94084.2656 - mse: 94084.2344 - val_loss: 65004.7969 - val_mse: 65004.7656\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 94055.4062 - mse: 94055.3906 - val_loss: 64982.2109 - val_mse: 64982.1836\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94026.4531 - mse: 94026.4375 - val_loss: 64960.4805 - val_mse: 64960.4531\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93997.5781 - mse: 93997.5469 - val_loss: 64938.1016 - val_mse: 64938.0664\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93968.6094 - mse: 93968.5859 - val_loss: 64915.8281 - val_mse: 64915.8086\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93939.4766 - mse: 93939.4609 - val_loss: 64893.4531 - val_mse: 64893.4219\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93910.5859 - mse: 93910.5469 - val_loss: 64871.0117 - val_mse: 64870.9766\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93881.6562 - mse: 93881.6172 - val_loss: 64848.8984 - val_mse: 64848.8672\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93852.7734 - mse: 93852.7422 - val_loss: 64826.3242 - val_mse: 64826.3047\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93823.8281 - mse: 93823.8047 - val_loss: 64804.3750 - val_mse: 64804.3477\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93794.9531 - mse: 93794.9062 - val_loss: 64782.2344 - val_mse: 64782.1992\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93766.1328 - mse: 93766.0859 - val_loss: 64760.0898 - val_mse: 64760.0508\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93737.4062 - mse: 93737.3750 - val_loss: 64738.2656 - val_mse: 64738.2305\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93708.6250 - mse: 93708.5938 - val_loss: 64716.2695 - val_mse: 64716.2461\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93679.7891 - mse: 93679.7578 - val_loss: 64693.8867 - val_mse: 64693.8438\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93651.1094 - mse: 93651.0703 - val_loss: 64671.8945 - val_mse: 64671.8672\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93622.5703 - mse: 93622.5547 - val_loss: 64649.4609 - val_mse: 64649.4336\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93593.9375 - mse: 93593.9062 - val_loss: 64627.7422 - val_mse: 64627.7070\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93565.3984 - mse: 93565.3672 - val_loss: 64605.8320 - val_mse: 64605.8047\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93536.7578 - mse: 93536.7266 - val_loss: 64584.0469 - val_mse: 64584.0195\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93508.0078 - mse: 93507.9766 - val_loss: 64561.8633 - val_mse: 64561.8281\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93479.1953 - mse: 93479.1641 - val_loss: 64539.8164 - val_mse: 64539.7969\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93450.5469 - mse: 93450.5234 - val_loss: 64517.7891 - val_mse: 64517.7422\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93421.9609 - mse: 93421.9375 - val_loss: 64495.7656 - val_mse: 64495.7461\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93393.5078 - mse: 93393.4766 - val_loss: 64473.9102 - val_mse: 64473.8867\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93365.1719 - mse: 93365.1562 - val_loss: 64451.9688 - val_mse: 64451.9414\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93336.7109 - mse: 93336.6797 - val_loss: 64430.6562 - val_mse: 64430.6250\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93308.3125 - mse: 93308.2812 - val_loss: 64408.6484 - val_mse: 64408.6133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93279.8828 - mse: 93279.8359 - val_loss: 64386.6172 - val_mse: 64386.5859\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93251.3906 - mse: 93251.3438 - val_loss: 64365.0938 - val_mse: 64365.0586\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93222.9453 - mse: 93222.9141 - val_loss: 64343.4727 - val_mse: 64343.4414\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93194.4453 - mse: 93194.4062 - val_loss: 64321.5664 - val_mse: 64321.5352\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93166.1484 - mse: 93166.1328 - val_loss: 64299.6289 - val_mse: 64299.5977\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93137.5391 - mse: 93137.4844 - val_loss: 64277.8711 - val_mse: 64277.8281\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93109.3750 - mse: 93109.3516 - val_loss: 64255.9766 - val_mse: 64255.9531\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93081.1484 - mse: 93081.1016 - val_loss: 64234.7812 - val_mse: 64234.7461\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93052.7812 - mse: 93052.7578 - val_loss: 64212.9258 - val_mse: 64212.8984\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93024.4922 - mse: 93024.4688 - val_loss: 64190.9102 - val_mse: 64190.8711\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92996.1016 - mse: 92996.0625 - val_loss: 64169.1680 - val_mse: 64169.1445\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92967.7500 - mse: 92967.7031 - val_loss: 64147.7930 - val_mse: 64147.7461\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92939.6406 - mse: 92939.5938 - val_loss: 64126.1562 - val_mse: 64126.1289\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92911.3906 - mse: 92911.3750 - val_loss: 64104.6094 - val_mse: 64104.5781\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92883.1797 - mse: 92883.1484 - val_loss: 64083.0117 - val_mse: 64082.9883\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92854.9141 - mse: 92854.8828 - val_loss: 64061.7109 - val_mse: 64061.6836\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92826.6641 - mse: 92826.6328 - val_loss: 64039.7344 - val_mse: 64039.7109\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92798.3594 - mse: 92798.3359 - val_loss: 64018.3359 - val_mse: 64018.3047\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92770.1875 - mse: 92770.1484 - val_loss: 63996.6562 - val_mse: 63996.6172\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92742.0859 - mse: 92742.0547 - val_loss: 63975.5352 - val_mse: 63975.5039\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92714.0078 - mse: 92713.9766 - val_loss: 63953.7578 - val_mse: 63953.7227\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92685.8594 - mse: 92685.8359 - val_loss: 63932.5938 - val_mse: 63932.5742\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92658.0312 - mse: 92658.0000 - val_loss: 63910.8477 - val_mse: 63910.8125\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92630.0547 - mse: 92630.0234 - val_loss: 63889.8281 - val_mse: 63889.8125\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92602.1641 - mse: 92602.1250 - val_loss: 63868.6680 - val_mse: 63868.6484\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92574.4531 - mse: 92574.4375 - val_loss: 63846.9258 - val_mse: 63846.8945\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92546.4375 - mse: 92546.4219 - val_loss: 63825.5469 - val_mse: 63825.5078\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92518.6562 - mse: 92518.6016 - val_loss: 63804.2969 - val_mse: 63804.2578\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92490.5078 - mse: 92490.4688 - val_loss: 63783.0352 - val_mse: 63783.0039\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92462.6172 - mse: 92462.5703 - val_loss: 63761.9414 - val_mse: 63761.9023\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92434.7500 - mse: 92434.7188 - val_loss: 63740.5273 - val_mse: 63740.5078\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92406.7344 - mse: 92406.7031 - val_loss: 63719.4375 - val_mse: 63719.4180\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92378.7656 - mse: 92378.7266 - val_loss: 63697.8594 - val_mse: 63697.8164\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92350.7969 - mse: 92350.7734 - val_loss: 63676.8242 - val_mse: 63676.7969\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92323.0391 - mse: 92323.0156 - val_loss: 63655.1328 - val_mse: 63655.1016\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92295.0078 - mse: 92294.9922 - val_loss: 63634.1875 - val_mse: 63634.1445\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92267.0625 - mse: 92267.0391 - val_loss: 63612.8984 - val_mse: 63612.8711\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92239.2344 - mse: 92239.2031 - val_loss: 63591.2422 - val_mse: 63591.2109\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92211.3438 - mse: 92211.3281 - val_loss: 63570.3242 - val_mse: 63570.2852\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92183.7031 - mse: 92183.6875 - val_loss: 63548.9453 - val_mse: 63548.9141\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92155.9453 - mse: 92155.9375 - val_loss: 63528.1562 - val_mse: 63528.1328\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92128.2344 - mse: 92128.2031 - val_loss: 63507.1758 - val_mse: 63507.1484\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92100.7891 - mse: 92100.7578 - val_loss: 63485.9805 - val_mse: 63485.9336\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92073.0625 - mse: 92073.0469 - val_loss: 63465.2969 - val_mse: 63465.2773\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92045.5781 - mse: 92045.5469 - val_loss: 63444.3242 - val_mse: 63444.2930\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e122178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d588720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
