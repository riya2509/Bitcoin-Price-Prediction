{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_9928\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4a7cf",
   "metadata": {},
   "source": [
    "### Reading the RobustScaler Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0  priceUSD\n",
       "0           0  0.0    0.0495\n",
       "1           1  0.0    0.0726\n",
       "2           2  0.0    0.0859\n",
       "3           3  0.0    0.0783\n",
       "4           4  0.0    0.0767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_RobustScaler_data2.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>393.7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>386.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>0.0</td>\n",
       "      <td>379.4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0.0</td>\n",
       "      <td>384.7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>388.4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1556 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  priceUSD\n",
       "0     0.0    0.0495\n",
       "1     0.0    0.0726\n",
       "2     0.0    0.0859\n",
       "3     0.0    0.0783\n",
       "4     0.0    0.0767\n",
       "...   ...       ...\n",
       "1551  0.0  393.7880\n",
       "1552  0.0  386.2650\n",
       "1553  0.0  379.4510\n",
       "1554  0.0  384.7020\n",
       "1555  0.0  388.4040\n",
       "\n",
       "[1556 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.03681321805888427\n",
      "Test score of trained model: -1.3525807357539277\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685f5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d74ea26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50894.125414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.597264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>181.884160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>23853.767360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.013526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.016795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50894.125414\n",
       "1    RMSE    225.597264\n",
       "2     MAE    181.884160\n",
       "3    MAPE  23853.767360\n",
       "4      r2     -0.013526\n",
       "5  adj_r2     -0.016795"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7575c",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1a9412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.03681318131916189\n",
      "Test score of trained model: -1.3525654212569238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af8ed868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50894.117723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.597247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>181.884373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.013526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.016795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50894.117723\n",
       "1    RMSE    225.597247\n",
       "2     MAE    181.884373\n",
       "3      r2     -0.013526\n",
       "4  adj_r2     -0.016795"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53d840",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af0c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.03681127550443364\n",
      "Test score of trained model: -1.3524727314211393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "019188ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>50894.071179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>225.597144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>181.885706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.013525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.016794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  50894.071179\n",
       "1    RMSE    225.597144\n",
       "2     MAE    181.885706\n",
       "3      r2     -0.013525\n",
       "4  adj_r2     -0.016794"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f23dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 0.026290270686013528\n",
      "Test score of trained model: -1.8790823159394954\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff54b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>51158.507803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>226.182466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>184.628351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.018791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>-0.022077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  51158.507803\n",
       "1    RMSE    226.182466\n",
       "2     MAE    184.628351\n",
       "3      r2     -0.018791\n",
       "4  adj_r2     -0.022077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.03, max_depth=10, n_estimators=1000,\n",
      "                          subsample=0.1)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -0.0023024106271190004\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.03, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83904edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.015398271871882363\n",
      "   Metric         Score\n",
      "0     MSE  50988.151084\n",
      "1    RMSE    225.805560\n",
      "2     MAE    182.924262\n",
      "3      r2     -0.015398\n",
      "4  adj_r2     -0.018674\n",
      "Best Score: -0.010197501442558422\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.013480157297731443\n",
      "   Metric         Score\n",
      "0     MSE  50891.833099\n",
      "1    RMSE    225.592183\n",
      "2     MAE    181.881294\n",
      "3      r2     -0.013480\n",
      "4  adj_r2     -0.016749\n",
      "Best Score: -0.009354946112885232\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 20}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: -0.013754678821394029\n",
      "   Metric         Score\n",
      "0     MSE  50905.618178\n",
      "1    RMSE    225.622734\n",
      "2     MAE    182.040262\n",
      "3      r2     -0.013755\n",
      "4  adj_r2     -0.017025\n",
      "Best Score: -0.009403630887380254\n",
      "Best params: {'bootstrap': True, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 10}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: -0.01532359324398147\n",
      "   Metric         Score\n",
      "0     MSE  50984.401102\n",
      "1    RMSE    225.797257\n",
      "2     MAE    182.891270\n",
      "3      r2     -0.015324\n",
      "4  adj_r2     -0.018599\n",
      "Best Score: -0.009658575685077197\n",
      "Best params: {'bootstrap': True, 'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 20}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: -0.014277166137836472\n",
      "   Metric         Score\n",
      "0     MSE  50931.854841\n",
      "1    RMSE    225.680869\n",
      "2     MAE    182.311801\n",
      "3      r2     -0.014277\n",
      "4  adj_r2     -0.017549\n",
      "Best Score: -0.009005924980126067\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35cdb2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8cbe442",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e60738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 170.0343 - mean_absolute_error: 165.5777 - val_loss: 129.3652 - val_mean_absolute_error: 128.0933\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.9492 - mean_absolute_error: 165.4898 - val_loss: 128.0658 - val_mean_absolute_error: 127.9779\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3403 - mean_absolute_error: 165.2939 - val_loss: 127.6937 - val_mean_absolute_error: 127.6562\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8664 - mean_absolute_error: 163.5813 - val_loss: 124.7550 - val_mean_absolute_error: 123.9911\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.9563 - mean_absolute_error: 161.2439 - val_loss: 124.5994 - val_mean_absolute_error: 123.9563\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.7658 - mean_absolute_error: 161.1785 - val_loss: 124.4820 - val_mean_absolute_error: 123.9585\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.6932 - mean_absolute_error: 161.1938 - val_loss: 124.4202 - val_mean_absolute_error: 123.9548\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.6192 - mean_absolute_error: 161.1831 - val_loss: 124.4947 - val_mean_absolute_error: 124.0211\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.5939 - mean_absolute_error: 161.1747 - val_loss: 124.3572 - val_mean_absolute_error: 123.9622\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.5660 - mean_absolute_error: 161.1740 - val_loss: 124.4049 - val_mean_absolute_error: 124.0056\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4980 - mean_absolute_error: 161.1515 - val_loss: 124.4212 - val_mean_absolute_error: 124.0383\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.5359 - mean_absolute_error: 161.1747 - val_loss: 124.2569 - val_mean_absolute_error: 123.9755\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.5935 - mean_absolute_error: 161.2898 - val_loss: 124.2419 - val_mean_absolute_error: 123.9549\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4510 - mean_absolute_error: 161.1537 - val_loss: 124.2896 - val_mean_absolute_error: 124.0361\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4570 - mean_absolute_error: 161.1835 - val_loss: 124.2053 - val_mean_absolute_error: 123.9768\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4286 - mean_absolute_error: 161.1755 - val_loss: 124.1895 - val_mean_absolute_error: 123.9549\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3803 - mean_absolute_error: 161.1409 - val_loss: 124.2821 - val_mean_absolute_error: 124.0235\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3853 - mean_absolute_error: 161.1536 - val_loss: 124.1850 - val_mean_absolute_error: 123.9656\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3672 - mean_absolute_error: 161.1512 - val_loss: 124.1643 - val_mean_absolute_error: 123.9604\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3696 - mean_absolute_error: 161.1647 - val_loss: 124.2637 - val_mean_absolute_error: 124.0313\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4238 - mean_absolute_error: 161.2247 - val_loss: 124.1349 - val_mean_absolute_error: 123.9550\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3595 - mean_absolute_error: 161.1583 - val_loss: 124.2565 - val_mean_absolute_error: 124.0605\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4021 - mean_absolute_error: 161.2121 - val_loss: 124.1962 - val_mean_absolute_error: 123.9974\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3182 - mean_absolute_error: 161.1393 - val_loss: 124.1365 - val_mean_absolute_error: 123.9611\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3129 - mean_absolute_error: 161.1498 - val_loss: 124.2341 - val_mean_absolute_error: 124.0432\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3673 - mean_absolute_error: 161.1874 - val_loss: 124.1381 - val_mean_absolute_error: 123.9740\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3209 - mean_absolute_error: 161.1679 - val_loss: 124.1040 - val_mean_absolute_error: 123.9599\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3329 - mean_absolute_error: 161.1760 - val_loss: 124.1424 - val_mean_absolute_error: 123.9869\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3515 - mean_absolute_error: 161.1895 - val_loss: 124.0982 - val_mean_absolute_error: 123.9643\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3435 - mean_absolute_error: 161.2022 - val_loss: 124.0911 - val_mean_absolute_error: 123.9562\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3430 - mean_absolute_error: 161.2062 - val_loss: 124.0827 - val_mean_absolute_error: 123.9581\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2990 - mean_absolute_error: 161.1651 - val_loss: 124.1834 - val_mean_absolute_error: 124.0335\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2894 - mean_absolute_error: 161.1648 - val_loss: 124.0971 - val_mean_absolute_error: 123.9694\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2799 - mean_absolute_error: 161.1537 - val_loss: 124.0813 - val_mean_absolute_error: 123.9623\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2825 - mean_absolute_error: 161.1618 - val_loss: 124.0576 - val_mean_absolute_error: 123.9543\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2806 - mean_absolute_error: 161.1701 - val_loss: 124.4046 - val_mean_absolute_error: 124.2228\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3141 - mean_absolute_error: 161.1859 - val_loss: 124.1058 - val_mean_absolute_error: 123.9825\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2922 - mean_absolute_error: 161.1799 - val_loss: 124.0795 - val_mean_absolute_error: 123.9647\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2922 - mean_absolute_error: 161.1810 - val_loss: 124.0840 - val_mean_absolute_error: 123.9660\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2758 - mean_absolute_error: 161.1580 - val_loss: 124.0502 - val_mean_absolute_error: 123.9543\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2800 - mean_absolute_error: 161.1752 - val_loss: 124.1872 - val_mean_absolute_error: 124.0553\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2995 - mean_absolute_error: 161.1837 - val_loss: 124.1027 - val_mean_absolute_error: 123.9889\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2691 - mean_absolute_error: 161.1745 - val_loss: 124.0415 - val_mean_absolute_error: 123.9556\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2380 - mean_absolute_error: 161.1410 - val_loss: 124.1373 - val_mean_absolute_error: 124.0300\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2705 - mean_absolute_error: 161.1692 - val_loss: 124.0624 - val_mean_absolute_error: 123.9706\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2669 - mean_absolute_error: 161.1713 - val_loss: 124.0413 - val_mean_absolute_error: 123.9599\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2451 - mean_absolute_error: 161.1577 - val_loss: 124.0556 - val_mean_absolute_error: 123.9712\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2270 - mean_absolute_error: 161.1381 - val_loss: 124.0497 - val_mean_absolute_error: 123.9608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2252 - mean_absolute_error: 161.1290 - val_loss: 124.1326 - val_mean_absolute_error: 124.0347\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2368 - mean_absolute_error: 161.1461 - val_loss: 124.0402 - val_mean_absolute_error: 123.9628\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.2220 - mean_absolute_error: 161.1424 - val_loss: 124.0408 - val_mean_absolute_error: 123.9636\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2463 - mean_absolute_error: 161.1453 - val_loss: 124.0601 - val_mean_absolute_error: 123.9765\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2388 - mean_absolute_error: 161.1625 - val_loss: 124.0798 - val_mean_absolute_error: 123.9958\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2237 - mean_absolute_error: 161.1460 - val_loss: 124.0535 - val_mean_absolute_error: 123.9792\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2394 - mean_absolute_error: 161.1559 - val_loss: 124.0934 - val_mean_absolute_error: 124.0120\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2135 - mean_absolute_error: 161.1478 - val_loss: 124.0215 - val_mean_absolute_error: 123.9564\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2367 - mean_absolute_error: 161.1664 - val_loss: 124.0301 - val_mean_absolute_error: 123.9660\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2264 - mean_absolute_error: 161.1577 - val_loss: 124.0193 - val_mean_absolute_error: 123.9565\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2284 - mean_absolute_error: 161.1597 - val_loss: 124.0107 - val_mean_absolute_error: 123.9545\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2162 - mean_absolute_error: 161.1507 - val_loss: 124.0119 - val_mean_absolute_error: 123.9554\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2164 - mean_absolute_error: 161.1464 - val_loss: 124.0636 - val_mean_absolute_error: 123.9856\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2343 - mean_absolute_error: 161.1589 - val_loss: 124.0764 - val_mean_absolute_error: 124.0000\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2796 - mean_absolute_error: 161.2086 - val_loss: 124.1333 - val_mean_absolute_error: 124.0458\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2242 - mean_absolute_error: 161.1630 - val_loss: 124.1001 - val_mean_absolute_error: 124.0253\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2025 - mean_absolute_error: 161.1439 - val_loss: 124.0179 - val_mean_absolute_error: 123.9643\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3014 - mean_absolute_error: 161.2230 - val_loss: 124.0294 - val_mean_absolute_error: 123.9656\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1969 - mean_absolute_error: 161.1398 - val_loss: 124.1790 - val_mean_absolute_error: 124.0926\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2205 - mean_absolute_error: 161.1603 - val_loss: 124.0229 - val_mean_absolute_error: 123.9693\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2504 - mean_absolute_error: 161.1876 - val_loss: 124.0199 - val_mean_absolute_error: 123.9572\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2199 - mean_absolute_error: 161.1666 - val_loss: 124.0214 - val_mean_absolute_error: 123.9676\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2263 - mean_absolute_error: 161.1585 - val_loss: 124.0014 - val_mean_absolute_error: 123.9561\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1964 - mean_absolute_error: 161.1496 - val_loss: 124.0079 - val_mean_absolute_error: 123.9631\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2117 - mean_absolute_error: 161.1597 - val_loss: 124.0202 - val_mean_absolute_error: 123.9721\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2020 - mean_absolute_error: 161.1542 - val_loss: 124.0039 - val_mean_absolute_error: 123.9582\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2326 - mean_absolute_error: 161.1804 - val_loss: 124.0645 - val_mean_absolute_error: 124.0061\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2014 - mean_absolute_error: 161.1512 - val_loss: 124.0076 - val_mean_absolute_error: 123.9604\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.1898 - mean_absolute_error: 161.1346 - val_loss: 124.1730 - val_mean_absolute_error: 124.1033\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2302 - mean_absolute_error: 161.1747 - val_loss: 124.0042 - val_mean_absolute_error: 123.9554\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2027 - mean_absolute_error: 161.1544 - val_loss: 124.0614 - val_mean_absolute_error: 124.0100\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1892 - mean_absolute_error: 161.1454 - val_loss: 124.0034 - val_mean_absolute_error: 123.9624\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1886 - mean_absolute_error: 161.1481 - val_loss: 124.0010 - val_mean_absolute_error: 123.9623\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2012 - mean_absolute_error: 161.1583 - val_loss: 124.0027 - val_mean_absolute_error: 123.9544\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2109 - mean_absolute_error: 161.1566 - val_loss: 124.0456 - val_mean_absolute_error: 123.9834\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2015 - mean_absolute_error: 161.1581 - val_loss: 124.0051 - val_mean_absolute_error: 123.9649\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1915 - mean_absolute_error: 161.1481 - val_loss: 123.9970 - val_mean_absolute_error: 123.9545\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.1788 - mean_absolute_error: 161.1423 - val_loss: 124.0116 - val_mean_absolute_error: 123.9736\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2058 - mean_absolute_error: 161.1589 - val_loss: 124.0053 - val_mean_absolute_error: 123.9603\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2388 - mean_absolute_error: 161.1875 - val_loss: 124.0031 - val_mean_absolute_error: 123.9552\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1867 - mean_absolute_error: 161.1377 - val_loss: 124.0032 - val_mean_absolute_error: 123.9559\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1823 - mean_absolute_error: 161.1337 - val_loss: 124.1796 - val_mean_absolute_error: 124.1105\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2132 - mean_absolute_error: 161.1656 - val_loss: 124.0214 - val_mean_absolute_error: 123.9826\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1789 - mean_absolute_error: 161.1418 - val_loss: 124.0055 - val_mean_absolute_error: 123.9671\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1929 - mean_absolute_error: 161.1510 - val_loss: 123.9996 - val_mean_absolute_error: 123.9674\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1963 - mean_absolute_error: 161.1519 - val_loss: 124.0223 - val_mean_absolute_error: 123.9838\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2026 - mean_absolute_error: 161.1546 - val_loss: 124.0001 - val_mean_absolute_error: 123.9629\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2005 - mean_absolute_error: 161.1595 - val_loss: 123.9996 - val_mean_absolute_error: 123.9622\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1783 - mean_absolute_error: 161.1333 - val_loss: 123.9966 - val_mean_absolute_error: 123.9547\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1969 - mean_absolute_error: 161.1498 - val_loss: 124.0197 - val_mean_absolute_error: 123.9613\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1947 - mean_absolute_error: 161.1530 - val_loss: 124.0207 - val_mean_absolute_error: 123.9840\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.1945 - mean_absolute_error: 161.1510 - val_loss: 124.1350 - val_mean_absolute_error: 124.0737\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db0a7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667f1ee4",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb8a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f352810",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62d7398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 170.1165 - mean_absolute_error: 165.5759 - val_loss: 129.3812 - val_mean_absolute_error: 128.0842\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.9182 - mean_absolute_error: 165.4554 - val_loss: 127.9993 - val_mean_absolute_error: 127.9152\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.2549 - mean_absolute_error: 165.2061 - val_loss: 127.6100 - val_mean_absolute_error: 127.5622\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.6404 - mean_absolute_error: 164.5677 - val_loss: 126.6118 - val_mean_absolute_error: 126.4951\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6250 - mean_absolute_error: 162.2739 - val_loss: 124.4336 - val_mean_absolute_error: 123.9568\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.6752 - mean_absolute_error: 161.2572 - val_loss: 124.3976 - val_mean_absolute_error: 124.0711\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.5915 - mean_absolute_error: 161.2338 - val_loss: 124.3303 - val_mean_absolute_error: 123.9619\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.5187 - mean_absolute_error: 161.1689 - val_loss: 124.4155 - val_mean_absolute_error: 124.0456\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4800 - mean_absolute_error: 161.1597 - val_loss: 124.2652 - val_mean_absolute_error: 123.9603\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4568 - mean_absolute_error: 161.1630 - val_loss: 124.3254 - val_mean_absolute_error: 124.0084\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4762 - mean_absolute_error: 161.1741 - val_loss: 124.2391 - val_mean_absolute_error: 123.9615\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4478 - mean_absolute_error: 161.1636 - val_loss: 124.2211 - val_mean_absolute_error: 123.9555\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4227 - mean_absolute_error: 161.1475 - val_loss: 124.2164 - val_mean_absolute_error: 123.9567\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4362 - mean_absolute_error: 161.1724 - val_loss: 124.3122 - val_mean_absolute_error: 124.0197\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4372 - mean_absolute_error: 161.1570 - val_loss: 124.3692 - val_mean_absolute_error: 124.0648\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4374 - mean_absolute_error: 161.1734 - val_loss: 124.2274 - val_mean_absolute_error: 123.9694\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4371 - mean_absolute_error: 161.1794 - val_loss: 124.2058 - val_mean_absolute_error: 123.9585\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4552 - mean_absolute_error: 161.1896 - val_loss: 124.3179 - val_mean_absolute_error: 124.0263\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4123 - mean_absolute_error: 161.1519 - val_loss: 124.2358 - val_mean_absolute_error: 123.9767\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3842 - mean_absolute_error: 161.1296 - val_loss: 124.1898 - val_mean_absolute_error: 123.9571\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4019 - mean_absolute_error: 161.1598 - val_loss: 124.2520 - val_mean_absolute_error: 123.9931\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3852 - mean_absolute_error: 161.1391 - val_loss: 124.1786 - val_mean_absolute_error: 123.9563\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3809 - mean_absolute_error: 161.1476 - val_loss: 124.2676 - val_mean_absolute_error: 124.0172\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3774 - mean_absolute_error: 161.1440 - val_loss: 124.1849 - val_mean_absolute_error: 123.9589\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3829 - mean_absolute_error: 161.1493 - val_loss: 124.1930 - val_mean_absolute_error: 123.9568\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.4376 - mean_absolute_error: 161.2020 - val_loss: 124.1735 - val_mean_absolute_error: 123.9554\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3557 - mean_absolute_error: 161.1305 - val_loss: 124.2824 - val_mean_absolute_error: 124.0239\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3750 - mean_absolute_error: 161.1400 - val_loss: 124.1986 - val_mean_absolute_error: 123.9693\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3959 - mean_absolute_error: 161.1619 - val_loss: 124.1881 - val_mean_absolute_error: 123.9682\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3901 - mean_absolute_error: 161.1690 - val_loss: 124.1735 - val_mean_absolute_error: 123.9613\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3952 - mean_absolute_error: 161.1694 - val_loss: 124.2154 - val_mean_absolute_error: 123.9856\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3558 - mean_absolute_error: 161.1403 - val_loss: 124.1638 - val_mean_absolute_error: 123.9593\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3598 - mean_absolute_error: 161.1414 - val_loss: 124.2565 - val_mean_absolute_error: 124.0131\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3832 - mean_absolute_error: 161.1609 - val_loss: 124.2312 - val_mean_absolute_error: 124.0011\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3574 - mean_absolute_error: 161.1495 - val_loss: 124.1891 - val_mean_absolute_error: 123.9756\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3446 - mean_absolute_error: 161.1365 - val_loss: 124.1760 - val_mean_absolute_error: 123.9555\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3754 - mean_absolute_error: 161.1566 - val_loss: 124.2026 - val_mean_absolute_error: 123.9583\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3762 - mean_absolute_error: 161.1556 - val_loss: 124.2478 - val_mean_absolute_error: 124.0185\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3693 - mean_absolute_error: 161.1498 - val_loss: 124.2737 - val_mean_absolute_error: 124.0335\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3641 - mean_absolute_error: 161.1471 - val_loss: 124.1705 - val_mean_absolute_error: 123.9655\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3461 - mean_absolute_error: 161.1436 - val_loss: 124.1704 - val_mean_absolute_error: 123.9696\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3433 - mean_absolute_error: 161.1412 - val_loss: 124.1656 - val_mean_absolute_error: 123.9583\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3575 - mean_absolute_error: 161.1517 - val_loss: 124.1566 - val_mean_absolute_error: 123.9555\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3544 - mean_absolute_error: 161.1475 - val_loss: 124.1653 - val_mean_absolute_error: 123.9657\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3398 - mean_absolute_error: 161.1439 - val_loss: 124.1513 - val_mean_absolute_error: 123.9586\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3366 - mean_absolute_error: 161.1434 - val_loss: 124.1519 - val_mean_absolute_error: 123.9593\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3420 - mean_absolute_error: 161.1466 - val_loss: 124.1579 - val_mean_absolute_error: 123.9649\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3476 - mean_absolute_error: 161.1480 - val_loss: 124.1887 - val_mean_absolute_error: 123.9751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3368 - mean_absolute_error: 161.1410 - val_loss: 124.1581 - val_mean_absolute_error: 123.9660\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3551 - mean_absolute_error: 161.1523 - val_loss: 124.2113 - val_mean_absolute_error: 124.0024\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3471 - mean_absolute_error: 161.1446 - val_loss: 124.1655 - val_mean_absolute_error: 123.9630\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3474 - mean_absolute_error: 161.1530 - val_loss: 124.1727 - val_mean_absolute_error: 123.9701\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3765 - mean_absolute_error: 161.1534 - val_loss: 124.1866 - val_mean_absolute_error: 123.9592\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3474 - mean_absolute_error: 161.1509 - val_loss: 124.1612 - val_mean_absolute_error: 123.9654\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3386 - mean_absolute_error: 161.1413 - val_loss: 124.1503 - val_mean_absolute_error: 123.9586\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3296 - mean_absolute_error: 161.1442 - val_loss: 124.1478 - val_mean_absolute_error: 123.9624\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3375 - mean_absolute_error: 161.1467 - val_loss: 124.1599 - val_mean_absolute_error: 123.9727\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3290 - mean_absolute_error: 161.1412 - val_loss: 124.1666 - val_mean_absolute_error: 123.9769\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3315 - mean_absolute_error: 161.1417 - val_loss: 124.1523 - val_mean_absolute_error: 123.9568\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3344 - mean_absolute_error: 161.1442 - val_loss: 124.1484 - val_mean_absolute_error: 123.9617\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3335 - mean_absolute_error: 161.1464 - val_loss: 124.1622 - val_mean_absolute_error: 123.9723\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3443 - mean_absolute_error: 161.1442 - val_loss: 124.1538 - val_mean_absolute_error: 123.9575\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3338 - mean_absolute_error: 161.1470 - val_loss: 124.1488 - val_mean_absolute_error: 123.9667\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 161.3184 - mean_absolute_error: 161.1398 - val_loss: 124.1459 - val_mean_absolute_error: 123.9661\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3403 - mean_absolute_error: 161.1544 - val_loss: 124.1761 - val_mean_absolute_error: 123.9818\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3281 - mean_absolute_error: 161.1422 - val_loss: 124.1538 - val_mean_absolute_error: 123.9696\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3265 - mean_absolute_error: 161.1448 - val_loss: 124.1576 - val_mean_absolute_error: 123.9610\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3361 - mean_absolute_error: 161.1497 - val_loss: 124.1619 - val_mean_absolute_error: 123.9748\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3317 - mean_absolute_error: 161.1480 - val_loss: 124.1469 - val_mean_absolute_error: 123.9717\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3216 - mean_absolute_error: 161.1442 - val_loss: 124.1534 - val_mean_absolute_error: 123.9700\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3188 - mean_absolute_error: 161.1399 - val_loss: 124.1455 - val_mean_absolute_error: 123.9628\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3341 - mean_absolute_error: 161.1514 - val_loss: 124.1458 - val_mean_absolute_error: 123.9577\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3318 - mean_absolute_error: 161.1522 - val_loss: 124.1393 - val_mean_absolute_error: 123.9662\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3284 - mean_absolute_error: 161.1497 - val_loss: 124.1594 - val_mean_absolute_error: 123.9657\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3312 - mean_absolute_error: 161.1480 - val_loss: 124.1471 - val_mean_absolute_error: 123.9696\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3203 - mean_absolute_error: 161.1422 - val_loss: 124.1478 - val_mean_absolute_error: 123.9730\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3148 - mean_absolute_error: 161.1421 - val_loss: 124.1377 - val_mean_absolute_error: 123.9666\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3211 - mean_absolute_error: 161.1469 - val_loss: 124.1373 - val_mean_absolute_error: 123.9658\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3070 - mean_absolute_error: 161.1380 - val_loss: 124.1398 - val_mean_absolute_error: 123.9727\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3270 - mean_absolute_error: 161.1482 - val_loss: 124.1280 - val_mean_absolute_error: 123.9572\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3254 - mean_absolute_error: 161.1536 - val_loss: 124.1341 - val_mean_absolute_error: 123.9590\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3248 - mean_absolute_error: 161.1473 - val_loss: 124.1498 - val_mean_absolute_error: 123.9759\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3202 - mean_absolute_error: 161.1490 - val_loss: 124.1330 - val_mean_absolute_error: 123.9656\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3076 - mean_absolute_error: 161.1404 - val_loss: 124.1297 - val_mean_absolute_error: 123.9648\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3005 - mean_absolute_error: 161.1380 - val_loss: 124.1328 - val_mean_absolute_error: 123.9690\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3207 - mean_absolute_error: 161.1536 - val_loss: 124.1358 - val_mean_absolute_error: 123.9626\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3084 - mean_absolute_error: 161.1425 - val_loss: 124.1311 - val_mean_absolute_error: 123.9681\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3284 - mean_absolute_error: 161.1539 - val_loss: 124.1269 - val_mean_absolute_error: 123.9606\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3108 - mean_absolute_error: 161.1470 - val_loss: 124.1229 - val_mean_absolute_error: 123.9630\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3007 - mean_absolute_error: 161.1405 - val_loss: 124.1316 - val_mean_absolute_error: 123.9689\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2999 - mean_absolute_error: 161.1386 - val_loss: 124.1298 - val_mean_absolute_error: 123.9695\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3030 - mean_absolute_error: 161.1386 - val_loss: 124.1331 - val_mean_absolute_error: 123.9661\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3150 - mean_absolute_error: 161.1534 - val_loss: 124.1254 - val_mean_absolute_error: 123.9630\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3029 - mean_absolute_error: 161.1428 - val_loss: 124.1231 - val_mean_absolute_error: 123.9641\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3021 - mean_absolute_error: 161.1419 - val_loss: 124.1161 - val_mean_absolute_error: 123.9607\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3072 - mean_absolute_error: 161.1505 - val_loss: 124.1301 - val_mean_absolute_error: 123.9705\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3023 - mean_absolute_error: 161.1433 - val_loss: 124.1257 - val_mean_absolute_error: 123.9672\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2986 - mean_absolute_error: 161.1398 - val_loss: 124.1169 - val_mean_absolute_error: 123.9630\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.3011 - mean_absolute_error: 161.1485 - val_loss: 124.1310 - val_mean_absolute_error: 123.9730\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 161.2935 - mean_absolute_error: 161.1371 - val_loss: 124.1294 - val_mean_absolute_error: 123.9687\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c04eb63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371e317",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d86b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2846c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9ec31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 19.8485 - mse: 94895.2109 - val_loss: 14.7178 - val_mse: 65642.4688\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.7707 - mse: 94895.2031 - val_loss: 13.5211 - val_mse: 65642.4688\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3528 - mse: 94895.2266 - val_loss: 13.4639 - val_mse: 65642.4688\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3371 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1719 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4635 - val_mse: 65642.4688\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1797 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2344 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1797 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2266 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1797 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2188 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1797 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.1875 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3369 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19bdfebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f83c6d",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f574b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2fb0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "335144e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 4ms/step - loss: 94881.0469 - mse: 94877.9375 - val_loss: 65611.3047 - val_mse: 65611.0547\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94816.9219 - mse: 94816.8281 - val_loss: 65544.8672 - val_mse: 65544.8281\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94708.8359 - mse: 94708.7891 - val_loss: 65442.8750 - val_mse: 65442.8594\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94557.5703 - mse: 94557.5547 - val_loss: 65310.0312 - val_mse: 65310.0078\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94362.8047 - mse: 94362.7812 - val_loss: 65144.2930 - val_mse: 65144.2500\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94126.1094 - mse: 94126.0703 - val_loss: 64947.2227 - val_mse: 64947.2031\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93859.5234 - mse: 93859.4922 - val_loss: 64726.3945 - val_mse: 64726.3633\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93560.3438 - mse: 93560.3203 - val_loss: 64490.1914 - val_mse: 64490.1641\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93229.5625 - mse: 93229.5469 - val_loss: 64220.4297 - val_mse: 64220.3906\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92869.7266 - mse: 92869.6953 - val_loss: 63935.8125 - val_mse: 63935.7578\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92484.2578 - mse: 92484.2422 - val_loss: 63633.0078 - val_mse: 63632.9922\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92075.1484 - mse: 92075.1172 - val_loss: 63312.6484 - val_mse: 63312.6172\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 91645.5234 - mse: 91645.4766 - val_loss: 62976.0938 - val_mse: 62976.0664\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 91194.3906 - mse: 91194.3672 - val_loss: 62626.5117 - val_mse: 62626.4766\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 90720.8750 - mse: 90720.8438 - val_loss: 62268.9883 - val_mse: 62268.9531\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 90233.5547 - mse: 90233.5391 - val_loss: 61890.3008 - val_mse: 61890.2656\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 89726.2812 - mse: 89726.2422 - val_loss: 61512.1992 - val_mse: 61512.1680\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 89205.2734 - mse: 89205.2500 - val_loss: 61109.3906 - val_mse: 61109.3672\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 88677.4688 - mse: 88677.4219 - val_loss: 60709.8164 - val_mse: 60709.7773\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 88137.2344 - mse: 88137.2188 - val_loss: 60321.1367 - val_mse: 60321.1094\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 87595.7109 - mse: 87595.6875 - val_loss: 59905.0508 - val_mse: 59905.0273\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 87039.1328 - mse: 87039.1172 - val_loss: 59500.1445 - val_mse: 59500.1133\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 86480.6172 - mse: 86480.6016 - val_loss: 59097.9141 - val_mse: 59097.8828\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 85919.2109 - mse: 85919.1797 - val_loss: 58679.8008 - val_mse: 58679.7617\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 85352.2891 - mse: 85352.2578 - val_loss: 58281.1914 - val_mse: 58281.1523\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 84784.1641 - mse: 84784.1328 - val_loss: 57878.7812 - val_mse: 57878.7578\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 84220.7109 - mse: 84220.6875 - val_loss: 57474.8086 - val_mse: 57474.7773\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 83658.0859 - mse: 83658.0312 - val_loss: 57067.7812 - val_mse: 57067.7461\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 83093.0938 - mse: 83093.0547 - val_loss: 56683.6172 - val_mse: 56683.5898\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 82532.0469 - mse: 82532.0234 - val_loss: 56302.2500 - val_mse: 56302.2188\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 81967.9609 - mse: 81967.9297 - val_loss: 55911.0664 - val_mse: 55911.0391\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 81411.0000 - mse: 81410.9766 - val_loss: 55526.3320 - val_mse: 55526.2969\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 80864.3125 - mse: 80864.3047 - val_loss: 55157.0195 - val_mse: 55156.9844\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 80326.1016 - mse: 80326.0703 - val_loss: 54795.3633 - val_mse: 54795.3320\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 79791.3750 - mse: 79791.3438 - val_loss: 54451.9258 - val_mse: 54451.9102\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 79260.1953 - mse: 79260.1562 - val_loss: 54104.3398 - val_mse: 54104.3164\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 78742.8359 - mse: 78742.7969 - val_loss: 53773.6367 - val_mse: 53773.5977\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 78233.7891 - mse: 78233.7422 - val_loss: 53450.8047 - val_mse: 53450.7617\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 77738.0547 - mse: 77738.0312 - val_loss: 53142.2891 - val_mse: 53142.2500\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 77256.3203 - mse: 77256.2969 - val_loss: 52853.2266 - val_mse: 52853.1992\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 76787.4062 - mse: 76787.3750 - val_loss: 52561.3477 - val_mse: 52561.3086\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 76329.6484 - mse: 76329.6328 - val_loss: 52291.6719 - val_mse: 52291.6328\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 75890.9922 - mse: 75890.9531 - val_loss: 52037.7969 - val_mse: 52037.7695\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 75464.6016 - mse: 75464.5625 - val_loss: 51791.0742 - val_mse: 51791.0352\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 75046.7891 - mse: 75046.7344 - val_loss: 51554.7227 - val_mse: 51554.6992\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 74642.2109 - mse: 74642.1797 - val_loss: 51331.8633 - val_mse: 51331.8320\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 74245.4297 - mse: 74245.3906 - val_loss: 51123.5781 - val_mse: 51123.5352\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 73864.8047 - mse: 73864.7812 - val_loss: 50919.3789 - val_mse: 50919.3438\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 73493.7891 - mse: 73493.7578 - val_loss: 50739.5898 - val_mse: 50739.5547\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 73135.9688 - mse: 73135.9141 - val_loss: 50563.0273 - val_mse: 50563.0000\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 72791.5391 - mse: 72791.5078 - val_loss: 50395.9414 - val_mse: 50395.9102\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 72464.5469 - mse: 72464.5156 - val_loss: 50243.6211 - val_mse: 50243.5938\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 72151.7031 - mse: 72151.6953 - val_loss: 50101.1250 - val_mse: 50101.0820\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 71847.6406 - mse: 71847.6016 - val_loss: 49978.9688 - val_mse: 49978.9414\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 71559.1719 - mse: 71559.1484 - val_loss: 49862.8477 - val_mse: 49862.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 71285.2969 - mse: 71285.2578 - val_loss: 49751.7617 - val_mse: 49751.7305\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 71020.1953 - mse: 71020.1719 - val_loss: 49660.0391 - val_mse: 49660.0156\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 70774.1484 - mse: 70774.1172 - val_loss: 49577.5273 - val_mse: 49577.4961\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 70535.6797 - mse: 70535.6562 - val_loss: 49500.5430 - val_mse: 49500.5078\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 70313.7891 - mse: 70313.7500 - val_loss: 49438.1484 - val_mse: 49438.1211\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 70105.6641 - mse: 70105.6250 - val_loss: 49383.1328 - val_mse: 49383.1094\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 69910.3984 - mse: 69910.3750 - val_loss: 49334.4453 - val_mse: 49334.4180\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 69720.8984 - mse: 69720.8750 - val_loss: 49298.0469 - val_mse: 49298.0234\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 69548.0625 - mse: 69548.0312 - val_loss: 49266.8672 - val_mse: 49266.8242\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 69384.1562 - mse: 69384.1250 - val_loss: 49246.1133 - val_mse: 49246.0820\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 69232.4766 - mse: 69232.4531 - val_loss: 49229.9844 - val_mse: 49229.9531\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 69090.6094 - mse: 69090.5859 - val_loss: 49220.0859 - val_mse: 49220.0547\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68952.9375 - mse: 68952.8984 - val_loss: 49216.2578 - val_mse: 49216.2227\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68829.9531 - mse: 68829.9141 - val_loss: 49218.1719 - val_mse: 49218.1406\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68718.3359 - mse: 68718.2891 - val_loss: 49224.8320 - val_mse: 49224.8008\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68612.3594 - mse: 68612.3359 - val_loss: 49236.2773 - val_mse: 49236.2500\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68509.0156 - mse: 68508.9922 - val_loss: 49252.7461 - val_mse: 49252.7109\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68419.9453 - mse: 68419.9141 - val_loss: 49269.0039 - val_mse: 49268.9805\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 68335.3516 - mse: 68335.3203 - val_loss: 49291.9023 - val_mse: 49291.8750\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 68255.1875 - mse: 68255.1641 - val_loss: 49315.4141 - val_mse: 49315.3867\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68187.9297 - mse: 68187.8906 - val_loss: 49348.2852 - val_mse: 49348.2578\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68120.0859 - mse: 68120.0469 - val_loss: 49372.3086 - val_mse: 49372.2891\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68061.7734 - mse: 68061.7422 - val_loss: 49405.6406 - val_mse: 49405.6172\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 68009.1016 - mse: 68009.0625 - val_loss: 49435.7539 - val_mse: 49435.7344\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67958.3984 - mse: 67958.3594 - val_loss: 49474.0820 - val_mse: 49474.0469\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67913.9531 - mse: 67913.9219 - val_loss: 49506.3320 - val_mse: 49506.2969\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67873.2344 - mse: 67873.2031 - val_loss: 49535.2539 - val_mse: 49535.2266\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67840.4219 - mse: 67840.3906 - val_loss: 49573.2578 - val_mse: 49573.2305\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67801.7734 - mse: 67801.7500 - val_loss: 49600.8281 - val_mse: 49600.8125\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67773.2188 - mse: 67773.1953 - val_loss: 49640.1797 - val_mse: 49640.1484\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67744.6250 - mse: 67744.6016 - val_loss: 49671.6992 - val_mse: 49671.6719\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67718.0781 - mse: 67718.0469 - val_loss: 49710.7617 - val_mse: 49710.7383\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67693.0312 - mse: 67692.9922 - val_loss: 49740.0000 - val_mse: 49739.9805\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67669.8672 - mse: 67669.8281 - val_loss: 49781.8555 - val_mse: 49781.8125\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67648.6094 - mse: 67648.5781 - val_loss: 49812.8945 - val_mse: 49812.8711\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67632.1641 - mse: 67632.1250 - val_loss: 49837.7891 - val_mse: 49837.7578\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67616.2031 - mse: 67616.1719 - val_loss: 49876.7305 - val_mse: 49876.6953\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67600.2578 - mse: 67600.2266 - val_loss: 49908.7422 - val_mse: 49908.7109\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67589.0312 - mse: 67589.0000 - val_loss: 49943.4336 - val_mse: 49943.4062\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67578.4609 - mse: 67578.4219 - val_loss: 49963.1562 - val_mse: 49963.1250\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67566.3594 - mse: 67566.3359 - val_loss: 49993.5508 - val_mse: 49993.5273\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67555.9219 - mse: 67555.8984 - val_loss: 50024.2930 - val_mse: 50024.2578\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 67548.5078 - mse: 67548.4766 - val_loss: 50051.8281 - val_mse: 50051.8125\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67539.6875 - mse: 67539.6406 - val_loss: 50072.0859 - val_mse: 50072.0430\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 67532.4062 - mse: 67532.3984 - val_loss: 50103.7109 - val_mse: 50103.6797\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21871ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd48c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
