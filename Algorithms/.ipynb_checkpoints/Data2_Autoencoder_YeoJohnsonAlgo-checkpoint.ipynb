{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_25088\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d272ee",
   "metadata": {},
   "source": [
    "### Reading the YeoJohnson Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0  priceUSD\n",
       "0           0  0.0    0.0495\n",
       "1           1  0.0    0.0726\n",
       "2           2  0.0    0.0859\n",
       "3           3  0.0    0.0783\n",
       "4           4  0.0    0.0767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_YeoJohnson_data2.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>393.7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>386.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>0.0</td>\n",
       "      <td>379.4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0.0</td>\n",
       "      <td>384.7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>388.4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1556 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  priceUSD\n",
       "0     0.0    0.0495\n",
       "1     0.0    0.0726\n",
       "2     0.0    0.0859\n",
       "3     0.0    0.0783\n",
       "4     0.0    0.0767\n",
       "...   ...       ...\n",
       "1551  0.0  393.7880\n",
       "1552  0.0  386.2650\n",
       "1553  0.0  379.4510\n",
       "1554  0.0  384.7020\n",
       "1555  0.0  388.4040\n",
       "\n",
       "[1556 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00046406120622166647\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0011078604734071629"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014108671039734011"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.04, max_depth=6, n_estimators=500,\n",
      "                          subsample=0.1)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -0.0025416642631610475\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.04, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.014610337007986862\n",
      "Best Score: -0.009272866149396064\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 10}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: -0.018814442482030236\n",
      "Best Score: -0.00971206207456996\n",
      "Best params: {'bootstrap': True, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.013409279695212106\n",
      "Best Score: -0.008603701124022223\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: -0.016498587084919025\n",
      "Best Score: -0.010457525264619206\n",
      "Best params: {'bootstrap': True, 'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 10}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: -0.0124314295629675\n",
      "Best Score: -0.009843819071182125\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e4dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e8d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965ded25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 170.0520 - mean_absolute_error: 165.5802 - val_loss: 129.3831 - val_mean_absolute_error: 128.1022\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.9853 - mean_absolute_error: 165.5217 - val_loss: 128.1361 - val_mean_absolute_error: 128.0502\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.5143 - mean_absolute_error: 165.4694 - val_loss: 128.0307 - val_mean_absolute_error: 128.0002\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.4467 - mean_absolute_error: 165.4171 - val_loss: 127.9802 - val_mean_absolute_error: 127.9507\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3974 - mean_absolute_error: 165.3679 - val_loss: 127.9351 - val_mean_absolute_error: 127.9060\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3525 - mean_absolute_error: 165.3231 - val_loss: 127.8945 - val_mean_absolute_error: 127.8649\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3096 - mean_absolute_error: 165.2802 - val_loss: 127.8537 - val_mean_absolute_error: 127.8248\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.2672 - mean_absolute_error: 165.2378 - val_loss: 127.8132 - val_mean_absolute_error: 127.7836\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.2244 - mean_absolute_error: 165.1950 - val_loss: 127.7717 - val_mean_absolute_error: 127.7425\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1815 - mean_absolute_error: 165.1521 - val_loss: 127.7309 - val_mean_absolute_error: 127.7009\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.1382 - mean_absolute_error: 165.1088 - val_loss: 127.6885 - val_mean_absolute_error: 127.6592\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0945 - mean_absolute_error: 165.0652 - val_loss: 127.6469 - val_mean_absolute_error: 127.6176\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0508 - mean_absolute_error: 165.0214 - val_loss: 127.6050 - val_mean_absolute_error: 127.5759\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0079 - mean_absolute_error: 164.9786 - val_loss: 127.5650 - val_mean_absolute_error: 127.5355\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.9664 - mean_absolute_error: 164.9370 - val_loss: 127.5253 - val_mean_absolute_error: 127.4965\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.9262 - mean_absolute_error: 164.8968 - val_loss: 127.4889 - val_mean_absolute_error: 127.4593\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 164.8889 - mean_absolute_error: 164.8595 - val_loss: 127.4525 - val_mean_absolute_error: 127.4231\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.8524 - mean_absolute_error: 164.8231 - val_loss: 127.4183 - val_mean_absolute_error: 127.3883\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.8161 - mean_absolute_error: 164.7867 - val_loss: 127.3831 - val_mean_absolute_error: 127.3540\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7798 - mean_absolute_error: 164.7504 - val_loss: 127.3501 - val_mean_absolute_error: 127.3205\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7436 - mean_absolute_error: 164.7143 - val_loss: 127.3167 - val_mean_absolute_error: 127.2876\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7075 - mean_absolute_error: 164.6781 - val_loss: 127.2845 - val_mean_absolute_error: 127.2549\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.6711 - mean_absolute_error: 164.6417 - val_loss: 127.2511 - val_mean_absolute_error: 127.2219\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.6340 - mean_absolute_error: 164.6047 - val_loss: 127.2174 - val_mean_absolute_error: 127.1880\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5970 - mean_absolute_error: 164.5676 - val_loss: 127.1839 - val_mean_absolute_error: 127.1547\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5600 - mean_absolute_error: 164.5306 - val_loss: 127.1508 - val_mean_absolute_error: 127.1208\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5221 - mean_absolute_error: 164.4927 - val_loss: 127.1165 - val_mean_absolute_error: 127.0873\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4852 - mean_absolute_error: 164.4558 - val_loss: 127.0828 - val_mean_absolute_error: 127.0532\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4476 - mean_absolute_error: 164.4182 - val_loss: 127.0487 - val_mean_absolute_error: 127.0196\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4099 - mean_absolute_error: 164.3805 - val_loss: 127.0145 - val_mean_absolute_error: 126.9847\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.3723 - mean_absolute_error: 164.3430 - val_loss: 126.9799 - val_mean_absolute_error: 126.9510\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.3351 - mean_absolute_error: 164.3057 - val_loss: 126.9460 - val_mean_absolute_error: 126.9166\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2972 - mean_absolute_error: 164.2678 - val_loss: 126.9112 - val_mean_absolute_error: 126.8819\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2592 - mean_absolute_error: 164.2299 - val_loss: 126.8772 - val_mean_absolute_error: 126.8474\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2214 - mean_absolute_error: 164.1920 - val_loss: 126.8415 - val_mean_absolute_error: 126.8124\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1834 - mean_absolute_error: 164.1540 - val_loss: 126.8070 - val_mean_absolute_error: 126.7773\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1458 - mean_absolute_error: 164.1164 - val_loss: 126.7720 - val_mean_absolute_error: 126.7428\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1083 - mean_absolute_error: 164.0790 - val_loss: 126.7376 - val_mean_absolute_error: 126.7078\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.0708 - mean_absolute_error: 164.0414 - val_loss: 126.7025 - val_mean_absolute_error: 126.6736\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.0330 - mean_absolute_error: 164.0036 - val_loss: 126.6680 - val_mean_absolute_error: 126.6385\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9956 - mean_absolute_error: 163.9662 - val_loss: 126.6334 - val_mean_absolute_error: 126.6043\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9588 - mean_absolute_error: 163.9294 - val_loss: 126.5994 - val_mean_absolute_error: 126.5698\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9217 - mean_absolute_error: 163.8923 - val_loss: 126.5642 - val_mean_absolute_error: 126.5349\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8846 - mean_absolute_error: 163.8553 - val_loss: 126.5304 - val_mean_absolute_error: 126.5008\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8490 - mean_absolute_error: 163.8196 - val_loss: 126.4973 - val_mean_absolute_error: 126.4681\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8129 - mean_absolute_error: 163.7836 - val_loss: 126.4640 - val_mean_absolute_error: 126.4342\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7769 - mean_absolute_error: 163.7475 - val_loss: 126.4294 - val_mean_absolute_error: 126.4005\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7413 - mean_absolute_error: 163.7120 - val_loss: 126.3970 - val_mean_absolute_error: 126.3675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7056 - mean_absolute_error: 163.6762 - val_loss: 126.3632 - val_mean_absolute_error: 126.3340\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.6706 - mean_absolute_error: 163.6412 - val_loss: 126.3318 - val_mean_absolute_error: 126.3019\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.6353 - mean_absolute_error: 163.6060 - val_loss: 126.2973 - val_mean_absolute_error: 126.2681\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.6001 - mean_absolute_error: 163.5707 - val_loss: 126.2639 - val_mean_absolute_error: 126.2344\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.5652 - mean_absolute_error: 163.5358 - val_loss: 126.2315 - val_mean_absolute_error: 126.2022\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.5320 - mean_absolute_error: 163.5026 - val_loss: 126.1993 - val_mean_absolute_error: 126.1696\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4988 - mean_absolute_error: 163.4694 - val_loss: 126.1673 - val_mean_absolute_error: 126.1383\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4664 - mean_absolute_error: 163.4371 - val_loss: 126.1360 - val_mean_absolute_error: 126.1064\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4353 - mean_absolute_error: 163.4059 - val_loss: 126.1049 - val_mean_absolute_error: 126.0757\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4050 - mean_absolute_error: 163.3756 - val_loss: 126.0757 - val_mean_absolute_error: 126.0457\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3755 - mean_absolute_error: 163.3461 - val_loss: 126.0448 - val_mean_absolute_error: 126.0156\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3457 - mean_absolute_error: 163.3163 - val_loss: 126.0155 - val_mean_absolute_error: 125.9859\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3162 - mean_absolute_error: 163.2868 - val_loss: 125.9856 - val_mean_absolute_error: 125.9565\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2865 - mean_absolute_error: 163.2571 - val_loss: 125.9575 - val_mean_absolute_error: 125.9279\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2566 - mean_absolute_error: 163.2272 - val_loss: 125.9269 - val_mean_absolute_error: 125.8980\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2268 - mean_absolute_error: 163.1974 - val_loss: 125.8985 - val_mean_absolute_error: 125.8690\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1967 - mean_absolute_error: 163.1674 - val_loss: 125.8683 - val_mean_absolute_error: 125.8391\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1670 - mean_absolute_error: 163.1376 - val_loss: 125.8393 - val_mean_absolute_error: 125.8095\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1376 - mean_absolute_error: 163.1083 - val_loss: 125.8102 - val_mean_absolute_error: 125.7809\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1080 - mean_absolute_error: 163.0786 - val_loss: 125.7809 - val_mean_absolute_error: 125.7513\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.0785 - mean_absolute_error: 163.0491 - val_loss: 125.7509 - val_mean_absolute_error: 125.7218\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.0493 - mean_absolute_error: 163.0199 - val_loss: 125.7232 - val_mean_absolute_error: 125.6934\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.0200 - mean_absolute_error: 162.9906 - val_loss: 125.6934 - val_mean_absolute_error: 125.6644\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9910 - mean_absolute_error: 162.9616 - val_loss: 125.6659 - val_mean_absolute_error: 125.6366\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9627 - mean_absolute_error: 162.9333 - val_loss: 125.6371 - val_mean_absolute_error: 125.6078\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9350 - mean_absolute_error: 162.9057 - val_loss: 125.6105 - val_mean_absolute_error: 125.5806\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9070 - mean_absolute_error: 162.8776 - val_loss: 125.5822 - val_mean_absolute_error: 125.5530\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8793 - mean_absolute_error: 162.8500 - val_loss: 125.5553 - val_mean_absolute_error: 125.5255\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8512 - mean_absolute_error: 162.8218 - val_loss: 125.5271 - val_mean_absolute_error: 125.4978\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8232 - mean_absolute_error: 162.7938 - val_loss: 125.4998 - val_mean_absolute_error: 125.4701\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7958 - mean_absolute_error: 162.7664 - val_loss: 125.4722 - val_mean_absolute_error: 125.4432\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7682 - mean_absolute_error: 162.7388 - val_loss: 125.4447 - val_mean_absolute_error: 125.4153\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7408 - mean_absolute_error: 162.7114 - val_loss: 125.4176 - val_mean_absolute_error: 125.3884\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7134 - mean_absolute_error: 162.6841 - val_loss: 125.3899 - val_mean_absolute_error: 125.3602\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6860 - mean_absolute_error: 162.6566 - val_loss: 125.3617 - val_mean_absolute_error: 125.3325\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6592 - mean_absolute_error: 162.6297 - val_loss: 125.3344 - val_mean_absolute_error: 125.3050\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6325 - mean_absolute_error: 162.6031 - val_loss: 125.3073 - val_mean_absolute_error: 125.2782\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6066 - mean_absolute_error: 162.5772 - val_loss: 125.2814 - val_mean_absolute_error: 125.2516\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5810 - mean_absolute_error: 162.5517 - val_loss: 125.2540 - val_mean_absolute_error: 125.2251\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5569 - mean_absolute_error: 162.5276 - val_loss: 125.2307 - val_mean_absolute_error: 125.2010\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5350 - mean_absolute_error: 162.5055 - val_loss: 125.2078 - val_mean_absolute_error: 125.1787\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5149 - mean_absolute_error: 162.4855 - val_loss: 125.1889 - val_mean_absolute_error: 125.1590\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4959 - mean_absolute_error: 162.4665 - val_loss: 125.1692 - val_mean_absolute_error: 125.1400\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4777 - mean_absolute_error: 162.4483 - val_loss: 125.1516 - val_mean_absolute_error: 125.1222\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4608 - mean_absolute_error: 162.4314 - val_loss: 125.1347 - val_mean_absolute_error: 125.1055\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4451 - mean_absolute_error: 162.4156 - val_loss: 125.1194 - val_mean_absolute_error: 125.0898\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4304 - mean_absolute_error: 162.4010 - val_loss: 125.1030 - val_mean_absolute_error: 125.0741\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4155 - mean_absolute_error: 162.3862 - val_loss: 125.0886 - val_mean_absolute_error: 125.0590\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4003 - mean_absolute_error: 162.3710 - val_loss: 125.0733 - val_mean_absolute_error: 125.0441\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3854 - mean_absolute_error: 162.3560 - val_loss: 125.0584 - val_mean_absolute_error: 125.0285\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3712 - mean_absolute_error: 162.3418 - val_loss: 125.0437 - val_mean_absolute_error: 125.0145\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3569 - mean_absolute_error: 162.3276 - val_loss: 125.0295 - val_mean_absolute_error: 124.9999\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e6b48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b987d",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672947d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "861eae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11b06de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 170.0908 - mean_absolute_error: 165.5802 - val_loss: 129.3906 - val_mean_absolute_error: 128.1022\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.9950 - mean_absolute_error: 165.5217 - val_loss: 128.1375 - val_mean_absolute_error: 128.0501\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.5142 - mean_absolute_error: 165.4698 - val_loss: 128.0309 - val_mean_absolute_error: 128.0006\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.4474 - mean_absolute_error: 165.4175 - val_loss: 127.9808 - val_mean_absolute_error: 127.9509\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3978 - mean_absolute_error: 165.3680 - val_loss: 127.9353 - val_mean_absolute_error: 127.9058\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3526 - mean_absolute_error: 165.3229 - val_loss: 127.8950 - val_mean_absolute_error: 127.8649\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.3093 - mean_absolute_error: 165.2796 - val_loss: 127.8529 - val_mean_absolute_error: 127.8234\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.2662 - mean_absolute_error: 165.2364 - val_loss: 127.8124 - val_mean_absolute_error: 127.7823\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.2234 - mean_absolute_error: 165.1937 - val_loss: 127.7708 - val_mean_absolute_error: 127.7412\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 165.1805 - mean_absolute_error: 165.1508 - val_loss: 127.7296 - val_mean_absolute_error: 127.6994\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.1372 - mean_absolute_error: 165.1075 - val_loss: 127.6873 - val_mean_absolute_error: 127.6577\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0939 - mean_absolute_error: 165.0642 - val_loss: 127.6466 - val_mean_absolute_error: 127.6164\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0502 - mean_absolute_error: 165.0204 - val_loss: 127.6045 - val_mean_absolute_error: 127.5750\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 165.0078 - mean_absolute_error: 164.9780 - val_loss: 127.5650 - val_mean_absolute_error: 127.5351\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.9668 - mean_absolute_error: 164.9371 - val_loss: 127.5252 - val_mean_absolute_error: 127.4959\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.9269 - mean_absolute_error: 164.8972 - val_loss: 127.4894 - val_mean_absolute_error: 127.4594\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.8897 - mean_absolute_error: 164.8599 - val_loss: 127.4533 - val_mean_absolute_error: 127.4236\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.8533 - mean_absolute_error: 164.8235 - val_loss: 127.4192 - val_mean_absolute_error: 127.3889\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.8168 - mean_absolute_error: 164.7869 - val_loss: 127.3839 - val_mean_absolute_error: 127.3544\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7804 - mean_absolute_error: 164.7506 - val_loss: 127.3505 - val_mean_absolute_error: 127.3203\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7441 - mean_absolute_error: 164.7143 - val_loss: 127.3171 - val_mean_absolute_error: 127.2875\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.7073 - mean_absolute_error: 164.6776 - val_loss: 127.2846 - val_mean_absolute_error: 127.2545\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.6704 - mean_absolute_error: 164.6406 - val_loss: 127.2505 - val_mean_absolute_error: 127.2209\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.6336 - mean_absolute_error: 164.6039 - val_loss: 127.2175 - val_mean_absolute_error: 127.1874\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5962 - mean_absolute_error: 164.5664 - val_loss: 127.1832 - val_mean_absolute_error: 127.1536\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5586 - mean_absolute_error: 164.5288 - val_loss: 127.1496 - val_mean_absolute_error: 127.1194\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.5208 - mean_absolute_error: 164.4909 - val_loss: 127.1147 - val_mean_absolute_error: 127.0851\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4827 - mean_absolute_error: 164.4530 - val_loss: 127.0810 - val_mean_absolute_error: 127.0509\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4449 - mean_absolute_error: 164.4152 - val_loss: 127.0460 - val_mean_absolute_error: 127.0165\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.4070 - mean_absolute_error: 164.3772 - val_loss: 127.0127 - val_mean_absolute_error: 126.9823\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.3693 - mean_absolute_error: 164.3396 - val_loss: 126.9772 - val_mean_absolute_error: 126.9477\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.3316 - mean_absolute_error: 164.3018 - val_loss: 126.9433 - val_mean_absolute_error: 126.9133\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2939 - mean_absolute_error: 164.2641 - val_loss: 126.9081 - val_mean_absolute_error: 126.8785\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2561 - mean_absolute_error: 164.2263 - val_loss: 126.8741 - val_mean_absolute_error: 126.8442\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.2189 - mean_absolute_error: 164.1892 - val_loss: 126.8387 - val_mean_absolute_error: 126.8092\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1809 - mean_absolute_error: 164.1511 - val_loss: 126.8050 - val_mean_absolute_error: 126.7749\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1431 - mean_absolute_error: 164.1134 - val_loss: 126.7697 - val_mean_absolute_error: 126.7401\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.1054 - mean_absolute_error: 164.0756 - val_loss: 126.7353 - val_mean_absolute_error: 126.7051\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.0676 - mean_absolute_error: 164.0378 - val_loss: 126.6998 - val_mean_absolute_error: 126.6703\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 164.0297 - mean_absolute_error: 164.0000 - val_loss: 126.6658 - val_mean_absolute_error: 126.6357\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9927 - mean_absolute_error: 163.9629 - val_loss: 126.6308 - val_mean_absolute_error: 126.6011\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9559 - mean_absolute_error: 163.9261 - val_loss: 126.5974 - val_mean_absolute_error: 126.5671\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.9188 - mean_absolute_error: 163.8891 - val_loss: 126.5625 - val_mean_absolute_error: 126.5328\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8825 - mean_absolute_error: 163.8528 - val_loss: 126.5292 - val_mean_absolute_error: 126.4990\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8465 - mean_absolute_error: 163.8167 - val_loss: 126.4945 - val_mean_absolute_error: 126.4648\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.8101 - mean_absolute_error: 163.7803 - val_loss: 126.4615 - val_mean_absolute_error: 126.4313\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7753 - mean_absolute_error: 163.7455 - val_loss: 126.4288 - val_mean_absolute_error: 126.3993\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7397 - mean_absolute_error: 163.7099 - val_loss: 126.3961 - val_mean_absolute_error: 126.3662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.7044 - mean_absolute_error: 163.6746 - val_loss: 126.3620 - val_mean_absolute_error: 126.3326\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.6686 - mean_absolute_error: 163.6388 - val_loss: 126.3295 - val_mean_absolute_error: 126.2992\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.6336 - mean_absolute_error: 163.6039 - val_loss: 126.2961 - val_mean_absolute_error: 126.2664\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.5986 - mean_absolute_error: 163.5688 - val_loss: 126.2626 - val_mean_absolute_error: 126.2324\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.5638 - mean_absolute_error: 163.5341 - val_loss: 126.2307 - val_mean_absolute_error: 126.2011\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.5308 - mean_absolute_error: 163.5010 - val_loss: 126.1979 - val_mean_absolute_error: 126.1678\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4980 - mean_absolute_error: 163.4682 - val_loss: 126.1660 - val_mean_absolute_error: 126.1367\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4660 - mean_absolute_error: 163.4362 - val_loss: 126.1351 - val_mean_absolute_error: 126.1052\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4344 - mean_absolute_error: 163.4045 - val_loss: 126.1040 - val_mean_absolute_error: 126.0744\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.4051 - mean_absolute_error: 163.3754 - val_loss: 126.0757 - val_mean_absolute_error: 126.0454\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3753 - mean_absolute_error: 163.3455 - val_loss: 126.0445 - val_mean_absolute_error: 126.0150\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3454 - mean_absolute_error: 163.3156 - val_loss: 126.0158 - val_mean_absolute_error: 125.9857\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.3159 - mean_absolute_error: 163.2862 - val_loss: 125.9855 - val_mean_absolute_error: 125.9559\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2863 - mean_absolute_error: 163.2566 - val_loss: 125.9570 - val_mean_absolute_error: 125.9267\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2566 - mean_absolute_error: 163.2269 - val_loss: 125.9269 - val_mean_absolute_error: 125.8974\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.2268 - mean_absolute_error: 163.1971 - val_loss: 125.8987 - val_mean_absolute_error: 125.8686\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1971 - mean_absolute_error: 163.1673 - val_loss: 125.8691 - val_mean_absolute_error: 125.8393\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1669 - mean_absolute_error: 163.1371 - val_loss: 125.8390 - val_mean_absolute_error: 125.8089\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1370 - mean_absolute_error: 163.1072 - val_loss: 125.8090 - val_mean_absolute_error: 125.7794\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.1073 - mean_absolute_error: 163.0776 - val_loss: 125.7806 - val_mean_absolute_error: 125.7505\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.0778 - mean_absolute_error: 163.0480 - val_loss: 125.7505 - val_mean_absolute_error: 125.7211\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 163.0482 - mean_absolute_error: 163.0184 - val_loss: 125.7217 - val_mean_absolute_error: 125.6916\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 163.0188 - mean_absolute_error: 162.9891 - val_loss: 125.6930 - val_mean_absolute_error: 125.6635\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9896 - mean_absolute_error: 162.9599 - val_loss: 125.6642 - val_mean_absolute_error: 125.6341\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9609 - mean_absolute_error: 162.9311 - val_loss: 125.6356 - val_mean_absolute_error: 125.6060\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9329 - mean_absolute_error: 162.9031 - val_loss: 125.6084 - val_mean_absolute_error: 125.5783\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.9047 - mean_absolute_error: 162.8750 - val_loss: 125.5793 - val_mean_absolute_error: 125.5498\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8766 - mean_absolute_error: 162.8469 - val_loss: 125.5530 - val_mean_absolute_error: 125.5229\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8488 - mean_absolute_error: 162.8191 - val_loss: 125.5247 - val_mean_absolute_error: 125.4951\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.8211 - mean_absolute_error: 162.7913 - val_loss: 125.4976 - val_mean_absolute_error: 125.4674\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7938 - mean_absolute_error: 162.7641 - val_loss: 125.4699 - val_mean_absolute_error: 125.4406\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7668 - mean_absolute_error: 162.7370 - val_loss: 125.4434 - val_mean_absolute_error: 125.4134\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 162.7393 - mean_absolute_error: 162.7095 - val_loss: 125.4160 - val_mean_absolute_error: 125.3863\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.7116 - mean_absolute_error: 162.6819 - val_loss: 125.3885 - val_mean_absolute_error: 125.3582\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6844 - mean_absolute_error: 162.6546 - val_loss: 125.3598 - val_mean_absolute_error: 125.3301\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6568 - mean_absolute_error: 162.6270 - val_loss: 125.3324 - val_mean_absolute_error: 125.3023\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6303 - mean_absolute_error: 162.6006 - val_loss: 125.3046 - val_mean_absolute_error: 125.2749\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.6041 - mean_absolute_error: 162.5743 - val_loss: 125.2787 - val_mean_absolute_error: 125.2486\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5787 - mean_absolute_error: 162.5489 - val_loss: 125.2514 - val_mean_absolute_error: 125.2220\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5547 - mean_absolute_error: 162.5250 - val_loss: 125.2276 - val_mean_absolute_error: 125.1975\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5330 - mean_absolute_error: 162.5033 - val_loss: 125.2059 - val_mean_absolute_error: 125.1763\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.5132 - mean_absolute_error: 162.4834 - val_loss: 125.1869 - val_mean_absolute_error: 125.1566\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4939 - mean_absolute_error: 162.4641 - val_loss: 125.1674 - val_mean_absolute_error: 125.1376\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4760 - mean_absolute_error: 162.4463 - val_loss: 125.1499 - val_mean_absolute_error: 125.1197\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4592 - mean_absolute_error: 162.4294 - val_loss: 125.1327 - val_mean_absolute_error: 125.1033\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4433 - mean_absolute_error: 162.4136 - val_loss: 125.1171 - val_mean_absolute_error: 125.0872\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4279 - mean_absolute_error: 162.3982 - val_loss: 125.1005 - val_mean_absolute_error: 125.0712\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 162.4128 - mean_absolute_error: 162.3831 - val_loss: 125.0860 - val_mean_absolute_error: 125.0560\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3981 - mean_absolute_error: 162.3684 - val_loss: 125.0705 - val_mean_absolute_error: 125.0408\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3835 - mean_absolute_error: 162.3537 - val_loss: 125.0569 - val_mean_absolute_error: 125.0265\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3690 - mean_absolute_error: 162.3392 - val_loss: 125.0413 - val_mean_absolute_error: 125.0117\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 162.3546 - mean_absolute_error: 162.3248 - val_loss: 125.0276 - val_mean_absolute_error: 124.9975\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "874823e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce16b1",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f467a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "717017e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d185672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 19.7963 - mse: 94895.1953 - val_loss: 14.6990 - val_mse: 65642.4688\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.7598 - mse: 94895.2109 - val_loss: 13.5157 - val_mse: 65642.4688\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3509 - mse: 94895.2031 - val_loss: 13.4636 - val_mse: 65642.4688\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3372 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1797 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4634 - val_mse: 65642.4688\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4628 - val_mse: 65642.4688\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1719 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4629 - val_mse: 65642.4688\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4631 - val_mse: 65642.4688\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4624 - val_mse: 65642.4688\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4627 - val_mse: 65642.4688\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1875 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2266 - val_loss: 13.4625 - val_mse: 65642.4688\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2344 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2031 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4630 - val_mse: 65642.4688\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2188 - val_loss: 13.4623 - val_mse: 65642.4688\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4633 - val_mse: 65642.4688\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.2109 - val_loss: 13.4626 - val_mse: 65642.4688\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 15.3370 - mse: 94895.1953 - val_loss: 13.4632 - val_mse: 65642.4688\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e117565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9859768",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5029507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17dc3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad645b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 3ms/step - loss: 94884.3047 - mse: 94881.2031 - val_loss: 65620.2891 - val_mse: 65620.0312\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94852.5156 - mse: 94852.4375 - val_loss: 65597.9844 - val_mse: 65597.9609\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94823.3047 - mse: 94823.2891 - val_loss: 65575.0547 - val_mse: 65575.0312\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94794.0156 - mse: 94793.9844 - val_loss: 65552.3281 - val_mse: 65552.2812\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94764.5938 - mse: 94764.5781 - val_loss: 65529.7656 - val_mse: 65529.7305\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94734.9453 - mse: 94734.9141 - val_loss: 65506.7031 - val_mse: 65506.6758\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94705.2891 - mse: 94705.2656 - val_loss: 65483.6133 - val_mse: 65483.5781\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94675.6328 - mse: 94675.5938 - val_loss: 65460.9102 - val_mse: 65460.8789\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94646.1719 - mse: 94646.1328 - val_loss: 65438.1562 - val_mse: 65438.1250\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94616.6797 - mse: 94616.6484 - val_loss: 65415.3672 - val_mse: 65415.3477\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94587.3672 - mse: 94587.3594 - val_loss: 65392.7891 - val_mse: 65392.7344\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94557.8750 - mse: 94557.8594 - val_loss: 65370.2031 - val_mse: 65370.1680\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94528.5859 - mse: 94528.5469 - val_loss: 65347.0664 - val_mse: 65347.0547\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94499.1016 - mse: 94499.0625 - val_loss: 65324.9453 - val_mse: 65324.8945\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94469.8906 - mse: 94469.8594 - val_loss: 65302.0977 - val_mse: 65302.0586\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94440.5938 - mse: 94440.5469 - val_loss: 65279.2930 - val_mse: 65279.2578\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94411.3984 - mse: 94411.3828 - val_loss: 65257.0586 - val_mse: 65257.0469\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94382.0391 - mse: 94381.9922 - val_loss: 65234.8750 - val_mse: 65234.8594\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94352.7109 - mse: 94352.6797 - val_loss: 65211.8203 - val_mse: 65211.7734\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94323.4688 - mse: 94323.4375 - val_loss: 65188.9648 - val_mse: 65188.9336\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94294.1562 - mse: 94294.1328 - val_loss: 65166.6602 - val_mse: 65166.6367\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94265.0078 - mse: 94264.9766 - val_loss: 65144.1172 - val_mse: 65144.0781\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94235.6562 - mse: 94235.6406 - val_loss: 65121.6602 - val_mse: 65121.6211\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94206.6641 - mse: 94206.6328 - val_loss: 65098.8398 - val_mse: 65098.8086\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94177.5625 - mse: 94177.5078 - val_loss: 65076.9258 - val_mse: 65076.9023\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94148.4453 - mse: 94148.4219 - val_loss: 65054.2461 - val_mse: 65054.2109\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94119.1953 - mse: 94119.1719 - val_loss: 65031.7812 - val_mse: 65031.7500\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94090.1797 - mse: 94090.1328 - val_loss: 65009.3164 - val_mse: 65009.2773\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94061.2266 - mse: 94061.1953 - val_loss: 64986.9336 - val_mse: 64986.8867\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94032.2578 - mse: 94032.2344 - val_loss: 64964.9648 - val_mse: 64964.9258\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94003.4688 - mse: 94003.4297 - val_loss: 64942.8281 - val_mse: 64942.7930\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93974.5312 - mse: 93974.5078 - val_loss: 64920.2461 - val_mse: 64920.2109\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93945.5547 - mse: 93945.5000 - val_loss: 64898.1680 - val_mse: 64898.1484\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93916.6875 - mse: 93916.6719 - val_loss: 64876.0312 - val_mse: 64876.0078\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93887.7734 - mse: 93887.7422 - val_loss: 64853.3398 - val_mse: 64853.3086\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93858.7734 - mse: 93858.7422 - val_loss: 64831.6523 - val_mse: 64831.6250\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93829.9062 - mse: 93829.8828 - val_loss: 64809.2383 - val_mse: 64809.2031\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93800.9609 - mse: 93800.9453 - val_loss: 64787.0273 - val_mse: 64786.9961\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93771.8828 - mse: 93771.8359 - val_loss: 64764.5273 - val_mse: 64764.4805\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93743.1250 - mse: 93743.0625 - val_loss: 64742.4180 - val_mse: 64742.4023\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93714.3516 - mse: 93714.3125 - val_loss: 64720.3945 - val_mse: 64720.3633\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93685.4844 - mse: 93685.4688 - val_loss: 64697.9375 - val_mse: 64697.9023\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93656.8359 - mse: 93656.7969 - val_loss: 64676.2383 - val_mse: 64676.2070\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93628.2109 - mse: 93628.1953 - val_loss: 64653.8789 - val_mse: 64653.8516\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93599.3281 - mse: 93599.2891 - val_loss: 64632.2031 - val_mse: 64632.1562\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93570.5859 - mse: 93570.5703 - val_loss: 64609.6992 - val_mse: 64609.6523\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93541.6875 - mse: 93541.6484 - val_loss: 64587.7266 - val_mse: 64587.6953\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93512.9844 - mse: 93512.9453 - val_loss: 64565.3359 - val_mse: 64565.3086\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93484.3125 - mse: 93484.2500 - val_loss: 64543.8789 - val_mse: 64543.8438\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93455.6719 - mse: 93455.6641 - val_loss: 64521.3906 - val_mse: 64521.3594\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93426.9688 - mse: 93426.9531 - val_loss: 64499.7539 - val_mse: 64499.7266\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93398.3672 - mse: 93398.3516 - val_loss: 64478.0391 - val_mse: 64478.0078\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93369.7422 - mse: 93369.7109 - val_loss: 64455.8984 - val_mse: 64455.8672\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93341.2422 - mse: 93341.1875 - val_loss: 64433.9570 - val_mse: 64433.9258\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93312.4453 - mse: 93312.4062 - val_loss: 64411.7578 - val_mse: 64411.7227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93283.7969 - mse: 93283.7578 - val_loss: 64389.8164 - val_mse: 64389.7812\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93255.2734 - mse: 93255.2578 - val_loss: 64368.1055 - val_mse: 64368.0781\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93226.9062 - mse: 93226.8750 - val_loss: 64346.2852 - val_mse: 64346.2578\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93198.3984 - mse: 93198.3516 - val_loss: 64324.5156 - val_mse: 64324.4883\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93170.0078 - mse: 93169.9844 - val_loss: 64302.7578 - val_mse: 64302.7227\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93141.5000 - mse: 93141.4609 - val_loss: 64280.7930 - val_mse: 64280.7617\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93113.1484 - mse: 93113.1094 - val_loss: 64258.8555 - val_mse: 64258.8281\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 93084.7734 - mse: 93084.7500 - val_loss: 64237.5117 - val_mse: 64237.4844\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93056.2656 - mse: 93056.2344 - val_loss: 64215.6562 - val_mse: 64215.6250\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 93027.8125 - mse: 93027.7969 - val_loss: 64193.7539 - val_mse: 64193.7266\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92999.5625 - mse: 92999.5078 - val_loss: 64172.1914 - val_mse: 64172.1602\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92971.2812 - mse: 92971.2266 - val_loss: 64150.2344 - val_mse: 64150.2109\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92942.8203 - mse: 92942.8047 - val_loss: 64128.4453 - val_mse: 64128.3984\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92914.5000 - mse: 92914.4609 - val_loss: 64107.2383 - val_mse: 64107.2070\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92886.1250 - mse: 92886.0625 - val_loss: 64085.5938 - val_mse: 64085.5703\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92857.8516 - mse: 92857.8281 - val_loss: 64063.6328 - val_mse: 64063.6055\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92829.5859 - mse: 92829.5625 - val_loss: 64042.0859 - val_mse: 64042.0547\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92801.5000 - mse: 92801.4531 - val_loss: 64020.6836 - val_mse: 64020.6562\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92773.1641 - mse: 92773.1328 - val_loss: 63999.0195 - val_mse: 63998.9844\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92745.0312 - mse: 92745.0000 - val_loss: 63977.7031 - val_mse: 63977.6797\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92717.1406 - mse: 92717.1172 - val_loss: 63956.4141 - val_mse: 63956.3750\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92689.0547 - mse: 92689.0234 - val_loss: 63934.9414 - val_mse: 63934.9219\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92660.9141 - mse: 92660.8906 - val_loss: 63913.4062 - val_mse: 63913.3711\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92633.1719 - mse: 92633.1484 - val_loss: 63891.9258 - val_mse: 63891.8906\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92605.4609 - mse: 92605.4219 - val_loss: 63870.8008 - val_mse: 63870.7695\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92577.6406 - mse: 92577.6250 - val_loss: 63849.8750 - val_mse: 63849.8477\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92549.8594 - mse: 92549.8203 - val_loss: 63828.5078 - val_mse: 63828.4883\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92522.0234 - mse: 92521.9922 - val_loss: 63806.9336 - val_mse: 63806.8906\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92494.2109 - mse: 92494.1641 - val_loss: 63785.8555 - val_mse: 63785.8398\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92466.3750 - mse: 92466.3672 - val_loss: 63764.6836 - val_mse: 63764.6484\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92438.6172 - mse: 92438.6094 - val_loss: 63743.1133 - val_mse: 63743.0820\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92410.9062 - mse: 92410.8594 - val_loss: 63722.1758 - val_mse: 63722.1445\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92382.9453 - mse: 92382.9219 - val_loss: 63701.1172 - val_mse: 63701.0820\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92355.1016 - mse: 92355.0781 - val_loss: 63679.8203 - val_mse: 63679.7930\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92327.2031 - mse: 92327.1562 - val_loss: 63658.9727 - val_mse: 63658.9336\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92299.5391 - mse: 92299.5156 - val_loss: 63637.0156 - val_mse: 63636.9883\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92271.7031 - mse: 92271.6719 - val_loss: 63616.4609 - val_mse: 63616.4375\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92243.9688 - mse: 92243.9453 - val_loss: 63595.2422 - val_mse: 63595.1992\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92216.1562 - mse: 92216.1016 - val_loss: 63574.0391 - val_mse: 63573.9961\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92188.3516 - mse: 92188.3125 - val_loss: 63553.2422 - val_mse: 63553.2031\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92160.7656 - mse: 92160.7422 - val_loss: 63531.6758 - val_mse: 63531.6484\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92133.0312 - mse: 92133.0078 - val_loss: 63510.2539 - val_mse: 63510.2305\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92105.2031 - mse: 92105.1719 - val_loss: 63489.3594 - val_mse: 63489.3281\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92077.6094 - mse: 92077.5625 - val_loss: 63468.3672 - val_mse: 63468.3203\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92049.6797 - mse: 92049.6562 - val_loss: 63447.5586 - val_mse: 63447.5312\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37b03d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55095481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
