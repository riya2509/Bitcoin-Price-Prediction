{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_14792\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23463a8e",
   "metadata": {},
   "source": [
    "### Reading the YeoJohnson PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0         1          2          3         4          5  \\\n",
       "0           0  32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1           1  32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2           2  33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3           3  32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4           4  32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "\n",
       "           6         7         8  ...        89        90        91        92  \\\n",
       "0  16.524812  0.166351 -8.700498  ...  1.923946  3.832444 -2.257067  2.835188   \n",
       "1  17.966608 -0.569542 -9.306701  ...  1.593726  0.604879  0.335266  1.183815   \n",
       "2  16.543319  0.781871 -8.695417  ...  0.497217 -0.891250  2.450366  2.249480   \n",
       "3  17.856147  1.884261 -6.869309  ... -0.687552 -0.829605 -5.461876  0.345240   \n",
       "4  16.420547  3.158366 -8.634797  ... -0.422376  1.025973  1.077336  0.491024   \n",
       "\n",
       "         93        94        95        96        97  priceUSD  \n",
       "0 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201    0.0495  \n",
       "1 -0.294895 -1.473127 -0.657472  0.007406 -2.294048    0.0726  \n",
       "2 -1.947763 -2.079104  1.532892  1.893578 -0.800749    0.0859  \n",
       "3 -0.446096 -0.270433  6.035264  4.706512 -1.654442    0.0783  \n",
       "4  0.339590 -0.503155  3.711262  1.314670 -0.031391    0.0767  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_YeoJohnson_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>10.438027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>9.018383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>8.221800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>6.376521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>5.447760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>-19.315494</td>\n",
       "      <td>0.236167</td>\n",
       "      <td>-2.750750</td>\n",
       "      <td>-5.370912</td>\n",
       "      <td>-0.186745</td>\n",
       "      <td>4.678685</td>\n",
       "      <td>1.096600</td>\n",
       "      <td>3.019217</td>\n",
       "      <td>2.146403</td>\n",
       "      <td>3.662000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429743</td>\n",
       "      <td>1.624900</td>\n",
       "      <td>1.085748</td>\n",
       "      <td>-0.379536</td>\n",
       "      <td>-0.537552</td>\n",
       "      <td>-0.248166</td>\n",
       "      <td>-0.836404</td>\n",
       "      <td>1.001076</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-19.318940</td>\n",
       "      <td>0.733044</td>\n",
       "      <td>-0.889637</td>\n",
       "      <td>-5.979197</td>\n",
       "      <td>-1.170327</td>\n",
       "      <td>4.752099</td>\n",
       "      <td>-1.059497</td>\n",
       "      <td>4.918116</td>\n",
       "      <td>1.074642</td>\n",
       "      <td>2.816077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>-0.073998</td>\n",
       "      <td>-0.315707</td>\n",
       "      <td>1.726772</td>\n",
       "      <td>0.086268</td>\n",
       "      <td>-0.590934</td>\n",
       "      <td>-1.087419</td>\n",
       "      <td>0.384172</td>\n",
       "      <td>0.323270</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-19.018647</td>\n",
       "      <td>0.730092</td>\n",
       "      <td>-4.161934</td>\n",
       "      <td>-3.696162</td>\n",
       "      <td>2.779836</td>\n",
       "      <td>1.157445</td>\n",
       "      <td>-1.148338</td>\n",
       "      <td>4.904417</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>3.601954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613840</td>\n",
       "      <td>-0.938060</td>\n",
       "      <td>0.686956</td>\n",
       "      <td>2.921627</td>\n",
       "      <td>1.419180</td>\n",
       "      <td>-0.648111</td>\n",
       "      <td>-1.180782</td>\n",
       "      <td>-0.634334</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-19.091961</td>\n",
       "      <td>-1.767811</td>\n",
       "      <td>0.812909</td>\n",
       "      <td>-4.477929</td>\n",
       "      <td>-1.827579</td>\n",
       "      <td>-0.380548</td>\n",
       "      <td>-2.042414</td>\n",
       "      <td>3.578432</td>\n",
       "      <td>-0.707056</td>\n",
       "      <td>4.743335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276470</td>\n",
       "      <td>-0.493735</td>\n",
       "      <td>0.480427</td>\n",
       "      <td>1.565258</td>\n",
       "      <td>-0.317555</td>\n",
       "      <td>-1.248186</td>\n",
       "      <td>-0.791837</td>\n",
       "      <td>-0.580324</td>\n",
       "      <td>0.377241</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>-18.978473</td>\n",
       "      <td>-4.552622</td>\n",
       "      <td>1.547258</td>\n",
       "      <td>-2.263347</td>\n",
       "      <td>-0.054753</td>\n",
       "      <td>-3.135464</td>\n",
       "      <td>-2.699181</td>\n",
       "      <td>3.506751</td>\n",
       "      <td>-0.261364</td>\n",
       "      <td>5.744565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037892</td>\n",
       "      <td>-0.282042</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>1.032256</td>\n",
       "      <td>-0.721593</td>\n",
       "      <td>-2.401458</td>\n",
       "      <td>-0.049565</td>\n",
       "      <td>-0.425631</td>\n",
       "      <td>1.137282</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2          3         4          5  \\\n",
       "0     32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1     32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2     33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3     32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4     32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "3483 -19.315494  0.236167  -2.750750  -5.370912 -0.186745   4.678685   \n",
       "3484 -19.318940  0.733044  -0.889637  -5.979197 -1.170327   4.752099   \n",
       "3485 -19.018647  0.730092  -4.161934  -3.696162  2.779836   1.157445   \n",
       "3486 -19.091961 -1.767811   0.812909  -4.477929 -1.827579  -0.380548   \n",
       "3487 -18.978473 -4.552622   1.547258  -2.263347 -0.054753  -3.135464   \n",
       "\n",
       "              6         7         8          9  ...        89        90  \\\n",
       "0     16.524812  0.166351 -8.700498  10.438027  ...  1.923946  3.832444   \n",
       "1     17.966608 -0.569542 -9.306701   9.018383  ...  1.593726  0.604879   \n",
       "2     16.543319  0.781871 -8.695417   8.221800  ...  0.497217 -0.891250   \n",
       "3     17.856147  1.884261 -6.869309   6.376521  ... -0.687552 -0.829605   \n",
       "4     16.420547  3.158366 -8.634797   5.447760  ... -0.422376  1.025973   \n",
       "...         ...       ...       ...        ...  ...       ...       ...   \n",
       "3483   1.096600  3.019217  2.146403   3.662000  ... -0.429743  1.624900   \n",
       "3484  -1.059497  4.918116  1.074642   2.816077  ... -0.004836 -0.073998   \n",
       "3485  -1.148338  4.904417 -0.041506   3.601954  ... -0.613840 -0.938060   \n",
       "3486  -2.042414  3.578432 -0.707056   4.743335  ...  0.276470 -0.493735   \n",
       "3487  -2.699181  3.506751 -0.261364   5.744565  ... -0.037892 -0.282042   \n",
       "\n",
       "            91        92        93        94        95        96        97  \\\n",
       "0    -2.257067  2.835188 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201   \n",
       "1     0.335266  1.183815 -0.294895 -1.473127 -0.657472  0.007406 -2.294048   \n",
       "2     2.450366  2.249480 -1.947763 -2.079104  1.532892  1.893578 -0.800749   \n",
       "3    -5.461876  0.345240 -0.446096 -0.270433  6.035264  4.706512 -1.654442   \n",
       "4     1.077336  0.491024  0.339590 -0.503155  3.711262  1.314670 -0.031391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  1.085748 -0.379536 -0.537552 -0.248166 -0.836404  1.001076  0.001219   \n",
       "3484 -0.315707  1.726772  0.086268 -0.590934 -1.087419  0.384172  0.323270   \n",
       "3485  0.686956  2.921627  1.419180 -0.648111 -1.180782 -0.634334  0.133916   \n",
       "3486  0.480427  1.565258 -0.317555 -1.248186 -0.791837 -0.580324  0.377241   \n",
       "3487  0.909180  1.032256 -0.721593 -2.401458 -0.049565 -0.425631  1.137282   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 99 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9412327462108896\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395333685563211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402823354757119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=4, n_estimators=1500,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9833017341771811\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 1500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9793089237891185\n",
      "Best Score: 0.9752420492261091\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9803019661284694\n",
      "Best Score: 0.9753890678464975\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9782699489951906\n",
      "Best Score: 0.9742049751266588\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9776932306076379\n",
      "Best Score: 0.9746669590759185\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9801900040119682\n",
      "Best Score: 0.975191299637372\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b58b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d62e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a707d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 2075.9734 - mean_absolute_error: 2070.8970 - val_loss: 1778.1779 - val_mean_absolute_error: 1762.2402\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 751.5843 - mean_absolute_error: 726.3957 - val_loss: 419.2788 - val_mean_absolute_error: 391.6981\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 349.5955 - mean_absolute_error: 321.6591 - val_loss: 349.3987 - val_mean_absolute_error: 321.2832\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 287.3476 - mean_absolute_error: 258.7935 - val_loss: 294.8294 - val_mean_absolute_error: 265.8369\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 242.7664 - mean_absolute_error: 213.3580 - val_loss: 259.9649 - val_mean_absolute_error: 230.3202\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 202.5309 - mean_absolute_error: 172.4560 - val_loss: 225.3735 - val_mean_absolute_error: 194.9042\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 184.1765 - mean_absolute_error: 153.3572 - val_loss: 208.3751 - val_mean_absolute_error: 177.3968\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 158.8346 - mean_absolute_error: 127.7330 - val_loss: 192.0647 - val_mean_absolute_error: 160.8311\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 144.0778 - mean_absolute_error: 113.0327 - val_loss: 174.2645 - val_mean_absolute_error: 143.3703\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 140.3949 - mean_absolute_error: 109.4619 - val_loss: 167.6046 - val_mean_absolute_error: 136.7590\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 128.9045 - mean_absolute_error: 98.0002 - val_loss: 147.7926 - val_mean_absolute_error: 116.9856\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 120.2071 - mean_absolute_error: 89.4542 - val_loss: 153.0959 - val_mean_absolute_error: 122.5331\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 110.7386 - mean_absolute_error: 80.1504 - val_loss: 138.5098 - val_mean_absolute_error: 108.0105\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 107.8621 - mean_absolute_error: 77.6039 - val_loss: 141.1331 - val_mean_absolute_error: 110.9177\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 102.0436 - mean_absolute_error: 72.1097 - val_loss: 132.6985 - val_mean_absolute_error: 102.8521\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 98.9952 - mean_absolute_error: 69.2076 - val_loss: 131.2780 - val_mean_absolute_error: 101.7572\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.5768 - mean_absolute_error: 67.1971 - val_loss: 120.8625 - val_mean_absolute_error: 91.6274\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.7150 - mean_absolute_error: 67.5112 - val_loss: 133.2635 - val_mean_absolute_error: 104.1884\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 87.6720 - mean_absolute_error: 58.6898 - val_loss: 123.9468 - val_mean_absolute_error: 95.1066\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.3336 - mean_absolute_error: 61.6781 - val_loss: 119.2672 - val_mean_absolute_error: 90.8529\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.7942 - mean_absolute_error: 55.3743 - val_loss: 116.9577 - val_mean_absolute_error: 88.7151\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.1102 - mean_absolute_error: 54.8970 - val_loss: 116.8024 - val_mean_absolute_error: 88.7643\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.2587 - mean_absolute_error: 54.3013 - val_loss: 119.7162 - val_mean_absolute_error: 91.8914\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 80.7959 - mean_absolute_error: 53.1050 - val_loss: 123.3796 - val_mean_absolute_error: 95.8235\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.9994 - mean_absolute_error: 50.5865 - val_loss: 117.0756 - val_mean_absolute_error: 89.8471\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 78.9069 - mean_absolute_error: 51.7779 - val_loss: 117.8644 - val_mean_absolute_error: 90.9605\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.5519 - mean_absolute_error: 46.6302 - val_loss: 138.2760 - val_mean_absolute_error: 111.3448\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.5170 - mean_absolute_error: 50.8601 - val_loss: 113.0203 - val_mean_absolute_error: 86.4722\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.8262 - mean_absolute_error: 46.3291 - val_loss: 120.1357 - val_mean_absolute_error: 93.7621\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 80.5950 - mean_absolute_error: 54.3259 - val_loss: 114.7934 - val_mean_absolute_error: 88.5075\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.0279 - mean_absolute_error: 41.9777 - val_loss: 112.0232 - val_mean_absolute_error: 86.1796\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 71.3761 - mean_absolute_error: 45.5575 - val_loss: 106.2384 - val_mean_absolute_error: 80.4820\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.6904 - mean_absolute_error: 45.1101 - val_loss: 112.0941 - val_mean_absolute_error: 86.7278\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.3461 - mean_absolute_error: 42.0074 - val_loss: 105.6257 - val_mean_absolute_error: 80.3366\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.7791 - mean_absolute_error: 40.5925 - val_loss: 109.3541 - val_mean_absolute_error: 84.2945\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.9488 - mean_absolute_error: 42.0153 - val_loss: 111.2477 - val_mean_absolute_error: 86.2971\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.9321 - mean_absolute_error: 40.1433 - val_loss: 106.6066 - val_mean_absolute_error: 81.9851\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.4199 - mean_absolute_error: 38.8666 - val_loss: 111.9005 - val_mean_absolute_error: 87.3150\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.7418 - mean_absolute_error: 37.3697 - val_loss: 108.0025 - val_mean_absolute_error: 83.6786\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.1964 - mean_absolute_error: 40.0454 - val_loss: 101.2081 - val_mean_absolute_error: 77.1775\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.9196 - mean_absolute_error: 34.9794 - val_loss: 111.5960 - val_mean_absolute_error: 87.6779\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.7116 - mean_absolute_error: 43.9856 - val_loss: 101.7439 - val_mean_absolute_error: 78.1855\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.5374 - mean_absolute_error: 36.9841 - val_loss: 102.6490 - val_mean_absolute_error: 79.1719\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.2184 - mean_absolute_error: 37.8335 - val_loss: 106.0490 - val_mean_absolute_error: 82.8279\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.9700 - mean_absolute_error: 36.7889 - val_loss: 99.1806 - val_mean_absolute_error: 76.1069\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4117 - mean_absolute_error: 38.4250 - val_loss: 96.9421 - val_mean_absolute_error: 74.0806\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.6767 - mean_absolute_error: 33.8654 - val_loss: 98.0519 - val_mean_absolute_error: 75.2885\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.7120 - mean_absolute_error: 31.0415 - val_loss: 99.6642 - val_mean_absolute_error: 77.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.5453 - mean_absolute_error: 35.0672 - val_loss: 100.4368 - val_mean_absolute_error: 78.0621\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.3051 - mean_absolute_error: 36.9651 - val_loss: 94.4070 - val_mean_absolute_error: 72.1838\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0130 - mean_absolute_error: 33.8700 - val_loss: 107.1437 - val_mean_absolute_error: 85.1599\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.4210 - mean_absolute_error: 32.4088 - val_loss: 97.3990 - val_mean_absolute_error: 75.4268\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.9797 - mean_absolute_error: 33.1151 - val_loss: 100.4978 - val_mean_absolute_error: 78.6623\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1227 - mean_absolute_error: 31.4477 - val_loss: 97.1023 - val_mean_absolute_error: 75.5048\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.8985 - mean_absolute_error: 31.3885 - val_loss: 94.6682 - val_mean_absolute_error: 73.2131\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1105 - mean_absolute_error: 29.7627 - val_loss: 100.1385 - val_mean_absolute_error: 78.9571\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.5980 - mean_absolute_error: 34.4092 - val_loss: 93.1958 - val_mean_absolute_error: 72.1198\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.1247 - mean_absolute_error: 31.1106 - val_loss: 101.7058 - val_mean_absolute_error: 80.8566\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.7468 - mean_absolute_error: 31.8491 - val_loss: 95.8858 - val_mean_absolute_error: 75.0479\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.5841 - mean_absolute_error: 33.7619 - val_loss: 104.1782 - val_mean_absolute_error: 83.3146\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.5661 - mean_absolute_error: 32.9315 - val_loss: 103.1079 - val_mean_absolute_error: 82.5849\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1380 - mean_absolute_error: 32.6979 - val_loss: 93.8000 - val_mean_absolute_error: 73.4405\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.7062 - mean_absolute_error: 29.3996 - val_loss: 98.1754 - val_mean_absolute_error: 77.8895\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.8163 - mean_absolute_error: 27.6986 - val_loss: 102.5628 - val_mean_absolute_error: 82.4702\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.1897 - mean_absolute_error: 30.1914 - val_loss: 93.8666 - val_mean_absolute_error: 73.8783\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.8932 - mean_absolute_error: 33.9968 - val_loss: 100.9767 - val_mean_absolute_error: 81.1603\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.9376 - mean_absolute_error: 32.1900 - val_loss: 94.9020 - val_mean_absolute_error: 75.2163\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4319 - mean_absolute_error: 32.8126 - val_loss: 97.0874 - val_mean_absolute_error: 77.5299\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.3274 - mean_absolute_error: 28.8689 - val_loss: 92.5840 - val_mean_absolute_error: 73.2351\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0394 - mean_absolute_error: 27.7076 - val_loss: 95.8254 - val_mean_absolute_error: 76.5558\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.1386 - mean_absolute_error: 32.9172 - val_loss: 93.4864 - val_mean_absolute_error: 74.3726\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1985 - mean_absolute_error: 30.1088 - val_loss: 100.8253 - val_mean_absolute_error: 81.7018\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.8124 - mean_absolute_error: 29.8160 - val_loss: 90.9235 - val_mean_absolute_error: 72.0073\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1680 - mean_absolute_error: 30.2724 - val_loss: 97.1724 - val_mean_absolute_error: 78.3298\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.2731 - mean_absolute_error: 29.5199 - val_loss: 95.8904 - val_mean_absolute_error: 77.1784\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8855 - mean_absolute_error: 27.2328 - val_loss: 91.4839 - val_mean_absolute_error: 72.8758\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.7184 - mean_absolute_error: 30.1905 - val_loss: 93.2249 - val_mean_absolute_error: 74.7348\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1317 - mean_absolute_error: 27.7348 - val_loss: 97.5288 - val_mean_absolute_error: 79.2006\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9983 - mean_absolute_error: 28.6864 - val_loss: 95.8598 - val_mean_absolute_error: 77.6043\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.9559 - mean_absolute_error: 31.7489 - val_loss: 97.3415 - val_mean_absolute_error: 79.1429\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8139 - mean_absolute_error: 28.7312 - val_loss: 95.4632 - val_mean_absolute_error: 77.3962\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3568 - mean_absolute_error: 28.4181 - val_loss: 93.5814 - val_mean_absolute_error: 75.7373\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8604 - mean_absolute_error: 28.0631 - val_loss: 95.8668 - val_mean_absolute_error: 78.1556\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6237 - mean_absolute_error: 25.9209 - val_loss: 96.1111 - val_mean_absolute_error: 78.4656\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.5502 - mean_absolute_error: 28.9689 - val_loss: 101.1060 - val_mean_absolute_error: 83.6450\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3057 - mean_absolute_error: 28.7800 - val_loss: 94.6470 - val_mean_absolute_error: 77.0930\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2513 - mean_absolute_error: 25.8289 - val_loss: 86.7052 - val_mean_absolute_error: 69.3895\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.6739 - mean_absolute_error: 30.3758 - val_loss: 90.4700 - val_mean_absolute_error: 73.2015\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.7364 - mean_absolute_error: 27.5052 - val_loss: 94.1489 - val_mean_absolute_error: 76.9299\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.5010 - mean_absolute_error: 28.3796 - val_loss: 93.2006 - val_mean_absolute_error: 76.0774\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.4842 - mean_absolute_error: 33.4409 - val_loss: 92.3460 - val_mean_absolute_error: 75.4195\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7423 - mean_absolute_error: 25.8065 - val_loss: 90.9678 - val_mean_absolute_error: 74.0037\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.3263 - mean_absolute_error: 25.4782 - val_loss: 91.0577 - val_mean_absolute_error: 74.2863\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.5162 - mean_absolute_error: 28.7588 - val_loss: 90.7666 - val_mean_absolute_error: 74.0222\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5978 - mean_absolute_error: 26.9126 - val_loss: 93.5674 - val_mean_absolute_error: 76.9322\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.0430 - mean_absolute_error: 25.4651 - val_loss: 91.1613 - val_mean_absolute_error: 74.6449\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7675 - mean_absolute_error: 25.2796 - val_loss: 89.0280 - val_mean_absolute_error: 72.5206\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.8215 - mean_absolute_error: 29.4093 - val_loss: 89.0940 - val_mean_absolute_error: 72.7076\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9165 - mean_absolute_error: 26.5894 - val_loss: 90.8620 - val_mean_absolute_error: 74.5073\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2509 - mean_absolute_error: 26.9520 - val_loss: 95.1758 - val_mean_absolute_error: 78.9203\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8fb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd03b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ef741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
