{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_16196\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a29a6",
   "metadata": {},
   "source": [
    "### Reading the StandardScaler PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-21.546803</td>\n",
       "      <td>21.888236</td>\n",
       "      <td>35.503365</td>\n",
       "      <td>5.660160</td>\n",
       "      <td>-26.331832</td>\n",
       "      <td>12.379384</td>\n",
       "      <td>-2.051919</td>\n",
       "      <td>-11.623255</td>\n",
       "      <td>14.491962</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176430</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>-1.617762</td>\n",
       "      <td>4.851347</td>\n",
       "      <td>-0.986824</td>\n",
       "      <td>-1.731225</td>\n",
       "      <td>-1.716534</td>\n",
       "      <td>-0.851530</td>\n",
       "      <td>0.791756</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-20.467464</td>\n",
       "      <td>19.329678</td>\n",
       "      <td>32.364053</td>\n",
       "      <td>2.508690</td>\n",
       "      <td>-21.807530</td>\n",
       "      <td>17.990350</td>\n",
       "      <td>0.487409</td>\n",
       "      <td>-9.238707</td>\n",
       "      <td>13.658044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>-0.692582</td>\n",
       "      <td>-0.658485</td>\n",
       "      <td>2.364729</td>\n",
       "      <td>-0.955016</td>\n",
       "      <td>-0.220255</td>\n",
       "      <td>-0.306149</td>\n",
       "      <td>0.337637</td>\n",
       "      <td>1.535654</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-21.553040</td>\n",
       "      <td>20.989382</td>\n",
       "      <td>38.002623</td>\n",
       "      <td>1.092770</td>\n",
       "      <td>-26.068214</td>\n",
       "      <td>27.985134</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>-7.937606</td>\n",
       "      <td>9.079073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225689</td>\n",
       "      <td>-1.950618</td>\n",
       "      <td>0.347227</td>\n",
       "      <td>-1.770900</td>\n",
       "      <td>0.365888</td>\n",
       "      <td>3.035515</td>\n",
       "      <td>0.782899</td>\n",
       "      <td>2.358052</td>\n",
       "      <td>0.764571</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-20.476512</td>\n",
       "      <td>18.351236</td>\n",
       "      <td>31.250748</td>\n",
       "      <td>3.056882</td>\n",
       "      <td>-19.329919</td>\n",
       "      <td>21.239035</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>-7.274807</td>\n",
       "      <td>1.728165</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.666576</td>\n",
       "      <td>1.314088</td>\n",
       "      <td>5.391434</td>\n",
       "      <td>0.970074</td>\n",
       "      <td>-0.903477</td>\n",
       "      <td>1.504675</td>\n",
       "      <td>-0.058709</td>\n",
       "      <td>-0.969687</td>\n",
       "      <td>-1.832201</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-19.851448</td>\n",
       "      <td>17.305678</td>\n",
       "      <td>31.264870</td>\n",
       "      <td>-1.355544</td>\n",
       "      <td>-20.816337</td>\n",
       "      <td>17.743847</td>\n",
       "      <td>-5.031513</td>\n",
       "      <td>-5.767874</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.138488</td>\n",
       "      <td>1.986231</td>\n",
       "      <td>4.660604</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>-1.609785</td>\n",
       "      <td>0.459965</td>\n",
       "      <td>0.276084</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>-1.280689</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0          1          2         3          4  \\\n",
       "0           0 -21.546803  21.888236  35.503365  5.660160 -26.331832   \n",
       "1           1 -20.467464  19.329678  32.364053  2.508690 -21.807530   \n",
       "2           2 -21.553040  20.989382  38.002623  1.092770 -26.068214   \n",
       "3           3 -20.476512  18.351236  31.250748  3.056882 -19.329919   \n",
       "4           4 -19.851448  17.305678  31.264870 -1.355544 -20.816337   \n",
       "\n",
       "           5         6          7          8  ...        99       100  \\\n",
       "0  12.379384 -2.051919 -11.623255  14.491962  ...  1.176430 -0.174391   \n",
       "1  17.990350  0.487409  -9.238707  13.658044  ...  0.625548 -0.692582   \n",
       "2  27.985134 -1.260956  -7.937606   9.079073  ...  0.225689 -1.950618   \n",
       "3  21.239035  0.827941  -7.274807   1.728165  ... -3.666576  1.314088   \n",
       "4  17.743847 -5.031513  -5.767874   0.032634  ... -3.138488  1.986231   \n",
       "\n",
       "        101       102       103       104       105       106       107  \\\n",
       "0 -1.617762  4.851347 -0.986824 -1.731225 -1.716534 -0.851530  0.791756   \n",
       "1 -0.658485  2.364729 -0.955016 -0.220255 -0.306149  0.337637  1.535654   \n",
       "2  0.347227 -1.770900  0.365888  3.035515  0.782899  2.358052  0.764571   \n",
       "3  5.391434  0.970074 -0.903477  1.504675 -0.058709 -0.969687 -1.832201   \n",
       "4  4.660604  0.186040 -1.609785  0.459965  0.276084 -0.073639 -1.280689   \n",
       "\n",
       "   priceUSD  \n",
       "0    0.0495  \n",
       "1    0.0726  \n",
       "2    0.0859  \n",
       "3    0.0783  \n",
       "4    0.0767  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_StandardScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-21.546803</td>\n",
       "      <td>21.888236</td>\n",
       "      <td>35.503365</td>\n",
       "      <td>5.660160</td>\n",
       "      <td>-26.331832</td>\n",
       "      <td>12.379384</td>\n",
       "      <td>-2.051919</td>\n",
       "      <td>-11.623255</td>\n",
       "      <td>14.491962</td>\n",
       "      <td>6.973156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176430</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>-1.617762</td>\n",
       "      <td>4.851347</td>\n",
       "      <td>-0.986824</td>\n",
       "      <td>-1.731225</td>\n",
       "      <td>-1.716534</td>\n",
       "      <td>-0.851530</td>\n",
       "      <td>0.791756</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.467464</td>\n",
       "      <td>19.329678</td>\n",
       "      <td>32.364053</td>\n",
       "      <td>2.508690</td>\n",
       "      <td>-21.807530</td>\n",
       "      <td>17.990350</td>\n",
       "      <td>0.487409</td>\n",
       "      <td>-9.238707</td>\n",
       "      <td>13.658044</td>\n",
       "      <td>7.049672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>-0.692582</td>\n",
       "      <td>-0.658485</td>\n",
       "      <td>2.364729</td>\n",
       "      <td>-0.955016</td>\n",
       "      <td>-0.220255</td>\n",
       "      <td>-0.306149</td>\n",
       "      <td>0.337637</td>\n",
       "      <td>1.535654</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.553040</td>\n",
       "      <td>20.989382</td>\n",
       "      <td>38.002623</td>\n",
       "      <td>1.092770</td>\n",
       "      <td>-26.068214</td>\n",
       "      <td>27.985134</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>-7.937606</td>\n",
       "      <td>9.079073</td>\n",
       "      <td>7.710818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225689</td>\n",
       "      <td>-1.950618</td>\n",
       "      <td>0.347227</td>\n",
       "      <td>-1.770900</td>\n",
       "      <td>0.365888</td>\n",
       "      <td>3.035515</td>\n",
       "      <td>0.782899</td>\n",
       "      <td>2.358052</td>\n",
       "      <td>0.764571</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-20.476512</td>\n",
       "      <td>18.351236</td>\n",
       "      <td>31.250748</td>\n",
       "      <td>3.056882</td>\n",
       "      <td>-19.329919</td>\n",
       "      <td>21.239035</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>-7.274807</td>\n",
       "      <td>1.728165</td>\n",
       "      <td>8.850672</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.666576</td>\n",
       "      <td>1.314088</td>\n",
       "      <td>5.391434</td>\n",
       "      <td>0.970074</td>\n",
       "      <td>-0.903477</td>\n",
       "      <td>1.504675</td>\n",
       "      <td>-0.058709</td>\n",
       "      <td>-0.969687</td>\n",
       "      <td>-1.832201</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19.851448</td>\n",
       "      <td>17.305678</td>\n",
       "      <td>31.264870</td>\n",
       "      <td>-1.355544</td>\n",
       "      <td>-20.816337</td>\n",
       "      <td>17.743847</td>\n",
       "      <td>-5.031513</td>\n",
       "      <td>-5.767874</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>6.729982</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.138488</td>\n",
       "      <td>1.986231</td>\n",
       "      <td>4.660604</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>-1.609785</td>\n",
       "      <td>0.459965</td>\n",
       "      <td>0.276084</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>-1.280689</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>19.630066</td>\n",
       "      <td>-15.683449</td>\n",
       "      <td>12.690731</td>\n",
       "      <td>11.001457</td>\n",
       "      <td>5.864286</td>\n",
       "      <td>-0.502606</td>\n",
       "      <td>-4.160596</td>\n",
       "      <td>-5.122368</td>\n",
       "      <td>0.070994</td>\n",
       "      <td>-0.752235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897364</td>\n",
       "      <td>-1.091820</td>\n",
       "      <td>0.215364</td>\n",
       "      <td>0.031164</td>\n",
       "      <td>1.604445</td>\n",
       "      <td>1.208215</td>\n",
       "      <td>1.185574</td>\n",
       "      <td>-0.164827</td>\n",
       "      <td>-0.875868</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>20.276515</td>\n",
       "      <td>-16.158580</td>\n",
       "      <td>15.039984</td>\n",
       "      <td>10.943144</td>\n",
       "      <td>6.525591</td>\n",
       "      <td>-2.079491</td>\n",
       "      <td>-5.667626</td>\n",
       "      <td>-3.301163</td>\n",
       "      <td>1.249135</td>\n",
       "      <td>-1.241860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.227446</td>\n",
       "      <td>0.641690</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>1.327845</td>\n",
       "      <td>-0.476281</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.819836</td>\n",
       "      <td>-0.883276</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>19.438170</td>\n",
       "      <td>-15.359971</td>\n",
       "      <td>12.045600</td>\n",
       "      <td>11.126099</td>\n",
       "      <td>7.330382</td>\n",
       "      <td>2.191478</td>\n",
       "      <td>-3.713885</td>\n",
       "      <td>-2.973283</td>\n",
       "      <td>2.584260</td>\n",
       "      <td>-2.284411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.847139</td>\n",
       "      <td>1.112201</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>0.126362</td>\n",
       "      <td>-1.244953</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>-1.728047</td>\n",
       "      <td>2.350574</td>\n",
       "      <td>-0.696599</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>19.689729</td>\n",
       "      <td>-15.832295</td>\n",
       "      <td>14.363464</td>\n",
       "      <td>7.040175</td>\n",
       "      <td>5.504524</td>\n",
       "      <td>-0.254022</td>\n",
       "      <td>-7.509943</td>\n",
       "      <td>-3.425864</td>\n",
       "      <td>3.682001</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583045</td>\n",
       "      <td>-0.234759</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>-1.112261</td>\n",
       "      <td>-0.376768</td>\n",
       "      <td>1.382167</td>\n",
       "      <td>-1.502369</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>0.733646</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>19.733764</td>\n",
       "      <td>-16.067463</td>\n",
       "      <td>13.702033</td>\n",
       "      <td>4.868005</td>\n",
       "      <td>5.918601</td>\n",
       "      <td>2.041495</td>\n",
       "      <td>-6.626681</td>\n",
       "      <td>-3.216112</td>\n",
       "      <td>5.408380</td>\n",
       "      <td>0.370490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120860</td>\n",
       "      <td>-0.716691</td>\n",
       "      <td>0.970854</td>\n",
       "      <td>-0.946503</td>\n",
       "      <td>1.342224</td>\n",
       "      <td>1.764860</td>\n",
       "      <td>-1.262442</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.853410</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "0    -21.546803  21.888236  35.503365   5.660160 -26.331832  12.379384   \n",
       "1    -20.467464  19.329678  32.364053   2.508690 -21.807530  17.990350   \n",
       "2    -21.553040  20.989382  38.002623   1.092770 -26.068214  27.985134   \n",
       "3    -20.476512  18.351236  31.250748   3.056882 -19.329919  21.239035   \n",
       "4    -19.851448  17.305678  31.264870  -1.355544 -20.816337  17.743847   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3483  19.630066 -15.683449  12.690731  11.001457   5.864286  -0.502606   \n",
       "3484  20.276515 -16.158580  15.039984  10.943144   6.525591  -2.079491   \n",
       "3485  19.438170 -15.359971  12.045600  11.126099   7.330382   2.191478   \n",
       "3486  19.689729 -15.832295  14.363464   7.040175   5.504524  -0.254022   \n",
       "3487  19.733764 -16.067463  13.702033   4.868005   5.918601   2.041495   \n",
       "\n",
       "             6          7          8         9  ...        99       100  \\\n",
       "0    -2.051919 -11.623255  14.491962  6.973156  ...  1.176430 -0.174391   \n",
       "1     0.487409  -9.238707  13.658044  7.049672  ...  0.625548 -0.692582   \n",
       "2    -1.260956  -7.937606   9.079073  7.710818  ...  0.225689 -1.950618   \n",
       "3     0.827941  -7.274807   1.728165  8.850672  ... -3.666576  1.314088   \n",
       "4    -5.031513  -5.767874   0.032634  6.729982  ... -3.138488  1.986231   \n",
       "...        ...        ...        ...       ...  ...       ...       ...   \n",
       "3483 -4.160596  -5.122368   0.070994 -0.752235  ... -0.897364 -1.091820   \n",
       "3484 -5.667626  -3.301163   1.249135 -1.241860  ...  1.227446  0.641690   \n",
       "3485 -3.713885  -2.973283   2.584260 -2.284411  ... -0.847139  1.112201   \n",
       "3486 -7.509943  -3.425864   3.682001  0.000207  ... -0.583045 -0.234759   \n",
       "3487 -6.626681  -3.216112   5.408380  0.370490  ... -0.120860 -0.716691   \n",
       "\n",
       "           101       102       103       104       105       106       107  \\\n",
       "0    -1.617762  4.851347 -0.986824 -1.731225 -1.716534 -0.851530  0.791756   \n",
       "1    -0.658485  2.364729 -0.955016 -0.220255 -0.306149  0.337637  1.535654   \n",
       "2     0.347227 -1.770900  0.365888  3.035515  0.782899  2.358052  0.764571   \n",
       "3     5.391434  0.970074 -0.903477  1.504675 -0.058709 -0.969687 -1.832201   \n",
       "4     4.660604  0.186040 -1.609785  0.459965  0.276084 -0.073639 -1.280689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  0.215364  0.031164  1.604445  1.208215  1.185574 -0.164827 -0.875868   \n",
       "3484 -0.004896  1.327845 -0.476281  0.262175  0.819836 -0.883276  0.580323   \n",
       "3485 -0.247291  0.126362 -1.244953  0.926688 -1.728047  2.350574 -0.696599   \n",
       "3486  0.037219 -1.112261 -0.376768  1.382167 -1.502369 -0.047295  0.733646   \n",
       "3487  0.970854 -0.946503  1.342224  1.764860 -1.262442  0.002509  0.853410   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952274075968183\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995074865430632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916232851533238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.03, max_depth=4, n_estimators=1500,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9913707814410886\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 1500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c89d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9859230425620891\n",
      "Best Score: 0.9868133161796173\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 20}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9857002314800685\n",
      "Best Score: 0.9866767530590946\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9858394429025614\n",
      "Best Score: 0.9862398812546396\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.985591577402717\n",
      "Best Score: 0.9870152856167385\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.98635504169019\n",
      "Best Score: 0.9867381671499238\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56aa2f",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c38841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bbd4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02a481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 1965.0668 - mean_absolute_error: 1957.4308 - val_loss: 1200.8073 - val_mean_absolute_error: 1180.1183\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 390.8337 - mean_absolute_error: 367.2625 - val_loss: 203.6750 - val_mean_absolute_error: 179.4075\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 149.8680 - mean_absolute_error: 125.6887 - val_loss: 145.7970 - val_mean_absolute_error: 121.8610\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 125.0580 - mean_absolute_error: 101.2255 - val_loss: 137.0123 - val_mean_absolute_error: 113.1924\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 109.3572 - mean_absolute_error: 85.7191 - val_loss: 128.4426 - val_mean_absolute_error: 105.1214\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 101.4652 - mean_absolute_error: 78.1400 - val_loss: 116.5850 - val_mean_absolute_error: 93.3599\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 89.7978 - mean_absolute_error: 66.6848 - val_loss: 111.9333 - val_mean_absolute_error: 88.8123\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.7542 - mean_absolute_error: 62.8747 - val_loss: 130.5548 - val_mean_absolute_error: 107.9232\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 92.0565 - mean_absolute_error: 69.4307 - val_loss: 107.1474 - val_mean_absolute_error: 84.6712\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.6634 - mean_absolute_error: 60.3189 - val_loss: 103.5873 - val_mean_absolute_error: 81.3800\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.6344 - mean_absolute_error: 60.5647 - val_loss: 110.9348 - val_mean_absolute_error: 89.1115\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.2886 - mean_absolute_error: 61.5320 - val_loss: 102.3929 - val_mean_absolute_error: 80.6745\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.4395 - mean_absolute_error: 52.8970 - val_loss: 97.9301 - val_mean_absolute_error: 76.5106\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.6790 - mean_absolute_error: 51.3435 - val_loss: 94.8246 - val_mean_absolute_error: 73.6340\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.8244 - mean_absolute_error: 52.7439 - val_loss: 107.1805 - val_mean_absolute_error: 86.3510\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.6035 - mean_absolute_error: 49.7758 - val_loss: 99.2767 - val_mean_absolute_error: 78.5471\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.8354 - mean_absolute_error: 48.1907 - val_loss: 91.5987 - val_mean_absolute_error: 71.0643\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.2245 - mean_absolute_error: 46.7954 - val_loss: 99.9775 - val_mean_absolute_error: 79.6177\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.1458 - mean_absolute_error: 47.9242 - val_loss: 88.4481 - val_mean_absolute_error: 68.2619\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.8776 - mean_absolute_error: 45.8456 - val_loss: 99.8747 - val_mean_absolute_error: 79.9524\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.4620 - mean_absolute_error: 48.6517 - val_loss: 91.4138 - val_mean_absolute_error: 71.8061\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3366 - mean_absolute_error: 43.7305 - val_loss: 86.6171 - val_mean_absolute_error: 67.1338\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.8630 - mean_absolute_error: 44.4254 - val_loss: 87.8921 - val_mean_absolute_error: 68.6000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.4665 - mean_absolute_error: 44.1950 - val_loss: 96.2703 - val_mean_absolute_error: 77.1155\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4919 - mean_absolute_error: 42.3996 - val_loss: 92.1621 - val_mean_absolute_error: 73.1791\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.8638 - mean_absolute_error: 42.9506 - val_loss: 92.0753 - val_mean_absolute_error: 73.2596\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.4307 - mean_absolute_error: 38.7153 - val_loss: 87.6480 - val_mean_absolute_error: 69.0731\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.7390 - mean_absolute_error: 42.1354 - val_loss: 83.4018 - val_mean_absolute_error: 64.9046\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.6449 - mean_absolute_error: 39.2679 - val_loss: 84.9706 - val_mean_absolute_error: 66.6783\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.5994 - mean_absolute_error: 39.3659 - val_loss: 87.0346 - val_mean_absolute_error: 68.9471\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4187 - mean_absolute_error: 43.3857 - val_loss: 91.5656 - val_mean_absolute_error: 73.6282\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.0176 - mean_absolute_error: 39.0696 - val_loss: 89.9415 - val_mean_absolute_error: 72.0362\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1613 - mean_absolute_error: 35.3705 - val_loss: 97.9938 - val_mean_absolute_error: 80.1388\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.4441 - mean_absolute_error: 38.8218 - val_loss: 78.7592 - val_mean_absolute_error: 61.2457\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.9823 - mean_absolute_error: 34.5279 - val_loss: 76.6331 - val_mean_absolute_error: 59.2681\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.3150 - mean_absolute_error: 37.0049 - val_loss: 88.9710 - val_mean_absolute_error: 71.6454\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.9442 - mean_absolute_error: 36.7837 - val_loss: 82.4506 - val_mean_absolute_error: 65.3916\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.3874 - mean_absolute_error: 35.4065 - val_loss: 81.3357 - val_mean_absolute_error: 64.4384\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1874 - mean_absolute_error: 34.3028 - val_loss: 86.9932 - val_mean_absolute_error: 70.2811\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.6665 - mean_absolute_error: 36.9745 - val_loss: 80.0155 - val_mean_absolute_error: 63.3742\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.7046 - mean_absolute_error: 35.1573 - val_loss: 78.2376 - val_mean_absolute_error: 61.7239\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.6399 - mean_absolute_error: 36.1944 - val_loss: 77.7415 - val_mean_absolute_error: 61.3737\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.2688 - mean_absolute_error: 37.0008 - val_loss: 83.0562 - val_mean_absolute_error: 66.7910\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3484 - mean_absolute_error: 34.1738 - val_loss: 77.1120 - val_mean_absolute_error: 60.9633\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.6697 - mean_absolute_error: 32.6218 - val_loss: 76.7230 - val_mean_absolute_error: 60.7657\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.1236 - mean_absolute_error: 32.2257 - val_loss: 76.8279 - val_mean_absolute_error: 60.9767\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9973 - mean_absolute_error: 33.2614 - val_loss: 77.1989 - val_mean_absolute_error: 61.5012\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1801 - mean_absolute_error: 37.4965 - val_loss: 77.1816 - val_mean_absolute_error: 61.5284\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 48.1051 - mean_absolute_error: 32.5004 - val_loss: 91.6576 - val_mean_absolute_error: 75.9890\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.0435 - mean_absolute_error: 36.6026 - val_loss: 82.3076 - val_mean_absolute_error: 67.0184\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.4314 - mean_absolute_error: 31.1529 - val_loss: 78.0658 - val_mean_absolute_error: 62.7106\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8480 - mean_absolute_error: 31.6667 - val_loss: 74.1584 - val_mean_absolute_error: 59.0626\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9672 - mean_absolute_error: 31.8653 - val_loss: 74.4742 - val_mean_absolute_error: 59.3838\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.0724 - mean_absolute_error: 31.0353 - val_loss: 81.0678 - val_mean_absolute_error: 65.9566\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4814 - mean_absolute_error: 32.5256 - val_loss: 72.6901 - val_mean_absolute_error: 57.7146\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9035 - mean_absolute_error: 34.0274 - val_loss: 77.5588 - val_mean_absolute_error: 62.7033\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.7672 - mean_absolute_error: 37.0391 - val_loss: 76.8242 - val_mean_absolute_error: 62.1624\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.4646 - mean_absolute_error: 29.8123 - val_loss: 75.7090 - val_mean_absolute_error: 61.1525\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1433 - mean_absolute_error: 34.5841 - val_loss: 72.4137 - val_mean_absolute_error: 57.8849\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.9144 - mean_absolute_error: 35.4798 - val_loss: 103.7841 - val_mean_absolute_error: 89.5769\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1269 - mean_absolute_error: 34.7932 - val_loss: 74.3277 - val_mean_absolute_error: 60.0796\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.5574 - mean_absolute_error: 27.3325 - val_loss: 72.7180 - val_mean_absolute_error: 58.5176\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2647 - mean_absolute_error: 29.0692 - val_loss: 73.4664 - val_mean_absolute_error: 59.1894\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.6864 - mean_absolute_error: 27.6103 - val_loss: 70.8097 - val_mean_absolute_error: 56.7804\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9990 - mean_absolute_error: 30.9781 - val_loss: 67.5430 - val_mean_absolute_error: 53.5700\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3056 - mean_absolute_error: 32.3624 - val_loss: 83.6273 - val_mean_absolute_error: 69.8294\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.0467 - mean_absolute_error: 32.1835 - val_loss: 80.0332 - val_mean_absolute_error: 66.2656\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6806 - mean_absolute_error: 31.9318 - val_loss: 72.3306 - val_mean_absolute_error: 58.5625\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6029 - mean_absolute_error: 29.9125 - val_loss: 75.6853 - val_mean_absolute_error: 61.9933\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.5547 - mean_absolute_error: 30.9840 - val_loss: 70.8194 - val_mean_absolute_error: 57.3617\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7790 - mean_absolute_error: 28.2852 - val_loss: 77.8136 - val_mean_absolute_error: 64.3011\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.9189 - mean_absolute_error: 34.4908 - val_loss: 75.8212 - val_mean_absolute_error: 62.3289\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.0352 - mean_absolute_error: 30.6752 - val_loss: 73.2421 - val_mean_absolute_error: 59.8814\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9813 - mean_absolute_error: 29.6777 - val_loss: 73.5057 - val_mean_absolute_error: 60.1977\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7898 - mean_absolute_error: 28.5811 - val_loss: 77.6862 - val_mean_absolute_error: 64.5598\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.7033 - mean_absolute_error: 30.5463 - val_loss: 74.5573 - val_mean_absolute_error: 61.4815\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.8885 - mean_absolute_error: 27.8422 - val_loss: 69.6404 - val_mean_absolute_error: 56.6082\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.3928 - mean_absolute_error: 26.3926 - val_loss: 67.4931 - val_mean_absolute_error: 54.5890\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.5866 - mean_absolute_error: 27.7061 - val_loss: 68.4632 - val_mean_absolute_error: 55.5687\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.2971 - mean_absolute_error: 29.4445 - val_loss: 68.0710 - val_mean_absolute_error: 55.2050\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.6475 - mean_absolute_error: 29.8522 - val_loss: 70.0614 - val_mean_absolute_error: 57.3335\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.1136 - mean_absolute_error: 32.4273 - val_loss: 69.2224 - val_mean_absolute_error: 56.5934\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.7767 - mean_absolute_error: 27.1741 - val_loss: 62.0517 - val_mean_absolute_error: 49.4577\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.8402 - mean_absolute_error: 26.3025 - val_loss: 69.9403 - val_mean_absolute_error: 57.4658\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7396 - mean_absolute_error: 29.2783 - val_loss: 86.3297 - val_mean_absolute_error: 73.9476\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1240 - mean_absolute_error: 30.7292 - val_loss: 66.9909 - val_mean_absolute_error: 54.6237\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.3695 - mean_absolute_error: 26.0346 - val_loss: 64.3333 - val_mean_absolute_error: 51.9910\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.0300 - mean_absolute_error: 25.7738 - val_loss: 64.4044 - val_mean_absolute_error: 52.1491\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7972 - mean_absolute_error: 30.5963 - val_loss: 76.4870 - val_mean_absolute_error: 64.1674\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.3302 - mean_absolute_error: 27.1809 - val_loss: 69.3682 - val_mean_absolute_error: 57.2886\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6399 - mean_absolute_error: 33.5500 - val_loss: 78.1007 - val_mean_absolute_error: 65.9605\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2316 - mean_absolute_error: 29.1812 - val_loss: 67.3199 - val_mean_absolute_error: 55.2700\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.1559 - mean_absolute_error: 26.1153 - val_loss: 66.4134 - val_mean_absolute_error: 54.4217\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 36.4740 - mean_absolute_error: 24.5118 - val_loss: 65.8014 - val_mean_absolute_error: 53.8315\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.1542 - mean_absolute_error: 26.2502 - val_loss: 63.9761 - val_mean_absolute_error: 52.1843\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.6596 - mean_absolute_error: 26.8659 - val_loss: 67.8802 - val_mean_absolute_error: 56.0294\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 37.7935 - mean_absolute_error: 26.0109 - val_loss: 68.7532 - val_mean_absolute_error: 56.9789\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.3508 - mean_absolute_error: 31.5860 - val_loss: 65.1100 - val_mean_absolute_error: 53.3947\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2989 - mean_absolute_error: 29.5998 - val_loss: 87.1938 - val_mean_absolute_error: 75.6885\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9426 - mean_absolute_error: 33.3425 - val_loss: 66.7956 - val_mean_absolute_error: 55.1717\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5b7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230d7e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795df9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
