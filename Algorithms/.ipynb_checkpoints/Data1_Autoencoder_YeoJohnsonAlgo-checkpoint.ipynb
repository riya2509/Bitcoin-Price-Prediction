{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_10408\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e7c4",
   "metadata": {},
   "source": [
    "### Reading the YeoJohnson Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0         1          2          3         4          5  \\\n",
       "0           0  32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1           1  32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2           2  33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3           3  32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4           4  32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "\n",
       "           6         7         8  ...        89        90        91        92  \\\n",
       "0  16.524812  0.166351 -8.700498  ...  1.923946  3.832444 -2.257067  2.835188   \n",
       "1  17.966608 -0.569542 -9.306701  ...  1.593726  0.604879  0.335266  1.183815   \n",
       "2  16.543319  0.781871 -8.695417  ...  0.497217 -0.891250  2.450366  2.249480   \n",
       "3  17.856147  1.884261 -6.869309  ... -0.687552 -0.829605 -5.461876  0.345240   \n",
       "4  16.420547  3.158366 -8.634797  ... -0.422376  1.025973  1.077336  0.491024   \n",
       "\n",
       "         93        94        95        96        97  priceUSD  \n",
       "0 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201    0.0495  \n",
       "1 -0.294895 -1.473127 -0.657472  0.007406 -2.294048    0.0726  \n",
       "2 -1.947763 -2.079104  1.532892  1.893578 -0.800749    0.0859  \n",
       "3 -0.446096 -0.270433  6.035264  4.706512 -1.654442    0.0783  \n",
       "4  0.339590 -0.503155  3.711262  1.314670 -0.031391    0.0767  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_YeoJohnson_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>10.438027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>9.018383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>8.221800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>6.376521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>5.447760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>-19.315494</td>\n",
       "      <td>0.236167</td>\n",
       "      <td>-2.750750</td>\n",
       "      <td>-5.370912</td>\n",
       "      <td>-0.186745</td>\n",
       "      <td>4.678685</td>\n",
       "      <td>1.096600</td>\n",
       "      <td>3.019217</td>\n",
       "      <td>2.146403</td>\n",
       "      <td>3.662000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429743</td>\n",
       "      <td>1.624900</td>\n",
       "      <td>1.085748</td>\n",
       "      <td>-0.379536</td>\n",
       "      <td>-0.537552</td>\n",
       "      <td>-0.248166</td>\n",
       "      <td>-0.836404</td>\n",
       "      <td>1.001076</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-19.318940</td>\n",
       "      <td>0.733044</td>\n",
       "      <td>-0.889637</td>\n",
       "      <td>-5.979197</td>\n",
       "      <td>-1.170327</td>\n",
       "      <td>4.752099</td>\n",
       "      <td>-1.059497</td>\n",
       "      <td>4.918116</td>\n",
       "      <td>1.074642</td>\n",
       "      <td>2.816077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>-0.073998</td>\n",
       "      <td>-0.315707</td>\n",
       "      <td>1.726772</td>\n",
       "      <td>0.086268</td>\n",
       "      <td>-0.590934</td>\n",
       "      <td>-1.087419</td>\n",
       "      <td>0.384172</td>\n",
       "      <td>0.323270</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-19.018647</td>\n",
       "      <td>0.730092</td>\n",
       "      <td>-4.161934</td>\n",
       "      <td>-3.696162</td>\n",
       "      <td>2.779836</td>\n",
       "      <td>1.157445</td>\n",
       "      <td>-1.148338</td>\n",
       "      <td>4.904417</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>3.601954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613840</td>\n",
       "      <td>-0.938060</td>\n",
       "      <td>0.686956</td>\n",
       "      <td>2.921627</td>\n",
       "      <td>1.419180</td>\n",
       "      <td>-0.648111</td>\n",
       "      <td>-1.180782</td>\n",
       "      <td>-0.634334</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-19.091961</td>\n",
       "      <td>-1.767811</td>\n",
       "      <td>0.812909</td>\n",
       "      <td>-4.477929</td>\n",
       "      <td>-1.827579</td>\n",
       "      <td>-0.380548</td>\n",
       "      <td>-2.042414</td>\n",
       "      <td>3.578432</td>\n",
       "      <td>-0.707056</td>\n",
       "      <td>4.743335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276470</td>\n",
       "      <td>-0.493735</td>\n",
       "      <td>0.480427</td>\n",
       "      <td>1.565258</td>\n",
       "      <td>-0.317555</td>\n",
       "      <td>-1.248186</td>\n",
       "      <td>-0.791837</td>\n",
       "      <td>-0.580324</td>\n",
       "      <td>0.377241</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>-18.978473</td>\n",
       "      <td>-4.552622</td>\n",
       "      <td>1.547258</td>\n",
       "      <td>-2.263347</td>\n",
       "      <td>-0.054753</td>\n",
       "      <td>-3.135464</td>\n",
       "      <td>-2.699181</td>\n",
       "      <td>3.506751</td>\n",
       "      <td>-0.261364</td>\n",
       "      <td>5.744565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037892</td>\n",
       "      <td>-0.282042</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>1.032256</td>\n",
       "      <td>-0.721593</td>\n",
       "      <td>-2.401458</td>\n",
       "      <td>-0.049565</td>\n",
       "      <td>-0.425631</td>\n",
       "      <td>1.137282</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2          3         4          5  \\\n",
       "0     32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1     32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2     33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3     32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4     32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "3483 -19.315494  0.236167  -2.750750  -5.370912 -0.186745   4.678685   \n",
       "3484 -19.318940  0.733044  -0.889637  -5.979197 -1.170327   4.752099   \n",
       "3485 -19.018647  0.730092  -4.161934  -3.696162  2.779836   1.157445   \n",
       "3486 -19.091961 -1.767811   0.812909  -4.477929 -1.827579  -0.380548   \n",
       "3487 -18.978473 -4.552622   1.547258  -2.263347 -0.054753  -3.135464   \n",
       "\n",
       "              6         7         8          9  ...        89        90  \\\n",
       "0     16.524812  0.166351 -8.700498  10.438027  ...  1.923946  3.832444   \n",
       "1     17.966608 -0.569542 -9.306701   9.018383  ...  1.593726  0.604879   \n",
       "2     16.543319  0.781871 -8.695417   8.221800  ...  0.497217 -0.891250   \n",
       "3     17.856147  1.884261 -6.869309   6.376521  ... -0.687552 -0.829605   \n",
       "4     16.420547  3.158366 -8.634797   5.447760  ... -0.422376  1.025973   \n",
       "...         ...       ...       ...        ...  ...       ...       ...   \n",
       "3483   1.096600  3.019217  2.146403   3.662000  ... -0.429743  1.624900   \n",
       "3484  -1.059497  4.918116  1.074642   2.816077  ... -0.004836 -0.073998   \n",
       "3485  -1.148338  4.904417 -0.041506   3.601954  ... -0.613840 -0.938060   \n",
       "3486  -2.042414  3.578432 -0.707056   4.743335  ...  0.276470 -0.493735   \n",
       "3487  -2.699181  3.506751 -0.261364   5.744565  ... -0.037892 -0.282042   \n",
       "\n",
       "            91        92        93        94        95        96        97  \\\n",
       "0    -2.257067  2.835188 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201   \n",
       "1     0.335266  1.183815 -0.294895 -1.473127 -0.657472  0.007406 -2.294048   \n",
       "2     2.450366  2.249480 -1.947763 -2.079104  1.532892  1.893578 -0.800749   \n",
       "3    -5.461876  0.345240 -0.446096 -0.270433  6.035264  4.706512 -1.654442   \n",
       "4     1.077336  0.491024  0.339590 -0.503155  3.711262  1.314670 -0.031391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  1.085748 -0.379536 -0.537552 -0.248166 -0.836404  1.001076  0.001219   \n",
       "3484 -0.315707  1.726772  0.086268 -0.590934 -1.087419  0.384172  0.323270   \n",
       "3485  0.686956  2.921627  1.419180 -0.648111 -1.180782 -0.634334  0.133916   \n",
       "3486  0.480427  1.565258 -0.317555 -1.248186 -0.791837 -0.580324  0.377241   \n",
       "3487  0.909180  1.032256 -0.721593 -2.401458 -0.049565 -0.425631  1.137282   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 99 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9412327462108896\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395333685563211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402823354757119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=6, n_estimators=1000,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9829477780164713\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 1000, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9774487991332323\n",
      "Best Score: 0.9746891344246921\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9794277332665254\n",
      "Best Score: 0.9751707177098657\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9799071374631807\n",
      "Best Score: 0.9753944505948476\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9755858928463131\n",
      "Best Score: 0.9757027777663847\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 20}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9789299072076919\n",
      "Best Score: 0.9751712087118826\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce0f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f53d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5805da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 1925.0907 - mean_absolute_error: 1916.3882 - val_loss: 1051.0133 - val_mean_absolute_error: 1028.6763\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.2269 - mean_absolute_error: 530.3229 - val_loss: 392.2671 - val_mean_absolute_error: 366.8821\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 324.4345 - mean_absolute_error: 298.6511 - val_loss: 316.5970 - val_mean_absolute_error: 290.3983\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 268.1576 - mean_absolute_error: 241.7326 - val_loss: 277.6089 - val_mean_absolute_error: 250.8374\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 231.6049 - mean_absolute_error: 204.5079 - val_loss: 246.8540 - val_mean_absolute_error: 219.2948\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 195.6277 - mean_absolute_error: 167.7855 - val_loss: 225.4012 - val_mean_absolute_error: 197.4346\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 172.6006 - mean_absolute_error: 144.3984 - val_loss: 199.9062 - val_mean_absolute_error: 171.5529\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 159.0792 - mean_absolute_error: 130.6856 - val_loss: 189.3156 - val_mean_absolute_error: 160.7638\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 139.1628 - mean_absolute_error: 110.7216 - val_loss: 168.0865 - val_mean_absolute_error: 139.7336\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 132.0135 - mean_absolute_error: 103.6365 - val_loss: 158.8051 - val_mean_absolute_error: 130.4295\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 122.8992 - mean_absolute_error: 94.6102 - val_loss: 148.0955 - val_mean_absolute_error: 119.8850\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 114.8478 - mean_absolute_error: 86.6698 - val_loss: 152.2289 - val_mean_absolute_error: 124.2652\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 110.3403 - mean_absolute_error: 82.4654 - val_loss: 147.4705 - val_mean_absolute_error: 119.8343\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 113.0731 - mean_absolute_error: 85.3339 - val_loss: 141.1973 - val_mean_absolute_error: 113.6088\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 102.6387 - mean_absolute_error: 75.2207 - val_loss: 130.2419 - val_mean_absolute_error: 102.9298\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.3302 - mean_absolute_error: 69.0979 - val_loss: 132.1357 - val_mean_absolute_error: 104.9797\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 93.1214 - mean_absolute_error: 66.1846 - val_loss: 127.8501 - val_mean_absolute_error: 100.9753\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 89.6815 - mean_absolute_error: 63.0703 - val_loss: 124.5074 - val_mean_absolute_error: 98.0630\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 86.8960 - mean_absolute_error: 60.6294 - val_loss: 129.0385 - val_mean_absolute_error: 103.0097\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 91.7266 - mean_absolute_error: 65.6550 - val_loss: 120.3050 - val_mean_absolute_error: 94.3135\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 84.4313 - mean_absolute_error: 58.5212 - val_loss: 115.4325 - val_mean_absolute_error: 89.6757\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 84.0829 - mean_absolute_error: 58.3884 - val_loss: 133.7224 - val_mean_absolute_error: 108.0920\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.7578 - mean_absolute_error: 56.2992 - val_loss: 128.0510 - val_mean_absolute_error: 102.6810\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.0854 - mean_absolute_error: 55.8684 - val_loss: 114.5725 - val_mean_absolute_error: 89.5132\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.6958 - mean_absolute_error: 48.7265 - val_loss: 125.4007 - val_mean_absolute_error: 100.6365\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 79.5556 - mean_absolute_error: 54.7888 - val_loss: 119.2964 - val_mean_absolute_error: 94.5907\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.6410 - mean_absolute_error: 48.0916 - val_loss: 115.2115 - val_mean_absolute_error: 90.8128\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.4996 - mean_absolute_error: 48.1710 - val_loss: 117.9565 - val_mean_absolute_error: 93.7536\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.1181 - mean_absolute_error: 49.0608 - val_loss: 119.1442 - val_mean_absolute_error: 95.2653\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.9982 - mean_absolute_error: 47.1390 - val_loss: 111.1567 - val_mean_absolute_error: 87.4444\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.8454 - mean_absolute_error: 52.1473 - val_loss: 121.5042 - val_mean_absolute_error: 97.8277\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.5907 - mean_absolute_error: 45.0555 - val_loss: 127.6105 - val_mean_absolute_error: 104.0930\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.4554 - mean_absolute_error: 52.1662 - val_loss: 157.2134 - val_mean_absolute_error: 133.8475\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.6015 - mean_absolute_error: 45.4995 - val_loss: 111.9565 - val_mean_absolute_error: 88.9051\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.1127 - mean_absolute_error: 43.1675 - val_loss: 105.4253 - val_mean_absolute_error: 82.7124\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.9318 - mean_absolute_error: 42.2047 - val_loss: 118.0530 - val_mean_absolute_error: 95.3919\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.5755 - mean_absolute_error: 41.0170 - val_loss: 111.3149 - val_mean_absolute_error: 88.7866\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3490 - mean_absolute_error: 40.9890 - val_loss: 115.9596 - val_mean_absolute_error: 93.7352\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.5728 - mean_absolute_error: 40.4655 - val_loss: 110.4610 - val_mean_absolute_error: 88.4431\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.5399 - mean_absolute_error: 38.6122 - val_loss: 109.9453 - val_mean_absolute_error: 88.0493\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3217 - mean_absolute_error: 41.5846 - val_loss: 110.7555 - val_mean_absolute_error: 89.2207\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.5520 - mean_absolute_error: 41.0126 - val_loss: 108.7839 - val_mean_absolute_error: 87.3018\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.9302 - mean_absolute_error: 36.5442 - val_loss: 102.0122 - val_mean_absolute_error: 80.6921\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 57.9133 - mean_absolute_error: 36.7376 - val_loss: 111.3885 - val_mean_absolute_error: 90.3075\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.3337 - mean_absolute_error: 37.3566 - val_loss: 107.4274 - val_mean_absolute_error: 86.4578\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.0548 - mean_absolute_error: 39.1402 - val_loss: 107.0621 - val_mean_absolute_error: 86.2902\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.6112 - mean_absolute_error: 40.8652 - val_loss: 105.7464 - val_mean_absolute_error: 85.0231\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.4052 - mean_absolute_error: 37.7912 - val_loss: 105.5875 - val_mean_absolute_error: 85.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 59.2943 - mean_absolute_error: 38.8326 - val_loss: 114.2298 - val_mean_absolute_error: 93.9946\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 59.3413 - mean_absolute_error: 39.0467 - val_loss: 105.8211 - val_mean_absolute_error: 85.5814\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.0042 - mean_absolute_error: 41.8470 - val_loss: 101.5672 - val_mean_absolute_error: 81.4372\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.7756 - mean_absolute_error: 36.7660 - val_loss: 104.1582 - val_mean_absolute_error: 84.3008\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0071 - mean_absolute_error: 36.1503 - val_loss: 106.9575 - val_mean_absolute_error: 87.1069\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4458 - mean_absolute_error: 35.7074 - val_loss: 102.6028 - val_mean_absolute_error: 82.9572\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0658 - mean_absolute_error: 36.4751 - val_loss: 99.8436 - val_mean_absolute_error: 80.4151\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.2937 - mean_absolute_error: 33.8805 - val_loss: 108.6203 - val_mean_absolute_error: 89.2208\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.1238 - mean_absolute_error: 35.8410 - val_loss: 114.8978 - val_mean_absolute_error: 95.7567\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4646 - mean_absolute_error: 36.3478 - val_loss: 108.3949 - val_mean_absolute_error: 89.4384\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 58.0425 - mean_absolute_error: 39.0584 - val_loss: 117.5241 - val_mean_absolute_error: 98.4917\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.3177 - mean_absolute_error: 36.4585 - val_loss: 107.4486 - val_mean_absolute_error: 88.6125\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1157 - mean_absolute_error: 32.3708 - val_loss: 105.3901 - val_mean_absolute_error: 86.6726\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.4457 - mean_absolute_error: 32.8701 - val_loss: 95.7728 - val_mean_absolute_error: 77.2041\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.9858 - mean_absolute_error: 37.5476 - val_loss: 108.3038 - val_mean_absolute_error: 89.8185\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.6764 - mean_absolute_error: 32.3253 - val_loss: 98.0849 - val_mean_absolute_error: 79.8817\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.9257 - mean_absolute_error: 32.7104 - val_loss: 98.9322 - val_mean_absolute_error: 80.7976\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1071 - mean_absolute_error: 34.9254 - val_loss: 104.3514 - val_mean_absolute_error: 86.2489\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.6731 - mean_absolute_error: 34.6317 - val_loss: 100.3989 - val_mean_absolute_error: 82.4531\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1552 - mean_absolute_error: 33.2487 - val_loss: 106.0139 - val_mean_absolute_error: 88.1687\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3766 - mean_absolute_error: 32.6025 - val_loss: 96.0492 - val_mean_absolute_error: 78.3865\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.8537 - mean_absolute_error: 34.2140 - val_loss: 103.3072 - val_mean_absolute_error: 85.7056\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.3808 - mean_absolute_error: 38.8314 - val_loss: 96.7501 - val_mean_absolute_error: 79.2647\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.7563 - mean_absolute_error: 31.3199 - val_loss: 105.4230 - val_mean_absolute_error: 87.9394\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.6373 - mean_absolute_error: 32.3195 - val_loss: 97.6656 - val_mean_absolute_error: 80.4157\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.3970 - mean_absolute_error: 32.2401 - val_loss: 94.8950 - val_mean_absolute_error: 77.8159\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1616 - mean_absolute_error: 29.0823 - val_loss: 101.2273 - val_mean_absolute_error: 84.2011\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0319 - mean_absolute_error: 30.0685 - val_loss: 98.5384 - val_mean_absolute_error: 81.6263\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9162 - mean_absolute_error: 28.0869 - val_loss: 101.3770 - val_mean_absolute_error: 84.5873\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.5837 - mean_absolute_error: 29.7770 - val_loss: 102.5304 - val_mean_absolute_error: 85.7332\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6205 - mean_absolute_error: 34.9582 - val_loss: 96.1039 - val_mean_absolute_error: 79.5392\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.7813 - mean_absolute_error: 30.2516 - val_loss: 97.7925 - val_mean_absolute_error: 81.2987\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6491 - mean_absolute_error: 27.1822 - val_loss: 98.5108 - val_mean_absolute_error: 82.1334\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.5609 - mean_absolute_error: 34.2266 - val_loss: 94.6177 - val_mean_absolute_error: 78.3468\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3629 - mean_absolute_error: 30.0994 - val_loss: 95.4998 - val_mean_absolute_error: 79.2804\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1606 - mean_absolute_error: 35.0205 - val_loss: 99.7356 - val_mean_absolute_error: 83.6425\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8136 - mean_absolute_error: 30.7899 - val_loss: 97.1319 - val_mean_absolute_error: 81.1843\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.6063 - mean_absolute_error: 30.6826 - val_loss: 96.7833 - val_mean_absolute_error: 80.8888\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.1843 - mean_absolute_error: 29.3168 - val_loss: 98.5423 - val_mean_absolute_error: 82.7978\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.5367 - mean_absolute_error: 32.8228 - val_loss: 91.7706 - val_mean_absolute_error: 76.0659\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1515 - mean_absolute_error: 30.5281 - val_loss: 98.0167 - val_mean_absolute_error: 82.3871\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5771 - mean_absolute_error: 28.0215 - val_loss: 96.2712 - val_mean_absolute_error: 80.7932\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0732 - mean_absolute_error: 31.6153 - val_loss: 95.9183 - val_mean_absolute_error: 80.4873\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1568 - mean_absolute_error: 27.7832 - val_loss: 91.8399 - val_mean_absolute_error: 76.4758\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1976 - mean_absolute_error: 27.8766 - val_loss: 101.5777 - val_mean_absolute_error: 86.2550\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.8331 - mean_absolute_error: 33.6224 - val_loss: 93.8013 - val_mean_absolute_error: 78.6087\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.8559 - mean_absolute_error: 27.7094 - val_loss: 91.1895 - val_mean_absolute_error: 76.1031\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.3348 - mean_absolute_error: 29.2635 - val_loss: 90.7493 - val_mean_absolute_error: 75.6902\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 41.0007 - mean_absolute_error: 26.0171 - val_loss: 91.0001 - val_mean_absolute_error: 76.0867\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5161 - mean_absolute_error: 28.6076 - val_loss: 95.7349 - val_mean_absolute_error: 80.8534\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.9156 - mean_absolute_error: 39.1200 - val_loss: 92.3581 - val_mean_absolute_error: 77.6205\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9828 - mean_absolute_error: 28.2353 - val_loss: 87.0560 - val_mean_absolute_error: 72.3096\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00cc4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208c1bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c456d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
