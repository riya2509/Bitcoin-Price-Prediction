{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_5444\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a29a6",
   "metadata": {},
   "source": [
    "### Reading the StandardScaler PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-21.546803</td>\n",
       "      <td>21.888236</td>\n",
       "      <td>35.503365</td>\n",
       "      <td>5.660160</td>\n",
       "      <td>-26.331832</td>\n",
       "      <td>12.379384</td>\n",
       "      <td>-2.051919</td>\n",
       "      <td>-11.623255</td>\n",
       "      <td>14.491962</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176430</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>-1.617762</td>\n",
       "      <td>4.851347</td>\n",
       "      <td>-0.986824</td>\n",
       "      <td>-1.731225</td>\n",
       "      <td>-1.716534</td>\n",
       "      <td>-0.851530</td>\n",
       "      <td>0.791756</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-20.467464</td>\n",
       "      <td>19.329678</td>\n",
       "      <td>32.364053</td>\n",
       "      <td>2.508690</td>\n",
       "      <td>-21.807530</td>\n",
       "      <td>17.990350</td>\n",
       "      <td>0.487409</td>\n",
       "      <td>-9.238707</td>\n",
       "      <td>13.658044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>-0.692582</td>\n",
       "      <td>-0.658485</td>\n",
       "      <td>2.364729</td>\n",
       "      <td>-0.955016</td>\n",
       "      <td>-0.220255</td>\n",
       "      <td>-0.306149</td>\n",
       "      <td>0.337637</td>\n",
       "      <td>1.535654</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-21.553040</td>\n",
       "      <td>20.989382</td>\n",
       "      <td>38.002623</td>\n",
       "      <td>1.092770</td>\n",
       "      <td>-26.068214</td>\n",
       "      <td>27.985134</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>-7.937606</td>\n",
       "      <td>9.079073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225689</td>\n",
       "      <td>-1.950618</td>\n",
       "      <td>0.347227</td>\n",
       "      <td>-1.770900</td>\n",
       "      <td>0.365888</td>\n",
       "      <td>3.035515</td>\n",
       "      <td>0.782899</td>\n",
       "      <td>2.358052</td>\n",
       "      <td>0.764571</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-20.476512</td>\n",
       "      <td>18.351236</td>\n",
       "      <td>31.250748</td>\n",
       "      <td>3.056882</td>\n",
       "      <td>-19.329919</td>\n",
       "      <td>21.239035</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>-7.274807</td>\n",
       "      <td>1.728165</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.666576</td>\n",
       "      <td>1.314088</td>\n",
       "      <td>5.391434</td>\n",
       "      <td>0.970074</td>\n",
       "      <td>-0.903477</td>\n",
       "      <td>1.504675</td>\n",
       "      <td>-0.058709</td>\n",
       "      <td>-0.969687</td>\n",
       "      <td>-1.832201</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-19.851448</td>\n",
       "      <td>17.305678</td>\n",
       "      <td>31.264870</td>\n",
       "      <td>-1.355544</td>\n",
       "      <td>-20.816337</td>\n",
       "      <td>17.743847</td>\n",
       "      <td>-5.031513</td>\n",
       "      <td>-5.767874</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.138488</td>\n",
       "      <td>1.986231</td>\n",
       "      <td>4.660604</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>-1.609785</td>\n",
       "      <td>0.459965</td>\n",
       "      <td>0.276084</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>-1.280689</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0          1          2         3          4  \\\n",
       "0           0 -21.546803  21.888236  35.503365  5.660160 -26.331832   \n",
       "1           1 -20.467464  19.329678  32.364053  2.508690 -21.807530   \n",
       "2           2 -21.553040  20.989382  38.002623  1.092770 -26.068214   \n",
       "3           3 -20.476512  18.351236  31.250748  3.056882 -19.329919   \n",
       "4           4 -19.851448  17.305678  31.264870 -1.355544 -20.816337   \n",
       "\n",
       "           5         6          7          8  ...        99       100  \\\n",
       "0  12.379384 -2.051919 -11.623255  14.491962  ...  1.176430 -0.174391   \n",
       "1  17.990350  0.487409  -9.238707  13.658044  ...  0.625548 -0.692582   \n",
       "2  27.985134 -1.260956  -7.937606   9.079073  ...  0.225689 -1.950618   \n",
       "3  21.239035  0.827941  -7.274807   1.728165  ... -3.666576  1.314088   \n",
       "4  17.743847 -5.031513  -5.767874   0.032634  ... -3.138488  1.986231   \n",
       "\n",
       "        101       102       103       104       105       106       107  \\\n",
       "0 -1.617762  4.851347 -0.986824 -1.731225 -1.716534 -0.851530  0.791756   \n",
       "1 -0.658485  2.364729 -0.955016 -0.220255 -0.306149  0.337637  1.535654   \n",
       "2  0.347227 -1.770900  0.365888  3.035515  0.782899  2.358052  0.764571   \n",
       "3  5.391434  0.970074 -0.903477  1.504675 -0.058709 -0.969687 -1.832201   \n",
       "4  4.660604  0.186040 -1.609785  0.459965  0.276084 -0.073639 -1.280689   \n",
       "\n",
       "   priceUSD  \n",
       "0    0.0495  \n",
       "1    0.0726  \n",
       "2    0.0859  \n",
       "3    0.0783  \n",
       "4    0.0767  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_StandardScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-21.546803</td>\n",
       "      <td>21.888236</td>\n",
       "      <td>35.503365</td>\n",
       "      <td>5.660160</td>\n",
       "      <td>-26.331832</td>\n",
       "      <td>12.379384</td>\n",
       "      <td>-2.051919</td>\n",
       "      <td>-11.623255</td>\n",
       "      <td>14.491962</td>\n",
       "      <td>6.973156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176430</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>-1.617762</td>\n",
       "      <td>4.851347</td>\n",
       "      <td>-0.986824</td>\n",
       "      <td>-1.731225</td>\n",
       "      <td>-1.716534</td>\n",
       "      <td>-0.851530</td>\n",
       "      <td>0.791756</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.467464</td>\n",
       "      <td>19.329678</td>\n",
       "      <td>32.364053</td>\n",
       "      <td>2.508690</td>\n",
       "      <td>-21.807530</td>\n",
       "      <td>17.990350</td>\n",
       "      <td>0.487409</td>\n",
       "      <td>-9.238707</td>\n",
       "      <td>13.658044</td>\n",
       "      <td>7.049672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>-0.692582</td>\n",
       "      <td>-0.658485</td>\n",
       "      <td>2.364729</td>\n",
       "      <td>-0.955016</td>\n",
       "      <td>-0.220255</td>\n",
       "      <td>-0.306149</td>\n",
       "      <td>0.337637</td>\n",
       "      <td>1.535654</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.553040</td>\n",
       "      <td>20.989382</td>\n",
       "      <td>38.002623</td>\n",
       "      <td>1.092770</td>\n",
       "      <td>-26.068214</td>\n",
       "      <td>27.985134</td>\n",
       "      <td>-1.260956</td>\n",
       "      <td>-7.937606</td>\n",
       "      <td>9.079073</td>\n",
       "      <td>7.710818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225689</td>\n",
       "      <td>-1.950618</td>\n",
       "      <td>0.347227</td>\n",
       "      <td>-1.770900</td>\n",
       "      <td>0.365888</td>\n",
       "      <td>3.035515</td>\n",
       "      <td>0.782899</td>\n",
       "      <td>2.358052</td>\n",
       "      <td>0.764571</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-20.476512</td>\n",
       "      <td>18.351236</td>\n",
       "      <td>31.250748</td>\n",
       "      <td>3.056882</td>\n",
       "      <td>-19.329919</td>\n",
       "      <td>21.239035</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>-7.274807</td>\n",
       "      <td>1.728165</td>\n",
       "      <td>8.850672</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.666576</td>\n",
       "      <td>1.314088</td>\n",
       "      <td>5.391434</td>\n",
       "      <td>0.970074</td>\n",
       "      <td>-0.903477</td>\n",
       "      <td>1.504675</td>\n",
       "      <td>-0.058709</td>\n",
       "      <td>-0.969687</td>\n",
       "      <td>-1.832201</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19.851448</td>\n",
       "      <td>17.305678</td>\n",
       "      <td>31.264870</td>\n",
       "      <td>-1.355544</td>\n",
       "      <td>-20.816337</td>\n",
       "      <td>17.743847</td>\n",
       "      <td>-5.031513</td>\n",
       "      <td>-5.767874</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>6.729982</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.138488</td>\n",
       "      <td>1.986231</td>\n",
       "      <td>4.660604</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>-1.609785</td>\n",
       "      <td>0.459965</td>\n",
       "      <td>0.276084</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>-1.280689</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>19.630066</td>\n",
       "      <td>-15.683449</td>\n",
       "      <td>12.690731</td>\n",
       "      <td>11.001457</td>\n",
       "      <td>5.864286</td>\n",
       "      <td>-0.502606</td>\n",
       "      <td>-4.160596</td>\n",
       "      <td>-5.122368</td>\n",
       "      <td>0.070994</td>\n",
       "      <td>-0.752235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897364</td>\n",
       "      <td>-1.091820</td>\n",
       "      <td>0.215364</td>\n",
       "      <td>0.031164</td>\n",
       "      <td>1.604445</td>\n",
       "      <td>1.208215</td>\n",
       "      <td>1.185574</td>\n",
       "      <td>-0.164827</td>\n",
       "      <td>-0.875868</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>20.276515</td>\n",
       "      <td>-16.158580</td>\n",
       "      <td>15.039984</td>\n",
       "      <td>10.943144</td>\n",
       "      <td>6.525591</td>\n",
       "      <td>-2.079491</td>\n",
       "      <td>-5.667626</td>\n",
       "      <td>-3.301163</td>\n",
       "      <td>1.249135</td>\n",
       "      <td>-1.241860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.227446</td>\n",
       "      <td>0.641690</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>1.327845</td>\n",
       "      <td>-0.476281</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.819836</td>\n",
       "      <td>-0.883276</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>19.438170</td>\n",
       "      <td>-15.359971</td>\n",
       "      <td>12.045600</td>\n",
       "      <td>11.126099</td>\n",
       "      <td>7.330382</td>\n",
       "      <td>2.191478</td>\n",
       "      <td>-3.713885</td>\n",
       "      <td>-2.973283</td>\n",
       "      <td>2.584260</td>\n",
       "      <td>-2.284411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.847139</td>\n",
       "      <td>1.112201</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>0.126362</td>\n",
       "      <td>-1.244953</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>-1.728047</td>\n",
       "      <td>2.350574</td>\n",
       "      <td>-0.696599</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>19.689729</td>\n",
       "      <td>-15.832295</td>\n",
       "      <td>14.363464</td>\n",
       "      <td>7.040175</td>\n",
       "      <td>5.504524</td>\n",
       "      <td>-0.254022</td>\n",
       "      <td>-7.509943</td>\n",
       "      <td>-3.425864</td>\n",
       "      <td>3.682001</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583045</td>\n",
       "      <td>-0.234759</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>-1.112261</td>\n",
       "      <td>-0.376768</td>\n",
       "      <td>1.382167</td>\n",
       "      <td>-1.502369</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>0.733646</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>19.733764</td>\n",
       "      <td>-16.067463</td>\n",
       "      <td>13.702033</td>\n",
       "      <td>4.868005</td>\n",
       "      <td>5.918601</td>\n",
       "      <td>2.041495</td>\n",
       "      <td>-6.626681</td>\n",
       "      <td>-3.216112</td>\n",
       "      <td>5.408380</td>\n",
       "      <td>0.370490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120860</td>\n",
       "      <td>-0.716691</td>\n",
       "      <td>0.970854</td>\n",
       "      <td>-0.946503</td>\n",
       "      <td>1.342224</td>\n",
       "      <td>1.764860</td>\n",
       "      <td>-1.262442</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.853410</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "0    -21.546803  21.888236  35.503365   5.660160 -26.331832  12.379384   \n",
       "1    -20.467464  19.329678  32.364053   2.508690 -21.807530  17.990350   \n",
       "2    -21.553040  20.989382  38.002623   1.092770 -26.068214  27.985134   \n",
       "3    -20.476512  18.351236  31.250748   3.056882 -19.329919  21.239035   \n",
       "4    -19.851448  17.305678  31.264870  -1.355544 -20.816337  17.743847   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3483  19.630066 -15.683449  12.690731  11.001457   5.864286  -0.502606   \n",
       "3484  20.276515 -16.158580  15.039984  10.943144   6.525591  -2.079491   \n",
       "3485  19.438170 -15.359971  12.045600  11.126099   7.330382   2.191478   \n",
       "3486  19.689729 -15.832295  14.363464   7.040175   5.504524  -0.254022   \n",
       "3487  19.733764 -16.067463  13.702033   4.868005   5.918601   2.041495   \n",
       "\n",
       "             6          7          8         9  ...        99       100  \\\n",
       "0    -2.051919 -11.623255  14.491962  6.973156  ...  1.176430 -0.174391   \n",
       "1     0.487409  -9.238707  13.658044  7.049672  ...  0.625548 -0.692582   \n",
       "2    -1.260956  -7.937606   9.079073  7.710818  ...  0.225689 -1.950618   \n",
       "3     0.827941  -7.274807   1.728165  8.850672  ... -3.666576  1.314088   \n",
       "4    -5.031513  -5.767874   0.032634  6.729982  ... -3.138488  1.986231   \n",
       "...        ...        ...        ...       ...  ...       ...       ...   \n",
       "3483 -4.160596  -5.122368   0.070994 -0.752235  ... -0.897364 -1.091820   \n",
       "3484 -5.667626  -3.301163   1.249135 -1.241860  ...  1.227446  0.641690   \n",
       "3485 -3.713885  -2.973283   2.584260 -2.284411  ... -0.847139  1.112201   \n",
       "3486 -7.509943  -3.425864   3.682001  0.000207  ... -0.583045 -0.234759   \n",
       "3487 -6.626681  -3.216112   5.408380  0.370490  ... -0.120860 -0.716691   \n",
       "\n",
       "           101       102       103       104       105       106       107  \\\n",
       "0    -1.617762  4.851347 -0.986824 -1.731225 -1.716534 -0.851530  0.791756   \n",
       "1    -0.658485  2.364729 -0.955016 -0.220255 -0.306149  0.337637  1.535654   \n",
       "2     0.347227 -1.770900  0.365888  3.035515  0.782899  2.358052  0.764571   \n",
       "3     5.391434  0.970074 -0.903477  1.504675 -0.058709 -0.969687 -1.832201   \n",
       "4     4.660604  0.186040 -1.609785  0.459965  0.276084 -0.073639 -1.280689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  0.215364  0.031164  1.604445  1.208215  1.185574 -0.164827 -0.875868   \n",
       "3484 -0.004896  1.327845 -0.476281  0.262175  0.819836 -0.883276  0.580323   \n",
       "3485 -0.247291  0.126362 -1.244953  0.926688 -1.728047  2.350574 -0.696599   \n",
       "3486  0.037219 -1.112261 -0.376768  1.382167 -1.502369 -0.047295  0.733646   \n",
       "3487  0.970854 -0.946503  1.342224  1.764860 -1.262442  0.002509  0.853410   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.63402524213572\n",
      "Test score of trained model: 99.16232851533238\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca95b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7049610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>120438.291201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>347.042204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>173.404786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>5131.059186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.991623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.990087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  120438.291201\n",
       "1    RMSE     347.042204\n",
       "2     MAE     173.404786\n",
       "3    MAPE    5131.059186\n",
       "4      r2       0.991623\n",
       "5  adj_r2       0.990087"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503b773",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24cf974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.6339210972619\n",
      "Test score of trained model: 99.17341445018131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b92e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>118844.383477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>344.738138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>173.318432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.991734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.990219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  118844.383477\n",
       "1    RMSE     344.738138\n",
       "2     MAE     173.318432\n",
       "3      r2       0.991734\n",
       "4  adj_r2       0.990219"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3165c",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231a3187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.63402200580589\n",
      "Test score of trained model: 99.16810930011275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "443a6d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>119607.144560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>345.842659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>173.233786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.991681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.990156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  119607.144560\n",
       "1    RMSE     345.842659\n",
       "2     MAE     173.233786\n",
       "3      r2       0.991681\n",
       "4  adj_r2       0.990156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82420f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.99604736877407\n",
      "Test score of trained model: 99.32729925093858\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e421dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>96719.215336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>310.997131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>142.018099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.993273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.992040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  96719.215336\n",
       "1    RMSE    310.997131\n",
       "2     MAE    142.018099\n",
       "3      r2      0.993273\n",
       "4  adj_r2      0.992040"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.04, max_depth=4, n_estimators=1000,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9916075309517314\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be9cf7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9862626098595566\n",
      "   Metric          Score\n",
      "0     MSE  197512.727168\n",
      "1    RMSE     444.424040\n",
      "2     MAE     162.016793\n",
      "3      r2       0.986263\n",
      "4  adj_r2       0.983744\n",
      "Best Score: 0.9856355339819937\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9861024187244571\n",
      "   Metric          Score\n",
      "0     MSE  199815.914865\n",
      "1    RMSE     447.007735\n",
      "2     MAE     162.806562\n",
      "3      r2       0.986102\n",
      "4  adj_r2       0.983554\n",
      "Best Score: 0.9866784478008224\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9854595337556302\n",
      "   Metric          Score\n",
      "0     MSE  209059.152638\n",
      "1    RMSE     457.229868\n",
      "2     MAE     167.434797\n",
      "3      r2       0.985460\n",
      "4  adj_r2       0.982793\n",
      "Best Score: 0.9864587904118857\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9858797720593757\n",
      "   Metric          Score\n",
      "0     MSE  203017.072404\n",
      "1    RMSE     450.574159\n",
      "2     MAE     161.788496\n",
      "3      r2       0.985880\n",
      "4  adj_r2       0.983291\n",
      "Best Score: 0.9865184259559037\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.985476864812556\n",
      "   Metric          Score\n",
      "0     MSE  208809.971077\n",
      "1    RMSE     456.957297\n",
      "2     MAE     167.979026\n",
      "3      r2       0.985477\n",
      "4  adj_r2       0.982814\n",
      "Best Score: 0.9863899789541806\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56aa2f",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c38841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bbd4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02a481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 1965.0668 - mean_absolute_error: 1957.4308 - val_loss: 1200.8073 - val_mean_absolute_error: 1180.1183\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 390.8337 - mean_absolute_error: 367.2625 - val_loss: 203.6750 - val_mean_absolute_error: 179.4075\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 149.8680 - mean_absolute_error: 125.6887 - val_loss: 145.7970 - val_mean_absolute_error: 121.8610\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 125.0580 - mean_absolute_error: 101.2255 - val_loss: 137.0123 - val_mean_absolute_error: 113.1924\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 109.3572 - mean_absolute_error: 85.7191 - val_loss: 128.4426 - val_mean_absolute_error: 105.1214\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 101.4652 - mean_absolute_error: 78.1400 - val_loss: 116.5850 - val_mean_absolute_error: 93.3599\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 89.7978 - mean_absolute_error: 66.6848 - val_loss: 111.9333 - val_mean_absolute_error: 88.8123\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.7542 - mean_absolute_error: 62.8747 - val_loss: 130.5548 - val_mean_absolute_error: 107.9232\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 92.0565 - mean_absolute_error: 69.4307 - val_loss: 107.1474 - val_mean_absolute_error: 84.6712\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.6634 - mean_absolute_error: 60.3189 - val_loss: 103.5873 - val_mean_absolute_error: 81.3800\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.6344 - mean_absolute_error: 60.5647 - val_loss: 110.9348 - val_mean_absolute_error: 89.1115\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 83.2886 - mean_absolute_error: 61.5320 - val_loss: 102.3929 - val_mean_absolute_error: 80.6745\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.4395 - mean_absolute_error: 52.8970 - val_loss: 97.9301 - val_mean_absolute_error: 76.5106\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.6790 - mean_absolute_error: 51.3435 - val_loss: 94.8246 - val_mean_absolute_error: 73.6340\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.8244 - mean_absolute_error: 52.7439 - val_loss: 107.1805 - val_mean_absolute_error: 86.3510\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.6035 - mean_absolute_error: 49.7758 - val_loss: 99.2767 - val_mean_absolute_error: 78.5471\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.8354 - mean_absolute_error: 48.1907 - val_loss: 91.5987 - val_mean_absolute_error: 71.0643\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.2245 - mean_absolute_error: 46.7954 - val_loss: 99.9775 - val_mean_absolute_error: 79.6177\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.1458 - mean_absolute_error: 47.9242 - val_loss: 88.4481 - val_mean_absolute_error: 68.2619\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.8776 - mean_absolute_error: 45.8456 - val_loss: 99.8747 - val_mean_absolute_error: 79.9524\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.4620 - mean_absolute_error: 48.6517 - val_loss: 91.4138 - val_mean_absolute_error: 71.8061\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3366 - mean_absolute_error: 43.7305 - val_loss: 86.6171 - val_mean_absolute_error: 67.1338\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.8630 - mean_absolute_error: 44.4254 - val_loss: 87.8921 - val_mean_absolute_error: 68.6000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.4665 - mean_absolute_error: 44.1950 - val_loss: 96.2703 - val_mean_absolute_error: 77.1155\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4919 - mean_absolute_error: 42.3996 - val_loss: 92.1621 - val_mean_absolute_error: 73.1791\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.8638 - mean_absolute_error: 42.9506 - val_loss: 92.0753 - val_mean_absolute_error: 73.2596\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.4307 - mean_absolute_error: 38.7153 - val_loss: 87.6480 - val_mean_absolute_error: 69.0731\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.7390 - mean_absolute_error: 42.1354 - val_loss: 83.4018 - val_mean_absolute_error: 64.9046\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.6449 - mean_absolute_error: 39.2679 - val_loss: 84.9706 - val_mean_absolute_error: 66.6783\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.5994 - mean_absolute_error: 39.3659 - val_loss: 87.0346 - val_mean_absolute_error: 68.9471\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.4187 - mean_absolute_error: 43.3857 - val_loss: 91.5656 - val_mean_absolute_error: 73.6282\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.0176 - mean_absolute_error: 39.0696 - val_loss: 89.9415 - val_mean_absolute_error: 72.0362\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1613 - mean_absolute_error: 35.3705 - val_loss: 97.9938 - val_mean_absolute_error: 80.1388\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.4441 - mean_absolute_error: 38.8218 - val_loss: 78.7592 - val_mean_absolute_error: 61.2457\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.9823 - mean_absolute_error: 34.5279 - val_loss: 76.6331 - val_mean_absolute_error: 59.2681\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.3150 - mean_absolute_error: 37.0049 - val_loss: 88.9710 - val_mean_absolute_error: 71.6454\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.9442 - mean_absolute_error: 36.7837 - val_loss: 82.4506 - val_mean_absolute_error: 65.3916\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.3874 - mean_absolute_error: 35.4065 - val_loss: 81.3357 - val_mean_absolute_error: 64.4384\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1874 - mean_absolute_error: 34.3028 - val_loss: 86.9932 - val_mean_absolute_error: 70.2811\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.6665 - mean_absolute_error: 36.9745 - val_loss: 80.0155 - val_mean_absolute_error: 63.3742\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.7046 - mean_absolute_error: 35.1573 - val_loss: 78.2376 - val_mean_absolute_error: 61.7239\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.6399 - mean_absolute_error: 36.1944 - val_loss: 77.7415 - val_mean_absolute_error: 61.3737\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.2688 - mean_absolute_error: 37.0008 - val_loss: 83.0562 - val_mean_absolute_error: 66.7910\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3484 - mean_absolute_error: 34.1738 - val_loss: 77.1120 - val_mean_absolute_error: 60.9633\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.6697 - mean_absolute_error: 32.6218 - val_loss: 76.7230 - val_mean_absolute_error: 60.7657\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.1236 - mean_absolute_error: 32.2257 - val_loss: 76.8279 - val_mean_absolute_error: 60.9767\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9973 - mean_absolute_error: 33.2614 - val_loss: 77.1989 - val_mean_absolute_error: 61.5012\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1801 - mean_absolute_error: 37.4965 - val_loss: 77.1816 - val_mean_absolute_error: 61.5284\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 48.1051 - mean_absolute_error: 32.5004 - val_loss: 91.6576 - val_mean_absolute_error: 75.9890\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.0435 - mean_absolute_error: 36.6026 - val_loss: 82.3076 - val_mean_absolute_error: 67.0184\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.4314 - mean_absolute_error: 31.1529 - val_loss: 78.0658 - val_mean_absolute_error: 62.7106\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8480 - mean_absolute_error: 31.6667 - val_loss: 74.1584 - val_mean_absolute_error: 59.0626\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9672 - mean_absolute_error: 31.8653 - val_loss: 74.4742 - val_mean_absolute_error: 59.3838\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.0724 - mean_absolute_error: 31.0353 - val_loss: 81.0678 - val_mean_absolute_error: 65.9566\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4814 - mean_absolute_error: 32.5256 - val_loss: 72.6901 - val_mean_absolute_error: 57.7146\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9035 - mean_absolute_error: 34.0274 - val_loss: 77.5588 - val_mean_absolute_error: 62.7033\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.7672 - mean_absolute_error: 37.0391 - val_loss: 76.8242 - val_mean_absolute_error: 62.1624\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.4646 - mean_absolute_error: 29.8123 - val_loss: 75.7090 - val_mean_absolute_error: 61.1525\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1433 - mean_absolute_error: 34.5841 - val_loss: 72.4137 - val_mean_absolute_error: 57.8849\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.9144 - mean_absolute_error: 35.4798 - val_loss: 103.7841 - val_mean_absolute_error: 89.5769\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.1269 - mean_absolute_error: 34.7932 - val_loss: 74.3277 - val_mean_absolute_error: 60.0796\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.5574 - mean_absolute_error: 27.3325 - val_loss: 72.7180 - val_mean_absolute_error: 58.5176\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2647 - mean_absolute_error: 29.0692 - val_loss: 73.4664 - val_mean_absolute_error: 59.1894\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.6864 - mean_absolute_error: 27.6103 - val_loss: 70.8097 - val_mean_absolute_error: 56.7804\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9990 - mean_absolute_error: 30.9781 - val_loss: 67.5430 - val_mean_absolute_error: 53.5700\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3056 - mean_absolute_error: 32.3624 - val_loss: 83.6273 - val_mean_absolute_error: 69.8294\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.0467 - mean_absolute_error: 32.1835 - val_loss: 80.0332 - val_mean_absolute_error: 66.2656\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6806 - mean_absolute_error: 31.9318 - val_loss: 72.3306 - val_mean_absolute_error: 58.5625\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6029 - mean_absolute_error: 29.9125 - val_loss: 75.6853 - val_mean_absolute_error: 61.9933\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.5547 - mean_absolute_error: 30.9840 - val_loss: 70.8194 - val_mean_absolute_error: 57.3617\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7790 - mean_absolute_error: 28.2852 - val_loss: 77.8136 - val_mean_absolute_error: 64.3011\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.9189 - mean_absolute_error: 34.4908 - val_loss: 75.8212 - val_mean_absolute_error: 62.3289\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.0352 - mean_absolute_error: 30.6752 - val_loss: 73.2421 - val_mean_absolute_error: 59.8814\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9813 - mean_absolute_error: 29.6777 - val_loss: 73.5057 - val_mean_absolute_error: 60.1977\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7898 - mean_absolute_error: 28.5811 - val_loss: 77.6862 - val_mean_absolute_error: 64.5598\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.7033 - mean_absolute_error: 30.5463 - val_loss: 74.5573 - val_mean_absolute_error: 61.4815\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.8885 - mean_absolute_error: 27.8422 - val_loss: 69.6404 - val_mean_absolute_error: 56.6082\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.3928 - mean_absolute_error: 26.3926 - val_loss: 67.4931 - val_mean_absolute_error: 54.5890\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.5866 - mean_absolute_error: 27.7061 - val_loss: 68.4632 - val_mean_absolute_error: 55.5687\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.2971 - mean_absolute_error: 29.4445 - val_loss: 68.0710 - val_mean_absolute_error: 55.2050\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.6475 - mean_absolute_error: 29.8522 - val_loss: 70.0614 - val_mean_absolute_error: 57.3335\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.1136 - mean_absolute_error: 32.4273 - val_loss: 69.2224 - val_mean_absolute_error: 56.5934\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.7767 - mean_absolute_error: 27.1741 - val_loss: 62.0517 - val_mean_absolute_error: 49.4577\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.8402 - mean_absolute_error: 26.3025 - val_loss: 69.9403 - val_mean_absolute_error: 57.4658\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7396 - mean_absolute_error: 29.2783 - val_loss: 86.3297 - val_mean_absolute_error: 73.9476\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1240 - mean_absolute_error: 30.7292 - val_loss: 66.9909 - val_mean_absolute_error: 54.6237\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.3695 - mean_absolute_error: 26.0346 - val_loss: 64.3333 - val_mean_absolute_error: 51.9910\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.0300 - mean_absolute_error: 25.7738 - val_loss: 64.4044 - val_mean_absolute_error: 52.1491\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7972 - mean_absolute_error: 30.5963 - val_loss: 76.4870 - val_mean_absolute_error: 64.1674\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.3302 - mean_absolute_error: 27.1809 - val_loss: 69.3682 - val_mean_absolute_error: 57.2886\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.6399 - mean_absolute_error: 33.5500 - val_loss: 78.1007 - val_mean_absolute_error: 65.9605\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2316 - mean_absolute_error: 29.1812 - val_loss: 67.3199 - val_mean_absolute_error: 55.2700\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.1559 - mean_absolute_error: 26.1153 - val_loss: 66.4134 - val_mean_absolute_error: 54.4217\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 36.4740 - mean_absolute_error: 24.5118 - val_loss: 65.8014 - val_mean_absolute_error: 53.8315\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.1542 - mean_absolute_error: 26.2502 - val_loss: 63.9761 - val_mean_absolute_error: 52.1843\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.6596 - mean_absolute_error: 26.8659 - val_loss: 67.8802 - val_mean_absolute_error: 56.0294\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 37.7935 - mean_absolute_error: 26.0109 - val_loss: 68.7532 - val_mean_absolute_error: 56.9789\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.3508 - mean_absolute_error: 31.5860 - val_loss: 65.1100 - val_mean_absolute_error: 53.3947\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2989 - mean_absolute_error: 29.5998 - val_loss: 87.1938 - val_mean_absolute_error: 75.6885\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9426 - mean_absolute_error: 33.3425 - val_loss: 66.7956 - val_mean_absolute_error: 55.1717\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5b7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230d7e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxvUlEQVR4nO3deZycVZno8d9TS1f1mnS6O3tCmhCQABogsggqgkhAR/DqILjAeL2GuSMOzlUU7riM4zjD3HEb7ox4QSPggjIgwmhQAoLgYIAEYgghkE5ISGfrTnd676qu5bl/nFPd1Wt6Tce3nu/nU59UnXc7b72d5yzvqfOKqmKMMaYwhKY7A8YYY44eC/rGGFNALOgbY0wBsaBvjDEFxIK+McYUEAv6xhhTQCzomz95IqIicsIk7/MJEfkfk7lPY44FFvRNPyKyS0R6RKR6QPoLPrgumaZ81YpIVkRum47jj2SiBYTfPiEiHXmv/5zMPI4iD3eKyD8czWOa6WFB3wzlNeDq3AcROQ0omb7sAHANcBj4oIjEpjkvU+F6VS3Le/3ZUCuJSGQ0aSMZ6/omWCzom6H8EBdkc64F7s5fQURiIvJ1EXldRA6KyHdFpNgvqxSRX4pIo4gc9u8X5m37hIh8VUT+S0TaReSRgS2LAccSn58vAClgqIB4mYjsFJFDIvIvIhLy254gIr8TkVa/7Gd5+32LiDznlz0nIm8Z5vh/JyI/yvu8xLd6IiLyNeCtwL/5Gvq/+XXeICLrRKRZRF4RkSuHO7+RiMgFIlIvIp8XkQPAD3x+7hORH4lIG/AXIjJfRB7yx6sTkU8MyH+/9ceYh0/4fTb7Y8z36SIi3xKRBhFpE5EXReRUv+wyEdnqr+9eEfnseM7fTD4L+mYo64EKETlZRMLAVcCPBqxzC3AisAI4AVgAfMkvCwE/AI4DFgPdwL8N2P5DwMeA2UARMFJQOB9YCPwUuBdXCA30PmAlcAZwOfDfffpXgUeASr+P/wsgIrOAXwG3AlXAN4FfiUjVCPkYRFX/FniKvpr69SJSCqwDfuLP7yrgOyKyfCz7zjMXmIX7Plf7tMuB+4CZwI9x3009MB/4APCPInJh3j4Grj8qfh//BFwJzAN2+2MBvAt4G+7vYIZfp8kv+z5wnaqWA6cCvx3tMc3UsqBvhpOr7V8MvAzszS3wNe/VwN+oarOqtgP/iAtuqGqTqt6vql1+2deAtw/Y/w9U9VVV7cYF8hUj5OVa4GFVPYwLpKtEZPaAdf7Z5+V14Nv0dU+lcMFyvqomVPX3Pv3dwHZV/aGqplX1HmAbQ7cixuo9wC5V/YHf9wvA/cCfj7DNrSLSkvf6at6yLPBlVU367wvgD6r6C1XNAtXAecDn/TluAr5H/9Za7/p5+xiNDwNrVPV5VU0CNwPn+ns7KaAceAMgqvqyqu7326WA5SJSoaqHVfX5MRzTTCEL+mY4P8TVxv+CAV07QA2uj39jLkgBv/bpiEiJiPw/EdntuxOeBGb6VkPOgbz3XUDZUJnwXUZ/jq+dquofgNd93vLtyXu/G1fjBfgcIMCzIvKSiORaAPP9egzYbsFQ+Rij44Cz84M4LnjOHWGbv1bVmXmvL+Yta1TVxID18893PpArfHMGnkv++mPR73tS1Q5cbX6Bqv4W14L7d6BBRG4XkQq/6vuBy4Ddvnvt3HEe30wyC/pmSKq6G3dD9zLg5wMWH8J12ZySF6RmqGoucH8GOAk4W1UrcF0A4ILvWL0PqMB1jxzw/doLGNzFsyjv/WJgnz+PA6r6CVWdD1zn93OCX37cgH0sJq9Fk6eT/jeyBwbvgVPV7gF+NyCIl6nq/xzxTIc31FS4+Wn7gFkiUp6XNvBcxjudbr/vyXddVeX2raq3quqZwHJcN8+NPv05Vb0c1731C1xrzhwDLOibkXwcuFBVO/MTfZfCHcC3ct0sIrJARC7xq5TjCoUW33f+5Qnk4VpgDXAargtoBa4r403iRhXl3OhvIC8CbgB+5vP153k3kQ/jgl8WWAucKCIf8jdkP4gLXL8cIg+bgLeJyGIRmYHr4sh3EDg+7/Mv/b4/KiJR/3qziJw8vq9gZKq6B3ga+CcRiYvIG3HXbuB9mCMJ++1zryLgHuBjIrJC3KipfwSeUdVd/pzOFpEormBMAFkRKRKRD4vIDFVNAW2479wcAyzom2Gp6g5V3TDM4s8DdcB634XzKK52D65PvRjXIliP6/oZMxFZAFwEfNvX2HOvjX6f+bX9B4GNuAD9K9yNRIA3A8+ISAfwEHCDqu5U1SZc3/tncN0VnwPeo6qHBuZDVdfhCpHN/hgDC4Z/BT4gbqTSrb6b5V24exz7cF1Z/wyMNNQ0N/on99o4mu8oz9XAEn+8B3D3AB4d4z5uwhXWuddv/T6+iLsnsR9Yir93g2uB3YErTHfjvsd/8cs+Cuzyfxt/ieveMscAsYeoGGNM4bCavjHGFBAL+sYYU0As6BtjTAGxoG+MMQXkmJ94qbq6WpcsWTLd2TDGmD8ZGzduPKSqNUMtO+aD/pIlS9iwYbhRg8YYYwYSkYG/Nu9l3TvGGFNALOgbY0wBOWLQF5FFIvK4nxv7JRG5wafPEjdf+Hb/b6VPFxG51c+/vVlEzsjb17V+/e0iMtT0uMYYY6bQaPr008BnVPV5P6HTRhFZh5t98TFVvUVEbsL9hPvzwKXAMv86G7gNN+Ngbg6Wlbj5TzaKyEN+ulxjjJk0qVSK+vp6EomBk5MGSzweZ+HChUSj0VFvc8Sg7+fH3u/ft4vIy7hZDi8HLvCr3QU8gQv6lwN3q5vfYb2IzBSReX7ddaraDOALjlW4CZ2MMWbS1NfXU15ezpIlS3CPfwgeVaWpqYn6+npqa2tHvd2Y+vT9gxNOB54B5uQ9MOEAMMe/X0D/ubvrfdpw6UMdZ7WIbBCRDY2NjWPJojHGkEgkqKqqCmzABxARqqqqxtyaGXXQF5Ey3Ex7n1bVtvxlvlY/aTO3qertqrpSVVfW1Aw51NQYY0YU5ICfM55zHFXQ9/Nl3w/8WFVzD9Q46Ltt8P82+PS99H+gxUKfNlz6lLj1se387lVrJRhjTL7RjN4R3NzkL6vqN/MWPUTffObX4uYzz6Vf40fxnAO0+m6g3wDv8g+6qMTNN/6bSTqPQW57Yge/325B3xhz9LW0tPCd73xnzNtddtlltLS0TH6G8oympn8e7oEIF4rIJv+6DLgFuFhEtgPv9J/BPZFoJ+4BG3cAfwXgb+B+FXjOv/4+d1N3KkTCQipjzwowxhx9wwX9dDo94nZr165l5syZU5QrZzSjd37P8M82vWiI9RX45DD7WoN79N2Ui4ZDpLP2hDZjzNF30003sWPHDlasWEE0GiUej1NZWcm2bdt49dVXueKKK9izZw+JRIIbbriB1atXA33TznR0dHDppZdy/vnn8/TTT7NgwQIefPBBiouLJ5y3Y37unfGKhIS01fSNKXhf+c+X2Lqv7cgrjsHy+RV8+c9OGXb5LbfcwpYtW9i0aRNPPPEE7373u9myZUvv0Mo1a9Ywa9Ysuru7efOb38z73/9+qqqq+u1j+/bt3HPPPdxxxx1ceeWV3H///XzkIx+ZcN6DHfSzFvSNMdPvrLPO6jeW/tZbb+WBBx4AYM+ePWzfvn1Q0K+trWXFihUAnHnmmezatWtS8hLcoB8Okc5Y944xhW6kGvnRUlpa2vv+iSee4NFHH+UPf/gDJSUlXHDBBUOOtY/FYr3vw+Ew3d3dk5KXwE64FgkLKavpG2OmQXl5Oe3t7UMua21tpbKykpKSErZt28b69euPat4CW9OPhqymb4yZHlVVVZx33nmceuqpFBcXM2fOnN5lq1at4rvf/S4nn3wyJ510Euecc85RzVtgg34kbDdyjTHT5yc/+cmQ6bFYjIcffnjIZbl+++rqarZs2dKb/tnPfnbS8hXg7p2Qde8YY8wAgQ360ZBY944xxgwQ2KBv3TvGGDNYcIN+yH6Ra4wxAwU36Iftx1nGGDNQcIN+KGQTrhljzACBDfrRsN3INcZMj/FOrQzw7W9/m66urknOUZ/ABv1IOGTdO8aYaXEsB/3A/jgrGhJSVtM3xkyD/KmVL774YmbPns29995LMpnkfe97H1/5ylfo7OzkyiuvpL6+nkwmwxe/+EUOHjzIvn37eMc73kF1dTWPP/74pOctsEHfhmwaYwB4+CY48OLk7nPuaXDpLcMuzp9a+ZFHHuG+++7j2WefRVV573vfy5NPPkljYyPz58/nV7/6FeDm5JkxYwbf/OY3efzxx6murp7cPHujeVziGhFpEJEteWk/y3uK1i4R2eTTl4hId96y7+Ztc6aIvCgidSJyq0zxU4sj9hAVY8wx4JFHHuGRRx7h9NNP54wzzmDbtm1s376d0047jXXr1vH5z3+ep556ihkzZhyV/Iympn8n8G/A3bkEVf1g7r2IfANozVt/h6quGGI/twGfAJ7BPVJxFTD0BBSTIBKyxyUaYxixRn40qCo333wz11133aBlzz//PGvXruULX/gCF110EV/60pemPD9HrOmr6pPAkM+y9bX1K4F7RtqHiMwDKlR1vX+c4t3AFWPO7RhEQiEydiPXGDMN8qdWvuSSS1izZg0dHR0A7N27l4aGBvbt20dJSQkf+chHuPHGG3n++ecHbTsVJtqn/1bgoKpuz0urFZEXgDbgC6r6FLAAqM9bp96nDUlEVgOrARYvXjyujEXDdiPXGDM98qdWvvTSS/nQhz7EueeeC0BZWRk/+tGPqKur48YbbyQUChGNRrntttsAWL16NatWrWL+/PnH5I3cq+lfy98PLFbVJhE5E/iFiIz5sTWqejtwO8DKlSvHVV23X+QaY6bTwKmVb7jhhn6fly5dyiWXXDJou0996lN86lOfmrJ8jTvoi0gE+G/Ambk0VU0CSf9+o4jsAE4E9gIL8zZf6NOmTK57R1WZ4nvGxhjzJ2MiP856J7BNVXu7bUSkRkTC/v3xwDJgp6ruB9pE5Bx/H+Aa4MEJHPuIomEX6O1mrjHG9BnNkM17gD8AJ4lIvYh83C+6isE3cN8GbPZDOO8D/lJVczeB/wr4HlAH7GAKR+6AG7IJ2LBNYwqUGzMSbOM5xyN276jq1cOk/8UQafcD9w+z/gbg1DHmb9wiIavpG1Oo4vE4TU1NVFVVBbZ7V1VpamoiHo+PabvA/iI3mqvp2wgeYwrOwoULqa+vp7GxcbqzMqXi8TgLFy488op5Ahv0w76mb2P1jSk80WiU2tra6c7GMSmws2z23si1oG+MMb0CG/QjIeveMcaYgYIb9G3IpjHGDBLYoB+1IZvGGDNIYIN+bsimzalvjDF9Ahv0czV9m3TNGGP6BDbo5/r0bdI1Y4zpE9igH+79Ra7V9I0xJiewQT/XvWM/zjLGmD6BDfp2I9cYYwYLbNC3G7nGGDNYYIO+3cg1xpjBghv0Q1bTN8aYgQIb9HMTrlmfvjHG9Als0LcnZxljzGCjeVziGhFpEJEteWl/JyJ7RWSTf12Wt+xmEakTkVdE5JK89FU+rU5Ebpr8U+nPnpxljDGDjaamfyewaoj0b6nqCv9aCyAiy3HPzj3Fb/MdEQn7h6X/O3ApsBy42q87ZSL2EBVjjBlkNM/IfVJEloxyf5cDP1XVJPCaiNQBZ/lldaq6E0BEfurX3Tr2LI9OxIZsGmPMIBPp079eRDb77p9Kn7YA2JO3Tr1PGy59SCKyWkQ2iMiG8T7jMmpDNo0xZpDxBv3bgKXACmA/8I3JyhCAqt6uqitVdWVNTc249mFPzjLGmMHG9WB0VT2Yey8idwC/9B/3AovyVl3o0xghfUpE7clZxhgzyLhq+iIyL+/j+4DcyJ6HgKtEJCYitcAy4FngOWCZiNSKSBHuZu9D48/2qPJIOCQ2ZNMYY/IcsaYvIvcAFwDVIlIPfBm4QERWAArsAq4DUNWXRORe3A3aNPBJVc34/VwP/AYIA2tU9aXJPpmBIiGxH2cZY0ye0YzeuXqI5O+PsP7XgK8Nkb4WWDum3E1QNByy7h1jjMkT2F/kgnuQSsa6d4wxplegg340LKRsyKYxxvQKdNCPhEI2ZNMYY/IEO+iH7UauMcbkC3TQj4ZD1r1jjDF5Ah303ZBN694xxpicYAd9G7JpjDH9BDroR8P2i1xjjMkX6KAftl/kGmNMP4EO+tFQyGr6xhiTJ9BB34ZsGmNMfwEP+jZk0xhj8gU66EdtyKYxxvQT6KBv3TvGGNNfwIN+iJTdyDXGmF6BDvpRG7JpjDH9HDHoi8gaEWkQkS15af8iIttEZLOIPCAiM336EhHpFpFN/vXdvG3OFJEXRaRORG4VEZmSM8oTtlk2jTGmn9HU9O8EVg1IWwecqqpvBF4Fbs5btkNVV/jXX+al3wZ8Avfc3GVD7HPSuV/kWk3fGGNyjhj0VfVJoHlA2iOqmvYf1wMLR9qHf5B6haquV1UF7gauGFeOxyBiQd8YY/qZjD79/w48nPe5VkReEJHfichbfdoCoD5vnXqfNqUioRAp694xxpheR3ww+khE5G+BNPBjn7QfWKyqTSJyJvALETllHPtdDawGWLx48bjzF7Uhm8YY08+4a/oi8hfAe4AP+y4bVDWpqk3+/UZgB3AisJf+XUALfdqQVPV2VV2pqitramrGm0UiYZt7xxhj8o0r6IvIKuBzwHtVtSsvvUZEwv798bgbtjtVdT/QJiLn+FE71wAPTjj3RxANCamM4sskY4wpeEfs3hGRe4ALgGoRqQe+jButEwPW+ZGX6/1InbcBfy8iKSAL/KWq5m4C/xVuJFAx7h5A/n2AydewjRlpd+hMVomEp3yEqDHGHPOOGPRV9eohkr8/zLr3A/cPs2wDcOqYcjcRt7+dM+ZdCawinVUi4aN2ZGOMOWYF9xe5kRhR7QGwETzGGOMFOOjHiWgKcN07xhhjghz0w/k1fQv6xhgDQQ76kRgRH/Rt2KYxxjgBDvpxIlkf9K2mb4wxQKCDfqy3T99u5BpjjBPsoJ9NAtika8YY4wU66IezNmTTGGPyBTjox3uDvvXpG2OME9ygHy4iZN07xhjTT3CDfiROOJOr6Vv3jjHGQKCDfoxQrnvHavrGGAMEPehnXPeO3cg1xhinIIK+3cg1xhgnwEE/jmSSgNo0DMYY4wU46McQlAgZm3DNGGO84Ab9cAyAGCmr6RtjjDeqoC8ia0SkQUS25KXNEpF1IrLd/1vp00VEbhWROhHZLCJn5G1zrV9/u4hcO/mnkycSB3zQt5q+McYAo6/p3wmsGpB2E/CYqi4DHvOfAS7FPRB9GbAauA1cIYF7vu7ZwFnAl3MFxZSIuJp+ESkbsmmMMd6ogr6qPgk0D0i+HLjLv78LuCIv/W511gMzRWQecAmwTlWbVfUwsI7BBcnk8UE/Jin7cZYxxngT6dOfo6r7/fsDwBz/fgGwJ2+9ep82XPogIrJaRDaIyIbGxsbx5S7S16dvN3KNMcaZlBu5qqrApEVWVb1dVVeq6sqamprx7SS/T99u5BpjDDCxoH/Qd9vg/23w6XuBRXnrLfRpw6VPjbw+favpG2OMM5Gg/xCQG4FzLfBgXvo1fhTPOUCr7wb6DfAuEan0N3Df5dOmRji/T9+CvjHGAERGs5KI3ANcAFSLSD1uFM4twL0i8nFgN3ClX30tcBlQB3QBHwNQ1WYR+SrwnF/v71V14M3hyeO7d+Ji3TvGGJMzqqCvqlcPs+iiIdZV4JPD7GcNsGbUuZsI371TLGnr3jHGGC+4v8jNBf1QmozV9I0xBiiIoG83co0xJifAQd/16RdLxvr0jTHGC27QDxcBUGyjd4wxpldwg36uph+yG7nGGJMT4KDv+vRtyKYxxvQJbtAXgXDMfpxljDF5ghv0ASIx4qTtwejGGOMFPujHpIeMzadvjDFA4IN+nBhpUhb0jTEGCHrQDxf5xyVa944xxkDQg34kTpHdyDXGmF4BD/oxYvSQsiGbxhgDFEDQL9K01fSNMcYLfNCP0mNDNo0xxgt40I9TRA9pG71jjDFA4IN+jKimbZy+McZ44w76InKSiGzKe7WJyKdF5O9EZG9e+mV529wsInUi8oqIXDI5pzCCcIyoWveOMcbkjOpxiUNR1VeAFQAiEgb2Ag/gnon7LVX9ev76IrIcuAo4BZgPPCoiJ6pqZrx5OKKIC/p2I9cYY5zJ6t65CNihqrtHWOdy4KeqmlTV13APTj9rko4/tEiciNosm8YYkzNZQf8q4J68z9eLyGYRWSMilT5tAbAnb516nzaIiKwWkQ0isqGxsXH8uYrEiGiPzadvjDHehIO+iBQB7wX+wyfdBizFdf3sB74x1n2q6u2qulJVV9bU1Iw/c5EY0WyPTcNgjDHeZNT0LwWeV9WDAKp6UFUzqpoF7qCvC2cvsChvu4U+bepE4oTIkM2mp/Qwxhjzp2Iygv7V5HXtiMi8vGXvA7b49w8BV4lITERqgWXAs5Nw/OH55+SGMskpPYwxxvypGPfoHQARKQUuBq7LS/4/IrICUGBXbpmqviQi9wJbgTTwySkduQO9z8mNaopsVgmFZEoPZ4wxx7oJBX1V7QSqBqR9dIT1vwZ8bSLHHBP/nNwYKdJZpciCvjGmwAX8F7mupl9kD0c3xhgg8EHf9enHSNmwTWOMIfBB39X07elZxhjjBDzo9+/TN8aYQhfsoB/2QV9SNumaMcYQ9KDfr3vHavrGGBPwoJ/fvWM1fWOMCXjQ90M2rU/fGGOAwAd9P2RTrHvHGGMg8EG/r0/fbuQaY0zgg77r07fuHWOMcYId9MN9N3Ktpm+MMUEP+vmjd6xP3xhjAh70Q2Gyoai7kWtDNo0xJuBBH9BwEUU24ZoxxgAFEfRj1r1jjDHeZDwYfZeIvCgim0Rkg0+bJSLrRGS7/7fSp4uI3CoidSKyWUTOmOjxj6Q36Fv3jjHGTFpN/x2qukJVV/rPNwGPqeoy4DH/GdxD1Jf512rgtkk6/vAicfcQFavpG2PMlHXvXA7c5d/fBVyRl363OuuBmQMepD75IkVW0zfGGG8ygr4Cj4jIRhFZ7dPmqOp+//4AMMe/XwDsydu23qf1IyKrRWSDiGxobGycWO4icXtyljHGeBN6MLp3vqruFZHZwDoR2Za/UFVVRMYUcVX1duB2gJUrV04sWkdixOi0J2cZYwyTUNNX1b3+3wbgAeAs4GCu28b/2+BX3wssytt8oU+bMhKJ+QejW03fGGMmFPRFpFREynPvgXcBW4CHgGv9atcCD/r3DwHX+FE85wCted1AU0Kse8cYY3pNtHtnDvCAiOT29RNV/bWIPAfcKyIfB3YDV/r11wKXAXVAF/CxCR7/iCQatwejG2OMN6Ggr6o7gTcNkd4EXDREugKfnMgxx0oiMZtl0xhjvMD/IlciceI2944xxgAFEPTd6B37cZYxxkBBBP04RaTtRq4xxlAQQb+ImPRY944xxlAQQT9OlAzpdHq6c2KMMdOuAIK+e3pWJpWY5owYY8z0C37Q98/JbW5rn+aMGGPM9At+0Pc1/UOH26Y5I8YYM/0KIOjHAWhpaydjP9AyxhS4Agj6rqYfyvbQ0G79+saYwlYwQT9Gir2Hu6c5M8YYM70KIOi77p0YKeot6BtjClwBBH1f05cU9Ye7pjkzxhgzvYIf9P2Qzeo4VtM3xhS84Ad9X9OfXyYW9I0xBa8Agr7r059binXvGGMKXgEE/SIAZheH2NeSIGtj9Y0xBWzcQV9EFonI4yKyVUReEpEbfPrficheEdnkX5flbXOziNSJyCsicslknMAR+Zp+dbHSk8nS2JE8Koc1xphj0UQel5gGPqOqz/uHo28UkXV+2bdU9ev5K4vIcuAq4BRgPvCoiJyoqpkJ5OHIfNCvirmplesPdzGnIj6lhzTGmGPVuGv6qrpfVZ/379uBl4EFI2xyOfBTVU2q6mu4h6OfNd7jj5q/kVvp/rGbucaYgjYpffoisgQ4HXjGJ10vIptFZI2IVPq0BcCevM3qGaaQEJHVIrJBRDY0NjZOLHN+yOaMqGtQWNA3xhSyCQd9ESkD7gc+raptwG3AUmAFsB/4xlj3qaq3q+pKVV1ZU1MzsQyGIyBhotpDdVmRjeAxxhS0CQV9EYniAv6PVfXnAKp6UFUzqpoF7qCvC2cvsChv84U+bepF4pBOsqCyxGr6xpiCNpHROwJ8H3hZVb+Zlz4vb7X3AVv8+4eAq0QkJiK1wDLg2fEef0wiRZBOsrCy2IK+MaagTWT0znnAR4EXRWSTT/vfwNUisgJQYBdwHYCqviQi9wJbcSN/PjnlI3dyIsXQ3czCymLWbT1INquEQnJUDm2MMceScQd9Vf09MFTkXDvCNl8DvjbeY47bsovhj/dw4vmr6UlnOdSRZLYN2zTGFKDg/yIX4G03AnBu/fcB2GNdPMaYAlUYQX/mIjjzY8zbeT/HyQEbwWOMKViFEfQB3voZCBfx6cj9djPXGFOwCifol89Bzr6Oy8NP07Nvy5HXN8aYACqcoA9w3g0kpJhrXv0UO793LWx9EBJt050rY4w5agor6JfMInv1z9heegZVex6Be69B/08t3Pke+P234dD2kbdv2gGbfgKZ9FHJrjHGTDZRPbbnl1+5cqVu2LBhUveZzmS5Ze0WNj/9CB+s3MalsRcpObzNLVx8LpxxLSy/HIpK/AZJ+K9/hSe/Dpkk1L4N3r8GyiY4RYQxxkwBEdmoqiuHXFaIQT/ngRfq+ae122hoT3LFUuF/zfkji3b9B9K8AyQMs2qhahk01UHTdlh+BRx3Hqz7IhTPgj+/ExadBeJ/rpBOwt6NcPAlmPcmWHAmhMJHzkgm5Y4XKqyGlzFmaljQH0F3T4a7/7CL2363g5auFGWxMNfO28Oqkld4Q/Qg0cN1gMDFX3E/8gLY/0f42UehZTdES2HGQohXwIEXIZ3o23l8Jix9B8x9I1Sd4F65dcGt/9z3YfO9bqqI2rdB7dvh+Atg1vF9hUk2A/tecPlYcEZfOsDh3S4fC98M0eIp+57GLZ10+c+1msz4vfQAvL4e3vkViNqPC83wLOiPQnsixVPbD/H7ukM8XXeIXU1dFEVCXHrqXN77pvksrSljQWUxYRFea+pk647dzNz+c06MNzM704h0H3a1+yXnwZxTXY1/+zrY+QS07+t/sKIyKK6E1j1uMrhT3w8I7Hwc2vwcdOXzofatkOmBHY9DosWlVy2D0z8C5XNh04/htSddeiTuWiHHXwCzT4bqE2HGIsimINUF7Qfd/useg70boLQGKmuh8jj/zAFxrZKKBVC11BVQFQtHbn1ks9C+37WCDm2Hnk6IlUOswqXvfAJ2Pw0Sgou+BGd9YuiWTyYNzTtcfvzjLY8pDS/Drt+773f2yf0L3aNly8/h/o+DZuGEd8IHf2yBP2hysXgS/r4s6I/Dlr2t3LthD794YS9tCXfjNhwS4pEQnT39pwyqKY/x9hNrKIv1zWqRymRJZbKowsp5ES6saaemp94F9fYD0HHQdf+86WoomeU2UnU3i1/7Hex6ygWaUASWXgQnXAg9XfDCj2DPerd+5RJY8WGYexrs/B3UPeoCcC/BTYGUp2oZLD4Hug/D4V3Q8rrrXkIhm3avnHDMHWNWrctHst29Eq1u+0QrjDR9UvVJrqXTVOfytmAlrPon14qJz4TOBth4Fzx/lyskwjGY90aYtwKKZ7qWi4Sg8RXXKjr0qtt28Tmw6ByYscAVMPEKV+iF3DTatO5xXWwNWyFa4grj+StcgTbSfyjVvv94AAf+CE99A17+z760ylo4cZUL/rOOd6/yeUMXjtmsK8z2/xFmLh7c3Zfx33e4aOTC9ZWH4Wcfca25U/4bPPw5V7hffc/4WncHX4Jnb3ff98xFrnKw4AyXx9HIpN29rWjJ6AKUqmsBH+2WaP0G+O0/uIJy1S0wZ/nE9tfTCUWlk5O3gVpeh5+vdnHh8n+H494yod1Z0J+ARCrDH/e0sLu5iz3NXbQn0iyfX8GKRTOpKYvx5PZGHnnpIOt3NpHKZHu3i4ZDRMMh0tkshzp6AHjD3HIWzyqhPB6lPB4hq0oilSGRylIaizBvRpy5FXFmlRZRHo/0rlcej1AaixAJCcl0ltTBVwglWyipPRvxQURV6ezJkG5rYGbXLhco2/a6Wny01AXR485zNfvhqLoCqXmHq7kffg2ad0Lza25ZrMy3Uma6oF1cCRXzXEFSdQLEZ0BPhysYisrcstx+X7wPfv156GrKO6APGCe8E07+M1c41G9wAb6ng94Cq2yuK9iql7l87XkWkq1HvnjhmGvpaN91cfdOwq4wyf3ta9YVXvnr5cRnwFnXwWkfcK2Wbb9yratM3rOW84NnOOq6szI97jxyLTRw39nxb3fHPfSqK+Czqb58ReKu9h4tcetWzHeDBTbf61qP1zzoCrhNP4Ff/BXMXu4Kn1iZm1Qwm3LH1SyUVEHpbCib465D+Tx33Cf/BTb/zB0jFIZk3pDlyiWw5HxXeLbudQVxrBxqTnIFeHez616q3wDpbghF3d9CSZVrOZZWu+uu6vKQbHMVi+bXINXpCujyea6wrj7R7bdqmdu2uNJ919mU6xJMJ12BIv5a9XS47zLR2vedR2KuVRqf0XcOqnBwixt0sfUXbt/ZjPubfOv/cj/S9E/T60fVXdeNd0L9c66isPhcV6jv+j1s/437+1xwJrzxg67wHctAjnSPO4d00hWAsXL3vYnA1ofgoetdJaGkElr2wLmfhAu/OO7WnAX9aaSq1DV08NttDTy1/RCN7UnaEynak2nCIaE4GiYWCdGeSNPU2TOmfUdCwsySIorCQlNnD8m0C1qzSotYNruMJVWuVpLKZntnFg2LEAmHKI9HmFEcpSLuWieZrKLA3Io4tTWlLKkqpbsnw/7WBAfbEsSiIeZUxJlTEae0qK+2ergrRf3hLvY0u18511aXsqS6hJKiIeby62qGHb91/3Yfdv+ZT/uAa0kM/uJcAMv0uP8g+bIZF/w7G9zvLJJt/t6BrzmXz4XZp7j/sJkeFwT2bYLORhfcs2kf4MUHllBfK0Hyatwls+CNV/YPKrnjt9a7wrF5Z999ldZ6t18Ju/3VnORq5/Pe5ALGjsdciyxcBDVvgJoTXSDM9Lj8Z3pcV1yq230/bXuhbZ8LkFf9pK9FCK675+lb/fm3u23CUbdvEVe4Zob4ewrH4Ozr4Py/cfvrbnGF++vPuKC3+79c3ivmu5ZRogUat/nrFXaF7+JzoXyO2zbR4o7V2eS+354O9x1K2NXsZ9W661AyCzoaXEHSssddv1Tn4PyNmcDcU12eultcK7njoCvU3vLX8Jbr3Xf765vhxXuhqNz9fZTNdt99zqFX3fWMz3TdqgdedAVW7jtbcr67jnXr3LJcesS/QtG+77+o1P3NxMrd33rLbncdB7a6oyUuL807Yf7p8IE1rqBe90XYsMb9jXzit+NqXVjQ/xORTGdoaEtyuKuH9kTaFQ6JNB3JNB2JNKmsEo+GiEXCZLJZDnelaOlywb66LEZVaRHhkFDX0MErB9upP9xNSCASChEOCVlVMlkllVHaE6neQmIqzC6PsWhWCYsqiymNRTjYlmB/a4LuVIYlVaXUVpcypyJGa3eK5s4UbYkUIRHCApFwiNKiMKUx18IpKQq7wjEaoq3bFY4tXT3EIiFXcBVHUXXfXzLlutV6Mko6k6UkFmF2eYyacvf9lPkWVHE0TCQsRPwU2z3pLMl0lpauFLubOnm9uYu27hTH15SxbE4Z82cUs781wevNXTR39nB8TSknz6tgRnF0zN9NNqsk0hk6kmkOd6ZoaE/Q2J5kZkmUM4+b1W+f7YkUhzp66Em788qqEg2HKIqEmFkcpapsiForuEIz0eoD7T4XdLpbYPl73WCCsVCFzkMuiMfKxny+Q8pmoa3eFYa5SkCi1QXOSLG7t6PqC+lMXgtzBiCutpzqdgX67qdd7byozLWkat/uuuAG1sTrHoNXf+2+k85GV2AKbn8ls1xX6/LL+7qh2vb7gLyif+A9uBVefdhtn6u5Z1J9La1kh6uIJNpcC6byOJh5nHufKyQSra7wa33dtdje+tn+97PqHnUF8YV/O66v14K+GVIilaE9736FqrKvJcFrTZ3sPtRJie9ymlMR7y2QDrQlSKRcP74qVBRHWVRZzMLKEhRl16EudjZ28HpzF3t8C6CrJ83cGcXMmxEnFgmxq6mL1w51kEhlCYeEypIoFfEoimtxpDNZOnsydCbTpLOD/z5FoCIeJZl2XWNDKQqHiISF7lSG8f6Ji3DEbedWxImEhUzWFaguu26jaDhELOICdE/anVNXMk3XCHkSgZPnVjCzJMqOxg4OtiWHXtE7vqaUc4+v4tQFM0imXEHSncpQUhShtChMLBqmsT3Z22LrSKbp7snQ7a9hSCAk4grckHuVxSK9hWlI+grEeDRETXmM6jJXWG+ub2VzfSudyTQLK4tZNKuEORUx4tEwsYgrqIuLQhRHw4RDIdoSKdq6XWVjVmmR31cRZbEopTG3fk8m6/LXk6HdV3Y6kuneAi+dVVdR6OjhcFeKWaVR3jC3gjfMKWV2RTExXzno7snQ2J6koT1JS1eKrp40nckMRZEQS2tKWTq7jAUzi4n4c+7qybCjsYMdjR00tCWZUxFn3ow4ZfEIW/e18cf6FnY0dDJ3Rty3ZkuZ7/9v1JS7cx5IfX7TGSWddX/r7u8yREN7gpf3t/Py/ja6kmkqiqPMKI6SVWXv4W7qW7pRhW99cMUR/kqH+zuyoG+OMdms0tmTprQoMuwDbVSVZDpLIpWhqydDIpWhPB6lsiRKJOy6YZLpDG3daUKC+w8fCREJCeJvMKYzWZo6e3pbULlWU3cqQyqT7S1UisIhYtEQZbEIS6pKOa7KdVHtaurklQPtHGxLMH9mMYsqS6gsjbKjsZOt+9qoa+hAUcI+aIpI3882Mi5YJlNZYtGQb7FEKIuFe1swlaVF1JS5lsiBtgTPvtbMc7ua6UxmWFpTxvE1pb6wDFMUCSHgWzJZDrQmWL+zied2HaYj2XcDPiQwsKysLitidnmc8rhvORWFEfpaf1mFTNZ9H53JNC3dLkCr0ltwdacyHOroIZNVQgInzC7jtAUzmVEcpf5wF683d3Goo4dkKkMinSGVGRxbIiEhNsRgiLEoCoeYVVrEzJIoje3JMXeLjkdZLMLS2WU0tiXY15oYtDweDVEWi1IWC9OTztKeTNOZTA+6DjD4+gysXITEVSaWzi7jhx8/e1z5PaaCvoisAv4VCAPfU9VbRlrfgr4xI0tnsuxvTVAai1AWixANuxv+nck0iXSWqtKiIWui45HNKoe7eohHXcF1pHwl0q7mnslqb4EjIiRSriZ+qCNJZzLXQkm7FoLvziuLuUEMZbEIkbDrogyLEI+Gegt1gMb2JNsOtNHc6brBEukssUiI2eUxZpfHqSyNukI2GqYrlWFnYyd1DR0cbEv0ttBi0RDHV5dxwuxSZlfEaWhLsr+1m5auFCfPK+f46rLeykl3T4bXm7s40OZaTw1tCdoS6d6u2Fgk1Jv3WMTV7MMiZFR9qylDZUkRp8yfwcnzyqmIR2lPpmntSiECc2fEiYYn9kPNYyboi0gYeBW4GKgHngOuVtWtw21jQd8YY8ZmpKB/tH/3fxZQp6o7VbUH+Clw+VHOgzHGFKyjHfQXAHvyPtf7NGOMMUfBMTnDl4isFpENIrKhsbFxurNjjDGBcbSD/l5gUd7nhT6tH1W9XVVXqurKmhqbvtgYYybL0Q76zwHLRKRWRIqAq4CHjnIejDGmYI085mqSqWpaRK4HfoMbsrlGVV86mnkwxphCdlSDPoCqrgXWHu3jGmOMOUZv5BpjjJkax/w0DCLSCOwe5+bVwKFJzM6fgkI8ZyjM8y7Ec4bCPO+xnvNxqjrkKJhjPuhPhIhsGO5XaUFViOcMhXnehXjOUJjnPZnnbN07xhhTQCzoG2NMAQl60L99ujMwDQrxnKEwz7sQzxkK87wn7ZwD3advjDGmv6DX9I0xxuSxoG+MMQUkkEFfRFaJyCsiUiciN013fqaKiCwSkcdFZKuIvCQiN/j0WSKyTkS2+38rpzuvk01EwiLygoj80n+uFZFn/DX/mZ/bKVBEZKaI3Cci20TkZRE5N+jXWkT+xv9tbxGRe0QkHsRrLSJrRKRBRLbkpQ15bcW51Z//ZhE5YyzHClzQ90/n+nfgUmA5cLWILJ/eXE2ZNPAZVV0OnAN80p/rTcBjqroMeMx/DpobgJfzPv8z8C1VPQE4DHx8WnI1tf4V+LWqvgF4E+78A3utRWQB8NfASlU9FTdf11UE81rfCawakDbctb0UWOZfq4HbxnKgwAV9CujpXKq6X1Wf9+/bcUFgAe587/Kr3QVcMS0ZnCIishB4N/A9/1mAC4H7/CpBPOcZwNuA7wOoao+qthDwa42bH6xYRCJACbCfAF5rVX0SaB6QPNy1vRy4W531wEwRmTfaYwUx6Bfk07lEZAlwOvAMMEdV9/tFB4A505WvKfJt4HNA1n+uAlpUNe0/B/Ga1wKNwA98t9b3RKSUAF9rVd0LfB14HRfsW4GNBP9a5wx3bScU44IY9AuOiJQB9wOfVtW2/GXqxuQGZlyuiLwHaFDVjdOdl6MsApwB3KaqpwOdDOjKCeC1rsTVamuB+UApg7tACsJkXtsgBv1RPZ0rKEQkigv4P1bVn/vkg7nmnv+3YbryNwXOA94rIrtwXXcX4vq6Z/ouAAjmNa8H6lX1Gf/5PlwhEORr/U7gNVVtVNUU8HPc9Q/6tc4Z7tpOKMYFMegXzNO5fF/294GXVfWbeYseAq71768FHjzaeZsqqnqzqi5U1SW4a/tbVf0w8DjwAb9aoM4ZQFUPAHtE5CSfdBGwlQBfa1y3zjkiUuL/1nPnHOhrnWe4a/sQcI0fxXMO0JrXDXRkqhq4F3AZ8CqwA/jb6c7PFJ7n+bgm32Zgk39dhuvjfgzYDjwKzJruvE7R+V8A/NK/Px54FqgD/gOITXf+puB8VwAb/PX+BVAZ9GsNfAXYBmwBfgjEgnitgXtw9y1SuFbdx4e7toDgRijuAF7EjW4a9bFsGgZjjCkgQezeMcYYMwwL+sYYU0As6BtjTAGxoG+MMQXEgr4xxhQQC/rGGFNALOgbY0wB+f9BRjjQR2jNeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499443ac",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25abc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0acdbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42814980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 1991.7213 - mean_absolute_error: 1985.3949 - val_loss: 1212.0287 - val_mean_absolute_error: 1194.8143\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 358.4244 - mean_absolute_error: 338.1797 - val_loss: 198.2523 - val_mean_absolute_error: 177.4206\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 143.8562 - mean_absolute_error: 123.0688 - val_loss: 151.2395 - val_mean_absolute_error: 130.6354\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 120.5175 - mean_absolute_error: 99.9805 - val_loss: 121.9348 - val_mean_absolute_error: 101.5006\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 103.7561 - mean_absolute_error: 83.4289 - val_loss: 134.8551 - val_mean_absolute_error: 114.4655\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.9720 - mean_absolute_error: 76.8286 - val_loss: 115.4050 - val_mean_absolute_error: 95.2816\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 92.3659 - mean_absolute_error: 72.3738 - val_loss: 108.5986 - val_mean_absolute_error: 88.8089\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 88.0567 - mean_absolute_error: 68.3186 - val_loss: 108.0974 - val_mean_absolute_error: 88.3842\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.3609 - mean_absolute_error: 65.8132 - val_loss: 106.3940 - val_mean_absolute_error: 86.9509\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.2736 - mean_absolute_error: 57.9129 - val_loss: 108.6768 - val_mean_absolute_error: 89.4616\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.1515 - mean_absolute_error: 62.0053 - val_loss: 98.8886 - val_mean_absolute_error: 79.8639\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.9222 - mean_absolute_error: 55.9623 - val_loss: 100.3396 - val_mean_absolute_error: 81.4022\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.5737 - mean_absolute_error: 55.7901 - val_loss: 97.1198 - val_mean_absolute_error: 78.3950\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.7641 - mean_absolute_error: 50.2109 - val_loss: 108.4714 - val_mean_absolute_error: 89.9154\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.1591 - mean_absolute_error: 51.7714 - val_loss: 91.5601 - val_mean_absolute_error: 73.2117\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.9286 - mean_absolute_error: 48.6880 - val_loss: 93.7725 - val_mean_absolute_error: 75.7228\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.0825 - mean_absolute_error: 48.0195 - val_loss: 96.7426 - val_mean_absolute_error: 78.6268\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.5303 - mean_absolute_error: 47.6114 - val_loss: 92.8246 - val_mean_absolute_error: 75.0758\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.3975 - mean_absolute_error: 44.6920 - val_loss: 100.3461 - val_mean_absolute_error: 82.5736\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.3475 - mean_absolute_error: 46.7336 - val_loss: 90.1552 - val_mean_absolute_error: 72.6761\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.0291 - mean_absolute_error: 48.5876 - val_loss: 86.7367 - val_mean_absolute_error: 69.4141\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.7382 - mean_absolute_error: 47.4690 - val_loss: 79.2156 - val_mean_absolute_error: 62.0628\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.2242 - mean_absolute_error: 43.1410 - val_loss: 90.2592 - val_mean_absolute_error: 73.2155\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.8623 - mean_absolute_error: 43.9436 - val_loss: 94.2176 - val_mean_absolute_error: 77.3082\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.2456 - mean_absolute_error: 44.3868 - val_loss: 85.8102 - val_mean_absolute_error: 69.0715\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.0462 - mean_absolute_error: 46.3530 - val_loss: 81.7031 - val_mean_absolute_error: 65.0922\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.8441 - mean_absolute_error: 39.2492 - val_loss: 91.8939 - val_mean_absolute_error: 75.4649\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.1215 - mean_absolute_error: 39.7105 - val_loss: 79.0003 - val_mean_absolute_error: 62.6663\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.8283 - mean_absolute_error: 40.5435 - val_loss: 84.6374 - val_mean_absolute_error: 68.3715\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.0822 - mean_absolute_error: 36.8277 - val_loss: 79.1578 - val_mean_absolute_error: 62.9546\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.4387 - mean_absolute_error: 38.3663 - val_loss: 80.4732 - val_mean_absolute_error: 64.5500\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.6477 - mean_absolute_error: 38.7107 - val_loss: 94.4787 - val_mean_absolute_error: 78.7104\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1171 - mean_absolute_error: 37.2882 - val_loss: 81.8585 - val_mean_absolute_error: 66.0923\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.2633 - mean_absolute_error: 35.5279 - val_loss: 75.0200 - val_mean_absolute_error: 59.3187\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.7365 - mean_absolute_error: 40.0984 - val_loss: 79.1911 - val_mean_absolute_error: 63.5871\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.8109 - mean_absolute_error: 37.2807 - val_loss: 76.5601 - val_mean_absolute_error: 61.0400\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.0271 - mean_absolute_error: 36.6036 - val_loss: 78.5975 - val_mean_absolute_error: 63.3044\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.0026 - mean_absolute_error: 39.7145 - val_loss: 83.4544 - val_mean_absolute_error: 68.2002\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.5825 - mean_absolute_error: 38.4171 - val_loss: 83.0851 - val_mean_absolute_error: 68.0121\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.9697 - mean_absolute_error: 32.8494 - val_loss: 79.7338 - val_mean_absolute_error: 64.6178\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.8234 - mean_absolute_error: 36.8228 - val_loss: 87.6724 - val_mean_absolute_error: 72.7506\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.2458 - mean_absolute_error: 34.3907 - val_loss: 78.9552 - val_mean_absolute_error: 64.1694\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.2688 - mean_absolute_error: 34.5202 - val_loss: 77.3046 - val_mean_absolute_error: 62.6071\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4275 - mean_absolute_error: 32.7823 - val_loss: 76.4610 - val_mean_absolute_error: 61.8951\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.8843 - mean_absolute_error: 36.3554 - val_loss: 76.2439 - val_mean_absolute_error: 61.7875\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.1903 - mean_absolute_error: 37.7504 - val_loss: 73.8814 - val_mean_absolute_error: 59.4589\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.9571 - mean_absolute_error: 32.6338 - val_loss: 88.9218 - val_mean_absolute_error: 74.5477\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.6023 - mean_absolute_error: 36.3257 - val_loss: 75.3111 - val_mean_absolute_error: 61.0781\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 47.4826 - mean_absolute_error: 33.2935 - val_loss: 78.3764 - val_mean_absolute_error: 64.2526\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.6981 - mean_absolute_error: 35.5920 - val_loss: 74.3127 - val_mean_absolute_error: 60.1797\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1139 - mean_absolute_error: 32.0856 - val_loss: 75.9695 - val_mean_absolute_error: 62.0069\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.4663 - mean_absolute_error: 35.5771 - val_loss: 72.1227 - val_mean_absolute_error: 58.3108\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.2693 - mean_absolute_error: 32.4572 - val_loss: 76.5116 - val_mean_absolute_error: 62.7039\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6959 - mean_absolute_error: 37.9862 - val_loss: 73.9416 - val_mean_absolute_error: 60.2560\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.4191 - mean_absolute_error: 31.7467 - val_loss: 79.3946 - val_mean_absolute_error: 65.7695\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.4938 - mean_absolute_error: 36.9009 - val_loss: 81.3216 - val_mean_absolute_error: 67.7393\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.8476 - mean_absolute_error: 35.3152 - val_loss: 72.2048 - val_mean_absolute_error: 58.6670\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.1128 - mean_absolute_error: 31.6575 - val_loss: 83.3708 - val_mean_absolute_error: 69.9988\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.4131 - mean_absolute_error: 36.9977 - val_loss: 75.6248 - val_mean_absolute_error: 62.2783\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.8753 - mean_absolute_error: 39.5157 - val_loss: 70.9178 - val_mean_absolute_error: 57.6875\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.0097 - mean_absolute_error: 31.7455 - val_loss: 74.9100 - val_mean_absolute_error: 61.6978\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.7428 - mean_absolute_error: 29.5514 - val_loss: 71.5431 - val_mean_absolute_error: 58.4081\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.4276 - mean_absolute_error: 32.3149 - val_loss: 81.7004 - val_mean_absolute_error: 68.7079\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.5357 - mean_absolute_error: 38.5087 - val_loss: 71.9238 - val_mean_absolute_error: 58.9142\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2471 - mean_absolute_error: 30.3055 - val_loss: 74.8454 - val_mean_absolute_error: 61.9692\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.0784 - mean_absolute_error: 29.2296 - val_loss: 74.6685 - val_mean_absolute_error: 61.8090\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.4791 - mean_absolute_error: 27.6305 - val_loss: 67.2185 - val_mean_absolute_error: 54.3375\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.7360 - mean_absolute_error: 31.9596 - val_loss: 78.6229 - val_mean_absolute_error: 65.9295\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5507 - mean_absolute_error: 30.8329 - val_loss: 70.6543 - val_mean_absolute_error: 58.0028\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.7203 - mean_absolute_error: 32.1196 - val_loss: 77.2141 - val_mean_absolute_error: 64.7279\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.7377 - mean_absolute_error: 33.2138 - val_loss: 71.0512 - val_mean_absolute_error: 58.5669\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8691 - mean_absolute_error: 34.4014 - val_loss: 74.1636 - val_mean_absolute_error: 61.7545\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.2200 - mean_absolute_error: 27.7853 - val_loss: 70.1650 - val_mean_absolute_error: 57.7512\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.3852 - mean_absolute_error: 31.9773 - val_loss: 72.4352 - val_mean_absolute_error: 60.0535\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.8939 - mean_absolute_error: 29.6135 - val_loss: 73.3376 - val_mean_absolute_error: 61.0257\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2806 - mean_absolute_error: 29.0200 - val_loss: 70.4316 - val_mean_absolute_error: 58.2035\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.9854 - mean_absolute_error: 31.7893 - val_loss: 66.3438 - val_mean_absolute_error: 54.1800\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.4885 - mean_absolute_error: 30.3386 - val_loss: 85.0420 - val_mean_absolute_error: 73.0034\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.0560 - mean_absolute_error: 30.0036 - val_loss: 67.2184 - val_mean_absolute_error: 55.2162\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.0131 - mean_absolute_error: 32.0419 - val_loss: 70.9566 - val_mean_absolute_error: 58.9962\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6005 - mean_absolute_error: 31.6490 - val_loss: 69.3465 - val_mean_absolute_error: 57.4239\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.3685 - mean_absolute_error: 29.4810 - val_loss: 97.3488 - val_mean_absolute_error: 85.3968\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1116 - mean_absolute_error: 31.2674 - val_loss: 72.0806 - val_mean_absolute_error: 60.3517\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.1292 - mean_absolute_error: 30.3718 - val_loss: 69.2109 - val_mean_absolute_error: 57.5156\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.2732 - mean_absolute_error: 27.5599 - val_loss: 82.1435 - val_mean_absolute_error: 70.3636\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.1249 - mean_absolute_error: 29.4219 - val_loss: 66.3063 - val_mean_absolute_error: 54.6333\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.2854 - mean_absolute_error: 26.6384 - val_loss: 74.1207 - val_mean_absolute_error: 62.5470\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.5423 - mean_absolute_error: 29.9971 - val_loss: 69.8652 - val_mean_absolute_error: 58.3317\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.7842 - mean_absolute_error: 29.2752 - val_loss: 68.6507 - val_mean_absolute_error: 57.1426\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.3427 - mean_absolute_error: 30.8730 - val_loss: 69.8696 - val_mean_absolute_error: 58.4412\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.7444 - mean_absolute_error: 28.3251 - val_loss: 69.4201 - val_mean_absolute_error: 58.0519\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.5173 - mean_absolute_error: 28.1766 - val_loss: 71.8413 - val_mean_absolute_error: 60.5340\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.9611 - mean_absolute_error: 27.6466 - val_loss: 72.4096 - val_mean_absolute_error: 61.1302\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.2334 - mean_absolute_error: 27.9262 - val_loss: 74.8470 - val_mean_absolute_error: 63.5868\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.2162 - mean_absolute_error: 26.9611 - val_loss: 64.4655 - val_mean_absolute_error: 53.2346\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 39.2783 - mean_absolute_error: 28.1026 - val_loss: 68.4269 - val_mean_absolute_error: 57.3079\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.6703 - mean_absolute_error: 31.5614 - val_loss: 65.0713 - val_mean_absolute_error: 53.9504\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.7038 - mean_absolute_error: 30.5835 - val_loss: 71.0743 - val_mean_absolute_error: 60.0252\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.3662 - mean_absolute_error: 27.3407 - val_loss: 66.0971 - val_mean_absolute_error: 55.0571\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 38.0783 - mean_absolute_error: 27.0566 - val_loss: 72.9511 - val_mean_absolute_error: 62.0074\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60ee915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef7be0",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7876ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bb1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7ef457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 24.0994 - mse: 15693514.0000 - val_loss: 10.9292 - val_mse: 16956754.0000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 7.7270 - mse: 14798384.0000 - val_loss: 5.9999 - val_mse: 15811780.0000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.7764 - mse: 13637864.0000 - val_loss: 4.1110 - val_mse: 14567734.0000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.3914 - mse: 12413785.0000 - val_loss: 3.0723 - val_mse: 13186252.0000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.5419 - mse: 11050705.0000 - val_loss: 2.3574 - val_mse: 11659177.0000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9890 - mse: 9611470.0000 - val_loss: 1.9205 - val_mse: 10238609.0000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6637 - mse: 8318754.0000 - val_loss: 1.6825 - val_mse: 8793764.0000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3928 - mse: 7003680.5000 - val_loss: 1.3670 - val_mse: 7460887.0000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2536 - mse: 6050481.0000 - val_loss: 1.2735 - val_mse: 6465085.5000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0929 - mse: 5118407.0000 - val_loss: 1.1084 - val_mse: 5515764.0000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9629 - mse: 4322310.5000 - val_loss: 1.0217 - val_mse: 4720153.0000\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9360 - mse: 3720055.5000 - val_loss: 0.9397 - val_mse: 4052763.5000\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8294 - mse: 3170772.5000 - val_loss: 0.9012 - val_mse: 3561325.5000\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8013 - mse: 2781834.2500 - val_loss: 0.8193 - val_mse: 3131601.7500\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7085 - mse: 2388812.0000 - val_loss: 0.7572 - val_mse: 2766836.2500\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6881 - mse: 2146549.7500 - val_loss: 0.8410 - val_mse: 2432318.2500\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6637 - mse: 1872987.0000 - val_loss: 0.6997 - val_mse: 2257774.0000\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6339 - mse: 1754439.7500 - val_loss: 0.6340 - val_mse: 2090661.1250\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5655 - mse: 1594273.2500 - val_loss: 0.5738 - val_mse: 1865849.7500\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5238 - mse: 1445805.2500 - val_loss: 0.5482 - val_mse: 1691972.8750\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4994 - mse: 1303088.2500 - val_loss: 0.5314 - val_mse: 1540490.3750\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5071 - mse: 1222792.8750 - val_loss: 0.5161 - val_mse: 1404109.1250\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4761 - mse: 1118902.8750 - val_loss: 0.4640 - val_mse: 1317465.1250\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4354 - mse: 984997.7500 - val_loss: 0.4513 - val_mse: 1248821.1250\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4155 - mse: 944254.0625 - val_loss: 0.4318 - val_mse: 1149523.3750\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3986 - mse: 869735.3750 - val_loss: 0.4157 - val_mse: 1028819.9375\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3903 - mse: 802953.5625 - val_loss: 0.4080 - val_mse: 975637.8125\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4410 - mse: 760814.5000 - val_loss: 0.4167 - val_mse: 924400.6250\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3879 - mse: 716090.8750 - val_loss: 0.3834 - val_mse: 879431.3125\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3650 - mse: 660329.7500 - val_loss: 0.3676 - val_mse: 814238.2500\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3512 - mse: 621963.5000 - val_loss: 0.3553 - val_mse: 734327.3750\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3400 - mse: 570133.2500 - val_loss: 0.3473 - val_mse: 697730.8125\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3331 - mse: 546077.2500 - val_loss: 0.3405 - val_mse: 670946.3125\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3258 - mse: 516133.2188 - val_loss: 0.3328 - val_mse: 645707.7500\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3335 - mse: 502865.0312 - val_loss: 0.3305 - val_mse: 614461.3750\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3277 - mse: 483732.0000 - val_loss: 0.3505 - val_mse: 659511.3125\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3242 - mse: 467496.3750 - val_loss: 0.3261 - val_mse: 595458.2500\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3071 - mse: 450499.7188 - val_loss: 0.3196 - val_mse: 568712.8750\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3017 - mse: 434821.0938 - val_loss: 0.3036 - val_mse: 541512.0000\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2945 - mse: 431223.1875 - val_loss: 0.3026 - val_mse: 509834.9062\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2875 - mse: 392464.9375 - val_loss: 0.2908 - val_mse: 526725.0625\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2838 - mse: 394800.9688 - val_loss: 0.2984 - val_mse: 477487.8750\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 381907.8438 - val_loss: 0.2808 - val_mse: 483477.5625\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2698 - mse: 363488.0000 - val_loss: 0.2761 - val_mse: 466657.5312\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2624 - mse: 362744.9375 - val_loss: 0.2656 - val_mse: 436108.5625\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2578 - mse: 339488.5000 - val_loss: 0.2666 - val_mse: 441830.7812\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2493 - mse: 334555.2812 - val_loss: 0.2519 - val_mse: 431976.4062\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2429 - mse: 327374.6875 - val_loss: 0.2503 - val_mse: 391282.6875\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2387 - mse: 316059.9688 - val_loss: 0.2455 - val_mse: 421200.7188\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2333 - mse: 292381.2188 - val_loss: 0.2371 - val_mse: 374728.7812\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2293 - mse: 291815.4062 - val_loss: 0.2870 - val_mse: 428773.0000\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2579 - mse: 312752.9688 - val_loss: 0.2347 - val_mse: 351350.9062\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2185 - mse: 266783.7812 - val_loss: 0.2189 - val_mse: 337548.6250\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2083 - mse: 261893.7031 - val_loss: 0.2119 - val_mse: 314864.1250\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1980 - mse: 246657.4844 - val_loss: 0.2035 - val_mse: 290105.0000\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1899 - mse: 220111.0312 - val_loss: 0.1963 - val_mse: 295918.9688\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1838 - mse: 218273.1562 - val_loss: 0.1867 - val_mse: 295507.4375\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1776 - mse: 211860.5938 - val_loss: 0.1864 - val_mse: 276741.5312\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1725 - mse: 202761.3438 - val_loss: 0.1818 - val_mse: 259463.6875\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1699 - mse: 188810.3125 - val_loss: 0.1776 - val_mse: 237116.8438\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1629 - mse: 183565.6406 - val_loss: 0.1724 - val_mse: 222421.4062\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1608 - mse: 176686.9062 - val_loss: 0.2128 - val_mse: 202132.7656\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1995 - mse: 189704.3125 - val_loss: 0.1894 - val_mse: 239808.4062\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1670 - mse: 170748.9688 - val_loss: 0.1729 - val_mse: 211922.4219\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1566 - mse: 161388.0781 - val_loss: 0.1681 - val_mse: 183986.9062\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1518 - mse: 149694.8438 - val_loss: 0.1597 - val_mse: 190758.7969\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1491 - mse: 148098.7031 - val_loss: 0.1569 - val_mse: 192263.6562\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1483 - mse: 143521.1875 - val_loss: 0.1551 - val_mse: 192028.5000\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1569 - mse: 142885.4844 - val_loss: 0.1669 - val_mse: 171214.3125\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1551 - mse: 137193.0000 - val_loss: 0.1565 - val_mse: 187547.7188\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1480 - mse: 134170.8281 - val_loss: 0.1522 - val_mse: 152587.2188\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1417 - mse: 122878.2344 - val_loss: 0.1426 - val_mse: 148520.1094\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1384 - mse: 115235.8828 - val_loss: 0.1448 - val_mse: 149268.7969\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1374 - mse: 116321.9922 - val_loss: 0.1428 - val_mse: 150203.0938\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1344 - mse: 110935.8750 - val_loss: 0.1393 - val_mse: 149632.7969\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1325 - mse: 110191.5078 - val_loss: 0.1352 - val_mse: 143470.3438\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1303 - mse: 104227.6406 - val_loss: 0.1333 - val_mse: 135754.6406\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1276 - mse: 101820.6016 - val_loss: 0.1307 - val_mse: 143033.3906\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1235 - mse: 99055.5000 - val_loss: 0.1270 - val_mse: 127621.0000\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1227 - mse: 98318.1172 - val_loss: 0.1274 - val_mse: 117431.4531\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1178 - mse: 91249.7266 - val_loss: 0.1220 - val_mse: 112668.7422\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1156 - mse: 87927.6953 - val_loss: 0.1223 - val_mse: 116797.3594\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1147 - mse: 85938.9141 - val_loss: 0.1183 - val_mse: 109591.3281\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1135 - mse: 84471.4766 - val_loss: 0.1206 - val_mse: 120064.6562\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1184 - mse: 81114.2969 - val_loss: 0.1270 - val_mse: 113324.5078\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1151 - mse: 81711.7188 - val_loss: 0.1225 - val_mse: 107768.6953\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1156 - mse: 81381.7422 - val_loss: 0.1545 - val_mse: 109370.1094\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1204 - mse: 76814.3047 - val_loss: 0.1207 - val_mse: 98148.7188\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1143 - mse: 77185.9609 - val_loss: 0.1151 - val_mse: 99413.4375\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1125 - mse: 74259.2578 - val_loss: 0.1113 - val_mse: 95504.8203\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1096 - mse: 70996.4609 - val_loss: 0.1164 - val_mse: 94077.9375\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1082 - mse: 71522.7500 - val_loss: 0.1113 - val_mse: 87497.0625\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1100 - mse: 67718.2188 - val_loss: 0.1131 - val_mse: 85059.0469\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1083 - mse: 70386.4766 - val_loss: 0.1107 - val_mse: 72909.3359\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1105 - mse: 66348.1172 - val_loss: 0.1310 - val_mse: 70203.6328\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1166 - mse: 64674.6875 - val_loss: 0.1245 - val_mse: 95459.8438\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1094 - mse: 67815.6094 - val_loss: 0.1154 - val_mse: 76042.8906\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1069 - mse: 62760.6250 - val_loss: 0.1134 - val_mse: 79254.9531\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1059 - mse: 63130.2852 - val_loss: 0.1116 - val_mse: 82399.9453\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1160 - mse: 62337.2109 - val_loss: 0.1481 - val_mse: 74653.5703\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac759f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a571c33",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264cbb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a713473",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0f8e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11637935.0000 - mse: 11637914.0000 - val_loss: 737571.5625 - val_mse: 737525.9375\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 290684.2812 - mse: 290638.7812 - val_loss: 241755.4688 - val_mse: 241710.0000\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 91443.8984 - mse: 91398.0938 - val_loss: 144441.7969 - val_mse: 144395.8906\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 51230.8555 - mse: 51184.6836 - val_loss: 104608.1016 - val_mse: 104561.7344\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 35627.0234 - mse: 35580.5430 - val_loss: 86458.3828 - val_mse: 86411.5781\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 29629.0391 - mse: 29581.9609 - val_loss: 73463.1797 - val_mse: 73415.9453\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 27259.6289 - mse: 27212.1680 - val_loss: 71579.6484 - val_mse: 71532.0234\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 23282.1816 - mse: 23234.4980 - val_loss: 66644.9297 - val_mse: 66597.1250\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 21012.1309 - mse: 20964.2754 - val_loss: 70537.1250 - val_mse: 70489.3125\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 20649.3906 - mse: 20601.3633 - val_loss: 72903.6250 - val_mse: 72855.4375\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17757.4668 - mse: 17709.3496 - val_loss: 66117.9688 - val_mse: 66069.9844\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17502.5879 - mse: 17454.3594 - val_loss: 64113.3906 - val_mse: 64064.8945\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15860.5928 - mse: 15812.2148 - val_loss: 61369.3125 - val_mse: 61320.8086\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14434.6484 - mse: 14386.1602 - val_loss: 53224.3867 - val_mse: 53175.7734\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13942.1436 - mse: 13893.5068 - val_loss: 58421.7539 - val_mse: 58373.0742\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16214.1416 - mse: 16165.3584 - val_loss: 62225.8867 - val_mse: 62176.8906\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15142.4375 - mse: 15093.5713 - val_loss: 58785.6172 - val_mse: 58736.6641\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17619.5762 - mse: 17570.5859 - val_loss: 61834.3945 - val_mse: 61785.3242\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19368.3613 - mse: 19319.3594 - val_loss: 67106.6797 - val_mse: 67057.8750\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13755.7441 - mse: 13706.6377 - val_loss: 54851.5742 - val_mse: 54802.3867\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13463.2285 - mse: 13413.9990 - val_loss: 58992.9258 - val_mse: 58943.4844\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11895.9756 - mse: 11846.6465 - val_loss: 58126.4062 - val_mse: 58077.0039\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14202.2090 - mse: 14152.7910 - val_loss: 57346.0508 - val_mse: 57296.6641\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13680.9580 - mse: 13631.3672 - val_loss: 47520.6953 - val_mse: 47471.0469\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11488.7490 - mse: 11439.0518 - val_loss: 62609.5117 - val_mse: 62559.9297\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9636.4746 - mse: 9586.6914 - val_loss: 52345.5391 - val_mse: 52295.6875\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14081.3447 - mse: 14031.4668 - val_loss: 65096.9766 - val_mse: 65046.8242\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17628.8301 - mse: 17578.8633 - val_loss: 56601.9141 - val_mse: 56551.7773\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9566.0693 - mse: 9516.0127 - val_loss: 49294.7617 - val_mse: 49244.6133\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8642.2568 - mse: 8592.1006 - val_loss: 50349.5273 - val_mse: 50299.2383\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8993.7305 - mse: 8943.4854 - val_loss: 58397.2812 - val_mse: 58346.9844\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17506.9453 - mse: 17456.6152 - val_loss: 52308.7852 - val_mse: 52258.4141\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12371.1357 - mse: 12320.7324 - val_loss: 66457.0000 - val_mse: 66406.3672\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10234.1680 - mse: 10183.6914 - val_loss: 54200.5859 - val_mse: 54150.0000\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9483.3643 - mse: 9432.8320 - val_loss: 55451.7500 - val_mse: 55401.2617\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7916.7983 - mse: 7866.1909 - val_loss: 45843.0352 - val_mse: 45792.3906\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8870.9873 - mse: 8820.2949 - val_loss: 50826.7031 - val_mse: 50776.0859\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7576.1440 - mse: 7525.3779 - val_loss: 45653.5859 - val_mse: 45602.7500\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9577.5898 - mse: 9526.7979 - val_loss: 51156.0742 - val_mse: 51105.2461\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7228.4795 - mse: 7177.6201 - val_loss: 47584.5898 - val_mse: 47533.8320\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6904.4043 - mse: 6853.5068 - val_loss: 48895.2891 - val_mse: 48844.2656\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12628.2344 - mse: 12577.2676 - val_loss: 49840.9961 - val_mse: 49790.0547\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9426.1562 - mse: 9375.1689 - val_loss: 50811.1602 - val_mse: 50760.1445\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15115.0752 - mse: 15064.0596 - val_loss: 44622.9648 - val_mse: 44572.0312\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10383.4873 - mse: 10332.4346 - val_loss: 46780.2539 - val_mse: 46729.1406\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7411.4653 - mse: 7360.3408 - val_loss: 44243.2148 - val_mse: 44191.9766\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6885.1172 - mse: 6833.9482 - val_loss: 65775.2812 - val_mse: 65724.3750\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8337.2832 - mse: 8286.0596 - val_loss: 40960.4258 - val_mse: 40909.2031\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7504.0596 - mse: 7452.7896 - val_loss: 44403.6641 - val_mse: 44352.3281\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5997.0562 - mse: 5945.7314 - val_loss: 42635.1914 - val_mse: 42583.7852\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6022.0698 - mse: 5970.6206 - val_loss: 40825.4492 - val_mse: 40773.9609\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8550.5957 - mse: 8499.1318 - val_loss: 45678.9766 - val_mse: 45627.7266\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9792.2842 - mse: 9740.7949 - val_loss: 44362.5000 - val_mse: 44310.9531\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7607.6997 - mse: 7556.1748 - val_loss: 42468.3320 - val_mse: 42416.7031\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7622.7197 - mse: 7571.1611 - val_loss: 42129.5703 - val_mse: 42077.9805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10061.0840 - mse: 10009.4756 - val_loss: 40352.2812 - val_mse: 40300.7461\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6550.5996 - mse: 6498.9844 - val_loss: 46900.2969 - val_mse: 46848.5430\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8891.4648 - mse: 8839.7939 - val_loss: 42769.8438 - val_mse: 42718.1953\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8295.1250 - mse: 8243.4229 - val_loss: 43553.5547 - val_mse: 43501.7109\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9075.2227 - mse: 9023.4854 - val_loss: 56145.3477 - val_mse: 56093.4375\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8746.4697 - mse: 8694.7012 - val_loss: 46707.6953 - val_mse: 46655.8477\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5464.7812 - mse: 5412.9805 - val_loss: 40447.0586 - val_mse: 40395.2578\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8853.2588 - mse: 8801.3965 - val_loss: 44572.9727 - val_mse: 44521.1992\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9541.5869 - mse: 9489.6826 - val_loss: 41380.3711 - val_mse: 41328.4258\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7694.5674 - mse: 7642.6235 - val_loss: 45057.2773 - val_mse: 45005.2734\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9101.5723 - mse: 9049.6191 - val_loss: 49964.1172 - val_mse: 49911.9609\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7697.1416 - mse: 7645.1064 - val_loss: 52711.0859 - val_mse: 52658.8477\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7812.8018 - mse: 7760.7148 - val_loss: 39611.2773 - val_mse: 39559.2266\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6413.1333 - mse: 6361.0820 - val_loss: 46130.1055 - val_mse: 46078.1367\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7185.3066 - mse: 7133.1963 - val_loss: 41388.0078 - val_mse: 41335.8477\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4289.6587 - mse: 4237.5225 - val_loss: 42172.9297 - val_mse: 42120.7070\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5487.5864 - mse: 5435.3979 - val_loss: 41292.9336 - val_mse: 41240.7227\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4749.8032 - mse: 4697.5352 - val_loss: 47445.6172 - val_mse: 47393.3750\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6791.0933 - mse: 6738.8184 - val_loss: 45065.5508 - val_mse: 45013.0781\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12458.0889 - mse: 12405.7402 - val_loss: 46971.2383 - val_mse: 46918.8047\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10237.4688 - mse: 10185.1533 - val_loss: 37541.6211 - val_mse: 37489.3125\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12010.4131 - mse: 11958.0957 - val_loss: 75443.4219 - val_mse: 75390.6641\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6002.5229 - mse: 5950.1562 - val_loss: 40939.2266 - val_mse: 40886.8398\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3517.6135 - mse: 3465.2156 - val_loss: 36287.4297 - val_mse: 36235.0000\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3630.4832 - mse: 3578.0100 - val_loss: 38720.6758 - val_mse: 38668.1523\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4055.0911 - mse: 4002.5449 - val_loss: 39964.5039 - val_mse: 39911.8398\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10716.2314 - mse: 10663.5811 - val_loss: 42183.2266 - val_mse: 42130.6406\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4844.6211 - mse: 4791.9028 - val_loss: 39877.3086 - val_mse: 39824.5156\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3091.2351 - mse: 3038.4619 - val_loss: 38222.7383 - val_mse: 38169.9609\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4661.0898 - mse: 4608.2739 - val_loss: 37418.6836 - val_mse: 37365.9531\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6226.3926 - mse: 6173.5830 - val_loss: 41924.9141 - val_mse: 41872.1133\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4919.6807 - mse: 4866.8315 - val_loss: 40283.4102 - val_mse: 40230.5430\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9150.2090 - mse: 9097.3184 - val_loss: 43598.8750 - val_mse: 43545.9023\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8809.5811 - mse: 8756.7207 - val_loss: 41391.3125 - val_mse: 41338.4141\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7329.2969 - mse: 7276.3833 - val_loss: 42827.7305 - val_mse: 42774.7539\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8542.6982 - mse: 8489.7881 - val_loss: 49606.8438 - val_mse: 49553.8477\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8291.7295 - mse: 8238.8057 - val_loss: 44446.0820 - val_mse: 44393.1367\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8746.6816 - mse: 8693.7266 - val_loss: 35642.6562 - val_mse: 35589.7461\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5596.0273 - mse: 5543.0811 - val_loss: 37037.4180 - val_mse: 36984.3945\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5524.0903 - mse: 5471.0957 - val_loss: 41007.6211 - val_mse: 40954.7773\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3825.6621 - mse: 3772.6567 - val_loss: 39756.5781 - val_mse: 39703.6562\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2208.6902 - mse: 2155.6321 - val_loss: 32356.0820 - val_mse: 32303.0820\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4339.0854 - mse: 4285.9873 - val_loss: 40199.4062 - val_mse: 40146.3516\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4590.1177 - mse: 4536.9780 - val_loss: 37551.1953 - val_mse: 37498.0195\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5213.0029 - mse: 5159.7896 - val_loss: 50708.4375 - val_mse: 50655.3672\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9854663e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
