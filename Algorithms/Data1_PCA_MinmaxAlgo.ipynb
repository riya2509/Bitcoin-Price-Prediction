{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_12116\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedd650",
   "metadata": {},
   "source": [
    "### Reading the MINMAX PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.655104</td>\n",
       "      <td>0.802061</td>\n",
       "      <td>1.817268</td>\n",
       "      <td>-1.285273</td>\n",
       "      <td>-1.640494</td>\n",
       "      <td>1.700293</td>\n",
       "      <td>-1.001414</td>\n",
       "      <td>1.101779</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153301</td>\n",
       "      <td>-0.027586</td>\n",
       "      <td>0.225252</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.170539</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>0.146309</td>\n",
       "      <td>0.208756</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.614658</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>1.686412</td>\n",
       "      <td>-1.009045</td>\n",
       "      <td>-1.609771</td>\n",
       "      <td>1.699671</td>\n",
       "      <td>-0.747059</td>\n",
       "      <td>1.416030</td>\n",
       "      <td>-0.615753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261052</td>\n",
       "      <td>-0.121278</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.108756</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>0.147877</td>\n",
       "      <td>0.246103</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>1.104297</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.636358</td>\n",
       "      <td>0.825494</td>\n",
       "      <td>1.710698</td>\n",
       "      <td>-1.048296</td>\n",
       "      <td>-1.626373</td>\n",
       "      <td>1.841579</td>\n",
       "      <td>-0.698989</td>\n",
       "      <td>1.496502</td>\n",
       "      <td>-0.499075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356758</td>\n",
       "      <td>-0.111855</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>0.276770</td>\n",
       "      <td>0.029030</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.214689</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.641610</td>\n",
       "      <td>0.745754</td>\n",
       "      <td>1.603314</td>\n",
       "      <td>-1.195112</td>\n",
       "      <td>-0.952689</td>\n",
       "      <td>1.644297</td>\n",
       "      <td>-0.151961</td>\n",
       "      <td>1.282045</td>\n",
       "      <td>-0.588409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.076649</td>\n",
       "      <td>0.157377</td>\n",
       "      <td>-0.213748</td>\n",
       "      <td>0.256696</td>\n",
       "      <td>0.187187</td>\n",
       "      <td>0.140654</td>\n",
       "      <td>0.291811</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.646880</td>\n",
       "      <td>0.760457</td>\n",
       "      <td>1.639556</td>\n",
       "      <td>-1.193579</td>\n",
       "      <td>-1.102717</td>\n",
       "      <td>1.673044</td>\n",
       "      <td>-0.434564</td>\n",
       "      <td>1.083872</td>\n",
       "      <td>-0.812450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>-0.236417</td>\n",
       "      <td>0.286961</td>\n",
       "      <td>0.041868</td>\n",
       "      <td>0.133825</td>\n",
       "      <td>0.244540</td>\n",
       "      <td>0.446112</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -3.655104  0.802061  1.817268 -1.285273 -1.640494  1.700293   \n",
       "1           1 -3.614658  0.803416  1.686412 -1.009045 -1.609771  1.699671   \n",
       "2           2 -3.636358  0.825494  1.710698 -1.048296 -1.626373  1.841579   \n",
       "3           3 -3.641610  0.745754  1.603314 -1.195112 -0.952689  1.644297   \n",
       "4           4 -3.646880  0.760457  1.639556 -1.193579 -1.102717  1.673044   \n",
       "\n",
       "          6         7         8  ...        29        30        31        32  \\\n",
       "0 -1.001414  1.101779 -0.999867  ...  0.153301 -0.027586  0.225252  0.007899   \n",
       "1 -0.747059  1.416030 -0.615753  ...  0.261052 -0.121278  0.115798  0.108756   \n",
       "2 -0.698989  1.496502 -0.499075  ...  0.356758 -0.111855  0.145736 -0.008782   \n",
       "3 -0.151961  1.282045 -0.588409  ...  0.360500  0.076649  0.157377 -0.213748   \n",
       "4 -0.434564  1.083872 -0.812450  ...  0.285444  0.095544  0.122837 -0.236417   \n",
       "\n",
       "         33        34        35        36        37  priceUSD  \n",
       "0  0.170539  0.097393  0.146309  0.208756  1.173401    0.0495  \n",
       "1  0.043790  0.147877  0.246103  0.141600  1.104297    0.0726  \n",
       "2  0.276770  0.029030  0.211571  0.214689  0.931091    0.0859  \n",
       "3  0.256696  0.187187  0.140654  0.291811  0.537814    0.0783  \n",
       "4  0.286961  0.041868  0.133825  0.244540  0.446112    0.0767  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_MinMaxScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.655104</td>\n",
       "      <td>0.802061</td>\n",
       "      <td>1.817268</td>\n",
       "      <td>-1.285273</td>\n",
       "      <td>-1.640494</td>\n",
       "      <td>1.700293</td>\n",
       "      <td>-1.001414</td>\n",
       "      <td>1.101779</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>0.152710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153301</td>\n",
       "      <td>-0.027586</td>\n",
       "      <td>0.225252</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.170539</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>0.146309</td>\n",
       "      <td>0.208756</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.614658</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>1.686412</td>\n",
       "      <td>-1.009045</td>\n",
       "      <td>-1.609771</td>\n",
       "      <td>1.699671</td>\n",
       "      <td>-0.747059</td>\n",
       "      <td>1.416030</td>\n",
       "      <td>-0.615753</td>\n",
       "      <td>0.506121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261052</td>\n",
       "      <td>-0.121278</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.108756</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>0.147877</td>\n",
       "      <td>0.246103</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>1.104297</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.636358</td>\n",
       "      <td>0.825494</td>\n",
       "      <td>1.710698</td>\n",
       "      <td>-1.048296</td>\n",
       "      <td>-1.626373</td>\n",
       "      <td>1.841579</td>\n",
       "      <td>-0.698989</td>\n",
       "      <td>1.496502</td>\n",
       "      <td>-0.499075</td>\n",
       "      <td>0.612378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356758</td>\n",
       "      <td>-0.111855</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>0.276770</td>\n",
       "      <td>0.029030</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.214689</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.641610</td>\n",
       "      <td>0.745754</td>\n",
       "      <td>1.603314</td>\n",
       "      <td>-1.195112</td>\n",
       "      <td>-0.952689</td>\n",
       "      <td>1.644297</td>\n",
       "      <td>-0.151961</td>\n",
       "      <td>1.282045</td>\n",
       "      <td>-0.588409</td>\n",
       "      <td>0.833923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.076649</td>\n",
       "      <td>0.157377</td>\n",
       "      <td>-0.213748</td>\n",
       "      <td>0.256696</td>\n",
       "      <td>0.187187</td>\n",
       "      <td>0.140654</td>\n",
       "      <td>0.291811</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.646880</td>\n",
       "      <td>0.760457</td>\n",
       "      <td>1.639556</td>\n",
       "      <td>-1.193579</td>\n",
       "      <td>-1.102717</td>\n",
       "      <td>1.673044</td>\n",
       "      <td>-0.434564</td>\n",
       "      <td>1.083872</td>\n",
       "      <td>-0.812450</td>\n",
       "      <td>0.726314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>-0.236417</td>\n",
       "      <td>0.286961</td>\n",
       "      <td>0.041868</td>\n",
       "      <td>0.133825</td>\n",
       "      <td>0.244540</td>\n",
       "      <td>0.446112</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>4.827080</td>\n",
       "      <td>3.872729</td>\n",
       "      <td>-0.564335</td>\n",
       "      <td>-0.964944</td>\n",
       "      <td>0.955012</td>\n",
       "      <td>-0.208703</td>\n",
       "      <td>-0.160729</td>\n",
       "      <td>0.079293</td>\n",
       "      <td>-0.353848</td>\n",
       "      <td>0.195394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.265255</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>-0.052400</td>\n",
       "      <td>0.188256</td>\n",
       "      <td>0.122504</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>4.874243</td>\n",
       "      <td>4.078286</td>\n",
       "      <td>-0.498325</td>\n",
       "      <td>-1.028046</td>\n",
       "      <td>0.857928</td>\n",
       "      <td>-0.213927</td>\n",
       "      <td>-0.295887</td>\n",
       "      <td>0.083715</td>\n",
       "      <td>-0.351354</td>\n",
       "      <td>0.203269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087225</td>\n",
       "      <td>0.475346</td>\n",
       "      <td>-0.080046</td>\n",
       "      <td>-0.166548</td>\n",
       "      <td>0.307902</td>\n",
       "      <td>0.089965</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.139277</td>\n",
       "      <td>0.202801</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>4.873536</td>\n",
       "      <td>3.950721</td>\n",
       "      <td>-0.594500</td>\n",
       "      <td>-0.959722</td>\n",
       "      <td>1.011089</td>\n",
       "      <td>-0.306760</td>\n",
       "      <td>-0.063507</td>\n",
       "      <td>0.463026</td>\n",
       "      <td>-0.061280</td>\n",
       "      <td>0.456087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133529</td>\n",
       "      <td>0.307913</td>\n",
       "      <td>-0.229377</td>\n",
       "      <td>0.031294</td>\n",
       "      <td>0.255388</td>\n",
       "      <td>-0.049842</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.269696</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>4.822283</td>\n",
       "      <td>4.116169</td>\n",
       "      <td>-0.434845</td>\n",
       "      <td>-0.844725</td>\n",
       "      <td>0.491708</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.857335</td>\n",
       "      <td>0.091674</td>\n",
       "      <td>-0.184611</td>\n",
       "      <td>0.583483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138564</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>-0.106430</td>\n",
       "      <td>0.072532</td>\n",
       "      <td>0.355768</td>\n",
       "      <td>0.043088</td>\n",
       "      <td>-0.011649</td>\n",
       "      <td>0.177111</td>\n",
       "      <td>0.143189</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>4.781473</td>\n",
       "      <td>4.086459</td>\n",
       "      <td>-0.413840</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>0.451225</td>\n",
       "      <td>-0.145129</td>\n",
       "      <td>-0.835111</td>\n",
       "      <td>0.209077</td>\n",
       "      <td>0.051204</td>\n",
       "      <td>0.802018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252241</td>\n",
       "      <td>0.203734</td>\n",
       "      <td>-0.005977</td>\n",
       "      <td>0.298842</td>\n",
       "      <td>0.464687</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>-0.004168</td>\n",
       "      <td>0.162576</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -3.655104  0.802061  1.817268 -1.285273 -1.640494  1.700293 -1.001414   \n",
       "1    -3.614658  0.803416  1.686412 -1.009045 -1.609771  1.699671 -0.747059   \n",
       "2    -3.636358  0.825494  1.710698 -1.048296 -1.626373  1.841579 -0.698989   \n",
       "3    -3.641610  0.745754  1.603314 -1.195112 -0.952689  1.644297 -0.151961   \n",
       "4    -3.646880  0.760457  1.639556 -1.193579 -1.102717  1.673044 -0.434564   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  4.827080  3.872729 -0.564335 -0.964944  0.955012 -0.208703 -0.160729   \n",
       "3484  4.874243  4.078286 -0.498325 -1.028046  0.857928 -0.213927 -0.295887   \n",
       "3485  4.873536  3.950721 -0.594500 -0.959722  1.011089 -0.306760 -0.063507   \n",
       "3486  4.822283  4.116169 -0.434845 -0.844725  0.491708 -0.136111 -0.857335   \n",
       "3487  4.781473  4.086459 -0.413840 -0.719069  0.451225 -0.145129 -0.835111   \n",
       "\n",
       "             7         8         9  ...        29        30        31  \\\n",
       "0     1.101779 -0.999867  0.152710  ...  0.153301 -0.027586  0.225252   \n",
       "1     1.416030 -0.615753  0.506121  ...  0.261052 -0.121278  0.115798   \n",
       "2     1.496502 -0.499075  0.612378  ...  0.356758 -0.111855  0.145736   \n",
       "3     1.282045 -0.588409  0.833923  ...  0.360500  0.076649  0.157377   \n",
       "4     1.083872 -0.812450  0.726314  ...  0.285444  0.095544  0.122837   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3483  0.079293 -0.353848  0.195394  ...  0.004526  0.315107 -0.007492   \n",
       "3484  0.083715 -0.351354  0.203269  ... -0.087225  0.475346 -0.080046   \n",
       "3485  0.463026 -0.061280  0.456087  ... -0.133529  0.307913 -0.229377   \n",
       "3486  0.091674 -0.184611  0.583483  ... -0.138564  0.315845 -0.106430   \n",
       "3487  0.209077  0.051204  0.802018  ... -0.252241  0.203734 -0.005977   \n",
       "\n",
       "            32        33        34        35        36        37   priceUSD  \n",
       "0     0.007899  0.170539  0.097393  0.146309  0.208756  1.173401     0.0495  \n",
       "1     0.108756  0.043790  0.147877  0.246103  0.141600  1.104297     0.0726  \n",
       "2    -0.008782  0.276770  0.029030  0.211571  0.214689  0.931091     0.0859  \n",
       "3    -0.213748  0.256696  0.187187  0.140654  0.291811  0.537814     0.0783  \n",
       "4    -0.236417  0.286961  0.041868  0.133825  0.244540  0.446112     0.0767  \n",
       "...        ...       ...       ...       ...       ...       ...        ...  \n",
       "3483  0.132500  0.265255  0.171378 -0.052400  0.188256  0.122504  9349.0000  \n",
       "3484 -0.166548  0.307902  0.089965  0.003772  0.139277  0.202801  9394.0000  \n",
       "3485  0.031294  0.255388 -0.049842  0.003653  0.269696  0.125988  9366.0000  \n",
       "3486  0.072532  0.355768  0.043088 -0.011649  0.177111  0.143189  9393.0000  \n",
       "3487  0.298842  0.464687  0.020750 -0.004168  0.162576 -0.000135  9398.0000  \n",
       "\n",
       "[3488 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912317839223562\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911351784683259"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913277109132441"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.03, max_depth=6, n_estimators=1000,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.992172378839305\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.03, 'max_depth': 6, 'n_estimators': 1000, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c89d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9935314054516078\n",
      "Best Score: 0.9922151529854562\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9931043583105772\n",
      "Best Score: 0.9925767230130992\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9939930321774656\n",
      "Best Score: 0.9922341110609185\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9947399339785231\n",
      "Best Score: 0.9926341619832322\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9937031994871356\n",
      "Best Score: 0.9925736299365532\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cb6b8",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd750a5e",
   "metadata": {},
   "source": [
    "### LSTMs expect the data to be in 3 dimensions. We need to split the data into sequences of some preset length. The shape we want to obtain is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff2945a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQ_LEN = 100\n",
    "\n",
    "def to_sequences(data, seq_len):\n",
    "    d = []\n",
    "\n",
    "    for index in range(len(data) - seq_len):\n",
    "        d.append(data[index: index + seq_len])\n",
    "\n",
    "    return np.array(d)\n",
    "\n",
    "def preprocess(data_raw, seq_len, train_split):\n",
    "\n",
    "    data = to_sequences(data_raw, seq_len)\n",
    "\n",
    "    num_train = int(train_split * data.shape[0])\n",
    "\n",
    "    X_train = data[:num_train, :-1, :]\n",
    "    y_train = data[:num_train, -1, :]\n",
    "\n",
    "    X_test = data[num_train:, :-1, :]\n",
    "    y_test = data[num_train:, -1, :]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test =\\\n",
    " preprocess(finaldata, SEQ_LEN, train_split = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ecfe343",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CuDNNLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m WINDOW_SIZE \u001b[38;5;241m=\u001b[39m SEQ_LEN \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Bidirectional(\n\u001b[1;32m---> 11\u001b[0m   \u001b[43mCuDNNLSTM\u001b[49m(WINDOW_SIZE, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     12\u001b[0m   input_shape\u001b[38;5;241m=\u001b[39m(WINDOW_SIZE, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     13\u001b[0m ))\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(rate\u001b[38;5;241m=\u001b[39mDROPOUT))\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Bidirectional(\n\u001b[0;32m     17\u001b[0m   CuDNNLSTM((WINDOW_SIZE \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m), return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m ))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CuDNNLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from tensorflow.keras.layers import Bidirectional \n",
    "DROPOUT = 0.2\n",
    "WINDOW_SIZE = SEQ_LEN - 1\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Bidirectional(\n",
    "  CuDNNLSTM(WINDOW_SIZE, return_sequences=True),\n",
    "  input_shape=(WINDOW_SIZE, X_train.shape[-1])\n",
    "))\n",
    "model.add(Dropout(rate=DROPOUT))\n",
    "\n",
    "model.add(Bidirectional(\n",
    "  CuDNNLSTM((WINDOW_SIZE * 2), return_sequences=True)\n",
    "))\n",
    "model.add(Dropout(rate=DROPOUT))\n",
    "\n",
    "model.add(Bidirectional(\n",
    "  CuDNNLSTM(WINDOW_SIZE, return_sequences=False)\n",
    "))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1f5e9",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f41996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf2669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d43b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42759983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 2116.8113 - mean_absolute_error: 2113.4070 - val_loss: 2169.3162 - val_mean_absolute_error: 2160.4958\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1057.4983 - mean_absolute_error: 1033.9836 - val_loss: 406.0324 - val_mean_absolute_error: 376.6014\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 247.3941 - mean_absolute_error: 216.8650 - val_loss: 210.0865 - val_mean_absolute_error: 179.0924\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 176.2959 - mean_absolute_error: 145.5588 - val_loss: 182.5172 - val_mean_absolute_error: 152.0863\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 154.5115 - mean_absolute_error: 123.9923 - val_loss: 160.9641 - val_mean_absolute_error: 130.4518\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 139.9216 - mean_absolute_error: 109.4904 - val_loss: 157.1498 - val_mean_absolute_error: 126.5859\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 136.4698 - mean_absolute_error: 106.0749 - val_loss: 148.6258 - val_mean_absolute_error: 118.4248\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 129.2671 - mean_absolute_error: 99.0610 - val_loss: 145.9676 - val_mean_absolute_error: 116.0159\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 124.8320 - mean_absolute_error: 94.8360 - val_loss: 138.2331 - val_mean_absolute_error: 108.2966\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 119.8564 - mean_absolute_error: 89.9998 - val_loss: 135.9245 - val_mean_absolute_error: 106.1914\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 115.4240 - mean_absolute_error: 85.6740 - val_loss: 132.0690 - val_mean_absolute_error: 102.3013\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 110.5363 - mean_absolute_error: 80.9576 - val_loss: 126.6715 - val_mean_absolute_error: 97.1270\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 112.2219 - mean_absolute_error: 82.7983 - val_loss: 128.2005 - val_mean_absolute_error: 98.9143\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 106.6400 - mean_absolute_error: 77.3271 - val_loss: 118.9212 - val_mean_absolute_error: 89.5754\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 104.2599 - mean_absolute_error: 75.0775 - val_loss: 118.7727 - val_mean_absolute_error: 89.7130\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 103.5084 - mean_absolute_error: 74.5017 - val_loss: 114.6599 - val_mean_absolute_error: 85.7300\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 100.5867 - mean_absolute_error: 71.7835 - val_loss: 113.8050 - val_mean_absolute_error: 85.0974\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 99.2551 - mean_absolute_error: 70.5884 - val_loss: 108.8626 - val_mean_absolute_error: 80.3717\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 93.3175 - mean_absolute_error: 64.8715 - val_loss: 114.2789 - val_mean_absolute_error: 85.7754\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.9264 - mean_absolute_error: 62.6589 - val_loss: 104.6909 - val_mean_absolute_error: 76.4875\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 94.6307 - mean_absolute_error: 66.4614 - val_loss: 107.7885 - val_mean_absolute_error: 79.6625\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.3191 - mean_absolute_error: 62.3727 - val_loss: 101.1127 - val_mean_absolute_error: 73.2692\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 92.8567 - mean_absolute_error: 65.0472 - val_loss: 104.4305 - val_mean_absolute_error: 76.7761\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 88.8888 - mean_absolute_error: 61.3025 - val_loss: 98.9104 - val_mean_absolute_error: 71.4626\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.6487 - mean_absolute_error: 58.2263 - val_loss: 96.4132 - val_mean_absolute_error: 69.0546\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.4205 - mean_absolute_error: 58.1862 - val_loss: 95.7427 - val_mean_absolute_error: 68.5937\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.4322 - mean_absolute_error: 55.3494 - val_loss: 105.2109 - val_mean_absolute_error: 78.4450\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 84.5387 - mean_absolute_error: 57.6748 - val_loss: 98.1489 - val_mean_absolute_error: 71.4395\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.7190 - mean_absolute_error: 56.0460 - val_loss: 95.0582 - val_mean_absolute_error: 68.5323\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 79.6264 - mean_absolute_error: 53.1185 - val_loss: 90.1225 - val_mean_absolute_error: 63.6035\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 79.6610 - mean_absolute_error: 53.3255 - val_loss: 94.0374 - val_mean_absolute_error: 67.8557\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 76.2572 - mean_absolute_error: 50.0793 - val_loss: 87.5108 - val_mean_absolute_error: 61.4532\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 76.8197 - mean_absolute_error: 50.8976 - val_loss: 85.6664 - val_mean_absolute_error: 59.8170\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.6907 - mean_absolute_error: 49.9271 - val_loss: 91.6537 - val_mean_absolute_error: 65.9710\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.1722 - mean_absolute_error: 48.6077 - val_loss: 82.5066 - val_mean_absolute_error: 56.9812\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 74.3506 - mean_absolute_error: 48.9233 - val_loss: 86.6563 - val_mean_absolute_error: 61.3439\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.7048 - mean_absolute_error: 45.4668 - val_loss: 82.3531 - val_mean_absolute_error: 57.2196\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 71.9118 - mean_absolute_error: 46.8436 - val_loss: 85.6245 - val_mean_absolute_error: 60.5492\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.9640 - mean_absolute_error: 48.0338 - val_loss: 88.3095 - val_mean_absolute_error: 63.5756\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.3204 - mean_absolute_error: 45.6472 - val_loss: 82.9046 - val_mean_absolute_error: 58.3371\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 71.8379 - mean_absolute_error: 47.3161 - val_loss: 84.8246 - val_mean_absolute_error: 60.4280\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.6567 - mean_absolute_error: 45.2313 - val_loss: 81.4295 - val_mean_absolute_error: 57.0256\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.6813 - mean_absolute_error: 42.4079 - val_loss: 83.4839 - val_mean_absolute_error: 59.3379\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.6009 - mean_absolute_error: 44.4759 - val_loss: 85.5938 - val_mean_absolute_error: 61.6197\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.3683 - mean_absolute_error: 42.4501 - val_loss: 81.6087 - val_mean_absolute_error: 57.9049\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 67.5341 - mean_absolute_error: 43.8643 - val_loss: 94.5454 - val_mean_absolute_error: 71.1127\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.0232 - mean_absolute_error: 42.5105 - val_loss: 76.9340 - val_mean_absolute_error: 53.4286\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.1267 - mean_absolute_error: 45.7157 - val_loss: 84.4910 - val_mean_absolute_error: 61.1293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.5729 - mean_absolute_error: 43.3348 - val_loss: 75.2412 - val_mean_absolute_error: 52.0372\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3829 - mean_absolute_error: 40.1896 - val_loss: 73.5875 - val_mean_absolute_error: 50.4605\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.3946 - mean_absolute_error: 41.3675 - val_loss: 71.2614 - val_mean_absolute_error: 48.2969\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.7172 - mean_absolute_error: 38.8613 - val_loss: 74.8366 - val_mean_absolute_error: 52.0432\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.7763 - mean_absolute_error: 40.0708 - val_loss: 98.7459 - val_mean_absolute_error: 75.9218\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 61.6144 - mean_absolute_error: 39.0391 - val_loss: 81.5255 - val_mean_absolute_error: 59.1005\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.4370 - mean_absolute_error: 39.9370 - val_loss: 71.9525 - val_mean_absolute_error: 49.5861\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.6966 - mean_absolute_error: 40.3588 - val_loss: 92.4437 - val_mean_absolute_error: 70.1243\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.3875 - mean_absolute_error: 40.2129 - val_loss: 74.7219 - val_mean_absolute_error: 52.6056\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.1869 - mean_absolute_error: 38.1277 - val_loss: 73.8107 - val_mean_absolute_error: 51.8610\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.1662 - mean_absolute_error: 38.2455 - val_loss: 90.7272 - val_mean_absolute_error: 69.0241\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.8246 - mean_absolute_error: 38.0184 - val_loss: 70.0649 - val_mean_absolute_error: 48.3231\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.6347 - mean_absolute_error: 37.9874 - val_loss: 72.2139 - val_mean_absolute_error: 50.5777\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.6498 - mean_absolute_error: 37.1167 - val_loss: 81.4057 - val_mean_absolute_error: 59.7935\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.8039 - mean_absolute_error: 36.3193 - val_loss: 74.0408 - val_mean_absolute_error: 52.6036\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.4698 - mean_absolute_error: 36.1789 - val_loss: 69.2374 - val_mean_absolute_error: 48.0552\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.8301 - mean_absolute_error: 40.6790 - val_loss: 72.5056 - val_mean_absolute_error: 51.3583\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.4929 - mean_absolute_error: 37.4610 - val_loss: 68.7342 - val_mean_absolute_error: 47.7266\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.2688 - mean_absolute_error: 35.3582 - val_loss: 74.9233 - val_mean_absolute_error: 54.1406\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.7504 - mean_absolute_error: 34.9958 - val_loss: 69.4858 - val_mean_absolute_error: 48.7915\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 55.2803 - mean_absolute_error: 34.5695 - val_loss: 69.9392 - val_mean_absolute_error: 49.2951\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.8228 - mean_absolute_error: 34.1758 - val_loss: 70.9535 - val_mean_absolute_error: 50.4487\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 57.0169 - mean_absolute_error: 36.4987 - val_loss: 66.9063 - val_mean_absolute_error: 46.4357\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.0259 - mean_absolute_error: 33.6172 - val_loss: 67.8673 - val_mean_absolute_error: 47.5728\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.1993 - mean_absolute_error: 34.9429 - val_loss: 68.4953 - val_mean_absolute_error: 48.2982\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.1819 - mean_absolute_error: 34.0358 - val_loss: 66.3404 - val_mean_absolute_error: 46.2398\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.2811 - mean_absolute_error: 32.2548 - val_loss: 64.3812 - val_mean_absolute_error: 44.3605\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4700 - mean_absolute_error: 32.4995 - val_loss: 69.4590 - val_mean_absolute_error: 49.5399\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.3712 - mean_absolute_error: 34.4742 - val_loss: 64.8745 - val_mean_absolute_error: 45.0853\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.9428 - mean_absolute_error: 35.1928 - val_loss: 64.9589 - val_mean_absolute_error: 45.2922\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.7361 - mean_absolute_error: 35.0983 - val_loss: 83.1585 - val_mean_absolute_error: 63.7149\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.1119 - mean_absolute_error: 37.5762 - val_loss: 67.3941 - val_mean_absolute_error: 47.8523\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.0649 - mean_absolute_error: 35.6022 - val_loss: 66.8991 - val_mean_absolute_error: 47.4628\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.0601 - mean_absolute_error: 32.6476 - val_loss: 75.8509 - val_mean_absolute_error: 56.4365\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.3457 - mean_absolute_error: 34.0604 - val_loss: 66.8478 - val_mean_absolute_error: 47.5950\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3024 - mean_absolute_error: 31.1371 - val_loss: 69.6356 - val_mean_absolute_error: 50.5610\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.4578 - mean_absolute_error: 31.3830 - val_loss: 64.1245 - val_mean_absolute_error: 45.1092\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6703 - mean_absolute_error: 32.6948 - val_loss: 66.4627 - val_mean_absolute_error: 47.5526\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.7301 - mean_absolute_error: 31.8533 - val_loss: 65.0312 - val_mean_absolute_error: 46.1269\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.3242 - mean_absolute_error: 30.5138 - val_loss: 66.3280 - val_mean_absolute_error: 47.5760\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6200 - mean_absolute_error: 32.8931 - val_loss: 62.4654 - val_mean_absolute_error: 43.8145\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.1659 - mean_absolute_error: 29.5676 - val_loss: 62.1788 - val_mean_absolute_error: 43.5655\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.7627 - mean_absolute_error: 31.2284 - val_loss: 68.1878 - val_mean_absolute_error: 49.6630\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.5582 - mean_absolute_error: 32.1189 - val_loss: 59.9446 - val_mean_absolute_error: 41.5649\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.6976 - mean_absolute_error: 31.3548 - val_loss: 66.5359 - val_mean_absolute_error: 48.2367\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9501 - mean_absolute_error: 30.7117 - val_loss: 63.3427 - val_mean_absolute_error: 45.1921\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.4792 - mean_absolute_error: 34.3293 - val_loss: 63.6278 - val_mean_absolute_error: 45.4790\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.2842 - mean_absolute_error: 30.1952 - val_loss: 62.6084 - val_mean_absolute_error: 44.5118\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 47.2103 - mean_absolute_error: 29.1850 - val_loss: 67.4041 - val_mean_absolute_error: 49.5322\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.6213 - mean_absolute_error: 29.7212 - val_loss: 61.0008 - val_mean_absolute_error: 43.0815\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.9741 - mean_absolute_error: 32.1116 - val_loss: 62.9764 - val_mean_absolute_error: 45.1110\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.7100 - mean_absolute_error: 33.8957 - val_loss: 72.0888 - val_mean_absolute_error: 54.3689\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1bf05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2fb5f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd34713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
