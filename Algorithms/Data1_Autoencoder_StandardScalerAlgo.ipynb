{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_21156\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997e90c",
   "metadata": {},
   "source": [
    "### Reading the StandardScaler Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.272445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.704053</td>\n",
       "      <td>1.120934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.353933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.883147</td>\n",
       "      <td>2.657742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.295429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.163925</td>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.192652</td>\n",
       "      <td>1.870249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.236208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.837456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.469148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>3.095343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.405711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.357963</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.251772</td>\n",
       "      <td>1.284827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.265765</td>\n",
       "      <td>0.541070</td>\n",
       "      <td>1.093741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.610268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.480020</td>\n",
       "      <td>1.381913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0    1         2         3         4    5    6  \\\n",
       "0           0  1.272445  0.0  1.704053  1.120934  0.000000  0.0  0.0   \n",
       "1           1  1.295429  0.0  1.163925  0.983769  0.000000  0.0  0.0   \n",
       "2           2  0.236208  0.0  2.837456  0.000000  0.000000  0.0  0.0   \n",
       "3           3  0.000000  0.0  1.357963  0.984608  0.195242  0.0  0.0   \n",
       "4           4  0.000000  0.0  1.265765  0.541070  1.093741  0.0  0.0   \n",
       "\n",
       "          7    8  ...        99  100       101  102       103       104  105  \\\n",
       "0  0.000000  0.0  ...  0.000000  0.0  1.353933  0.0  1.883147  2.657742  0.0   \n",
       "1  0.631568  0.0  ...  0.000000  0.0  1.538430  0.0  1.192652  1.870249  0.0   \n",
       "2  0.742867  0.0  ...  0.000000  0.0  2.469148  0.0  0.563751  3.095343  0.0   \n",
       "3  0.322820  0.0  ...  0.021757  0.0  0.676755  0.0  1.251772  1.284827  0.0   \n",
       "4  0.713462  0.0  ...  0.000000  0.0  1.610268  0.0  1.480020  1.381913  0.0   \n",
       "\n",
       "        106  107  priceUSD  \n",
       "0  0.000000  0.0    0.0495  \n",
       "1  0.000000  0.0    0.0726  \n",
       "2  2.405711  0.0    0.0859  \n",
       "3  0.532028  0.0    0.0783  \n",
       "4  0.505411  0.0    0.0767  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_StandardScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.272445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.704053</td>\n",
       "      <td>1.120934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.353933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883147</td>\n",
       "      <td>2.657742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.295429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.163925</td>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.538430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.192652</td>\n",
       "      <td>1.870249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.469148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>3.095343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.405711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.357963</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.251772</td>\n",
       "      <td>1.284827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.265765</td>\n",
       "      <td>0.541070</td>\n",
       "      <td>1.093741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.610268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480020</td>\n",
       "      <td>1.381913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.179494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614658</td>\n",
       "      <td>0.307597</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>1.324451</td>\n",
       "      <td>0.889618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.348079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.255987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427702</td>\n",
       "      <td>0.383041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.422990</td>\n",
       "      <td>1.447299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.341647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111734</td>\n",
       "      <td>0.241010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271751</td>\n",
       "      <td>1.107438</td>\n",
       "      <td>1.205667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153612</td>\n",
       "      <td>0.399873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298529</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067724</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>1.353312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394479</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.438531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306807</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.595487</td>\n",
       "      <td>0.821820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4    5         6  \\\n",
       "0     1.272445  0.000000  1.704053  1.120934  0.000000  0.0  0.000000   \n",
       "1     1.295429  0.000000  1.163925  0.983769  0.000000  0.0  0.000000   \n",
       "2     0.236208  0.000000  2.837456  0.000000  0.000000  0.0  0.000000   \n",
       "3     0.000000  0.000000  1.357963  0.984608  0.195242  0.0  0.000000   \n",
       "4     0.000000  0.000000  1.265765  0.541070  1.093741  0.0  0.000000   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3483  0.000000  0.227086  0.000000  0.024436  0.179494  0.0  0.000000   \n",
       "3484  0.216949  0.348079  0.000000  0.000000  0.353724  0.0  0.135385   \n",
       "3485  0.000000  0.661399  0.000000  0.078300  0.341647  0.0  0.218927   \n",
       "3486  0.000000  0.093544  0.000000  0.153612  0.399873  0.0  0.095809   \n",
       "3487  0.000000  0.000000  0.394479  0.035400  0.438531  0.0  0.000000   \n",
       "\n",
       "             7    8         9  ...        99       100       101       102  \\\n",
       "0     0.000000  0.0  0.000000  ...  0.000000  0.000000  1.353933  0.000000   \n",
       "1     0.631568  0.0  0.000000  ...  0.000000  0.000000  1.538430  0.000000   \n",
       "2     0.742867  0.0  0.000000  ...  0.000000  0.000000  2.469148  0.000000   \n",
       "3     0.322820  0.0  0.000000  ...  0.021757  0.000000  0.676755  0.000000   \n",
       "4     0.713462  0.0  0.000000  ...  0.000000  0.000000  1.610268  0.000000   \n",
       "...        ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "3483  0.000000  0.0  0.000000  ...  0.614658  0.307597  0.039078  0.058152   \n",
       "3484  0.255987  0.0  0.000000  ...  0.427702  0.383041  0.000000  0.000000   \n",
       "3485  0.000000  0.0  0.020619  ...  0.111734  0.241010  0.000000  0.271751   \n",
       "3486  0.000000  0.0  0.125356  ...  0.298529  0.103416  0.000000  0.067724   \n",
       "3487  0.247208  0.0  0.050051  ...  0.306807  0.103375  0.000000  0.164673   \n",
       "\n",
       "           103       104  105       106  107   priceUSD  \n",
       "0     1.883147  2.657742  0.0  0.000000  0.0     0.0495  \n",
       "1     1.192652  1.870249  0.0  0.000000  0.0     0.0726  \n",
       "2     0.563751  3.095343  0.0  2.405711  0.0     0.0859  \n",
       "3     1.251772  1.284827  0.0  0.532028  0.0     0.0783  \n",
       "4     1.480020  1.381913  0.0  0.505411  0.0     0.0767  \n",
       "...        ...       ...  ...       ...  ...        ...  \n",
       "3483  1.324451  0.889618  0.0  0.000000  0.0  9349.0000  \n",
       "3484  1.422990  1.447299  0.0  0.000000  0.0  9394.0000  \n",
       "3485  1.107438  1.205667  0.0  0.000000  0.0  9366.0000  \n",
       "3486  0.839254  1.353312  0.0  0.000000  0.0  9393.0000  \n",
       "3487  0.595487  0.821820  0.0  0.000000  0.0  9398.0000  \n",
       "\n",
       "[3488 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da37122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 86.86393743144387\n",
      "Test score of trained model: 87.19523254414288\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1c28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc516491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1.841037e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.356848e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>9.837747e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>7.305705e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.719523e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.484733e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  1.841037e+06\n",
       "1    RMSE  1.356848e+03\n",
       "2     MAE  9.837747e+02\n",
       "3    MAPE  7.305705e+04\n",
       "4      r2  8.719523e-01\n",
       "5  adj_r2  8.484733e-01"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5ef55",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02135487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 86.86347911952669\n",
      "Test score of trained model: 87.20001260520664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b15884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1.840350e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.356595e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>9.837432e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.720001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.485299e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  1.840350e+06\n",
       "1    RMSE  1.356595e+03\n",
       "2     MAE  9.837432e+02\n",
       "3      r2  8.720001e-01\n",
       "4  adj_r2  8.485299e-01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5599b1",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bd854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 86.8639304339428\n",
      "Test score of trained model: 87.19620916096387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd14b46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1.840897e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.356796e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>9.837583e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.719621e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.484849e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  1.840897e+06\n",
       "1    RMSE  1.356796e+03\n",
       "2     MAE  9.837583e+02\n",
       "3      r2  8.719621e-01\n",
       "4  adj_r2  8.484849e-01"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6affb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.66859466994535\n",
      "Test score of trained model: 93.89658161821015\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93797818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>877534.085666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>936.767893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>555.168189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.938966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.927774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  877534.085666\n",
       "1    RMSE     936.767893\n",
       "2     MAE     555.168189\n",
       "3      r2       0.938966\n",
       "4  adj_r2       0.927774"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=8, n_estimators=1500,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9023963839345344\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 1500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: 0.8926066456273914\n",
      "   Metric         Score\n",
      "0     MSE  1.544075e+06\n",
      "1    RMSE  1.242608e+03\n",
      "2     MAE  7.584381e+02\n",
      "3      r2  8.926066e-01\n",
      "4  adj_r2  8.729148e-01\n",
      "Best Score: 0.8651420870900317\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: 0.8905904524245984\n",
      "   Metric         Score\n",
      "0     MSE  1.573063e+06\n",
      "1    RMSE  1.254218e+03\n",
      "2     MAE  7.623828e+02\n",
      "3      r2  8.905905e-01\n",
      "4  adj_r2  8.705289e-01\n",
      "Best Score: 0.8648503442131357\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: 0.8845862953911846\n",
      "   Metric         Score\n",
      "0     MSE  1.659389e+06\n",
      "1    RMSE  1.288173e+03\n",
      "2     MAE  7.755417e+02\n",
      "3      r2  8.845863e-01\n",
      "4  adj_r2  8.634239e-01\n",
      "Best Score: 0.869741824283263\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: 0.8825840757962089\n",
      "   Metric         Score\n",
      "0     MSE  1.688177e+06\n",
      "1    RMSE  1.299298e+03\n",
      "2     MAE  7.840600e+02\n",
      "3      r2  8.825841e-01\n",
      "4  adj_r2  8.610545e-01\n",
      "Best Score: 0.8682376685431915\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: 0.8927738342697967\n",
      "   Metric         Score\n",
      "0     MSE  1.541671e+06\n",
      "1    RMSE  1.241640e+03\n",
      "2     MAE  7.405038e+02\n",
      "3      r2  8.927738e-01\n",
      "4  adj_r2  8.731127e-01\n",
      "Best Score: 0.8671421706299489\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feebca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a9fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a46884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2116.6958 - mean_absolute_error: 2113.5232 - val_loss: 2204.4280 - val_mean_absolute_error: 2199.3467\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1967.4637 - mean_absolute_error: 1958.8795 - val_loss: 2019.9888 - val_mean_absolute_error: 2009.5829\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1742.5967 - mean_absolute_error: 1728.6528 - val_loss: 1579.4561 - val_mean_absolute_error: 1560.4722\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1130.6588 - mean_absolute_error: 1106.7896 - val_loss: 1089.0056 - val_mean_absolute_error: 1062.2150\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 879.2118 - mean_absolute_error: 852.0579 - val_loss: 967.6157 - val_mean_absolute_error: 940.3318\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 806.8529 - mean_absolute_error: 779.3030 - val_loss: 925.4561 - val_mean_absolute_error: 897.3883\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 768.3546 - mean_absolute_error: 740.4603 - val_loss: 891.7680 - val_mean_absolute_error: 863.8555\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 739.7768 - mean_absolute_error: 711.8352 - val_loss: 864.1634 - val_mean_absolute_error: 835.9772\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 719.5744 - mean_absolute_error: 691.4058 - val_loss: 839.8708 - val_mean_absolute_error: 811.5092\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 693.6263 - mean_absolute_error: 665.1532 - val_loss: 819.6343 - val_mean_absolute_error: 791.2070\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 670.6307 - mean_absolute_error: 642.0309 - val_loss: 789.2600 - val_mean_absolute_error: 760.4487\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 653.2165 - mean_absolute_error: 624.4668 - val_loss: 781.7360 - val_mean_absolute_error: 752.9847\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 639.0957 - mean_absolute_error: 610.2855 - val_loss: 768.2490 - val_mean_absolute_error: 739.5200\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 625.2532 - mean_absolute_error: 596.4625 - val_loss: 745.5580 - val_mean_absolute_error: 716.4963\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 614.1804 - mean_absolute_error: 585.2620 - val_loss: 739.3896 - val_mean_absolute_error: 710.6177\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 605.4484 - mean_absolute_error: 576.6777 - val_loss: 729.8879 - val_mean_absolute_error: 701.0749\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 593.5087 - mean_absolute_error: 564.6357 - val_loss: 728.7859 - val_mean_absolute_error: 700.1229\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 589.3051 - mean_absolute_error: 560.5652 - val_loss: 721.6652 - val_mean_absolute_error: 693.0184\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 577.4173 - mean_absolute_error: 548.8282 - val_loss: 777.3889 - val_mean_absolute_error: 748.2856\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 577.0289 - mean_absolute_error: 548.3726 - val_loss: 716.2696 - val_mean_absolute_error: 687.8685\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 567.0417 - mean_absolute_error: 538.5372 - val_loss: 714.2750 - val_mean_absolute_error: 685.9114\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 564.1732 - mean_absolute_error: 535.7291 - val_loss: 714.7073 - val_mean_absolute_error: 686.0429\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 561.5214 - mean_absolute_error: 533.1263 - val_loss: 704.4338 - val_mean_absolute_error: 676.1398\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 553.2531 - mean_absolute_error: 524.9308 - val_loss: 701.6656 - val_mean_absolute_error: 673.3155\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.0640 - mean_absolute_error: 526.8456 - val_loss: 701.8173 - val_mean_absolute_error: 673.5894\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 545.0662 - mean_absolute_error: 516.9079 - val_loss: 692.3154 - val_mean_absolute_error: 664.2958\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 544.6454 - mean_absolute_error: 516.5445 - val_loss: 690.9914 - val_mean_absolute_error: 663.1343\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 536.4039 - mean_absolute_error: 508.5841 - val_loss: 701.3903 - val_mean_absolute_error: 673.3820\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 531.2213 - mean_absolute_error: 503.2829 - val_loss: 685.0197 - val_mean_absolute_error: 657.2325\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 530.7502 - mean_absolute_error: 502.9641 - val_loss: 687.9215 - val_mean_absolute_error: 660.0482\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 521.7723 - mean_absolute_error: 494.0358 - val_loss: 684.1917 - val_mean_absolute_error: 656.3663\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 521.8652 - mean_absolute_error: 494.1306 - val_loss: 677.1194 - val_mean_absolute_error: 649.4014\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 509.9183 - mean_absolute_error: 482.2071 - val_loss: 672.2512 - val_mean_absolute_error: 644.7250\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 510.6479 - mean_absolute_error: 483.0134 - val_loss: 667.2996 - val_mean_absolute_error: 639.6619\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 502.7074 - mean_absolute_error: 475.1764 - val_loss: 665.8274 - val_mean_absolute_error: 638.3509\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 503.0404 - mean_absolute_error: 475.5269 - val_loss: 665.7449 - val_mean_absolute_error: 638.4301\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 495.1400 - mean_absolute_error: 467.7704 - val_loss: 662.6287 - val_mean_absolute_error: 635.3562\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 484.9858 - mean_absolute_error: 457.6826 - val_loss: 658.4915 - val_mean_absolute_error: 631.2314\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 494.0305 - mean_absolute_error: 466.8602 - val_loss: 665.4761 - val_mean_absolute_error: 638.2032\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 481.4246 - mean_absolute_error: 454.2110 - val_loss: 652.0995 - val_mean_absolute_error: 624.8297\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 482.1481 - mean_absolute_error: 454.9384 - val_loss: 647.3037 - val_mean_absolute_error: 620.2224\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 475.1105 - mean_absolute_error: 448.0056 - val_loss: 643.8619 - val_mean_absolute_error: 616.8189\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.6628 - mean_absolute_error: 444.6192 - val_loss: 647.5848 - val_mean_absolute_error: 620.5361\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 463.2100 - mean_absolute_error: 436.2545 - val_loss: 679.2148 - val_mean_absolute_error: 652.0016\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.8652 - mean_absolute_error: 434.9852 - val_loss: 634.1519 - val_mean_absolute_error: 607.3817\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 453.2206 - mean_absolute_error: 426.4277 - val_loss: 630.7010 - val_mean_absolute_error: 603.9368\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 450.8075 - mean_absolute_error: 424.0718 - val_loss: 658.0793 - val_mean_absolute_error: 631.1851\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 448.8721 - mean_absolute_error: 422.2087 - val_loss: 658.2103 - val_mean_absolute_error: 631.3475\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 451.8617 - mean_absolute_error: 425.2719 - val_loss: 647.4915 - val_mean_absolute_error: 621.0923\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.8997 - mean_absolute_error: 413.3778 - val_loss: 624.0261 - val_mean_absolute_error: 597.5231\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.8430 - mean_absolute_error: 413.4695 - val_loss: 634.1488 - val_mean_absolute_error: 607.6729\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 429.7267 - mean_absolute_error: 403.3957 - val_loss: 620.7950 - val_mean_absolute_error: 594.5457\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 430.7434 - mean_absolute_error: 404.4587 - val_loss: 615.0364 - val_mean_absolute_error: 588.6900\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 427.3259 - mean_absolute_error: 401.1097 - val_loss: 609.6406 - val_mean_absolute_error: 583.4125\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.2588 - mean_absolute_error: 393.1823 - val_loss: 606.6602 - val_mean_absolute_error: 580.7505\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 417.0679 - mean_absolute_error: 391.0829 - val_loss: 610.1718 - val_mean_absolute_error: 584.0823\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.0422 - mean_absolute_error: 387.1296 - val_loss: 619.1127 - val_mean_absolute_error: 593.2341\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.7685 - mean_absolute_error: 387.9966 - val_loss: 602.6392 - val_mean_absolute_error: 576.7958\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 406.8075 - mean_absolute_error: 381.1223 - val_loss: 608.9805 - val_mean_absolute_error: 583.2684\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 396.4923 - mean_absolute_error: 370.8864 - val_loss: 600.0231 - val_mean_absolute_error: 574.5658\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 397.7312 - mean_absolute_error: 372.2382 - val_loss: 604.9602 - val_mean_absolute_error: 579.4400\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 391.2271 - mean_absolute_error: 365.8171 - val_loss: 613.1122 - val_mean_absolute_error: 587.6016\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 394.5311 - mean_absolute_error: 369.1996 - val_loss: 622.2382 - val_mean_absolute_error: 596.9427\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 384.8835 - mean_absolute_error: 359.6842 - val_loss: 586.7697 - val_mean_absolute_error: 561.6816\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 381.4129 - mean_absolute_error: 356.2691 - val_loss: 593.7324 - val_mean_absolute_error: 568.5790\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 382.7001 - mean_absolute_error: 357.6770 - val_loss: 580.9818 - val_mean_absolute_error: 555.8358\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 375.7143 - mean_absolute_error: 350.6768 - val_loss: 595.7078 - val_mean_absolute_error: 570.6057\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 371.0401 - mean_absolute_error: 346.1391 - val_loss: 565.5144 - val_mean_absolute_error: 540.6469\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 363.5592 - mean_absolute_error: 338.7496 - val_loss: 592.4833 - val_mean_absolute_error: 567.8698\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 359.9349 - mean_absolute_error: 335.2395 - val_loss: 561.3876 - val_mean_absolute_error: 536.8138\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 357.6252 - mean_absolute_error: 333.0481 - val_loss: 575.0956 - val_mean_absolute_error: 550.4565\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 357.5228 - mean_absolute_error: 333.0538 - val_loss: 566.3933 - val_mean_absolute_error: 541.9378\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 354.6743 - mean_absolute_error: 330.3221 - val_loss: 576.1599 - val_mean_absolute_error: 551.7322\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 350.4642 - mean_absolute_error: 326.1548 - val_loss: 564.6543 - val_mean_absolute_error: 540.2649\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 344.3726 - mean_absolute_error: 320.1401 - val_loss: 550.5806 - val_mean_absolute_error: 526.3582\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 343.6812 - mean_absolute_error: 319.5551 - val_loss: 571.2552 - val_mean_absolute_error: 547.0803\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 344.5599 - mean_absolute_error: 320.5192 - val_loss: 552.1814 - val_mean_absolute_error: 528.1906\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 340.1513 - mean_absolute_error: 316.2487 - val_loss: 563.6891 - val_mean_absolute_error: 539.7429\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 334.5416 - mean_absolute_error: 310.7037 - val_loss: 556.9922 - val_mean_absolute_error: 533.1075\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 326.3048 - mean_absolute_error: 302.5523 - val_loss: 542.2000 - val_mean_absolute_error: 518.4937\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 333.9476 - mean_absolute_error: 310.2481 - val_loss: 534.3476 - val_mean_absolute_error: 510.5792\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 327.6607 - mean_absolute_error: 303.9807 - val_loss: 525.6226 - val_mean_absolute_error: 502.0430\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 322.5287 - mean_absolute_error: 298.9763 - val_loss: 533.7886 - val_mean_absolute_error: 510.3171\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 317.9988 - mean_absolute_error: 294.5361 - val_loss: 552.9497 - val_mean_absolute_error: 529.3721\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 320.9137 - mean_absolute_error: 297.4971 - val_loss: 534.1590 - val_mean_absolute_error: 510.7978\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 314.5040 - mean_absolute_error: 291.1799 - val_loss: 525.1284 - val_mean_absolute_error: 501.8563\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 314.6813 - mean_absolute_error: 291.4305 - val_loss: 533.5577 - val_mean_absolute_error: 510.3527\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 306.4319 - mean_absolute_error: 283.2125 - val_loss: 522.6188 - val_mean_absolute_error: 499.3894\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 310.8489 - mean_absolute_error: 287.7171 - val_loss: 536.2355 - val_mean_absolute_error: 513.1734\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 307.8840 - mean_absolute_error: 284.7815 - val_loss: 511.3110 - val_mean_absolute_error: 488.2573\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 301.8386 - mean_absolute_error: 278.8546 - val_loss: 520.6880 - val_mean_absolute_error: 497.7189\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 295.9207 - mean_absolute_error: 272.9614 - val_loss: 517.1862 - val_mean_absolute_error: 494.2460\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 294.0574 - mean_absolute_error: 271.1949 - val_loss: 506.4311 - val_mean_absolute_error: 483.5755\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 292.6793 - mean_absolute_error: 269.8628 - val_loss: 511.8698 - val_mean_absolute_error: 489.0461\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 293.9750 - mean_absolute_error: 271.2218 - val_loss: 511.1296 - val_mean_absolute_error: 488.3795\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 293.0942 - mean_absolute_error: 270.4049 - val_loss: 500.4455 - val_mean_absolute_error: 477.8286\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 283.0433 - mean_absolute_error: 260.3764 - val_loss: 495.4747 - val_mean_absolute_error: 472.8357\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 288.2190 - mean_absolute_error: 265.5977 - val_loss: 500.9290 - val_mean_absolute_error: 478.3549\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 281.2153 - mean_absolute_error: 258.6915 - val_loss: 502.9233 - val_mean_absolute_error: 480.3742\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 283.0928 - mean_absolute_error: 260.6140 - val_loss: 499.2413 - val_mean_absolute_error: 476.7077\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37768832",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab05fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0093c",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6649c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670b4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37cc95f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 4ms/step - loss: 2123.6440 - mean_absolute_error: 2121.1467 - val_loss: 2258.9814 - val_mean_absolute_error: 2256.8403\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1992.7178 - mean_absolute_error: 1987.3324 - val_loss: 2031.0710 - val_mean_absolute_error: 2023.7465\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1673.3490 - mean_absolute_error: 1662.9625 - val_loss: 1359.5433 - val_mean_absolute_error: 1345.3751\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 975.9802 - mean_absolute_error: 959.8163 - val_loss: 1058.3730 - val_mean_absolute_error: 1041.6118\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 840.0151 - mean_absolute_error: 822.8359 - val_loss: 936.6511 - val_mean_absolute_error: 919.3039\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 778.6326 - mean_absolute_error: 761.2207 - val_loss: 902.6206 - val_mean_absolute_error: 885.0230\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 742.1761 - mean_absolute_error: 724.5568 - val_loss: 878.4772 - val_mean_absolute_error: 860.9582\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 715.4750 - mean_absolute_error: 697.7614 - val_loss: 846.8557 - val_mean_absolute_error: 829.1586\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 700.2626 - mean_absolute_error: 682.4092 - val_loss: 833.2660 - val_mean_absolute_error: 815.4683\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 690.7868 - mean_absolute_error: 672.8883 - val_loss: 828.3517 - val_mean_absolute_error: 810.4328\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 678.3340 - mean_absolute_error: 660.3061 - val_loss: 813.9603 - val_mean_absolute_error: 795.9025\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 662.1519 - mean_absolute_error: 644.0332 - val_loss: 803.4060 - val_mean_absolute_error: 785.3942\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 660.9980 - mean_absolute_error: 642.8195 - val_loss: 803.1473 - val_mean_absolute_error: 784.7969\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 648.4614 - mean_absolute_error: 630.1882 - val_loss: 799.2082 - val_mean_absolute_error: 781.0359\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 648.3665 - mean_absolute_error: 630.0396 - val_loss: 777.4949 - val_mean_absolute_error: 759.1048\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 637.2401 - mean_absolute_error: 618.8360 - val_loss: 778.9400 - val_mean_absolute_error: 760.6606\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 637.7406 - mean_absolute_error: 619.3627 - val_loss: 767.2532 - val_mean_absolute_error: 748.8405\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 630.5989 - mean_absolute_error: 612.1697 - val_loss: 763.8854 - val_mean_absolute_error: 745.4591\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 627.6204 - mean_absolute_error: 609.1364 - val_loss: 761.6045 - val_mean_absolute_error: 743.1977\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 623.1503 - mean_absolute_error: 604.6580 - val_loss: 759.7829 - val_mean_absolute_error: 741.3431\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 610.8317 - mean_absolute_error: 592.3523 - val_loss: 750.4932 - val_mean_absolute_error: 731.8907\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 608.9156 - mean_absolute_error: 590.3502 - val_loss: 745.9081 - val_mean_absolute_error: 727.4521\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 599.1465 - mean_absolute_error: 580.5316 - val_loss: 750.7620 - val_mean_absolute_error: 732.0892\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 598.5036 - mean_absolute_error: 579.8685 - val_loss: 733.1104 - val_mean_absolute_error: 714.5173\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 590.5134 - mean_absolute_error: 571.8940 - val_loss: 725.6591 - val_mean_absolute_error: 706.9656\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 590.1969 - mean_absolute_error: 571.5104 - val_loss: 720.5145 - val_mean_absolute_error: 701.7789\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 582.1750 - mean_absolute_error: 563.4073 - val_loss: 717.7756 - val_mean_absolute_error: 699.0898\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 578.8574 - mean_absolute_error: 560.1902 - val_loss: 719.7202 - val_mean_absolute_error: 700.9874\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 572.3981 - mean_absolute_error: 553.7008 - val_loss: 712.5901 - val_mean_absolute_error: 693.9064\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 570.8333 - mean_absolute_error: 552.1117 - val_loss: 711.9841 - val_mean_absolute_error: 693.3951\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 560.0738 - mean_absolute_error: 541.3706 - val_loss: 702.8344 - val_mean_absolute_error: 683.9478\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 552.2975 - mean_absolute_error: 533.5554 - val_loss: 700.8832 - val_mean_absolute_error: 682.2354\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 551.2198 - mean_absolute_error: 532.4691 - val_loss: 693.7719 - val_mean_absolute_error: 674.9463\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 545.9468 - mean_absolute_error: 527.1199 - val_loss: 682.2007 - val_mean_absolute_error: 663.4116\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 536.3710 - mean_absolute_error: 517.6472 - val_loss: 699.5021 - val_mean_absolute_error: 680.8844\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 540.4053 - mean_absolute_error: 521.6547 - val_loss: 679.7425 - val_mean_absolute_error: 660.9932\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 529.4463 - mean_absolute_error: 510.7143 - val_loss: 667.9828 - val_mean_absolute_error: 649.2556\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 522.4215 - mean_absolute_error: 503.7598 - val_loss: 667.1586 - val_mean_absolute_error: 648.4435\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 514.5032 - mean_absolute_error: 495.7830 - val_loss: 656.4018 - val_mean_absolute_error: 637.6458\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 510.2518 - mean_absolute_error: 491.5939 - val_loss: 651.5935 - val_mean_absolute_error: 632.9081\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 505.0796 - mean_absolute_error: 486.4672 - val_loss: 648.5645 - val_mean_absolute_error: 629.9219\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 497.4471 - mean_absolute_error: 478.8526 - val_loss: 640.7166 - val_mean_absolute_error: 622.1334\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 489.1934 - mean_absolute_error: 470.6190 - val_loss: 655.7917 - val_mean_absolute_error: 637.2790\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 484.8401 - mean_absolute_error: 466.3205 - val_loss: 661.9705 - val_mean_absolute_error: 643.4935\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 491.5386 - mean_absolute_error: 472.9849 - val_loss: 630.6382 - val_mean_absolute_error: 612.1330\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 470.9637 - mean_absolute_error: 452.4796 - val_loss: 659.4046 - val_mean_absolute_error: 641.0343\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 474.4856 - mean_absolute_error: 456.0596 - val_loss: 618.1582 - val_mean_absolute_error: 599.8280\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 464.5582 - mean_absolute_error: 446.1800 - val_loss: 619.8394 - val_mean_absolute_error: 601.4365\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 464.5564 - mean_absolute_error: 446.1943 - val_loss: 611.2017 - val_mean_absolute_error: 592.7877\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 449.8588 - mean_absolute_error: 431.4846 - val_loss: 614.5914 - val_mean_absolute_error: 596.4160\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 450.9449 - mean_absolute_error: 432.7035 - val_loss: 608.7265 - val_mean_absolute_error: 590.4680\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 441.1045 - mean_absolute_error: 422.8789 - val_loss: 606.9430 - val_mean_absolute_error: 588.7731\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 444.4753 - mean_absolute_error: 426.2917 - val_loss: 620.1022 - val_mean_absolute_error: 601.9590\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 433.5464 - mean_absolute_error: 415.4315 - val_loss: 594.1915 - val_mean_absolute_error: 576.1323\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 434.9398 - mean_absolute_error: 416.9144 - val_loss: 581.5942 - val_mean_absolute_error: 563.5500\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.0963 - mean_absolute_error: 401.0836 - val_loss: 590.0526 - val_mean_absolute_error: 572.1089\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.8327 - mean_absolute_error: 401.9024 - val_loss: 611.7474 - val_mean_absolute_error: 593.9177\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 420.9961 - mean_absolute_error: 403.0953 - val_loss: 599.6298 - val_mean_absolute_error: 581.7388\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 411.1692 - mean_absolute_error: 393.2766 - val_loss: 573.0194 - val_mean_absolute_error: 555.2454\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 404.6004 - mean_absolute_error: 386.8618 - val_loss: 569.5667 - val_mean_absolute_error: 551.8757\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 399.5723 - mean_absolute_error: 381.8691 - val_loss: 555.4611 - val_mean_absolute_error: 537.7512\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 391.3855 - mean_absolute_error: 373.6822 - val_loss: 548.3660 - val_mean_absolute_error: 530.7098\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 386.4857 - mean_absolute_error: 368.8606 - val_loss: 545.7044 - val_mean_absolute_error: 528.1171\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 382.2868 - mean_absolute_error: 364.7110 - val_loss: 539.5527 - val_mean_absolute_error: 522.0265\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 373.5173 - mean_absolute_error: 355.9797 - val_loss: 545.5149 - val_mean_absolute_error: 528.0267\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 379.8264 - mean_absolute_error: 362.3552 - val_loss: 539.2896 - val_mean_absolute_error: 521.7218\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 375.0050 - mean_absolute_error: 357.5018 - val_loss: 534.9419 - val_mean_absolute_error: 517.5345\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 365.7076 - mean_absolute_error: 348.3118 - val_loss: 532.0378 - val_mean_absolute_error: 514.6675\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 355.1931 - mean_absolute_error: 337.9001 - val_loss: 524.4086 - val_mean_absolute_error: 507.1385\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 354.4834 - mean_absolute_error: 337.2059 - val_loss: 521.7275 - val_mean_absolute_error: 504.4170\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 348.0136 - mean_absolute_error: 330.7491 - val_loss: 516.2551 - val_mean_absolute_error: 499.0194\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 349.0369 - mean_absolute_error: 331.8117 - val_loss: 523.4331 - val_mean_absolute_error: 506.2282\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 337.4869 - mean_absolute_error: 320.3168 - val_loss: 509.7216 - val_mean_absolute_error: 492.5529\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 335.4726 - mean_absolute_error: 318.3563 - val_loss: 503.9836 - val_mean_absolute_error: 486.8643\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 327.7413 - mean_absolute_error: 310.6328 - val_loss: 511.8191 - val_mean_absolute_error: 494.7302\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 327.5875 - mean_absolute_error: 310.5183 - val_loss: 512.6943 - val_mean_absolute_error: 495.6084\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 328.7217 - mean_absolute_error: 311.7055 - val_loss: 511.6234 - val_mean_absolute_error: 494.6290\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 318.4518 - mean_absolute_error: 301.4863 - val_loss: 498.4056 - val_mean_absolute_error: 481.4309\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 315.1520 - mean_absolute_error: 298.1958 - val_loss: 491.8404 - val_mean_absolute_error: 474.8675\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 314.3635 - mean_absolute_error: 297.4449 - val_loss: 497.8051 - val_mean_absolute_error: 480.9698\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 310.3929 - mean_absolute_error: 293.5045 - val_loss: 518.1922 - val_mean_absolute_error: 501.2564\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 309.8420 - mean_absolute_error: 292.9539 - val_loss: 483.0762 - val_mean_absolute_error: 466.2313\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 304.9817 - mean_absolute_error: 288.1219 - val_loss: 495.8661 - val_mean_absolute_error: 479.0237\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 300.7503 - mean_absolute_error: 283.9101 - val_loss: 474.3453 - val_mean_absolute_error: 457.5466\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 299.6086 - mean_absolute_error: 282.7992 - val_loss: 486.6996 - val_mean_absolute_error: 469.9391\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 304.8392 - mean_absolute_error: 288.0287 - val_loss: 478.7037 - val_mean_absolute_error: 461.8701\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 295.6144 - mean_absolute_error: 278.7505 - val_loss: 467.8044 - val_mean_absolute_error: 451.0261\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 287.7943 - mean_absolute_error: 271.0360 - val_loss: 465.3876 - val_mean_absolute_error: 448.6191\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 284.1704 - mean_absolute_error: 267.4158 - val_loss: 475.0800 - val_mean_absolute_error: 458.3695\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 282.8671 - mean_absolute_error: 266.1304 - val_loss: 480.2545 - val_mean_absolute_error: 463.5783\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 283.5114 - mean_absolute_error: 266.7814 - val_loss: 472.0911 - val_mean_absolute_error: 455.3983\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 280.5139 - mean_absolute_error: 263.7861 - val_loss: 462.5074 - val_mean_absolute_error: 445.7714\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 282.5273 - mean_absolute_error: 265.7737 - val_loss: 470.9342 - val_mean_absolute_error: 454.1929\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 272.1621 - mean_absolute_error: 255.4466 - val_loss: 452.5210 - val_mean_absolute_error: 435.8246\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 269.1265 - mean_absolute_error: 252.4288 - val_loss: 454.2027 - val_mean_absolute_error: 437.5166\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 264.3079 - mean_absolute_error: 247.6349 - val_loss: 451.3892 - val_mean_absolute_error: 434.6929\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 267.6864 - mean_absolute_error: 251.0157 - val_loss: 468.0035 - val_mean_absolute_error: 451.2861\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 266.0565 - mean_absolute_error: 249.3554 - val_loss: 447.2365 - val_mean_absolute_error: 430.5098\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 264.3794 - mean_absolute_error: 247.6770 - val_loss: 442.8865 - val_mean_absolute_error: 426.1660\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 255.6494 - mean_absolute_error: 238.9744 - val_loss: 443.0057 - val_mean_absolute_error: 426.3149\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae4419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219a91b",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6401551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f063732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "129cf893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 25.6380 - mse: 15691930.0000 - val_loss: 11.9751 - val_mse: 16924468.0000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 10.7872 - mse: 15164022.0000 - val_loss: 9.7022 - val_mse: 16534031.0000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 9.4644 - mse: 14918161.0000 - val_loss: 8.8538 - val_mse: 16417544.0000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 8.8418 - mse: 14779604.0000 - val_loss: 8.3346 - val_mse: 16219485.0000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 8.3135 - mse: 14663461.0000 - val_loss: 7.8082 - val_mse: 16062125.0000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 7.4405 - mse: 14566553.0000 - val_loss: 6.5511 - val_mse: 15767372.0000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 5.3719 - mse: 13854644.0000 - val_loss: 5.2349 - val_mse: 15157227.0000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.5089 - mse: 13074084.0000 - val_loss: 4.5262 - val_mse: 13911941.0000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.0551 - mse: 12464473.0000 - val_loss: 4.2085 - val_mse: 13780103.0000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.7420 - mse: 12110570.0000 - val_loss: 3.9080 - val_mse: 13412075.0000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.5521 - mse: 11779233.0000 - val_loss: 3.8190 - val_mse: 12669415.0000\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.4070 - mse: 11520322.0000 - val_loss: 3.5334 - val_mse: 12541422.0000\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.2668 - mse: 11321791.0000 - val_loss: 3.3523 - val_mse: 12399702.0000\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.0916 - mse: 11106237.0000 - val_loss: 3.2803 - val_mse: 12196849.0000\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.1558 - mse: 11012892.0000 - val_loss: 3.2016 - val_mse: 12214750.0000\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.9668 - mse: 10689549.0000 - val_loss: 3.1131 - val_mse: 11524658.0000\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.8121 - mse: 10442366.0000 - val_loss: 3.0574 - val_mse: 11134419.0000\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.6453 - mse: 10354025.0000 - val_loss: 2.8917 - val_mse: 11020158.0000\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.5789 - mse: 10173497.0000 - val_loss: 2.7312 - val_mse: 11212610.0000\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.4763 - mse: 9920902.0000 - val_loss: 2.6163 - val_mse: 10957856.0000\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.4116 - mse: 9764612.0000 - val_loss: 2.5499 - val_mse: 10844233.0000\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3337 - mse: 9603827.0000 - val_loss: 2.5009 - val_mse: 10478871.0000\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.2690 - mse: 9354627.0000 - val_loss: 2.4436 - val_mse: 10513396.0000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.2079 - mse: 9243828.0000 - val_loss: 2.4145 - val_mse: 9954760.0000\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.1627 - mse: 9014753.0000 - val_loss: 2.3344 - val_mse: 9889812.0000\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0957 - mse: 8894058.0000 - val_loss: 2.2939 - val_mse: 9609153.0000\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0389 - mse: 8565258.0000 - val_loss: 2.2477 - val_mse: 9503162.0000\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9834 - mse: 8508937.0000 - val_loss: 2.2149 - val_mse: 9217600.0000\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9527 - mse: 8195128.0000 - val_loss: 2.1683 - val_mse: 9084335.0000\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.8923 - mse: 8055982.5000 - val_loss: 2.1609 - val_mse: 9333161.0000\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.8540 - mse: 7990662.0000 - val_loss: 2.1005 - val_mse: 8873144.0000\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.8112 - mse: 7698929.5000 - val_loss: 2.0787 - val_mse: 8564107.0000\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.7449 - mse: 7658332.0000 - val_loss: 2.0206 - val_mse: 8170202.5000\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.7379 - mse: 7251221.5000 - val_loss: 2.0258 - val_mse: 8737168.0000\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6723 - mse: 7424366.5000 - val_loss: 1.9388 - val_mse: 8001374.5000\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6369 - mse: 7171675.5000 - val_loss: 1.9275 - val_mse: 7716076.0000\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5744 - mse: 6876843.0000 - val_loss: 1.9673 - val_mse: 8218833.0000\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5929 - mse: 7061415.0000 - val_loss: 1.8490 - val_mse: 7500520.5000\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5179 - mse: 6564844.5000 - val_loss: 1.8277 - val_mse: 7257003.0000\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5341 - mse: 6644957.0000 - val_loss: 1.8205 - val_mse: 7474231.5000\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.4458 - mse: 6504406.5000 - val_loss: 1.7886 - val_mse: 7712055.0000\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.4565 - mse: 6482537.5000 - val_loss: 1.7594 - val_mse: 7182855.5000\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.4060 - mse: 6279968.5000 - val_loss: 1.7338 - val_mse: 7020318.5000\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3899 - mse: 6273363.0000 - val_loss: 1.7076 - val_mse: 6973109.5000\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3412 - mse: 5939509.0000 - val_loss: 1.7153 - val_mse: 6762131.5000\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3229 - mse: 5955797.0000 - val_loss: 1.6821 - val_mse: 6798166.5000\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3121 - mse: 5975462.5000 - val_loss: 1.6615 - val_mse: 6936690.5000\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3055 - mse: 5750184.0000 - val_loss: 1.6561 - val_mse: 6707193.0000\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2812 - mse: 5811178.0000 - val_loss: 1.6068 - val_mse: 6618975.0000\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2559 - mse: 5719225.5000 - val_loss: 1.6016 - val_mse: 6480832.0000\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2406 - mse: 5547954.5000 - val_loss: 1.5812 - val_mse: 6337258.5000\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2327 - mse: 5460102.5000 - val_loss: 1.5575 - val_mse: 6160114.0000\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2022 - mse: 5320048.0000 - val_loss: 1.5475 - val_mse: 5950288.0000\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1841 - mse: 5164637.5000 - val_loss: 1.5183 - val_mse: 6020112.5000\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1672 - mse: 5185670.0000 - val_loss: 1.5118 - val_mse: 5829934.0000\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1527 - mse: 4944606.5000 - val_loss: 1.5096 - val_mse: 5716170.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1382 - mse: 4906603.5000 - val_loss: 1.5022 - val_mse: 5720478.5000\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1318 - mse: 4813087.5000 - val_loss: 1.4636 - val_mse: 5344028.5000\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1161 - mse: 4514174.5000 - val_loss: 1.4495 - val_mse: 5370628.0000\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1006 - mse: 4546157.5000 - val_loss: 1.4186 - val_mse: 5430041.0000\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0687 - mse: 4497435.5000 - val_loss: 1.3989 - val_mse: 5182871.5000\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0419 - mse: 4263248.0000 - val_loss: 1.3915 - val_mse: 5197565.5000\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0348 - mse: 4270678.0000 - val_loss: 1.4155 - val_mse: 5227419.5000\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0329 - mse: 4112834.5000 - val_loss: 1.3564 - val_mse: 4871866.5000\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0015 - mse: 4042744.7500 - val_loss: 1.3444 - val_mse: 4629024.5000\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9925 - mse: 3854198.7500 - val_loss: 1.3616 - val_mse: 5044039.5000\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0022 - mse: 3925512.2500 - val_loss: 1.3176 - val_mse: 4686116.0000\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9662 - mse: 3780205.2500 - val_loss: 1.2899 - val_mse: 4535223.0000\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9457 - mse: 3650316.7500 - val_loss: 1.2904 - val_mse: 4389485.5000\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9347 - mse: 3531579.0000 - val_loss: 1.3039 - val_mse: 4311853.5000\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9101 - mse: 3452227.2500 - val_loss: 1.2567 - val_mse: 4297030.0000\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8970 - mse: 3412391.7500 - val_loss: 1.2336 - val_mse: 4043560.0000\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8861 - mse: 3253489.0000 - val_loss: 1.2101 - val_mse: 4097543.2500\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8938 - mse: 3300050.7500 - val_loss: 1.2368 - val_mse: 3863570.2500\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8670 - mse: 3096121.7500 - val_loss: 1.2471 - val_mse: 4076552.7500\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8679 - mse: 3199376.7500 - val_loss: 1.2153 - val_mse: 4467978.5000\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8870 - mse: 3380334.2500 - val_loss: 1.1973 - val_mse: 4098341.5000\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8494 - mse: 3098743.2500 - val_loss: 1.1855 - val_mse: 3986664.2500\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8271 - mse: 3084538.5000 - val_loss: 1.1308 - val_mse: 3882069.2500\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8133 - mse: 3040012.5000 - val_loss: 1.1267 - val_mse: 3844875.7500\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7949 - mse: 2943563.5000 - val_loss: 1.1050 - val_mse: 3787134.2500\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7842 - mse: 2925649.5000 - val_loss: 1.0832 - val_mse: 3769576.0000\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7730 - mse: 2919105.0000 - val_loss: 1.0912 - val_mse: 3661340.0000\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7591 - mse: 2821961.2500 - val_loss: 1.1058 - val_mse: 3601156.2500\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7504 - mse: 2782191.5000 - val_loss: 1.0896 - val_mse: 3652456.2500\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7366 - mse: 2753267.2500 - val_loss: 1.0724 - val_mse: 3635727.2500\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7274 - mse: 2674781.5000 - val_loss: 1.0836 - val_mse: 3577252.7500\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7128 - mse: 2665889.2500 - val_loss: 1.1039 - val_mse: 3422849.7500\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7032 - mse: 2628211.7500 - val_loss: 1.0755 - val_mse: 3473430.2500\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7110 - mse: 2553697.5000 - val_loss: 1.0862 - val_mse: 3356890.5000\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6824 - mse: 2514716.2500 - val_loss: 1.0700 - val_mse: 3416949.2500\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6731 - mse: 2502933.2500 - val_loss: 1.0838 - val_mse: 3302458.5000\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6541 - mse: 2434880.2500 - val_loss: 1.0484 - val_mse: 3326758.2500\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6476 - mse: 2419232.7500 - val_loss: 1.0368 - val_mse: 3317288.2500\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6368 - mse: 2408062.5000 - val_loss: 1.0294 - val_mse: 3214081.5000\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6310 - mse: 2334871.5000 - val_loss: 1.0245 - val_mse: 3263645.7500\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6175 - mse: 2346759.0000 - val_loss: 1.0240 - val_mse: 3160386.5000\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6189 - mse: 2309124.2500 - val_loss: 1.0301 - val_mse: 3133701.5000\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6296 - mse: 2305367.5000 - val_loss: 1.0348 - val_mse: 3201735.5000\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6046 - mse: 2279583.0000 - val_loss: 1.0531 - val_mse: 3123310.0000\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ddfb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAss0lEQVR4nO3deZxcZZ3v8c+v1t473Z1OyEpCCJBENEBAkHGMoBAWEUcHV8Q7jujo3NG5bujoDF7HGe69c9XxXsHLNuCGOiKKCg6LIDCyGEKEQAJJSEI6W3c66fRe63P/eE51VzrdpJNeKqf6+3696tVVp86p8zt1kt95nt95zilzziEiIuETKXUAIiJydJTARURCSglcRCSklMBFREJKCVxEJKSUwEVEQkoJXI5JZnabmf1jqeN4NWb2HTP78qu8f62ZfX+c1jXfzLrNLDoenyflQQl8HJnZVjNLm9n0IdOfMTNnZgtKENMXzWxL8J+/xcx+PNkxjDcz+5CZPVbqOJxzH3POfTWIaaWZtUzgul5xztU453JHslzwXeWC/V/8mD1RsQ4Tw4R+N1OZEvj42wK8t/DCzE4FqkoRiJldBVwJvMU5VwOsAB4sQRyxyV7nRAtZS/jxIPkXP3YOnWm4/XSk+64c9/WxTAl8/H0P+GDR66uA7xbPYGZJM/sXM3vFzPYEXfHK4L0GM/uVmbWZ2f7g+dyiZR82s6+a2X+aWZeZ3Te0xV/kTOA/nHObAZxzu51zNxZ91kIz+13wOfeb2f8tdPmHazUFPYy3BM/PMrPHzazDzHYFyyaK5nVm9gkz2whsDKZdamZrg2V+b2avLZr/NDNbE8TyY6Bi1N/4wTG+wcz+YGYHgr9vGLK9jwTreMDMvl1c4jCzfzez3cGyj5jZsqL3bjOzG8zsHjPrAd5cKPOYWTVwLzB7mBZuwsy+G6zzeTNbMeT7/KyZPWtmPWZ2i5nNNLN7i2JsCOZdEHynseB1o5n9m5ntDP6d/Pwov6+tZvZ5M3sW6DGzE4P1fNjMXgF+a2YRM/uSmW0zs9Zge+qHxDUw/xGuf0nwb7oj+H4uK3rvYjN7IfgudpjZZ4Lp04P/Fx1mts/MHjWzKZnLpuRGT7AngLrgH2YUeA8wtA56HXASsBw4EZgD/H3wXgT4N+B4YD7QB/zfIcu/D/gvwAwgAXzmVWL5YJAkVtihrcYfAk8D04Gv4g82o5UD/jZY9hzgfODjQ+a5HHg9sNTMTgNuBT4KNAH/D7jb/MEsAfwcf/BrBP4deOcRxAL4pAb8GvhWsI6vA782s6Zglh8CTwXvXYvvnRS7F1iM/17XAD8Y8v77gK8BtcBACcc51wNcBOwcpoV7GfAjYBpwN4fuy3cCb8X/e3hbEMMXgWb8v4W/GWFzv4fv2S0L4v3GCPONxnuBS4IYs8G0NwFLgAuBDwWPNwMnADXDbEfx/KNiZnHgl8B9+G34r8APzOzkYJZbgI8652qB1zB4cPg00IL/jmbiv6+peU8Q55we4/QAtgJvAb4E/DOwCrgfiOH/gS0ADOgBFhUtdw6wZYTPXA7sL3r9MPClotcfB37zKjG9H3ggWGc78Plg+nz8f9bqonl/CHw/eL4SaBlu+0ZYz6eAu4peO+C8otc3AF8dssyL+P/4fwrsBKzovd8D/zjCuj4EPDbM9CuBp4ZMezyYv7C9VUXvfb+wvcN81rRgG+qD17cB3x0yz22FGEf4vq4FHih6vRToG/J9vr/o9Z3ADUWv/yvw8+D5giCeGDALyAMNo/g3+aFguzuKHpuHxPAXRa8L6zmhaNqDwMeLXp8MZIJYDpl/mBgO+W6C6W8EdgORoml3ANcGz1/BH/Drhiz334FfACeO1//dsD7UAp8Y38O31j7EkPIJvtVQBTwddAE7gN8E0zGzKjP7f0F3tRN4BJg2pPW8u+h5L75FNCzn3A+cc2/BJ6SPAV81swuB2fgDQ0/R7NtGu4FmdlLQjd0dxPlP+NZ4se1Fz48HPl3Y5mC75wVxzAZ2uOB/55HGUmT2MMttw/dwZgP7nHO9w8VnZlEzu87MNgfbszV4a/pw8x+Bofuqwg6uE+8pet43zOvh9u08/LbsH2UMTzjnphU9Fg15f7jtKp429Hvdhk/eMw/zGYczG9junMsP+ew5wfN3AhcD28yX+s4Jpv8vYBNwn5m9bGbXHMW6y4IS+ARwzm3Dn8y8GPjZkLf34v9jLiv6D1Xv/ElG8N3Dk4HXO+fq8K1T8C33scSUcc79O/Asvju6C2gI6rcF84ue91B08jU4gDQXvX8DsAFYHMT5xWFiLE7I24GvDUkkVc65O4JY5phZ8fLzOXI78QeKYvOBHcE6Gs2s+ITyvKLn7wPeju9B1eNblgzZplfrpk9mF347flumjdPnDRd78bSh32uhN7NnhPlHaycwb0j9urC/cM79wTn3dnx55efAT4LpXc65TzvnTsCXqP6bmZ1/FOsPPSXwifNhfAmhuIVL0Nq4CfiGmc0AMLM5QasYfH21D+gIarr/cLQBmB9CdomZ1QYnoi7C10yfDA4yq4GvmFnCzP4EX4MteAnfWrwkqFV+CUgWvV8LdALdZnYK8FeHCecm4GNm9nrzqgux4cscWeBvzCxuZn8GnHX4zbOK4gdwD3CSmb3PzGJm9m582eJXRdt7bbC95wzZ3loghS8zVeF7FEdiD9BUOLk3kZxzu/C18uvNn/SOm9mfHm65MbgD+FvzJ4Fr8N/Nj51z2cMsd5Bh9tdT+F7J54JtWInfJz8K9tH7zazeOZfB/1vLB59zqfmTrQYcwJ+PyQ+3znKnBD5BnHObnXOrR3j78/gu4BNBd/0BfKsb4JtAJb6l/gS+vHK0OvEt41fwtc//CfyVc65wAu59+JOM+/AHioFyj3PuAL6+fjO+RdSDP3FU8Jlg+S58cn7V8eXBd/ER/Mmv/fjt/1DwXhr4s+D1PuDdHNpzGeoN+ANd8eMAcCm+F9MOfA641Dm3N1jm/fjzDe3APwYxp4L3vovvvu8AXsB/96PmnNuAT3QvByWiiR5nfSW+Dr0BaMWfgxjJOXboOPAzj2Bdt+LLgo/ge5b9+Pr8kZjDoftrHj5hX4T/93498MHguwS/jVuD/yMfw+8/8CeaHwC68Qf/651zDx1hPGXBDi47ylRmZtfiTwx9oNSxTAbzwxU3OOeOupcjUkpqgcuUYWZnmtmioJy0Cl/z/nmJwxI5arpqSqaS4/ClmSZ8OeivnHPPlDYkkaOnEoqISEiphCIiElKTWkKZPn26W7BgwWSuUkQk9J5++um9zrnmodMnNYEvWLCA1atHGlknIiLDMbNhr0xWCUVEJKSUwEVEQkoJXEQkpDQOXESOaZlMhpaWFvr7+0sdyoSrqKhg7ty5xOPxUc2vBC4ix7SWlhZqa2tZsGABB9+wsrw452hvb6elpYWFCxeOahmVUETkmNbf309TU1NZJ28AM6OpqemIehpK4CJyzCv35F1wpNsZigT+4Po9XP/wplKHISJyTAlFAv/dS23c+MjLpQ5DRKaojo4Orr/++iNe7uKLL6ajo2P8AwqEIoHHoxEy2Sn5gxsicgwYKYFns6/+o0T33HMP06ZNm6CoRpHAzWyemT1kZi+Y2fNm9slg+rVmtsPM1gaPiycqyEQsQjqnBC4ipXHNNdewefNmli9fzplnnskb3/hGLrvsMpYuXQrA5ZdfzhlnnMGyZcu48cYbB5ZbsGABe/fuZevWrSxZsoSPfOQjLFu2jAsuuIC+vr4xxzWaYYRZ4NPOuTXB7xc+bWb3B+99wzn3L2OO4jAS0QiZnCOfd0QiU+Nkhogc6iu/fJ4XdnaO62cunV3HP7xt2avOc91117Fu3TrWrl3Lww8/zCWXXMK6desGhvvdeuutNDY20tfXx5lnnsk73/lOmpqaDvqMjRs3cscdd3DTTTdxxRVXcOedd/KBD4ztx68Om8CDH1DdFTzvMrP1+N+3mzSJmO8opHN5KiLRyVy1iMghzjrrrIPGan/rW9/irrvuAmD79u1s3LjxkAS+cOFCli9fDsAZZ5zB1q1bxxzHEV3IY2YLgNOAJ4Fzgb82sw/if+370865/cMsczVwNcD8+fOPKshE1CfwTC5PRVwJXGSqOlxLebJUV1cPPH/44Yd54IEHePzxx6mqqmLlypXDjuVOJpMDz6PR6LiUUEZ9EtPMaoA7gU855zqBG4BFwHJ8C/1/D7ecc+5G59wK59yK5uZDbmc7KgMtcJ3IFJESqK2tpaura9j3Dhw4QENDA1VVVWzYsIEnnnhi0uIaVQvczOL45P0D59zPAJxze4revwn41YREyMElFBGRydbU1MS5557La17zGiorK5k5c+bAe6tWreI73/kOS5Ys4eSTT+bss8+etLgOm8DNXxp0C7DeOff1oumzgvo4wDuAdRMToh9GCJDJ6vc7RaQ0fvjDHw47PZlMcu+99w77XqHOPX36dNatG0yRn/nMZ8YlptG0wM8FrgSeM7O1wbQvAu81s+WAA7YCHx2XiIYx2ALPTdQqRERCZzSjUB4Dhhu7d8/4hzO8wknMlGrgIiIDQnElZlInMUVEDhGKBD5QA8+pBi4iUhCKBK5hhCIihwpXAtdJTBGRAaFI4PGoP4ea1jBCESmBo72dLMA3v/lNent7xzkiLxQJPKkLeUSkhI7VBB6KHzVORP39T1QDF5FSKL6d7Fvf+lZmzJjBT37yE1KpFO94xzv4yle+Qk9PD1dccQUtLS3kcjm+/OUvs2fPHnbu3Mmb3/xmpk+fzkMPPTSucYUjgccGb2YlIlPYvdfA7ufG9zOPOxUuuu5VZym+nex9993HT3/6U5566imcc1x22WU88sgjtLW1MXv2bH79618D/h4p9fX1fP3rX+ehhx5i+vTp4xs3ISmhDNbAlcBFpLTuu+8+7rvvPk477TROP/10NmzYwMaNGzn11FO5//77+fznP8+jjz5KfX39hMcSqha4ErjIFHeYlvJkcM7xhS98gY9+9NC7h6xZs4Z77rmHL33pS5x//vn8/d///YTGEooWuO5GKCKlVHw72QsvvJBbb72V7u5uAHbs2EFrays7d+6kqqqKD3zgA3z2s59lzZo1hyw73kLRAo9H1AIXkdIpvp3sRRddxPve9z7OOeccAGpqavj+97/Ppk2b+OxnP0skEiEej3PDDTcAcPXVV7Nq1Spmz5497icxzbnJG1u9YsUKt3r16qNadvHf3cNfvvEEPr/qlHGOSkSOZevXr2fJkiWlDmPSDLe9Zva0c27F0HlDUUIBf0dCtcBFRAaFJ4HHIhpGKCJSJDQJPK4WuMiUNZml3lI60u0MTQJPxJTARaaiiooK2tvbyz6JO+dob2+noqJi1MuEYhQK+ASeUglFZMqZO3cuLS0ttLW1lTqUCVdRUcHcuXNHPX94Eng0QkYtcJEpJx6Ps3DhwlKHcUwKVwlFLXARkQHhSeA6iSkicpDwJHANIxQROUhoEriGEYqIHCw0CTwRi5BSAhcRGRCqBK6TmCIig8KTwKOqgYuIFAtVAlcNXERkUHgSuC6lFxE5SGgSeDwaIZMr73shiIgcidAkcLXARUQOFq4EnsuX/R3JRERG67AJ3MzmmdlDZvaCmT1vZp8Mpjea2f1mtjH42zCRgSaDHzZWGUVExBtNCzwLfNo5txQ4G/iEmS0FrgEedM4tBh4MXk+YeNQA/TK9iEjBYRO4c26Xc25N8LwLWA/MAd4O3B7Mdjtw+QTFCPhhhKBfphcRKTiiGriZLQBOA54EZjrndgVv7QZmjrDM1Wa22sxWj+WG7IlYFFACFxEpGHUCN7Ma4E7gU865zuL3nD+zOGxx2jl3o3NuhXNuRXNz81EHWiih6GpMERFvVAnczOL45P0D59zPgsl7zGxW8P4soHViQvQSwUlM3dBKRMQbzSgUA24B1jvnvl701t3AVcHzq4BfjH94gwqjUFRCERHxRvObmOcCVwLPmdnaYNoXgeuAn5jZh4FtwBUTEmEgMTCMUAlcRARGkcCdc48BNsLb549vOCOLF0ahKIGLiABhuhJTwwhFRA4SngSuGriIyEFCk8BVQhEROVhoErhGoYiIHCw0CVwlFBGRg4UugWsYoYiIF5oErhq4iMjBQpPAVUIRETlYeBJ4VPdCEREpFroErhq4iIgXmgQeiRixiKmEIiISCE0CB/0yvYhIsdAlcJVQRES8UCXweDSiYYQiIoFQJfBENKJRKCIigVAl8GQsQiY37E9viohMOaFK4PFohHQ2V+owRESOCaFK4BqFIiIyKHwJXCcxRUSAsCXwaIRMVjVwEREIWQKPxyKk1AIXEQFClsATUdXARUQKQpXAk7oSU0RkQKgSeDyqm1mJiBSEKoFrGKGIyKDwJXCVUEREgLAl8GiUjFrgIiJAyBJ4PGYaRigiEghVAk8Gwwid08U8IiKhSuCFX6bP5pXARUQOm8DN7FYzazWzdUXTrjWzHWa2NnhcPLFhevHgh401EkVEZHQt8NuAVcNM/4ZzbnnwuGd8wxpeoQWuBC4iMooE7px7BNg3CbEcViGB62pMEZGx1cD/2syeDUosDSPNZGZXm9lqM1vd1tY2htUNllD0s2oiIkefwG8AFgHLgV3A/x5pRufcjc65Fc65Fc3NzUe5Oi9ZKKGoBS4icnQJ3Dm3xzmXc87lgZuAs8Y3rOEldBJTRGTAUSVwM5tV9PIdwLqR5h1PqoGLiAyKHW4GM7sDWAlMN7MW4B+AlWa2HHDAVuCjExfiIA0jFBEZdNgE7px77zCTb5mAWA5LwwhFRAaF8kpMncQUEQlbAlcJRURkQLgSuFrgIiIDwpXA1QIXERkQrgSuYYQiIgNClcA1jFBEZFCoEnihBa57oYiIhCyBJwdKKPpBBxGRUCVwlVBERAaFKoFHI0Y0YqRzuVKHIiJScqFK4OCHEqoFLiISxgQei6gGLiJCCBN4PBrRKBQREUKYwJMxlVBERCCECdyXUJTARURCl8DjUVMLXESEECbwRCyiuxGKiBCWBP7HH8M9nwP8MEKVUEREwpLAW5+H1bdCLkMiplEoIiIQlgQ+YynkM9C+mbgu5BERAUKTwJf4v23rNYxQRCQQjgQ+/SSwCLSu1zBCEZFAOBJ4vBIaT4DWF3wJRQlcRCQkCRx8GaV1vW5mJSISCFECXwr7XqYqklEJRUSEUCXwJeDyzM6+omGEIiKEKoEvBWBWaqtKKCIihCmBN54AkTiz01tJZfP0pLKljkhEpKTCk8CjcZh+EovcKwA8tmlviQMSESmt8CRwgBlLmNa9idqKGL9d31rqaERESip0CdwObOeCE6p46MVWnNNPq4nI1HXYBG5mt5pZq5mtK5rWaGb3m9nG4G/DxIYZCE5kXjq7k9auFM/v7JyU1YqIHItG0wK/DVg1ZNo1wIPOucXAg8HriRfcE+XM6j2YwYMqo4jIFHbYBO6cewTYN2Ty24Hbg+e3A5ePb1gjmHY8xKuoObCR182dxm9fVAIXkanraGvgM51zu4Lnu4GZI81oZleb2WozW93W1naUqwtEItB8CrS+wPmnzOCP2zto60qN7TNFREJqzCcxnT+TOOLZROfcjc65Fc65Fc3NzWNdna+D73mBN5/sP+thtcJFZIo62gS+x8xmAQR/Jy+LHv8G6GllWXotM+uSPKQELiJT1NEm8LuBq4LnVwG/GJ9wRuE174Samdh/fovzTpnBIy/tpTetqzJFZOoZzTDCO4DHgZPNrMXMPgxcB7zVzDYCbwleT454Bbz+o7D5Qa5c2EV3Ksu/PrBx0lYvInKsGM0olPc652Y55+LOubnOuVucc+3OufOdc4udc29xzg0dpTKxVvwFJGpYuuV23nPmPG5+bAsvaEy4iEwx4boSs6CyAU6/Cp77KV84t4ZplXG+cNdz5PK6MlNEpo5wJnCAs/8KgPq1N/PlS5fyx+0d/ODJbSUOSkRk8oQ3gU+bB6e+C56+jbcvyPLGxdP5n795kZb9vaWOTERkUoQ3gQOs/AJEotidH+ZrbzsFgE/+aK1+ck1EpoRwJ/DGhXDZt6DlD8xf+7/4pz87lae37ecb979U6shERCZcuBM4wLJ3wJl/Cb//P1xW8UfevWIeN/xuM49uHONl+yIix7jwJ3CAC74Gx70W7voYX3lTPYuaa/jbH69lf0+61JGJiEyY8kjg8Qr489sgn6Pi7o/wr1csY293mu8+rlEpIlK+yiOBAzQtgrd9E7Y/ybIN32blyc1874mt9GdypY5MRGRClE8CBz+s8PQPwmPf4DOLdrC3O83da3eWOioRkQlRXgkcYNX/gOZTWPbkZzlzhuPmx17Wb2eKSFkqvwSeqIK3fxvraeOaBRt5aU83j27cW+qoRETGXfklcIA5p8O0+Szv/U+aa5Pc/NiWUkckIjLuyjOBm8HJlxDd8gh/eVYzj7zUxqbWrlJHJSIyrsozgQOccgnkUryr/kUAnnh5cu94KyIy0co3gc8/ByobaGx5gPrKOC/s0v3CRaS8lG8Cj8Zg8YXYS//BqcdV8bx+8EFEykz5JnCAUy6G/g4uqN3Chl2dZHWXQhEpI+WdwBedD9Ek52SeIJXNs7W9p9QRiYiMm/JO4MkaOGElx+/9HeBURhGRslLeCRzglItJdG3ntdEWncgUkbJS/gn8pIsAeFfdOv1yvYiUlfJP4LUzYfZpvIk1vLCzU/dFEZGyUf4JHOCkVczvewHXs5fWrlSpoxERGRdTJIFfiOFYGVmrMoqIlI2pkcCPex35mpmcF31GJzJFpGxMjQQeiRA56UJWRp9jww7dWlZEysPUSOAAiy+khl5iLU+WOhIRkXExdRL4CSvJWZyl3U/QncqWOhoRkTGbOgk8WUPHzLM5L/IMG1QHF5EyMKYEbmZbzew5M1trZqvHK6iJklh6MYsiu1j99B9KHYqIyJiNRwv8zc655c65FePwWROq9rWXkidC1bO309WfKXU4IiJjMnVKKADT5rP/pHfxbv6DXz/yRKmjEREZk7EmcAfcZ2ZPm9nVw81gZleb2WozW93W1jbG1Y1d06VfAYvS9MR1uj+4iITaWBP4nzjnTgcuAj5hZn86dAbn3I3OuRXOuRXNzc1jXN04qJvNjiV/wVvzj/H7R+8vdTQiIkdtTAncObcj+NsK3AWcNR5BTbQFl32B/VZPw2NfxeXVCheRcDrqBG5m1WZWW3gOXACsG6/AJlKksp5NSz7Bqdnn2PSbb5c6HBGRozKWFvhM4DEz+yPwFPBr59xvxiesiXfqZZ/k6cipLH7qS3TefQ3kc6UOSUTkiBx1AnfOveyce13wWOac+9p4BjbRKioqqP/IL/kRF1C35gYy3/tz6OsodVgiIqM2tYYRDnHirAbmX3kDf5f9S2zLw7gbV8KuZ0sdlojIqEzpBA7whkXTWX75p7gi9WX2d3bhbnkrPPODUoclInJYsVIHcCz48xXz6M+8g1W/PI7vVF7P6b/4ODx1Ixz/Bph3Fiw6DyrqSx2miMhBlMADV56zgMUza7n6+w282/2Kq1LraV79b9gT10PtbHjnTbDgT0odpojIgClfQil29glN/OJv3sR/zngvZ+38b5wXv50HX38LLl4Jt78NHvpnjVYRkWOGEvgQc6ZVctfH38DNH1xBXXU1H/5dJW/suJa1DRfC767D3fgmWPczJXIRKTlzzk3aylasWOFWrz7m7zo7wDnHY5v28qM/bOf+5/dwoXuMz1Xcxbz8DrL1C4idcSXMWg7HnQq1M0sdroiUKTN7erg7viqBj9KB3gy/fHYnv1jzCo0tD/Cx2K84LbJpcIbqGTD7NJi9HGaf7k9+VjWWLF4RKR9K4ONoW3sPP39mJ7988nmaujfxprpdvKFmJ9M7X2BW5hWi+Pur5JsWE5m7AppOhMYTYMZSmHFKiaMXkbBRAp8A6WyeXz27k5sf3cKmtm4WNdewbHqE2vbnqNyzhrPjmzgjsY3q9N7BheasgLOuhmWXQyxZsthFJDyUwCeYcw4zG3j9h637+D+/3cQjL7VRF03xnkVZ3j1jOydsuQNr3wjVzXD6B+GM/wLT5pUwchE51imBl8im1i7ueGo7d65poaM3w4nTK7nm5N2sPPALYpvv8zMtvgCWXg6L3wrV00sar4gce5TAS6w/k+PXz+7i9se38mzLASrjUc5t7uO90d9yzoF7qUq34TBszhkw53RoPgVmLPG18+oZENGIT5GpSgn8GOGc45ntHdy9dicbdnfy0p5u9vf0s8y2cknFs1yQfJ55ma0kcj2DC8UqoH4eNC70J0SbFkHtLKhshKomX4KJV5Zuo0RkQo2UwHUp/SQzM06f38Dp8xsGpu060Mfjm9t5bNMb+f7L+9jR08ts2jkp0sKJ8b28NnmAxfl9zNqzjdotjxLN9h38oZGYb63PPs233GuP85f/1wWPaHySt1JEJoNa4Megrv4Mm1q7eWlPF+t2dPLcjgOs39VJKpsHHDPZz7K6fk6uT3NidYoTrYU5vS8yreM5YqkDB3+YRXxrvXaWP3Fa3QQ1M32Lvn6evwApmvAHgUQN1MyAopOxIlJ6KqGEXDaXZ9u+Xjbu6Wbjni42t3Wzua2HzW3d9KYLl/U76unh1Noeljf0cUplF/Nj+zjOtVGXbSeZ3of17IXuVnAj3AogUQPTF/vae8U0SNb6OzEWyjcNC32yLyyfqJ6MzReZ0lRCCblYNMKi5hoWNdew6jXHDUx3zrGvJ83Ojn52dPSxZW8PL+3p4sHdXdy0sztotXvJWITjm6qYNz/JgmQnx0fbmR3r4riaKDNr4jRG+4jufxn2boSdz0B/J6Q6IZceObC6uTDvTJh7pm/ZRxP+0X8AunZB9x6YdjycvAoaFkzgNyQy9agFXsbyecfuzn627O1ha3sPW/f2sLW9l50dfezvSdPekz4owUcjxvSaBDPrKphRm+S4+gpm1VcytzrH0mQ7x7udJLq3g8v7Vng+B7ufg+1PQWfL8EHEqyDT65/PWAazXutb+claf+I1EvM1+niVH0JZNd3/rWyEygaIqo0hohKKDKujNz1QitnW3kNrZ4rWrhR7OvvZ3dlPR29mYF4zf7fG6kSMWNRIxCLMa6jipJk1LKtPMTuZpqnCMS2RJ1bV4OvryVpo3wwv/QZevBc6tkGqy7fuRyrjFEvWQ2W9L+NUTIPKaT6xJ2ohn4V8Bpzz952pbvYHgIq64CBRA5F4cJCI+R6CSj4SQkrgclT60jl2dPja+4t7utiyt4dUJk82n6c/k2fL3h52dPQdstzs+goWzajhxBk1VMSj9Kay9KRzNFYnWDa7jmWz6pheFaEvnaKvP0W9pWiyTujdC737/KMv+Nvf4UsyfR3+ed9+SPdAJOoTNPhpozkgVDf7k7eJap/YI1HfE0gGSb+iLjhY1PteQTThb3kQr/JDNqsa/UEpEhtcXmSCKYHLhOlOZdnc2s3uzn72dqdo7Uyxtb2HTa3dbG7rJptzVCdjVCWitHenSefyw37OvMZKzpjfwMLpNWRyedK5PNGIMbehknkNVcyqr6AqGaMqHqU6GSMRK7q4KZ/3yb1nr2/hp7sg1e1b6Pmcr+N37YL92+DAdsj0BS34LGT6/TKF5dzw8Y3MfPfEIv6AEo37sfs1M/2QzpoZ/gAQr/B/KxuDclFjcOCo9gePaMIvG4n6+PoP+J5KdRPUz1c5aQrTSUyZMDXJGK+bN43XDfPe0HvEZHJ5NrV2s27HAbr6s1QlolQmorR1pVjzyn5+v7mdn6/dScQgEYuQzTmy+eEbGTNqk8xpqGT2tErqKmJUJfxBIhmrIxGbRiIaIRaNEIsYsWiEmoYodbPi1FXGqauIU18Zp6YiRjRSNGwyn4d0t0+e2X7IpiCX8geDQo8g3e0Tfy44AOB8Gcfl/QEjl4VMjx/t07UbWtf78wDZ/sHzAUcqmvAjgKqn+x5BrMIfmNI9fl2xCqibA/VzoOY4X2aqbDi4ZORy/mBVuI6gbq6/CExX+oaWErhMKBsypjwejbBkVh1LZtUNO79zjlzeEYv6hJLLO/Z09rN9Xy+7O/vpS+foy+Q40JdhZ0cfLfv7WL+zk+5Ulp5Ult5MjiPpVJpBZTxKZTxKRTxKMhYhFjXi0QjVyRiNVQkaqhPUVc6gOjGbqkSUqkSM6qRfpioRoyIeoSJYvjIRpSIWIRmP+gNHxIhGbPB7yOd8Kai33T8Krf50j+8lFA4KiSpfxknUQk+rHxnUvikoI3VCts0n3USNr/tn+mDHalh/96uPGhpOJObXlazzJaRkUEZKVPsDV3+HX2+2P4gx7ctIhRPOA72Ial+OiiUhmvQ9j8YT/BDUyobDRSFHQQlcjilmRiw6mPSjEWP2NN/KHg3nHJmcI53Lk876Wn0258jmHN2pLJ39GTr7Mhzoy9DZn+VAX4beVJa+TI6+dI50zs+fyeXpTmV5eW83+7al6ezPks4eaWmlsE1QEYtSlRhM8pXB34aqRhqrZ9FUnWBale8V1FfGqSgcAKIRIg1gjf67qUnGaKxOMK0yPnCQO0ihlFR8roDg+7SIL+PEKn1voXMHdLwCnTt9jyPVOVi22fey72kk6/zJ48aFvpUfS/oST3+nPwC1b/bzpbsHD0LDfgkRsKhfNpb0n5usDR7B81hF0IMJHoVeSy7tY05U+RJU4WARq/AHu0JPKdUVxNHr369qHDxwZPv9Z0ZiwWdU+e+g0COJVUJNs++NVE7zB6BYsqisVXTOIxLz21P4XnH+wFwoyeVzvreTz/pYCt/PovP8ldHjSAlcyoqZkYj5ETKM8+3WM7k8vekcveksvencQG+gPzP4PJXJD0zL5n1vIpPL+3kyOXrTg/P3pHO83NbD6q372d+bZoRK0Qjb6XsO8WiEeHDAS2XzZHJ54tEIzTVJptcmaayqpqYiRk2yUF6KkohFqIhHqKtYRl3Ncmqnx4IeRIRkzPdCErEI8WiEXN6RzeXJ5v15jNpkjEjEDoknn3f0ZnJURCHmMr5H0LUb9m/xSb7/gE9qhaSZ6vIHjFRw4nr/Fp+EC8NKo4mgNV/h/2b6fUkq0zuYFLP9g9cdxCp80k7W+ATdt98fhPr2+y8rGiTjfGbwM4oPaJk+GHoV83h7/0+VwEVKJR6NUF8Zob5y/O8tk887ulJZDvRm6OhLB70H33PIO4cD8s7R3Z9lf2+a9u40fZkc6SBpOyARjZCMRUhl87R1p2jrSrG5rZueVJbulD/ojHQ+YbQiBnWVcWIR82V//J02C1cDm0FTdZLm2iQNVXFqK2ZSWzGX6qD3kYxHqaqOUt3gy0+ViSiJqD9gDDyikYPKUhXxKPGoEY9Ehj14jJtMP/S0+YNKth+yaX/+IxcMVy20rvNZDqnTFVrmAy30oLeRqBnsMdSM/+/mKoGLHAMiERson8ynasLWU+gR9KVzQTkpS1d/hlTW9xL6s/6gkM7mSWXzA2WcaMToSWXp6M3Q2Z8hFxwICuWhwiijnnSOtq5+WjtTdPRl2Lu3h67+7EDPI3WUZaiCaMSoiA0md99T8OcsCr2IyoHpEWKRiC+r5R25fJ6KeJSGqgQNVXGqEjHisQiJqFERj1KdiFGVrKQiXkM8EiEaN+IVNnBgiQcnxKMRv75EdOQDSj7vT74fNFJqAiiBi0wh0YgRjfjk11CdmPT15/OO/qxvsfemcvRmsgMHjHQ2TyqXJ5XJk8r6ZJ/K5OjP5Mnk82SyjnTOv+4vTM/58xzprL8uoS+TY39PhkwuHzwcZr73FI0Yfekc+3vTRfcPGptCuYmgN5J3bqD3BH4klR/xFOOf3nEqrz+haVzWW6AELiKTJhKxYLhnDGpKF0cqm6M/7a81SAfnKHpTObpTWVLZ3MDw1UxwMjwdHBBywXkNv4w/wKSyeX8ZADYw/DURixA1ozudHThpXjcBpTclcBGZcvzJ2vBfRTumAo2ZrTKzF81sk5ldM15BiYjI4R11AjezKPBt4CJgKfBeM1s6XoGJiMirG0sL/Cxgk3PuZedcGvgR8PbxCUtERA5nLAl8DrC96HVLMO0gZna1ma02s9VtbW1jWJ2IiBSb8DvYOOdudM6tcM6taG5unujViYhMGWNJ4DuAeUWv5wbTRERkEowlgf8BWGxmC80sAbwHuHt8whIRkcM56nHgzrmsmf018B9AFLjVOff8uEUmIiKvalJ/kcfM2oBtR7n4dGDvOIYTFlNxu6fiNsPU3O6puM1w5Nt9vHPukJOIk5rAx8LMVg/3k0Llbipu91TcZpia2z0VtxnGb7v1O0oiIiGlBC4iElJhSuA3ljqAEpmK2z0Vtxmm5nZPxW2Gcdru0NTARUTkYGFqgYuISBElcBGRkApFAp8K9x03s3lm9pCZvWBmz5vZJ4PpjWZ2v5ltDP42lDrW8WZmUTN7xsx+FbxeaGZPBvv7x8GVvmXFzKaZ2U/NbIOZrTezc8p9X5vZ3wb/tteZ2R1mVlGO+9rMbjWzVjNbVzRt2H1r3reC7X/WzE4/knUd8wl8Ct13PAt82jm3FDgb+ESwndcADzrnFgMPBq/LzSeB9UWv/wfwDefcicB+4MMliWpi/SvwG+fcKcDr8NtftvvazOYAfwOscM69Bn/19nsoz319G7BqyLSR9u1FwOLgcTVww5Gs6JhP4EyR+44753Y559YEz7vw/6Hn4Lf19mC224HLSxLgBDGzucAlwM3BawPOA34azFKO21wP/ClwC4BzLu2c66DM9zX+1h2VZhYDqoBdlOG+ds49AuwbMnmkfft24LvOewKYZmazRruuMCTwUd13vJyY2QLgNOBJYKZzblfw1m5gZqnimiDfBD4H5IPXTUCHcy4bvC7H/b0QaAP+LSgd3Wxm1ZTxvnbO7QD+BXgFn7gPAE9T/vu6YKR9O6b8FoYEPqWYWQ1wJ/Ap51xn8XvOj/ksm3GfZnYp0Oqce7rUsUyyGHA6cINz7jSghyHlkjLc1w341uZCYDZQzaFlhilhPPdtGBL4lLnvuJnF8cn7B865nwWT9xS6VMHf1lLFNwHOBS4zs6340th5+NrwtKCbDeW5v1uAFufck8Hrn+ITejnv67cAW5xzbc65DPAz/P4v931dMNK+HVN+C0MCnxL3HQ9qv7cA651zXy96627gquD5VcAvJju2ieKc+4Jzbq5zbgF+v/7WOfd+4CHgXcFsZbXNAM653cB2Mzs5mHQ+8AJlvK/xpZOzzawq+Lde2Oay3tdFRtq3dwMfDEajnA0cKCq1HJ5z7ph/ABcDLwGbgb8rdTwTtI1/gu9WPQusDR4X42vCDwIbgQeAxlLHOkHbvxL4VfD8BOApYBPw70Cy1PFNwPYuB1YH+/vnQEO572vgK8AGYB3wPSBZjvsauANf58/ge1sfHmnfAoYfZbcZeA4/SmfU69Kl9CIiIRWGEoqIiAxDCVxEJKSUwEVEQkoJXEQkpJTARURCSglcRCSklMBFRELq/wMmyj0uBjHl9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372a0f3",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfaa90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46c3d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f02276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 13662081.0000 - mse: 13662063.0000 - val_loss: 9398970.0000 - val_mse: 9398942.0000\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8569272.0000 - mse: 8569246.0000 - val_loss: 8293434.0000 - val_mse: 8293403.5000\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6984733.5000 - mse: 6984701.5000 - val_loss: 6273028.5000 - val_mse: 6272992.5000\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4409571.0000 - mse: 4409530.5000 - val_loss: 3872776.2500 - val_mse: 3872733.5000\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2524431.7500 - mse: 2524385.2500 - val_loss: 3023757.0000 - val_mse: 3023708.7500\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1981831.6250 - mse: 1981782.2500 - val_loss: 2798864.0000 - val_mse: 2798814.2500\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1785348.1250 - mse: 1785297.5000 - val_loss: 2570337.0000 - val_mse: 2570286.2500\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1623218.0000 - mse: 1623166.8750 - val_loss: 2436749.5000 - val_mse: 2436698.2500\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1563337.5000 - mse: 1563285.6250 - val_loss: 2326081.5000 - val_mse: 2326029.7500\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1459773.3750 - mse: 1459721.3750 - val_loss: 2250780.2500 - val_mse: 2250728.2500\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1403595.2500 - mse: 1403542.8750 - val_loss: 2232236.2500 - val_mse: 2232184.2500\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1342678.0000 - mse: 1342625.2500 - val_loss: 2193117.5000 - val_mse: 2193065.0000\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1301508.1250 - mse: 1301455.5000 - val_loss: 2102957.7500 - val_mse: 2102904.5000\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1266729.5000 - mse: 1266676.2500 - val_loss: 2058123.7500 - val_mse: 2058071.3750\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1251769.7500 - mse: 1251716.6250 - val_loss: 2005705.8750 - val_mse: 2005652.3750\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1209973.3750 - mse: 1209919.6250 - val_loss: 1989514.3750 - val_mse: 1989460.8750\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1170357.3750 - mse: 1170304.0000 - val_loss: 1944799.2500 - val_mse: 1944745.5000\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1148552.5000 - mse: 1148498.7500 - val_loss: 1981270.7500 - val_mse: 1981217.5000\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1145545.5000 - mse: 1145491.6250 - val_loss: 1883313.1250 - val_mse: 1883259.1250\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1130603.2500 - mse: 1130549.1250 - val_loss: 1993755.2500 - val_mse: 1993700.8750\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1084775.7500 - mse: 1084721.3750 - val_loss: 1958513.5000 - val_mse: 1958458.5000\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1085898.8750 - mse: 1085844.5000 - val_loss: 1832850.2500 - val_mse: 1832795.6250\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1059558.2500 - mse: 1059503.8750 - val_loss: 1796713.8750 - val_mse: 1796659.2500\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1053641.1250 - mse: 1053586.7500 - val_loss: 1763560.5000 - val_mse: 1763505.3750\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1052451.3750 - mse: 1052396.6250 - val_loss: 1820233.6250 - val_mse: 1820178.6250\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1030125.7500 - mse: 1030070.1250 - val_loss: 1803326.3750 - val_mse: 1803271.2500\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1008332.6250 - mse: 1008277.1875 - val_loss: 1749433.6250 - val_mse: 1749378.5000\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1004651.2500 - mse: 1004596.0625 - val_loss: 1748601.2500 - val_mse: 1748546.3750\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 995845.6250 - mse: 995790.1250 - val_loss: 1696029.1250 - val_mse: 1695973.5000\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 977338.6250 - mse: 977282.6250 - val_loss: 1730962.0000 - val_mse: 1730906.2500\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 950254.1250 - mse: 950197.6875 - val_loss: 1698099.6250 - val_mse: 1698043.3750\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 972599.0625 - mse: 972542.8750 - val_loss: 1651193.1250 - val_mse: 1651137.0000\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 930853.2500 - mse: 930796.6250 - val_loss: 1908261.5000 - val_mse: 1908204.7500\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 935797.7500 - mse: 935740.6250 - val_loss: 1624729.2500 - val_mse: 1624672.3750\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 904258.7500 - mse: 904202.0625 - val_loss: 1609406.6250 - val_mse: 1609350.0000\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 898629.1875 - mse: 898572.0000 - val_loss: 1614664.6250 - val_mse: 1614607.5000\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 881987.3125 - mse: 881930.8750 - val_loss: 1640202.1250 - val_mse: 1640145.0000\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 915286.0000 - mse: 915228.6250 - val_loss: 1940951.3750 - val_mse: 1940894.7500\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 863747.5000 - mse: 863690.0000 - val_loss: 1652608.3750 - val_mse: 1652550.7500\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 826725.3750 - mse: 826667.3125 - val_loss: 1614206.6250 - val_mse: 1614148.8750\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 816026.9375 - mse: 815968.6250 - val_loss: 1655759.1250 - val_mse: 1655700.8750\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 788524.1875 - mse: 788465.4375 - val_loss: 1579160.7500 - val_mse: 1579102.7500\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 770994.5625 - mse: 770935.9375 - val_loss: 1642386.7500 - val_mse: 1642328.2500\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 768305.1875 - mse: 768246.6250 - val_loss: 1578392.2500 - val_mse: 1578333.5000\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 760314.8125 - mse: 760255.5625 - val_loss: 1606242.6250 - val_mse: 1606183.6250\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 729313.8125 - mse: 729255.0625 - val_loss: 1639592.2500 - val_mse: 1639532.6250\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 706951.3125 - mse: 706892.2500 - val_loss: 1576707.6250 - val_mse: 1576648.5000\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 700227.3750 - mse: 700168.1250 - val_loss: 1554492.3750 - val_mse: 1554432.5000\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 692853.5625 - mse: 692794.1250 - val_loss: 1591290.8750 - val_mse: 1591231.5000\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 673904.1250 - mse: 673843.6250 - val_loss: 1613940.5000 - val_mse: 1613880.7500\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 665164.1875 - mse: 665104.0000 - val_loss: 1565098.3750 - val_mse: 1565038.1250\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 639572.0000 - mse: 639511.8125 - val_loss: 1582185.7500 - val_mse: 1582125.5000\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 650349.8750 - mse: 650289.5000 - val_loss: 1634773.5000 - val_mse: 1634713.0000\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 635978.9375 - mse: 635918.3125 - val_loss: 1549032.5000 - val_mse: 1548972.0000\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 600277.8125 - mse: 600217.0000 - val_loss: 1512920.6250 - val_mse: 1512860.2500\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 588124.5000 - mse: 588064.0000 - val_loss: 1494403.8750 - val_mse: 1494343.3750\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 587799.6875 - mse: 587739.3125 - val_loss: 1542443.6250 - val_mse: 1542382.8750\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 578191.5000 - mse: 578130.5625 - val_loss: 1501953.0000 - val_mse: 1501892.0000\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 559311.0000 - mse: 559250.0625 - val_loss: 1450631.1250 - val_mse: 1450570.2500\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 540265.7500 - mse: 540204.3750 - val_loss: 1637006.8750 - val_mse: 1636945.3750\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 542436.8125 - mse: 542375.6250 - val_loss: 1562607.1250 - val_mse: 1562545.7500\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 529656.0000 - mse: 529594.4375 - val_loss: 1446757.8750 - val_mse: 1446696.7500\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 527573.4375 - mse: 527512.3125 - val_loss: 1464230.8750 - val_mse: 1464169.0000\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 504832.4688 - mse: 504771.0312 - val_loss: 1530339.3750 - val_mse: 1530277.3750\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 503906.0000 - mse: 503844.4062 - val_loss: 1411427.5000 - val_mse: 1411365.8750\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 507116.9688 - mse: 507055.2500 - val_loss: 1461147.6250 - val_mse: 1461086.6250\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 501290.0938 - mse: 501228.3438 - val_loss: 1467495.2500 - val_mse: 1467432.8750\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 473485.9062 - mse: 473424.0000 - val_loss: 1420083.6250 - val_mse: 1420021.6250\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 487728.0625 - mse: 487666.0000 - val_loss: 1443715.5000 - val_mse: 1443653.6250\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 468345.5625 - mse: 468283.7188 - val_loss: 1442363.6250 - val_mse: 1442301.8750\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 466121.4062 - mse: 466059.3750 - val_loss: 1447932.3750 - val_mse: 1447869.8750\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 472015.0000 - mse: 471952.7188 - val_loss: 1466309.8750 - val_mse: 1466247.8750\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 451815.7500 - mse: 451753.6562 - val_loss: 1470686.7500 - val_mse: 1470625.0000\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 453962.9688 - mse: 453900.6875 - val_loss: 1458749.1250 - val_mse: 1458687.0000\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 434948.3438 - mse: 434886.0312 - val_loss: 1466651.1250 - val_mse: 1466588.5000\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 433048.2188 - mse: 432986.0625 - val_loss: 1410955.8750 - val_mse: 1410893.7500\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 428561.7500 - mse: 428499.6562 - val_loss: 1373052.3750 - val_mse: 1372989.6250\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 416795.1875 - mse: 416733.1875 - val_loss: 1372809.6250 - val_mse: 1372747.1250\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 425858.6875 - mse: 425796.7500 - val_loss: 1446433.2500 - val_mse: 1446370.8750\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 421323.4688 - mse: 421261.1875 - val_loss: 1339807.5000 - val_mse: 1339744.7500\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 403917.3438 - mse: 403855.0312 - val_loss: 1338769.2500 - val_mse: 1338706.8750\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 411954.5938 - mse: 411892.3438 - val_loss: 1295963.5000 - val_mse: 1295900.5000\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 396739.4688 - mse: 396676.6562 - val_loss: 1269937.6250 - val_mse: 1269874.7500\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 397856.8125 - mse: 397794.0625 - val_loss: 1365465.7500 - val_mse: 1365402.8750\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 416812.5312 - mse: 416750.0000 - val_loss: 1336432.3750 - val_mse: 1336369.5000\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 385691.4062 - mse: 385628.5938 - val_loss: 1275158.7500 - val_mse: 1275096.2500\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 381996.6250 - mse: 381933.8125 - val_loss: 1239753.7500 - val_mse: 1239690.7500\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 387618.9375 - mse: 387556.3438 - val_loss: 1301072.3750 - val_mse: 1301009.3750\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 376080.2188 - mse: 376017.5000 - val_loss: 1233900.6250 - val_mse: 1233838.0000\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 367549.9062 - mse: 367487.3125 - val_loss: 1218245.1250 - val_mse: 1218182.8750\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 358120.5938 - mse: 358057.9062 - val_loss: 1207673.8750 - val_mse: 1207611.0000\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 359569.9375 - mse: 359506.9375 - val_loss: 1205787.8750 - val_mse: 1205725.1250\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 356639.9688 - mse: 356577.4688 - val_loss: 1303946.3750 - val_mse: 1303883.6250\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 352989.4688 - mse: 352926.5312 - val_loss: 1297932.0000 - val_mse: 1297869.1250\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 375953.1250 - mse: 375890.2500 - val_loss: 1296862.6250 - val_mse: 1296800.0000\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 350750.9688 - mse: 350687.8125 - val_loss: 1253952.5000 - val_mse: 1253889.5000\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 343448.5312 - mse: 343385.8125 - val_loss: 1207923.0000 - val_mse: 1207860.1250\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 338002.1875 - mse: 337939.2812 - val_loss: 1299133.8750 - val_mse: 1299071.2500\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 338135.9062 - mse: 338073.1250 - val_loss: 1237217.6250 - val_mse: 1237154.8750\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 330643.0938 - mse: 330580.0938 - val_loss: 1421733.3750 - val_mse: 1421670.2500\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfff1e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2d573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
