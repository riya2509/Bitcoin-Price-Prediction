{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_11676\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997e90c",
   "metadata": {},
   "source": [
    "### Reading the StandardScaler Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.272445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.704053</td>\n",
       "      <td>1.120934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.353933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.883147</td>\n",
       "      <td>2.657742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.295429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.163925</td>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.192652</td>\n",
       "      <td>1.870249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.236208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.837456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.469148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>3.095343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.405711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.357963</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.251772</td>\n",
       "      <td>1.284827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.265765</td>\n",
       "      <td>0.541070</td>\n",
       "      <td>1.093741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.610268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.480020</td>\n",
       "      <td>1.381913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0    1         2         3         4    5    6  \\\n",
       "0           0  1.272445  0.0  1.704053  1.120934  0.000000  0.0  0.0   \n",
       "1           1  1.295429  0.0  1.163925  0.983769  0.000000  0.0  0.0   \n",
       "2           2  0.236208  0.0  2.837456  0.000000  0.000000  0.0  0.0   \n",
       "3           3  0.000000  0.0  1.357963  0.984608  0.195242  0.0  0.0   \n",
       "4           4  0.000000  0.0  1.265765  0.541070  1.093741  0.0  0.0   \n",
       "\n",
       "          7    8  ...        99  100       101  102       103       104  105  \\\n",
       "0  0.000000  0.0  ...  0.000000  0.0  1.353933  0.0  1.883147  2.657742  0.0   \n",
       "1  0.631568  0.0  ...  0.000000  0.0  1.538430  0.0  1.192652  1.870249  0.0   \n",
       "2  0.742867  0.0  ...  0.000000  0.0  2.469148  0.0  0.563751  3.095343  0.0   \n",
       "3  0.322820  0.0  ...  0.021757  0.0  0.676755  0.0  1.251772  1.284827  0.0   \n",
       "4  0.713462  0.0  ...  0.000000  0.0  1.610268  0.0  1.480020  1.381913  0.0   \n",
       "\n",
       "        106  107  priceUSD  \n",
       "0  0.000000  0.0    0.0495  \n",
       "1  0.000000  0.0    0.0726  \n",
       "2  2.405711  0.0    0.0859  \n",
       "3  0.532028  0.0    0.0783  \n",
       "4  0.505411  0.0    0.0767  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_StandardScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.272445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.704053</td>\n",
       "      <td>1.120934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.353933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883147</td>\n",
       "      <td>2.657742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.295429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.163925</td>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.538430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.192652</td>\n",
       "      <td>1.870249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.469148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>3.095343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.405711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.357963</td>\n",
       "      <td>0.984608</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.251772</td>\n",
       "      <td>1.284827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.265765</td>\n",
       "      <td>0.541070</td>\n",
       "      <td>1.093741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.610268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480020</td>\n",
       "      <td>1.381913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.179494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614658</td>\n",
       "      <td>0.307597</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>1.324451</td>\n",
       "      <td>0.889618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.348079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.255987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427702</td>\n",
       "      <td>0.383041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.422990</td>\n",
       "      <td>1.447299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.341647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111734</td>\n",
       "      <td>0.241010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271751</td>\n",
       "      <td>1.107438</td>\n",
       "      <td>1.205667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153612</td>\n",
       "      <td>0.399873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298529</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067724</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>1.353312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394479</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.438531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306807</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.595487</td>\n",
       "      <td>0.821820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4    5         6  \\\n",
       "0     1.272445  0.000000  1.704053  1.120934  0.000000  0.0  0.000000   \n",
       "1     1.295429  0.000000  1.163925  0.983769  0.000000  0.0  0.000000   \n",
       "2     0.236208  0.000000  2.837456  0.000000  0.000000  0.0  0.000000   \n",
       "3     0.000000  0.000000  1.357963  0.984608  0.195242  0.0  0.000000   \n",
       "4     0.000000  0.000000  1.265765  0.541070  1.093741  0.0  0.000000   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3483  0.000000  0.227086  0.000000  0.024436  0.179494  0.0  0.000000   \n",
       "3484  0.216949  0.348079  0.000000  0.000000  0.353724  0.0  0.135385   \n",
       "3485  0.000000  0.661399  0.000000  0.078300  0.341647  0.0  0.218927   \n",
       "3486  0.000000  0.093544  0.000000  0.153612  0.399873  0.0  0.095809   \n",
       "3487  0.000000  0.000000  0.394479  0.035400  0.438531  0.0  0.000000   \n",
       "\n",
       "             7    8         9  ...        99       100       101       102  \\\n",
       "0     0.000000  0.0  0.000000  ...  0.000000  0.000000  1.353933  0.000000   \n",
       "1     0.631568  0.0  0.000000  ...  0.000000  0.000000  1.538430  0.000000   \n",
       "2     0.742867  0.0  0.000000  ...  0.000000  0.000000  2.469148  0.000000   \n",
       "3     0.322820  0.0  0.000000  ...  0.021757  0.000000  0.676755  0.000000   \n",
       "4     0.713462  0.0  0.000000  ...  0.000000  0.000000  1.610268  0.000000   \n",
       "...        ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "3483  0.000000  0.0  0.000000  ...  0.614658  0.307597  0.039078  0.058152   \n",
       "3484  0.255987  0.0  0.000000  ...  0.427702  0.383041  0.000000  0.000000   \n",
       "3485  0.000000  0.0  0.020619  ...  0.111734  0.241010  0.000000  0.271751   \n",
       "3486  0.000000  0.0  0.125356  ...  0.298529  0.103416  0.000000  0.067724   \n",
       "3487  0.247208  0.0  0.050051  ...  0.306807  0.103375  0.000000  0.164673   \n",
       "\n",
       "           103       104  105       106  107   priceUSD  \n",
       "0     1.883147  2.657742  0.0  0.000000  0.0     0.0495  \n",
       "1     1.192652  1.870249  0.0  0.000000  0.0     0.0726  \n",
       "2     0.563751  3.095343  0.0  2.405711  0.0     0.0859  \n",
       "3     1.251772  1.284827  0.0  0.532028  0.0     0.0783  \n",
       "4     1.480020  1.381913  0.0  0.505411  0.0     0.0767  \n",
       "...        ...       ...  ...       ...  ...        ...  \n",
       "3483  1.324451  0.889618  0.0  0.000000  0.0  9349.0000  \n",
       "3484  1.422990  1.447299  0.0  0.000000  0.0  9394.0000  \n",
       "3485  1.107438  1.205667  0.0  0.000000  0.0  9366.0000  \n",
       "3486  0.839254  1.353312  0.0  0.000000  0.0  9393.0000  \n",
       "3487  0.595487  0.821820  0.0  0.000000  0.0  9398.0000  \n",
       "\n",
       "[3488 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696033133092869\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654355588959702"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719523254414289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f6cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8598",
   "metadata": {},
   "source": [
    "### Visualising the Training set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb1b1b",
   "metadata": {},
   "source": [
    "### Visualising the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=8, n_estimators=1500,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.902482505598834\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 8, 'n_estimators': 1500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: 0.8897739697803364\n",
      "Best Score: 0.863969239492269\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: 0.8965929588276618\n",
      "Best Score: 0.8671505521777825\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: 0.8904098800685958\n",
      "Best Score: 0.8704403873875151\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: 0.8841527699322463\n",
      "Best Score: 0.8641856024088155\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: 0.8875459245333887\n",
      "Best Score: 0.8684026644984076\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feebca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a9fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a46884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2116.6958 - mean_absolute_error: 2113.5232 - val_loss: 2204.4280 - val_mean_absolute_error: 2199.3467\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1967.4637 - mean_absolute_error: 1958.8795 - val_loss: 2019.9888 - val_mean_absolute_error: 2009.5829\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1742.5967 - mean_absolute_error: 1728.6528 - val_loss: 1579.4561 - val_mean_absolute_error: 1560.4722\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1130.6588 - mean_absolute_error: 1106.7896 - val_loss: 1089.0056 - val_mean_absolute_error: 1062.2150\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 879.2118 - mean_absolute_error: 852.0579 - val_loss: 967.6157 - val_mean_absolute_error: 940.3318\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 806.8529 - mean_absolute_error: 779.3030 - val_loss: 925.4561 - val_mean_absolute_error: 897.3883\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 768.3546 - mean_absolute_error: 740.4603 - val_loss: 891.7680 - val_mean_absolute_error: 863.8555\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 739.7768 - mean_absolute_error: 711.8352 - val_loss: 864.1634 - val_mean_absolute_error: 835.9772\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 719.5744 - mean_absolute_error: 691.4058 - val_loss: 839.8708 - val_mean_absolute_error: 811.5092\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 693.6263 - mean_absolute_error: 665.1532 - val_loss: 819.6343 - val_mean_absolute_error: 791.2070\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 670.6307 - mean_absolute_error: 642.0309 - val_loss: 789.2600 - val_mean_absolute_error: 760.4487\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 653.2165 - mean_absolute_error: 624.4668 - val_loss: 781.7360 - val_mean_absolute_error: 752.9847\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 639.0957 - mean_absolute_error: 610.2855 - val_loss: 768.2490 - val_mean_absolute_error: 739.5200\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 625.2532 - mean_absolute_error: 596.4625 - val_loss: 745.5580 - val_mean_absolute_error: 716.4963\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 614.1804 - mean_absolute_error: 585.2620 - val_loss: 739.3896 - val_mean_absolute_error: 710.6177\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 605.4484 - mean_absolute_error: 576.6777 - val_loss: 729.8879 - val_mean_absolute_error: 701.0749\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 593.5087 - mean_absolute_error: 564.6357 - val_loss: 728.7859 - val_mean_absolute_error: 700.1229\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 589.3051 - mean_absolute_error: 560.5652 - val_loss: 721.6652 - val_mean_absolute_error: 693.0184\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 577.4173 - mean_absolute_error: 548.8282 - val_loss: 777.3889 - val_mean_absolute_error: 748.2856\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 577.0289 - mean_absolute_error: 548.3726 - val_loss: 716.2696 - val_mean_absolute_error: 687.8685\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 567.0417 - mean_absolute_error: 538.5372 - val_loss: 714.2750 - val_mean_absolute_error: 685.9114\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 564.1732 - mean_absolute_error: 535.7291 - val_loss: 714.7073 - val_mean_absolute_error: 686.0429\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 561.5214 - mean_absolute_error: 533.1263 - val_loss: 704.4338 - val_mean_absolute_error: 676.1398\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 553.2531 - mean_absolute_error: 524.9308 - val_loss: 701.6656 - val_mean_absolute_error: 673.3155\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.0640 - mean_absolute_error: 526.8456 - val_loss: 701.8173 - val_mean_absolute_error: 673.5894\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 545.0662 - mean_absolute_error: 516.9079 - val_loss: 692.3154 - val_mean_absolute_error: 664.2958\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 544.6454 - mean_absolute_error: 516.5445 - val_loss: 690.9914 - val_mean_absolute_error: 663.1343\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 536.4039 - mean_absolute_error: 508.5841 - val_loss: 701.3903 - val_mean_absolute_error: 673.3820\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 531.2213 - mean_absolute_error: 503.2829 - val_loss: 685.0197 - val_mean_absolute_error: 657.2325\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 530.7502 - mean_absolute_error: 502.9641 - val_loss: 687.9215 - val_mean_absolute_error: 660.0482\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 521.7723 - mean_absolute_error: 494.0358 - val_loss: 684.1917 - val_mean_absolute_error: 656.3663\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 521.8652 - mean_absolute_error: 494.1306 - val_loss: 677.1194 - val_mean_absolute_error: 649.4014\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 509.9183 - mean_absolute_error: 482.2071 - val_loss: 672.2512 - val_mean_absolute_error: 644.7250\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 510.6479 - mean_absolute_error: 483.0134 - val_loss: 667.2996 - val_mean_absolute_error: 639.6619\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 502.7074 - mean_absolute_error: 475.1764 - val_loss: 665.8274 - val_mean_absolute_error: 638.3509\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 503.0404 - mean_absolute_error: 475.5269 - val_loss: 665.7449 - val_mean_absolute_error: 638.4301\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 495.1400 - mean_absolute_error: 467.7704 - val_loss: 662.6287 - val_mean_absolute_error: 635.3562\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 484.9858 - mean_absolute_error: 457.6826 - val_loss: 658.4915 - val_mean_absolute_error: 631.2314\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 494.0305 - mean_absolute_error: 466.8602 - val_loss: 665.4761 - val_mean_absolute_error: 638.2032\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 481.4246 - mean_absolute_error: 454.2110 - val_loss: 652.0995 - val_mean_absolute_error: 624.8297\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 482.1481 - mean_absolute_error: 454.9384 - val_loss: 647.3037 - val_mean_absolute_error: 620.2224\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 475.1105 - mean_absolute_error: 448.0056 - val_loss: 643.8619 - val_mean_absolute_error: 616.8189\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.6628 - mean_absolute_error: 444.6192 - val_loss: 647.5848 - val_mean_absolute_error: 620.5361\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 463.2100 - mean_absolute_error: 436.2545 - val_loss: 679.2148 - val_mean_absolute_error: 652.0016\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.8652 - mean_absolute_error: 434.9852 - val_loss: 634.1519 - val_mean_absolute_error: 607.3817\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 453.2206 - mean_absolute_error: 426.4277 - val_loss: 630.7010 - val_mean_absolute_error: 603.9368\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 450.8075 - mean_absolute_error: 424.0718 - val_loss: 658.0793 - val_mean_absolute_error: 631.1851\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 448.8721 - mean_absolute_error: 422.2087 - val_loss: 658.2103 - val_mean_absolute_error: 631.3475\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 451.8617 - mean_absolute_error: 425.2719 - val_loss: 647.4915 - val_mean_absolute_error: 621.0923\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.8997 - mean_absolute_error: 413.3778 - val_loss: 624.0261 - val_mean_absolute_error: 597.5231\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.8430 - mean_absolute_error: 413.4695 - val_loss: 634.1488 - val_mean_absolute_error: 607.6729\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 429.7267 - mean_absolute_error: 403.3957 - val_loss: 620.7950 - val_mean_absolute_error: 594.5457\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 430.7434 - mean_absolute_error: 404.4587 - val_loss: 615.0364 - val_mean_absolute_error: 588.6900\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 427.3259 - mean_absolute_error: 401.1097 - val_loss: 609.6406 - val_mean_absolute_error: 583.4125\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.2588 - mean_absolute_error: 393.1823 - val_loss: 606.6602 - val_mean_absolute_error: 580.7505\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 417.0679 - mean_absolute_error: 391.0829 - val_loss: 610.1718 - val_mean_absolute_error: 584.0823\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.0422 - mean_absolute_error: 387.1296 - val_loss: 619.1127 - val_mean_absolute_error: 593.2341\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.7685 - mean_absolute_error: 387.9966 - val_loss: 602.6392 - val_mean_absolute_error: 576.7958\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 406.8075 - mean_absolute_error: 381.1223 - val_loss: 608.9805 - val_mean_absolute_error: 583.2684\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 396.4923 - mean_absolute_error: 370.8864 - val_loss: 600.0231 - val_mean_absolute_error: 574.5658\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 397.7312 - mean_absolute_error: 372.2382 - val_loss: 604.9602 - val_mean_absolute_error: 579.4400\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 391.2271 - mean_absolute_error: 365.8171 - val_loss: 613.1122 - val_mean_absolute_error: 587.6016\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 394.5311 - mean_absolute_error: 369.1996 - val_loss: 622.2382 - val_mean_absolute_error: 596.9427\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 384.8835 - mean_absolute_error: 359.6842 - val_loss: 586.7697 - val_mean_absolute_error: 561.6816\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 381.4129 - mean_absolute_error: 356.2691 - val_loss: 593.7324 - val_mean_absolute_error: 568.5790\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 382.7001 - mean_absolute_error: 357.6770 - val_loss: 580.9818 - val_mean_absolute_error: 555.8358\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 375.7143 - mean_absolute_error: 350.6768 - val_loss: 595.7078 - val_mean_absolute_error: 570.6057\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 371.0401 - mean_absolute_error: 346.1391 - val_loss: 565.5144 - val_mean_absolute_error: 540.6469\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 363.5592 - mean_absolute_error: 338.7496 - val_loss: 592.4833 - val_mean_absolute_error: 567.8698\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 359.9349 - mean_absolute_error: 335.2395 - val_loss: 561.3876 - val_mean_absolute_error: 536.8138\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 357.6252 - mean_absolute_error: 333.0481 - val_loss: 575.0956 - val_mean_absolute_error: 550.4565\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 357.5228 - mean_absolute_error: 333.0538 - val_loss: 566.3933 - val_mean_absolute_error: 541.9378\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 354.6743 - mean_absolute_error: 330.3221 - val_loss: 576.1599 - val_mean_absolute_error: 551.7322\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 350.4642 - mean_absolute_error: 326.1548 - val_loss: 564.6543 - val_mean_absolute_error: 540.2649\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 344.3726 - mean_absolute_error: 320.1401 - val_loss: 550.5806 - val_mean_absolute_error: 526.3582\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 343.6812 - mean_absolute_error: 319.5551 - val_loss: 571.2552 - val_mean_absolute_error: 547.0803\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 344.5599 - mean_absolute_error: 320.5192 - val_loss: 552.1814 - val_mean_absolute_error: 528.1906\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 340.1513 - mean_absolute_error: 316.2487 - val_loss: 563.6891 - val_mean_absolute_error: 539.7429\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 334.5416 - mean_absolute_error: 310.7037 - val_loss: 556.9922 - val_mean_absolute_error: 533.1075\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 326.3048 - mean_absolute_error: 302.5523 - val_loss: 542.2000 - val_mean_absolute_error: 518.4937\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 333.9476 - mean_absolute_error: 310.2481 - val_loss: 534.3476 - val_mean_absolute_error: 510.5792\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 327.6607 - mean_absolute_error: 303.9807 - val_loss: 525.6226 - val_mean_absolute_error: 502.0430\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 322.5287 - mean_absolute_error: 298.9763 - val_loss: 533.7886 - val_mean_absolute_error: 510.3171\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 317.9988 - mean_absolute_error: 294.5361 - val_loss: 552.9497 - val_mean_absolute_error: 529.3721\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 320.9137 - mean_absolute_error: 297.4971 - val_loss: 534.1590 - val_mean_absolute_error: 510.7978\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 314.5040 - mean_absolute_error: 291.1799 - val_loss: 525.1284 - val_mean_absolute_error: 501.8563\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 314.6813 - mean_absolute_error: 291.4305 - val_loss: 533.5577 - val_mean_absolute_error: 510.3527\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 306.4319 - mean_absolute_error: 283.2125 - val_loss: 522.6188 - val_mean_absolute_error: 499.3894\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 310.8489 - mean_absolute_error: 287.7171 - val_loss: 536.2355 - val_mean_absolute_error: 513.1734\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 307.8840 - mean_absolute_error: 284.7815 - val_loss: 511.3110 - val_mean_absolute_error: 488.2573\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 301.8386 - mean_absolute_error: 278.8546 - val_loss: 520.6880 - val_mean_absolute_error: 497.7189\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 295.9207 - mean_absolute_error: 272.9614 - val_loss: 517.1862 - val_mean_absolute_error: 494.2460\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 294.0574 - mean_absolute_error: 271.1949 - val_loss: 506.4311 - val_mean_absolute_error: 483.5755\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 292.6793 - mean_absolute_error: 269.8628 - val_loss: 511.8698 - val_mean_absolute_error: 489.0461\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 293.9750 - mean_absolute_error: 271.2218 - val_loss: 511.1296 - val_mean_absolute_error: 488.3795\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 293.0942 - mean_absolute_error: 270.4049 - val_loss: 500.4455 - val_mean_absolute_error: 477.8286\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 283.0433 - mean_absolute_error: 260.3764 - val_loss: 495.4747 - val_mean_absolute_error: 472.8357\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 288.2190 - mean_absolute_error: 265.5977 - val_loss: 500.9290 - val_mean_absolute_error: 478.3549\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 281.2153 - mean_absolute_error: 258.6915 - val_loss: 502.9233 - val_mean_absolute_error: 480.3742\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 283.0928 - mean_absolute_error: 260.6140 - val_loss: 499.2413 - val_mean_absolute_error: 476.7077\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37768832",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab05fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7376bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
