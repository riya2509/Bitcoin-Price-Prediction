{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_14252\\646315669.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e7c4",
   "metadata": {},
   "source": [
    "### Reading the YeoJohnson Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0         1          2          3         4          5  \\\n",
       "0           0  32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1           1  32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2           2  33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3           3  32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4           4  32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "\n",
       "           6         7         8  ...        89        90        91        92  \\\n",
       "0  16.524812  0.166351 -8.700498  ...  1.923946  3.832444 -2.257067  2.835188   \n",
       "1  17.966608 -0.569542 -9.306701  ...  1.593726  0.604879  0.335266  1.183815   \n",
       "2  16.543319  0.781871 -8.695417  ...  0.497217 -0.891250  2.450366  2.249480   \n",
       "3  17.856147  1.884261 -6.869309  ... -0.687552 -0.829605 -5.461876  0.345240   \n",
       "4  16.420547  3.158366 -8.634797  ... -0.422376  1.025973  1.077336  0.491024   \n",
       "\n",
       "         93        94        95        96        97  priceUSD  \n",
       "0 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201    0.0495  \n",
       "1 -0.294895 -1.473127 -0.657472  0.007406 -2.294048    0.0726  \n",
       "2 -1.947763 -2.079104  1.532892  1.893578 -0.800749    0.0859  \n",
       "3 -0.446096 -0.270433  6.035264  4.706512 -1.654442    0.0783  \n",
       "4  0.339590 -0.503155  3.711262  1.314670 -0.031391    0.0767  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('PCA_YeoJohnson_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.837640</td>\n",
       "      <td>3.132764</td>\n",
       "      <td>18.739693</td>\n",
       "      <td>-20.866008</td>\n",
       "      <td>0.372720</td>\n",
       "      <td>-11.044245</td>\n",
       "      <td>16.524812</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>-8.700498</td>\n",
       "      <td>10.438027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.923946</td>\n",
       "      <td>3.832444</td>\n",
       "      <td>-2.257067</td>\n",
       "      <td>2.835188</td>\n",
       "      <td>-0.372358</td>\n",
       "      <td>-2.096878</td>\n",
       "      <td>-1.698082</td>\n",
       "      <td>-1.425736</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.698404</td>\n",
       "      <td>1.773636</td>\n",
       "      <td>15.820019</td>\n",
       "      <td>-18.043860</td>\n",
       "      <td>5.153551</td>\n",
       "      <td>-13.023228</td>\n",
       "      <td>17.966608</td>\n",
       "      <td>-0.569542</td>\n",
       "      <td>-9.306701</td>\n",
       "      <td>9.018383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593726</td>\n",
       "      <td>0.604879</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>-0.294895</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.657472</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-2.294048</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.090879</td>\n",
       "      <td>0.464927</td>\n",
       "      <td>16.262612</td>\n",
       "      <td>-15.361686</td>\n",
       "      <td>6.718747</td>\n",
       "      <td>-15.603086</td>\n",
       "      <td>16.543319</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>-8.695417</td>\n",
       "      <td>8.221800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-0.891250</td>\n",
       "      <td>2.450366</td>\n",
       "      <td>2.249480</td>\n",
       "      <td>-1.947763</td>\n",
       "      <td>-2.079104</td>\n",
       "      <td>1.532892</td>\n",
       "      <td>1.893578</td>\n",
       "      <td>-0.800749</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.781217</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>11.529916</td>\n",
       "      <td>-13.659240</td>\n",
       "      <td>5.869486</td>\n",
       "      <td>-9.849079</td>\n",
       "      <td>17.856147</td>\n",
       "      <td>1.884261</td>\n",
       "      <td>-6.869309</td>\n",
       "      <td>6.376521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687552</td>\n",
       "      <td>-0.829605</td>\n",
       "      <td>-5.461876</td>\n",
       "      <td>0.345240</td>\n",
       "      <td>-0.446096</td>\n",
       "      <td>-0.270433</td>\n",
       "      <td>6.035264</td>\n",
       "      <td>4.706512</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.896643</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>15.860615</td>\n",
       "      <td>-14.031376</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>-11.811843</td>\n",
       "      <td>16.420547</td>\n",
       "      <td>3.158366</td>\n",
       "      <td>-8.634797</td>\n",
       "      <td>5.447760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422376</td>\n",
       "      <td>1.025973</td>\n",
       "      <td>1.077336</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.339590</td>\n",
       "      <td>-0.503155</td>\n",
       "      <td>3.711262</td>\n",
       "      <td>1.314670</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>-19.315494</td>\n",
       "      <td>0.236167</td>\n",
       "      <td>-2.750750</td>\n",
       "      <td>-5.370912</td>\n",
       "      <td>-0.186745</td>\n",
       "      <td>4.678685</td>\n",
       "      <td>1.096600</td>\n",
       "      <td>3.019217</td>\n",
       "      <td>2.146403</td>\n",
       "      <td>3.662000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429743</td>\n",
       "      <td>1.624900</td>\n",
       "      <td>1.085748</td>\n",
       "      <td>-0.379536</td>\n",
       "      <td>-0.537552</td>\n",
       "      <td>-0.248166</td>\n",
       "      <td>-0.836404</td>\n",
       "      <td>1.001076</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-19.318940</td>\n",
       "      <td>0.733044</td>\n",
       "      <td>-0.889637</td>\n",
       "      <td>-5.979197</td>\n",
       "      <td>-1.170327</td>\n",
       "      <td>4.752099</td>\n",
       "      <td>-1.059497</td>\n",
       "      <td>4.918116</td>\n",
       "      <td>1.074642</td>\n",
       "      <td>2.816077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>-0.073998</td>\n",
       "      <td>-0.315707</td>\n",
       "      <td>1.726772</td>\n",
       "      <td>0.086268</td>\n",
       "      <td>-0.590934</td>\n",
       "      <td>-1.087419</td>\n",
       "      <td>0.384172</td>\n",
       "      <td>0.323270</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-19.018647</td>\n",
       "      <td>0.730092</td>\n",
       "      <td>-4.161934</td>\n",
       "      <td>-3.696162</td>\n",
       "      <td>2.779836</td>\n",
       "      <td>1.157445</td>\n",
       "      <td>-1.148338</td>\n",
       "      <td>4.904417</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>3.601954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613840</td>\n",
       "      <td>-0.938060</td>\n",
       "      <td>0.686956</td>\n",
       "      <td>2.921627</td>\n",
       "      <td>1.419180</td>\n",
       "      <td>-0.648111</td>\n",
       "      <td>-1.180782</td>\n",
       "      <td>-0.634334</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-19.091961</td>\n",
       "      <td>-1.767811</td>\n",
       "      <td>0.812909</td>\n",
       "      <td>-4.477929</td>\n",
       "      <td>-1.827579</td>\n",
       "      <td>-0.380548</td>\n",
       "      <td>-2.042414</td>\n",
       "      <td>3.578432</td>\n",
       "      <td>-0.707056</td>\n",
       "      <td>4.743335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276470</td>\n",
       "      <td>-0.493735</td>\n",
       "      <td>0.480427</td>\n",
       "      <td>1.565258</td>\n",
       "      <td>-0.317555</td>\n",
       "      <td>-1.248186</td>\n",
       "      <td>-0.791837</td>\n",
       "      <td>-0.580324</td>\n",
       "      <td>0.377241</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>-18.978473</td>\n",
       "      <td>-4.552622</td>\n",
       "      <td>1.547258</td>\n",
       "      <td>-2.263347</td>\n",
       "      <td>-0.054753</td>\n",
       "      <td>-3.135464</td>\n",
       "      <td>-2.699181</td>\n",
       "      <td>3.506751</td>\n",
       "      <td>-0.261364</td>\n",
       "      <td>5.744565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037892</td>\n",
       "      <td>-0.282042</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>1.032256</td>\n",
       "      <td>-0.721593</td>\n",
       "      <td>-2.401458</td>\n",
       "      <td>-0.049565</td>\n",
       "      <td>-0.425631</td>\n",
       "      <td>1.137282</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2          3         4          5  \\\n",
       "0     32.837640  3.132764  18.739693 -20.866008  0.372720 -11.044245   \n",
       "1     32.698404  1.773636  15.820019 -18.043860  5.153551 -13.023228   \n",
       "2     33.090879  0.464927  16.262612 -15.361686  6.718747 -15.603086   \n",
       "3     32.781217  1.794096  11.529916 -13.659240  5.869486  -9.849079   \n",
       "4     32.896643 -0.166702  15.860615 -14.031376  0.153960 -11.811843   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "3483 -19.315494  0.236167  -2.750750  -5.370912 -0.186745   4.678685   \n",
       "3484 -19.318940  0.733044  -0.889637  -5.979197 -1.170327   4.752099   \n",
       "3485 -19.018647  0.730092  -4.161934  -3.696162  2.779836   1.157445   \n",
       "3486 -19.091961 -1.767811   0.812909  -4.477929 -1.827579  -0.380548   \n",
       "3487 -18.978473 -4.552622   1.547258  -2.263347 -0.054753  -3.135464   \n",
       "\n",
       "              6         7         8          9  ...        89        90  \\\n",
       "0     16.524812  0.166351 -8.700498  10.438027  ...  1.923946  3.832444   \n",
       "1     17.966608 -0.569542 -9.306701   9.018383  ...  1.593726  0.604879   \n",
       "2     16.543319  0.781871 -8.695417   8.221800  ...  0.497217 -0.891250   \n",
       "3     17.856147  1.884261 -6.869309   6.376521  ... -0.687552 -0.829605   \n",
       "4     16.420547  3.158366 -8.634797   5.447760  ... -0.422376  1.025973   \n",
       "...         ...       ...       ...        ...  ...       ...       ...   \n",
       "3483   1.096600  3.019217  2.146403   3.662000  ... -0.429743  1.624900   \n",
       "3484  -1.059497  4.918116  1.074642   2.816077  ... -0.004836 -0.073998   \n",
       "3485  -1.148338  4.904417 -0.041506   3.601954  ... -0.613840 -0.938060   \n",
       "3486  -2.042414  3.578432 -0.707056   4.743335  ...  0.276470 -0.493735   \n",
       "3487  -2.699181  3.506751 -0.261364   5.744565  ... -0.037892 -0.282042   \n",
       "\n",
       "            91        92        93        94        95        96        97  \\\n",
       "0    -2.257067  2.835188 -0.372358 -2.096878 -1.698082 -1.425736 -0.033201   \n",
       "1     0.335266  1.183815 -0.294895 -1.473127 -0.657472  0.007406 -2.294048   \n",
       "2     2.450366  2.249480 -1.947763 -2.079104  1.532892  1.893578 -0.800749   \n",
       "3    -5.461876  0.345240 -0.446096 -0.270433  6.035264  4.706512 -1.654442   \n",
       "4     1.077336  0.491024  0.339590 -0.503155  3.711262  1.314670 -0.031391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3483  1.085748 -0.379536 -0.537552 -0.248166 -0.836404  1.001076  0.001219   \n",
       "3484 -0.315707  1.726772  0.086268 -0.590934 -1.087419  0.384172  0.323270   \n",
       "3485  0.686956  2.921627  1.419180 -0.648111 -1.180782 -0.634334  0.133916   \n",
       "3486  0.480427  1.565258 -0.317555 -1.248186 -0.791837 -0.580324  0.377241   \n",
       "3487  0.909180  1.032256 -0.721593 -2.401458 -0.049565 -0.425631  1.137282   \n",
       "\n",
       "       priceUSD  \n",
       "0        0.0495  \n",
       "1        0.0726  \n",
       "2        0.0859  \n",
       "3        0.0783  \n",
       "4        0.0767  \n",
       "...         ...  \n",
       "3483  9349.0000  \n",
       "3484  9394.0000  \n",
       "3485  9366.0000  \n",
       "3486  9393.0000  \n",
       "3487  9398.0000  \n",
       "\n",
       "[3488 rows x 99 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14234118490774\n",
      "Test score of trained model: 94.02823354757119\n"
     ]
    }
   ],
   "source": [
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a571d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55fc2f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>858605.503644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>926.609682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.247982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>24122.446463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  858605.503644\n",
       "1    RMSE     926.609682\n",
       "2     MAE     670.247982\n",
       "3    MAPE   24122.446463\n",
       "4      r2       0.940282\n",
       "5  adj_r2       0.930512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df117c14",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b0b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14224300146029\n",
      "Test score of trained model: 94.02074116036616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef8eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>859682.740160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>927.190779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.376568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  859682.740160\n",
       "1    RMSE     927.190779\n",
       "2     MAE     670.376568\n",
       "3      r2       0.940207\n",
       "4  adj_r2       0.930425"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24492141",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08632cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 94.14233880334643\n",
      "Test score of trained model: 94.02710187901044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56250573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>858768.212092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>926.697476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>670.263321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.940271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.930499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  858768.212092\n",
       "1    RMSE     926.697476\n",
       "2     MAE     670.263321\n",
       "3      r2       0.940271\n",
       "4  adj_r2       0.930499"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22e9c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7e6d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.99284958209076\n",
      "Test score of trained model: 98.90440187824827\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2988516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>157522.331895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>396.890831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>204.881696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.989044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.987252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  157522.331895\n",
       "1    RMSE     396.890831\n",
       "2     MAE     204.881696\n",
       "3      r2       0.989044\n",
       "4  adj_r2       0.987252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.02, max_depth=6, n_estimators=1500,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9824443667130819\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 1500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a0b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9799060617308104\n",
      "   Metric          Score\n",
      "0     MSE  288905.571329\n",
      "1    RMSE     537.499369\n",
      "2     MAE     237.928568\n",
      "3      r2       0.979906\n",
      "4  adj_r2       0.976619\n",
      "Best Score: 0.9748497282055306\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9804893665065109\n",
      "   Metric          Score\n",
      "0     MSE  280518.962530\n",
      "1    RMSE     529.640409\n",
      "2     MAE     242.483708\n",
      "3      r2       0.980489\n",
      "4  adj_r2       0.977297\n",
      "Best Score: 0.9746090795136542\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9808225380767001\n",
      "   Metric          Score\n",
      "0     MSE  275728.705810\n",
      "1    RMSE     525.098758\n",
      "2     MAE     236.723931\n",
      "3      r2       0.980823\n",
      "4  adj_r2       0.977685\n",
      "Best Score: 0.9753531154743568\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9793885903858499\n",
      "   Metric          Score\n",
      "0     MSE  296345.643681\n",
      "1    RMSE     544.376381\n",
      "2     MAE     242.233838\n",
      "3      r2       0.979389\n",
      "4  adj_r2       0.976016\n",
      "Best Score: 0.9760824962324405\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9807132411934273\n",
      "   Metric          Score\n",
      "0     MSE  277300.148803\n",
      "1    RMSE     526.592963\n",
      "2     MAE     233.439198\n",
      "3      r2       0.980713\n",
      "4  adj_r2       0.977558\n",
      "Best Score: 0.9753413716926552\n",
      "Best params: {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0452ec",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce0f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f53d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5805da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 1925.0907 - mean_absolute_error: 1916.3882 - val_loss: 1051.0133 - val_mean_absolute_error: 1028.6763\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.2269 - mean_absolute_error: 530.3229 - val_loss: 392.2671 - val_mean_absolute_error: 366.8821\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 324.4345 - mean_absolute_error: 298.6511 - val_loss: 316.5970 - val_mean_absolute_error: 290.3983\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 268.1576 - mean_absolute_error: 241.7326 - val_loss: 277.6089 - val_mean_absolute_error: 250.8374\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 231.6049 - mean_absolute_error: 204.5079 - val_loss: 246.8540 - val_mean_absolute_error: 219.2948\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 195.6277 - mean_absolute_error: 167.7855 - val_loss: 225.4012 - val_mean_absolute_error: 197.4346\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 172.6006 - mean_absolute_error: 144.3984 - val_loss: 199.9062 - val_mean_absolute_error: 171.5529\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 159.0792 - mean_absolute_error: 130.6856 - val_loss: 189.3156 - val_mean_absolute_error: 160.7638\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 139.1628 - mean_absolute_error: 110.7216 - val_loss: 168.0865 - val_mean_absolute_error: 139.7336\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 132.0135 - mean_absolute_error: 103.6365 - val_loss: 158.8051 - val_mean_absolute_error: 130.4295\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 122.8992 - mean_absolute_error: 94.6102 - val_loss: 148.0955 - val_mean_absolute_error: 119.8850\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 114.8478 - mean_absolute_error: 86.6698 - val_loss: 152.2289 - val_mean_absolute_error: 124.2652\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 110.3403 - mean_absolute_error: 82.4654 - val_loss: 147.4705 - val_mean_absolute_error: 119.8343\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 113.0731 - mean_absolute_error: 85.3339 - val_loss: 141.1973 - val_mean_absolute_error: 113.6088\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 102.6387 - mean_absolute_error: 75.2207 - val_loss: 130.2419 - val_mean_absolute_error: 102.9298\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.3302 - mean_absolute_error: 69.0979 - val_loss: 132.1357 - val_mean_absolute_error: 104.9797\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 93.1214 - mean_absolute_error: 66.1846 - val_loss: 127.8501 - val_mean_absolute_error: 100.9753\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 89.6815 - mean_absolute_error: 63.0703 - val_loss: 124.5074 - val_mean_absolute_error: 98.0630\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 86.8960 - mean_absolute_error: 60.6294 - val_loss: 129.0385 - val_mean_absolute_error: 103.0097\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 91.7266 - mean_absolute_error: 65.6550 - val_loss: 120.3050 - val_mean_absolute_error: 94.3135\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 84.4313 - mean_absolute_error: 58.5212 - val_loss: 115.4325 - val_mean_absolute_error: 89.6757\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 84.0829 - mean_absolute_error: 58.3884 - val_loss: 133.7224 - val_mean_absolute_error: 108.0920\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.7578 - mean_absolute_error: 56.2992 - val_loss: 128.0510 - val_mean_absolute_error: 102.6810\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 81.0854 - mean_absolute_error: 55.8684 - val_loss: 114.5725 - val_mean_absolute_error: 89.5132\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.6958 - mean_absolute_error: 48.7265 - val_loss: 125.4007 - val_mean_absolute_error: 100.6365\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 79.5556 - mean_absolute_error: 54.7888 - val_loss: 119.2964 - val_mean_absolute_error: 94.5907\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.6410 - mean_absolute_error: 48.0916 - val_loss: 115.2115 - val_mean_absolute_error: 90.8128\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 72.4996 - mean_absolute_error: 48.1710 - val_loss: 117.9565 - val_mean_absolute_error: 93.7536\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 73.1181 - mean_absolute_error: 49.0608 - val_loss: 119.1442 - val_mean_absolute_error: 95.2653\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.9982 - mean_absolute_error: 47.1390 - val_loss: 111.1567 - val_mean_absolute_error: 87.4444\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.8454 - mean_absolute_error: 52.1473 - val_loss: 121.5042 - val_mean_absolute_error: 97.8277\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.5907 - mean_absolute_error: 45.0555 - val_loss: 127.6105 - val_mean_absolute_error: 104.0930\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.4554 - mean_absolute_error: 52.1662 - val_loss: 157.2134 - val_mean_absolute_error: 133.8475\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.6015 - mean_absolute_error: 45.4995 - val_loss: 111.9565 - val_mean_absolute_error: 88.9051\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 66.1127 - mean_absolute_error: 43.1675 - val_loss: 105.4253 - val_mean_absolute_error: 82.7124\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.9318 - mean_absolute_error: 42.2047 - val_loss: 118.0530 - val_mean_absolute_error: 95.3919\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.5755 - mean_absolute_error: 41.0170 - val_loss: 111.3149 - val_mean_absolute_error: 88.7866\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3490 - mean_absolute_error: 40.9890 - val_loss: 115.9596 - val_mean_absolute_error: 93.7352\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.5728 - mean_absolute_error: 40.4655 - val_loss: 110.4610 - val_mean_absolute_error: 88.4431\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.5399 - mean_absolute_error: 38.6122 - val_loss: 109.9453 - val_mean_absolute_error: 88.0493\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.3217 - mean_absolute_error: 41.5846 - val_loss: 110.7555 - val_mean_absolute_error: 89.2207\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.5520 - mean_absolute_error: 41.0126 - val_loss: 108.7839 - val_mean_absolute_error: 87.3018\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.9302 - mean_absolute_error: 36.5442 - val_loss: 102.0122 - val_mean_absolute_error: 80.6921\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 57.9133 - mean_absolute_error: 36.7376 - val_loss: 111.3885 - val_mean_absolute_error: 90.3075\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.3337 - mean_absolute_error: 37.3566 - val_loss: 107.4274 - val_mean_absolute_error: 86.4578\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 60.0548 - mean_absolute_error: 39.1402 - val_loss: 107.0621 - val_mean_absolute_error: 86.2902\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.6112 - mean_absolute_error: 40.8652 - val_loss: 105.7464 - val_mean_absolute_error: 85.0231\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.4052 - mean_absolute_error: 37.7912 - val_loss: 105.5875 - val_mean_absolute_error: 85.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 59.2943 - mean_absolute_error: 38.8326 - val_loss: 114.2298 - val_mean_absolute_error: 93.9946\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 59.3413 - mean_absolute_error: 39.0467 - val_loss: 105.8211 - val_mean_absolute_error: 85.5814\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.0042 - mean_absolute_error: 41.8470 - val_loss: 101.5672 - val_mean_absolute_error: 81.4372\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.7756 - mean_absolute_error: 36.7660 - val_loss: 104.1582 - val_mean_absolute_error: 84.3008\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0071 - mean_absolute_error: 36.1503 - val_loss: 106.9575 - val_mean_absolute_error: 87.1069\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4458 - mean_absolute_error: 35.7074 - val_loss: 102.6028 - val_mean_absolute_error: 82.9572\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0658 - mean_absolute_error: 36.4751 - val_loss: 99.8436 - val_mean_absolute_error: 80.4151\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.2937 - mean_absolute_error: 33.8805 - val_loss: 108.6203 - val_mean_absolute_error: 89.2208\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.1238 - mean_absolute_error: 35.8410 - val_loss: 114.8978 - val_mean_absolute_error: 95.7567\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4646 - mean_absolute_error: 36.3478 - val_loss: 108.3949 - val_mean_absolute_error: 89.4384\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 58.0425 - mean_absolute_error: 39.0584 - val_loss: 117.5241 - val_mean_absolute_error: 98.4917\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.3177 - mean_absolute_error: 36.4585 - val_loss: 107.4486 - val_mean_absolute_error: 88.6125\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1157 - mean_absolute_error: 32.3708 - val_loss: 105.3901 - val_mean_absolute_error: 86.6726\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.4457 - mean_absolute_error: 32.8701 - val_loss: 95.7728 - val_mean_absolute_error: 77.2041\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.9858 - mean_absolute_error: 37.5476 - val_loss: 108.3038 - val_mean_absolute_error: 89.8185\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.6764 - mean_absolute_error: 32.3253 - val_loss: 98.0849 - val_mean_absolute_error: 79.8817\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.9257 - mean_absolute_error: 32.7104 - val_loss: 98.9322 - val_mean_absolute_error: 80.7976\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.1071 - mean_absolute_error: 34.9254 - val_loss: 104.3514 - val_mean_absolute_error: 86.2489\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.6731 - mean_absolute_error: 34.6317 - val_loss: 100.3989 - val_mean_absolute_error: 82.4531\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1552 - mean_absolute_error: 33.2487 - val_loss: 106.0139 - val_mean_absolute_error: 88.1687\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3766 - mean_absolute_error: 32.6025 - val_loss: 96.0492 - val_mean_absolute_error: 78.3865\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.8537 - mean_absolute_error: 34.2140 - val_loss: 103.3072 - val_mean_absolute_error: 85.7056\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.3808 - mean_absolute_error: 38.8314 - val_loss: 96.7501 - val_mean_absolute_error: 79.2647\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.7563 - mean_absolute_error: 31.3199 - val_loss: 105.4230 - val_mean_absolute_error: 87.9394\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.6373 - mean_absolute_error: 32.3195 - val_loss: 97.6656 - val_mean_absolute_error: 80.4157\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.3970 - mean_absolute_error: 32.2401 - val_loss: 94.8950 - val_mean_absolute_error: 77.8159\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1616 - mean_absolute_error: 29.0823 - val_loss: 101.2273 - val_mean_absolute_error: 84.2011\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0319 - mean_absolute_error: 30.0685 - val_loss: 98.5384 - val_mean_absolute_error: 81.6263\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9162 - mean_absolute_error: 28.0869 - val_loss: 101.3770 - val_mean_absolute_error: 84.5873\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.5837 - mean_absolute_error: 29.7770 - val_loss: 102.5304 - val_mean_absolute_error: 85.7332\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6205 - mean_absolute_error: 34.9582 - val_loss: 96.1039 - val_mean_absolute_error: 79.5392\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.7813 - mean_absolute_error: 30.2516 - val_loss: 97.7925 - val_mean_absolute_error: 81.2987\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.6491 - mean_absolute_error: 27.1822 - val_loss: 98.5108 - val_mean_absolute_error: 82.1334\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.5609 - mean_absolute_error: 34.2266 - val_loss: 94.6177 - val_mean_absolute_error: 78.3468\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3629 - mean_absolute_error: 30.0994 - val_loss: 95.4998 - val_mean_absolute_error: 79.2804\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1606 - mean_absolute_error: 35.0205 - val_loss: 99.7356 - val_mean_absolute_error: 83.6425\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8136 - mean_absolute_error: 30.7899 - val_loss: 97.1319 - val_mean_absolute_error: 81.1843\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.6063 - mean_absolute_error: 30.6826 - val_loss: 96.7833 - val_mean_absolute_error: 80.8888\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.1843 - mean_absolute_error: 29.3168 - val_loss: 98.5423 - val_mean_absolute_error: 82.7978\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.5367 - mean_absolute_error: 32.8228 - val_loss: 91.7706 - val_mean_absolute_error: 76.0659\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1515 - mean_absolute_error: 30.5281 - val_loss: 98.0167 - val_mean_absolute_error: 82.3871\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5771 - mean_absolute_error: 28.0215 - val_loss: 96.2712 - val_mean_absolute_error: 80.7932\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.0732 - mean_absolute_error: 31.6153 - val_loss: 95.9183 - val_mean_absolute_error: 80.4873\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1568 - mean_absolute_error: 27.7832 - val_loss: 91.8399 - val_mean_absolute_error: 76.4758\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1976 - mean_absolute_error: 27.8766 - val_loss: 101.5777 - val_mean_absolute_error: 86.2550\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.8331 - mean_absolute_error: 33.6224 - val_loss: 93.8013 - val_mean_absolute_error: 78.6087\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.8559 - mean_absolute_error: 27.7094 - val_loss: 91.1895 - val_mean_absolute_error: 76.1031\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.3348 - mean_absolute_error: 29.2635 - val_loss: 90.7493 - val_mean_absolute_error: 75.6902\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 41.0007 - mean_absolute_error: 26.0171 - val_loss: 91.0001 - val_mean_absolute_error: 76.0867\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.5161 - mean_absolute_error: 28.6076 - val_loss: 95.7349 - val_mean_absolute_error: 80.8534\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.9156 - mean_absolute_error: 39.1200 - val_loss: 92.3581 - val_mean_absolute_error: 77.6205\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9828 - mean_absolute_error: 28.2353 - val_loss: 87.0560 - val_mean_absolute_error: 72.3096\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00cc4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208c1bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff965dd",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670cd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40eb48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bce9e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 2052.3181 - mean_absolute_error: 2047.3967 - val_loss: 1620.7505 - val_mean_absolute_error: 1606.5142\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 674.2803 - mean_absolute_error: 654.1384 - val_loss: 373.9341 - val_mean_absolute_error: 352.1172\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 321.3103 - mean_absolute_error: 299.0652 - val_loss: 310.5586 - val_mean_absolute_error: 287.5480\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 263.5230 - mean_absolute_error: 240.1354 - val_loss: 253.5755 - val_mean_absolute_error: 229.6250\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 199.9262 - mean_absolute_error: 175.5110 - val_loss: 212.0829 - val_mean_absolute_error: 187.1021\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 158.9676 - mean_absolute_error: 133.7665 - val_loss: 207.2228 - val_mean_absolute_error: 181.9844\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 143.0218 - mean_absolute_error: 117.6501 - val_loss: 170.1884 - val_mean_absolute_error: 144.8408\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 129.8247 - mean_absolute_error: 104.4110 - val_loss: 153.9789 - val_mean_absolute_error: 128.5450\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 119.5831 - mean_absolute_error: 94.1765 - val_loss: 144.9792 - val_mean_absolute_error: 119.6531\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 112.0648 - mean_absolute_error: 86.6986 - val_loss: 133.2887 - val_mean_absolute_error: 107.9364\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 106.0700 - mean_absolute_error: 80.8121 - val_loss: 132.1406 - val_mean_absolute_error: 107.0094\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 97.7901 - mean_absolute_error: 72.7796 - val_loss: 126.7157 - val_mean_absolute_error: 101.7830\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.8435 - mean_absolute_error: 71.9612 - val_loss: 126.4386 - val_mean_absolute_error: 101.6248\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 96.4786 - mean_absolute_error: 71.7945 - val_loss: 129.0981 - val_mean_absolute_error: 104.5851\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.2111 - mean_absolute_error: 65.7432 - val_loss: 122.8936 - val_mean_absolute_error: 98.4659\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 100.7203 - mean_absolute_error: 76.4240 - val_loss: 116.7359 - val_mean_absolute_error: 92.5685\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 90.1378 - mean_absolute_error: 66.0049 - val_loss: 118.2089 - val_mean_absolute_error: 94.1830\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 85.5869 - mean_absolute_error: 61.6580 - val_loss: 137.3639 - val_mean_absolute_error: 113.5611\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 82.7900 - mean_absolute_error: 59.0179 - val_loss: 123.2360 - val_mean_absolute_error: 99.4546\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 76.8845 - mean_absolute_error: 53.2885 - val_loss: 115.4341 - val_mean_absolute_error: 91.9049\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 78.0178 - mean_absolute_error: 54.6355 - val_loss: 111.5000 - val_mean_absolute_error: 88.1644\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 76.5715 - mean_absolute_error: 53.3106 - val_loss: 114.9726 - val_mean_absolute_error: 91.8227\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 77.3839 - mean_absolute_error: 54.2929 - val_loss: 112.9328 - val_mean_absolute_error: 90.0127\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 76.6669 - mean_absolute_error: 53.7658 - val_loss: 116.2659 - val_mean_absolute_error: 93.4330\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 71.1964 - mean_absolute_error: 48.4585 - val_loss: 105.3614 - val_mean_absolute_error: 82.7513\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.5957 - mean_absolute_error: 48.0811 - val_loss: 116.8992 - val_mean_absolute_error: 94.4059\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 75.4033 - mean_absolute_error: 53.0430 - val_loss: 109.3075 - val_mean_absolute_error: 86.9842\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 70.7648 - mean_absolute_error: 48.5581 - val_loss: 106.6479 - val_mean_absolute_error: 84.5944\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.7202 - mean_absolute_error: 46.7530 - val_loss: 107.3692 - val_mean_absolute_error: 85.4922\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.8702 - mean_absolute_error: 47.9751 - val_loss: 109.8077 - val_mean_absolute_error: 87.9078\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.5122 - mean_absolute_error: 43.7204 - val_loss: 106.5580 - val_mean_absolute_error: 84.8381\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.9634 - mean_absolute_error: 42.3372 - val_loss: 111.2883 - val_mean_absolute_error: 89.6895\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 69.6977 - mean_absolute_error: 48.2160 - val_loss: 106.6135 - val_mean_absolute_error: 85.1370\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 68.5462 - mean_absolute_error: 47.2238 - val_loss: 113.0096 - val_mean_absolute_error: 91.6513\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 64.0338 - mean_absolute_error: 42.8508 - val_loss: 110.4114 - val_mean_absolute_error: 89.2196\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.1953 - mean_absolute_error: 41.1899 - val_loss: 105.8734 - val_mean_absolute_error: 84.8733\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 63.1526 - mean_absolute_error: 42.2543 - val_loss: 108.0122 - val_mean_absolute_error: 87.2137\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.3605 - mean_absolute_error: 40.5806 - val_loss: 97.5991 - val_mean_absolute_error: 76.9473\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.3491 - mean_absolute_error: 38.7219 - val_loss: 105.6262 - val_mean_absolute_error: 85.0428\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.5463 - mean_absolute_error: 39.0371 - val_loss: 95.9408 - val_mean_absolute_error: 75.4701\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.9347 - mean_absolute_error: 38.5252 - val_loss: 101.3310 - val_mean_absolute_error: 81.0254\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 61.8930 - mean_absolute_error: 41.6624 - val_loss: 100.4530 - val_mean_absolute_error: 80.2535\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 65.1695 - mean_absolute_error: 45.0703 - val_loss: 95.9010 - val_mean_absolute_error: 75.8858\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4732 - mean_absolute_error: 35.5116 - val_loss: 101.6727 - val_mean_absolute_error: 81.8168\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.7723 - mean_absolute_error: 37.9447 - val_loss: 105.0371 - val_mean_absolute_error: 85.2422\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.8351 - mean_absolute_error: 39.1101 - val_loss: 94.3798 - val_mean_absolute_error: 74.7434\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 62.6654 - mean_absolute_error: 43.0629 - val_loss: 102.8409 - val_mean_absolute_error: 83.3271\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.7059 - mean_absolute_error: 35.2504 - val_loss: 95.4883 - val_mean_absolute_error: 76.1105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.0223 - mean_absolute_error: 36.6624 - val_loss: 96.7076 - val_mean_absolute_error: 77.4496\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 59.9059 - mean_absolute_error: 40.7335 - val_loss: 101.5792 - val_mean_absolute_error: 82.3932\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 57.9036 - mean_absolute_error: 38.8366 - val_loss: 99.5997 - val_mean_absolute_error: 80.5875\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.4538 - mean_absolute_error: 34.5085 - val_loss: 97.1525 - val_mean_absolute_error: 78.2978\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.8019 - mean_absolute_error: 34.9942 - val_loss: 88.3924 - val_mean_absolute_error: 69.6603\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.8081 - mean_absolute_error: 31.1027 - val_loss: 97.1820 - val_mean_absolute_error: 78.4924\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 56.5238 - mean_absolute_error: 37.9045 - val_loss: 97.5071 - val_mean_absolute_error: 78.9264\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 52.2008 - mean_absolute_error: 33.6904 - val_loss: 92.1453 - val_mean_absolute_error: 73.7641\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 54.7826 - mean_absolute_error: 36.4006 - val_loss: 98.8418 - val_mean_absolute_error: 80.5104\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 53.7981 - mean_absolute_error: 35.5422 - val_loss: 92.1306 - val_mean_absolute_error: 73.8951\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.3211 - mean_absolute_error: 32.1450 - val_loss: 104.3226 - val_mean_absolute_error: 86.2712\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 58.1313 - mean_absolute_error: 40.0949 - val_loss: 100.0459 - val_mean_absolute_error: 81.9982\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.8974 - mean_absolute_error: 37.9436 - val_loss: 93.9977 - val_mean_absolute_error: 76.1364\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.2082 - mean_absolute_error: 37.3476 - val_loss: 96.1013 - val_mean_absolute_error: 78.2363\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 50.0009 - mean_absolute_error: 32.1976 - val_loss: 96.8329 - val_mean_absolute_error: 79.0397\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.4980 - mean_absolute_error: 33.8295 - val_loss: 95.8022 - val_mean_absolute_error: 78.1448\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.7945 - mean_absolute_error: 30.2021 - val_loss: 103.6391 - val_mean_absolute_error: 86.0488\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.1242 - mean_absolute_error: 33.6360 - val_loss: 98.6080 - val_mean_absolute_error: 81.1760\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.8050 - mean_absolute_error: 32.4821 - val_loss: 99.2846 - val_mean_absolute_error: 81.9966\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.5127 - mean_absolute_error: 34.2430 - val_loss: 98.1787 - val_mean_absolute_error: 80.9255\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.9348 - mean_absolute_error: 31.7327 - val_loss: 93.1209 - val_mean_absolute_error: 75.9962\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.7841 - mean_absolute_error: 30.7175 - val_loss: 98.5387 - val_mean_absolute_error: 81.5790\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.1112 - mean_absolute_error: 29.1367 - val_loss: 97.0844 - val_mean_absolute_error: 80.1292\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.6290 - mean_absolute_error: 27.7899 - val_loss: 95.2914 - val_mean_absolute_error: 78.5121\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 49.3715 - mean_absolute_error: 32.6485 - val_loss: 101.7021 - val_mean_absolute_error: 85.0117\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.2838 - mean_absolute_error: 29.6222 - val_loss: 96.2826 - val_mean_absolute_error: 79.5486\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.3298 - mean_absolute_error: 27.7207 - val_loss: 96.2343 - val_mean_absolute_error: 79.6856\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.2951 - mean_absolute_error: 28.8038 - val_loss: 103.9886 - val_mean_absolute_error: 87.6637\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.3419 - mean_absolute_error: 30.9396 - val_loss: 89.1683 - val_mean_absolute_error: 72.8183\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.3768 - mean_absolute_error: 31.0411 - val_loss: 98.4358 - val_mean_absolute_error: 82.1509\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8590 - mean_absolute_error: 30.6116 - val_loss: 89.6555 - val_mean_absolute_error: 73.4675\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 47.7076 - mean_absolute_error: 31.5295 - val_loss: 100.4474 - val_mean_absolute_error: 84.2643\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.6296 - mean_absolute_error: 32.5846 - val_loss: 90.8728 - val_mean_absolute_error: 74.9165\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.2387 - mean_absolute_error: 30.2633 - val_loss: 91.9892 - val_mean_absolute_error: 76.0505\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 45.7961 - mean_absolute_error: 29.8609 - val_loss: 100.5385 - val_mean_absolute_error: 84.7147\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.6347 - mean_absolute_error: 35.8336 - val_loss: 89.0944 - val_mean_absolute_error: 73.3794\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.6312 - mean_absolute_error: 28.9341 - val_loss: 91.1332 - val_mean_absolute_error: 75.4392\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.8637 - mean_absolute_error: 31.2592 - val_loss: 88.7396 - val_mean_absolute_error: 73.2033\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.1671 - mean_absolute_error: 27.6416 - val_loss: 94.8857 - val_mean_absolute_error: 79.4620\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 48.4562 - mean_absolute_error: 33.0131 - val_loss: 92.6661 - val_mean_absolute_error: 77.2460\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 44.9455 - mean_absolute_error: 29.5468 - val_loss: 90.0514 - val_mean_absolute_error: 74.6690\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2949 - mean_absolute_error: 27.9589 - val_loss: 95.0549 - val_mean_absolute_error: 79.7171\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.3494 - mean_absolute_error: 31.0578 - val_loss: 90.1879 - val_mean_absolute_error: 74.9249\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.1545 - mean_absolute_error: 26.9607 - val_loss: 91.2400 - val_mean_absolute_error: 76.1087\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 51.2775 - mean_absolute_error: 36.1947 - val_loss: 87.1149 - val_mean_absolute_error: 72.1241\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 46.6042 - mean_absolute_error: 31.5911 - val_loss: 118.0578 - val_mean_absolute_error: 102.9504\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 55.4335 - mean_absolute_error: 40.4414 - val_loss: 91.8163 - val_mean_absolute_error: 76.8133\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 43.2270 - mean_absolute_error: 28.2604 - val_loss: 92.1630 - val_mean_absolute_error: 77.1822\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 42.9657 - mean_absolute_error: 28.0743 - val_loss: 89.1253 - val_mean_absolute_error: 74.3028\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 40.3882 - mean_absolute_error: 25.6070 - val_loss: 88.6433 - val_mean_absolute_error: 73.8747\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.5710 - mean_absolute_error: 26.8585 - val_loss: 95.4982 - val_mean_absolute_error: 80.7548\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 41.2139 - mean_absolute_error: 26.5508 - val_loss: 84.9181 - val_mean_absolute_error: 70.3270\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89e309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8686b81",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68bd4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb9eb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc7c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 22.3608 - mse: 15632333.0000 - val_loss: 9.7485 - val_mse: 16731347.0000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 6.7086 - mse: 14335441.0000 - val_loss: 4.9560 - val_mse: 15038420.0000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.6736 - mse: 12646874.0000 - val_loss: 2.9674 - val_mse: 13067835.0000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3404 - mse: 10897275.0000 - val_loss: 2.0742 - val_mse: 11166339.0000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.7605 - mse: 9332310.0000 - val_loss: 1.6365 - val_mse: 9691988.0000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.4992 - mse: 8090660.0000 - val_loss: 1.4207 - val_mse: 8606538.0000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2773 - mse: 7235100.0000 - val_loss: 1.2492 - val_mse: 7460710.0000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1866 - mse: 6303845.5000 - val_loss: 1.1135 - val_mse: 6546323.5000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0492 - mse: 5617188.0000 - val_loss: 1.0394 - val_mse: 5863699.5000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9509 - mse: 4994804.5000 - val_loss: 0.9424 - val_mse: 5324076.0000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8746 - mse: 4487395.0000 - val_loss: 0.8396 - val_mse: 4791480.0000\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.8053 - mse: 4108610.0000 - val_loss: 0.7923 - val_mse: 4377493.0000\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7638 - mse: 3731722.2500 - val_loss: 0.8008 - val_mse: 3989276.0000\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.7382 - mse: 3417614.5000 - val_loss: 0.6879 - val_mse: 3834377.7500\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6699 - mse: 3235368.0000 - val_loss: 0.6694 - val_mse: 3458678.5000\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.6187 - mse: 3017934.7500 - val_loss: 0.6012 - val_mse: 3195176.2500\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5959 - mse: 2761230.7500 - val_loss: 0.5806 - val_mse: 3017174.2500\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5521 - mse: 2617865.7500 - val_loss: 0.5471 - val_mse: 2830961.7500\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5243 - mse: 2430458.5000 - val_loss: 0.5182 - val_mse: 2739441.5000\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.5008 - mse: 2359390.5000 - val_loss: 0.4994 - val_mse: 2496335.5000\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4841 - mse: 2217594.5000 - val_loss: 0.4799 - val_mse: 2372835.2500\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4709 - mse: 2084485.5000 - val_loss: 0.4885 - val_mse: 2336861.0000\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4689 - mse: 2016608.3750 - val_loss: 0.4538 - val_mse: 2308639.0000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4432 - mse: 1983315.7500 - val_loss: 0.4451 - val_mse: 2111773.2500\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4275 - mse: 1844998.0000 - val_loss: 0.4266 - val_mse: 2060486.0000\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4170 - mse: 1787361.7500 - val_loss: 0.4204 - val_mse: 1965609.0000\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4048 - mse: 1709523.1250 - val_loss: 0.4056 - val_mse: 1972700.2500\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3949 - mse: 1720723.5000 - val_loss: 0.3942 - val_mse: 1788772.5000\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4254 - mse: 1643055.0000 - val_loss: 0.4261 - val_mse: 1919579.0000\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3976 - mse: 1642057.0000 - val_loss: 0.3797 - val_mse: 1839273.3750\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3647 - mse: 1594888.1250 - val_loss: 0.3622 - val_mse: 1755498.8750\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3513 - mse: 1556165.0000 - val_loss: 0.3504 - val_mse: 1706755.6250\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3401 - mse: 1473146.2500 - val_loss: 0.3391 - val_mse: 1663166.6250\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3294 - mse: 1458195.0000 - val_loss: 0.3304 - val_mse: 1661319.2500\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3207 - mse: 1440802.1250 - val_loss: 0.3212 - val_mse: 1644004.7500\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3149 - mse: 1423780.1250 - val_loss: 0.3173 - val_mse: 1598555.7500\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3072 - mse: 1390340.1250 - val_loss: 0.3099 - val_mse: 1631403.8750\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3017 - mse: 1379520.8750 - val_loss: 0.3039 - val_mse: 1592753.2500\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2951 - mse: 1366930.1250 - val_loss: 0.2989 - val_mse: 1533725.0000\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2890 - mse: 1339930.6250 - val_loss: 0.2913 - val_mse: 1532256.8750\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2841 - mse: 1342600.1250 - val_loss: 0.2909 - val_mse: 1486187.5000\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2791 - mse: 1315246.5000 - val_loss: 0.2795 - val_mse: 1498347.1250\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2706 - mse: 1304429.2500 - val_loss: 0.2734 - val_mse: 1460942.6250\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2643 - mse: 1275548.7500 - val_loss: 0.2671 - val_mse: 1463357.8750\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2579 - mse: 1255327.2500 - val_loss: 0.2644 - val_mse: 1462391.5000\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2527 - mse: 1244832.6250 - val_loss: 0.2607 - val_mse: 1458759.1250\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2512 - mse: 1263537.7500 - val_loss: 0.2469 - val_mse: 1380565.1250\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2452 - mse: 1219504.7500 - val_loss: 0.2418 - val_mse: 1443267.2500\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2317 - mse: 1171590.3750 - val_loss: 0.2334 - val_mse: 1421028.2500\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2249 - mse: 1160485.8750 - val_loss: 0.2280 - val_mse: 1388728.2500\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2200 - mse: 1158056.3750 - val_loss: 0.2229 - val_mse: 1323250.7500\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2154 - mse: 1111871.5000 - val_loss: 0.2195 - val_mse: 1336148.3750\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2103 - mse: 1127275.5000 - val_loss: 0.2149 - val_mse: 1285171.1250\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2103 - mse: 1091042.3750 - val_loss: 0.2126 - val_mse: 1333767.8750\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2045 - mse: 1111046.0000 - val_loss: 0.2088 - val_mse: 1251082.5000\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2017 - mse: 1069972.0000 - val_loss: 0.2092 - val_mse: 1278711.7500\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2082 - mse: 1079856.1250 - val_loss: 0.2458 - val_mse: 1220905.2500\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2277 - mse: 1106104.5000 - val_loss: 0.2133 - val_mse: 1329900.1250\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2001 - mse: 1088160.7500 - val_loss: 0.2016 - val_mse: 1281282.8750\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1919 - mse: 1072897.5000 - val_loss: 0.1941 - val_mse: 1195438.8750\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1857 - mse: 1022047.4375 - val_loss: 0.1898 - val_mse: 1213516.2500\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1830 - mse: 1027495.9375 - val_loss: 0.1882 - val_mse: 1221339.1250\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1812 - mse: 1019131.4375 - val_loss: 0.1872 - val_mse: 1149278.6250\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1816 - mse: 995443.1250 - val_loss: 0.1852 - val_mse: 1175639.2500\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1781 - mse: 993212.0000 - val_loss: 0.1841 - val_mse: 1137588.6250\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1773 - mse: 993073.1875 - val_loss: 0.1840 - val_mse: 1163884.2500\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1757 - mse: 995003.4375 - val_loss: 0.1807 - val_mse: 1121237.6250\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1740 - mse: 966194.1250 - val_loss: 0.1785 - val_mse: 1151583.7500\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1723 - mse: 981315.1250 - val_loss: 0.1796 - val_mse: 1097572.7500\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1719 - mse: 951226.8125 - val_loss: 0.1794 - val_mse: 1162932.1250\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1724 - mse: 968020.0625 - val_loss: 0.1796 - val_mse: 1113405.6250\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1690 - mse: 953467.5000 - val_loss: 0.1730 - val_mse: 1161505.1250\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1658 - mse: 951382.4375 - val_loss: 0.1710 - val_mse: 1108830.2500\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1642 - mse: 934422.3750 - val_loss: 0.1748 - val_mse: 1137907.8750\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 938087.5000 - val_loss: 0.1675 - val_mse: 1085910.3750\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 923913.3750 - val_loss: 0.1651 - val_mse: 1122403.0000\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1593 - mse: 919965.3750 - val_loss: 0.1678 - val_mse: 1141087.8750\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1573 - mse: 926674.5625 - val_loss: 0.1603 - val_mse: 1089658.1250\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1532 - mse: 903051.5000 - val_loss: 0.1586 - val_mse: 1098961.2500\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1530 - mse: 905743.0625 - val_loss: 0.1551 - val_mse: 1078155.5000\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1481 - mse: 872823.6875 - val_loss: 0.1537 - val_mse: 1096590.0000\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1563 - mse: 891672.3750 - val_loss: 0.1645 - val_mse: 1092557.3750\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1508 - mse: 896243.2500 - val_loss: 0.1559 - val_mse: 1076498.1250\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1445 - mse: 876248.4375 - val_loss: 0.1492 - val_mse: 1049988.2500\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1433 - mse: 870757.3750 - val_loss: 0.1479 - val_mse: 1063232.3750\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1424 - mse: 868113.8750 - val_loss: 0.1468 - val_mse: 1049529.6250\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1466 - mse: 841996.4375 - val_loss: 0.1471 - val_mse: 1055478.3750\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1402 - mse: 866498.0000 - val_loss: 0.1450 - val_mse: 1022955.5625\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1392 - mse: 853467.5625 - val_loss: 0.1450 - val_mse: 1018508.2500\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1410 - mse: 854286.7500 - val_loss: 0.1455 - val_mse: 973600.0000\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1380 - mse: 830562.8750 - val_loss: 0.1434 - val_mse: 1001861.7500\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1370 - mse: 834480.0000 - val_loss: 0.1420 - val_mse: 1007100.5625\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1358 - mse: 837715.5000 - val_loss: 0.1423 - val_mse: 972803.8125\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1356 - mse: 831716.9375 - val_loss: 0.1402 - val_mse: 987050.6875\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1340 - mse: 808921.0000 - val_loss: 0.1399 - val_mse: 1005356.9375\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1376 - mse: 819358.2500 - val_loss: 0.1399 - val_mse: 988864.0000\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1373 - mse: 810642.5000 - val_loss: 0.1485 - val_mse: 994874.3750\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1380 - mse: 818968.0625 - val_loss: 0.1379 - val_mse: 981725.1250\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1319 - mse: 820618.8750 - val_loss: 0.1362 - val_mse: 944799.7500\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 791384.0000 - val_loss: 0.1342 - val_mse: 980079.5000\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0ac6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d9c54",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9417533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9681cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "525d2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 10315223.0000 - mse: 10315202.0000 - val_loss: 1018902.5000 - val_mse: 1018866.0000\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 606978.1250 - mse: 606941.0625 - val_loss: 434254.8750 - val_mse: 434216.9688\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 279046.4375 - mse: 279007.8750 - val_loss: 278811.9688 - val_mse: 278772.7500\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 180648.0156 - mse: 180608.3594 - val_loss: 238822.2188 - val_mse: 238781.8438\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 135841.8438 - mse: 135801.2188 - val_loss: 165024.8125 - val_mse: 164983.6719\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 97792.6172 - mse: 97751.1250 - val_loss: 120234.4688 - val_mse: 120192.5391\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 71865.1484 - mse: 71822.8672 - val_loss: 108187.2734 - val_mse: 108144.8281\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 53593.9453 - mse: 53551.1328 - val_loss: 80583.3828 - val_mse: 80540.1641\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 43148.6680 - mse: 43105.2383 - val_loss: 54414.2617 - val_mse: 54370.6875\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 38885.7188 - mse: 38841.9688 - val_loss: 57939.1094 - val_mse: 57895.2266\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 33145.3867 - mse: 33101.3242 - val_loss: 66290.6562 - val_mse: 66246.4141\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 29568.7773 - mse: 29524.4590 - val_loss: 51423.3242 - val_mse: 51378.9141\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 28173.9453 - mse: 28129.4238 - val_loss: 47269.9180 - val_mse: 47225.3242\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 24843.0508 - mse: 24798.3809 - val_loss: 46943.8242 - val_mse: 46899.1133\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 23558.5977 - mse: 23513.8086 - val_loss: 50671.6836 - val_mse: 50626.7109\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 24652.2324 - mse: 24607.2227 - val_loss: 60090.7148 - val_mse: 60045.6953\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 18788.9121 - mse: 18743.7637 - val_loss: 45181.7617 - val_mse: 45136.6680\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 18420.2305 - mse: 18374.9258 - val_loss: 47512.5586 - val_mse: 47467.2227\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14929.4229 - mse: 14883.9863 - val_loss: 38843.5625 - val_mse: 38798.0547\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16019.5859 - mse: 15974.0381 - val_loss: 52505.7930 - val_mse: 52460.0586\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16450.1699 - mse: 16404.5098 - val_loss: 32766.7676 - val_mse: 32721.0898\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15697.4424 - mse: 15651.7129 - val_loss: 53109.3516 - val_mse: 53063.5352\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19699.8203 - mse: 19653.9785 - val_loss: 49744.8398 - val_mse: 49698.8984\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15502.4463 - mse: 15456.5195 - val_loss: 54022.1055 - val_mse: 53976.2812\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14638.1357 - mse: 14592.2080 - val_loss: 31521.2500 - val_mse: 31475.2969\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16081.5596 - mse: 16035.5088 - val_loss: 45414.9609 - val_mse: 45368.7734\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11984.0215 - mse: 11937.9014 - val_loss: 34057.5391 - val_mse: 34011.3555\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17570.2598 - mse: 17524.0859 - val_loss: 66627.4219 - val_mse: 66581.3984\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 21566.7773 - mse: 21520.5449 - val_loss: 56148.5312 - val_mse: 56102.1133\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 29401.3789 - mse: 29355.1602 - val_loss: 36798.0156 - val_mse: 36751.6836\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11761.3105 - mse: 11715.0059 - val_loss: 37449.7812 - val_mse: 37403.3945\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12860.5625 - mse: 12814.2012 - val_loss: 49791.2500 - val_mse: 49744.8594\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9412.7539 - mse: 9366.3486 - val_loss: 45245.8477 - val_mse: 45199.2305\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7488.5400 - mse: 7442.0269 - val_loss: 33144.5859 - val_mse: 33098.1211\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9321.7686 - mse: 9275.1699 - val_loss: 42549.8438 - val_mse: 42503.3633\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10016.2812 - mse: 9969.6152 - val_loss: 54768.4414 - val_mse: 54721.7031\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14795.9189 - mse: 14749.2441 - val_loss: 42187.4102 - val_mse: 42140.6836\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 20495.6621 - mse: 20448.9434 - val_loss: 35448.9648 - val_mse: 35402.3711\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 23438.2109 - mse: 23391.5254 - val_loss: 65244.4531 - val_mse: 65197.7930\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12061.9326 - mse: 12015.1973 - val_loss: 29842.0137 - val_mse: 29795.2812\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14059.1133 - mse: 14012.3086 - val_loss: 31691.6133 - val_mse: 31644.7520\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 10219.0400 - mse: 10172.1807 - val_loss: 30958.3691 - val_mse: 30911.4629\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7037.9917 - mse: 6991.0845 - val_loss: 38320.5547 - val_mse: 38273.5352\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5701.9282 - mse: 5654.9385 - val_loss: 31339.6094 - val_mse: 31292.5957\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6136.2515 - mse: 6089.2417 - val_loss: 29704.8008 - val_mse: 29657.7285\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9126.2725 - mse: 9079.1914 - val_loss: 43203.5234 - val_mse: 43156.4180\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 16634.9473 - mse: 16587.9316 - val_loss: 34445.3789 - val_mse: 34398.2422\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19163.5977 - mse: 19116.5000 - val_loss: 72650.9844 - val_mse: 72603.7266\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13280.6318 - mse: 13233.4961 - val_loss: 46375.9258 - val_mse: 46328.6289\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11064.3682 - mse: 11017.1738 - val_loss: 34484.2930 - val_mse: 34437.0234\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7362.5918 - mse: 7315.3613 - val_loss: 28349.0703 - val_mse: 28301.7988\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6975.7388 - mse: 6928.4546 - val_loss: 40267.2266 - val_mse: 40220.1289\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11632.9219 - mse: 11585.6348 - val_loss: 25176.2773 - val_mse: 25128.9375\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11410.4072 - mse: 11363.0693 - val_loss: 29297.8770 - val_mse: 29250.5312\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8122.1118 - mse: 8074.7231 - val_loss: 26015.4336 - val_mse: 25968.0742\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6201.2446 - mse: 6153.8389 - val_loss: 47275.9375 - val_mse: 47228.5000\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8993.3672 - mse: 8945.9502 - val_loss: 36686.9336 - val_mse: 36639.6562\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19184.2227 - mse: 19136.7695 - val_loss: 39795.8320 - val_mse: 39748.2383\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 19175.3965 - mse: 19127.8691 - val_loss: 62076.6367 - val_mse: 62029.2773\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11218.9512 - mse: 11171.3838 - val_loss: 43317.8672 - val_mse: 43270.1680\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6035.7715 - mse: 5988.1279 - val_loss: 25606.6660 - val_mse: 25559.0566\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7876.0312 - mse: 7828.3667 - val_loss: 47990.2734 - val_mse: 47942.5000\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4098.6562 - mse: 4050.9185 - val_loss: 25933.0508 - val_mse: 25885.2871\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7733.0171 - mse: 7685.2803 - val_loss: 27152.7754 - val_mse: 27105.0547\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9670.3213 - mse: 9622.5205 - val_loss: 23900.1230 - val_mse: 23852.3711\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11041.3350 - mse: 10993.5371 - val_loss: 38116.7188 - val_mse: 38068.9688\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14361.7832 - mse: 14313.9688 - val_loss: 52908.5625 - val_mse: 52860.7617\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13464.7021 - mse: 13416.8584 - val_loss: 36139.5586 - val_mse: 36091.6328\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6593.9282 - mse: 6546.0361 - val_loss: 32765.6406 - val_mse: 32717.7168\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5837.6758 - mse: 5789.7124 - val_loss: 29087.6875 - val_mse: 29039.7910\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13631.3428 - mse: 13583.4150 - val_loss: 30439.4980 - val_mse: 30391.5664\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5246.6689 - mse: 5198.6299 - val_loss: 26499.7227 - val_mse: 26451.6934\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6218.9648 - mse: 6170.9404 - val_loss: 29683.7656 - val_mse: 29635.6660\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5926.9253 - mse: 5878.8423 - val_loss: 33367.7891 - val_mse: 33319.7188\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6464.9277 - mse: 6416.8501 - val_loss: 24069.5137 - val_mse: 24021.4883\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6081.0752 - mse: 6032.9893 - val_loss: 31245.6270 - val_mse: 31197.4590\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9467.1494 - mse: 9419.0264 - val_loss: 27864.5586 - val_mse: 27816.3457\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 13549.4121 - mse: 13501.2480 - val_loss: 41621.2383 - val_mse: 41573.1719\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 12032.4834 - mse: 11984.3018 - val_loss: 46410.1094 - val_mse: 46361.8086\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7224.5068 - mse: 7176.2866 - val_loss: 31955.2656 - val_mse: 31906.9824\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11522.3418 - mse: 11474.0957 - val_loss: 29170.6562 - val_mse: 29122.3672\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 9417.6387 - mse: 9369.3955 - val_loss: 55115.1484 - val_mse: 55066.8281\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 6892.6172 - mse: 6844.2598 - val_loss: 27883.1758 - val_mse: 27834.8145\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4068.0095 - mse: 4019.6196 - val_loss: 26343.6172 - val_mse: 26295.1699\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3197.2856 - mse: 3148.8345 - val_loss: 23529.8809 - val_mse: 23481.4219\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3230.6091 - mse: 3182.1526 - val_loss: 25931.0508 - val_mse: 25882.5820\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4489.7808 - mse: 4441.2754 - val_loss: 23534.6621 - val_mse: 23486.1953\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14238.1504 - mse: 14189.7061 - val_loss: 40768.6836 - val_mse: 40720.1250\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 11047.4727 - mse: 10998.9707 - val_loss: 38701.4297 - val_mse: 38652.9766\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5505.6611 - mse: 5457.1060 - val_loss: 36036.6562 - val_mse: 35988.0938\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8086.2910 - mse: 8037.7188 - val_loss: 47717.0977 - val_mse: 47668.5859\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 8256.0869 - mse: 8207.4795 - val_loss: 26109.3262 - val_mse: 26060.7285\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 15561.1992 - mse: 15512.5684 - val_loss: 29609.7812 - val_mse: 29561.0898\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 17922.2305 - mse: 17873.5273 - val_loss: 34343.9141 - val_mse: 34295.2188\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7715.1826 - mse: 7666.4272 - val_loss: 21405.2441 - val_mse: 21356.5098\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4657.8594 - mse: 4609.0952 - val_loss: 30116.7246 - val_mse: 30067.8809\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4915.1011 - mse: 4866.3047 - val_loss: 28174.2754 - val_mse: 28125.4922\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3832.6208 - mse: 3783.7737 - val_loss: 27153.1016 - val_mse: 27104.1855\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 4377.8394 - mse: 4328.9375 - val_loss: 34267.3438 - val_mse: 34218.3750\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 5697.7979 - mse: 5648.8667 - val_loss: 25952.1914 - val_mse: 25903.1797\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc51368a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c9b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
