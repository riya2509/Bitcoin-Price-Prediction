{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transactions        size  sentbyaddress    difficulty      hashrate  \\\n",
      "0              235     649.653            390  1.815430e+02  2.775561e+09   \n",
      "1              248     765.285            424  1.815430e+02  1.554461e+09   \n",
      "2              354     756.040            553  1.815430e+02  1.551287e+09   \n",
      "3              413     984.707            632  1.815430e+02  1.640430e+09   \n",
      "4              256     542.483            440  1.815430e+02  1.723493e+09   \n",
      "...            ...         ...            ...           ...           ...   \n",
      "3483        340402  706867.000         433958  1.546610e+13  1.157542e+20   \n",
      "3484        332402  704883.000         416980  1.546610e+13  1.253033e+20   \n",
      "3485        334290  770486.000         398021  1.546610e+13  1.113635e+20   \n",
      "3486        303573  650769.000         338567  1.546610e+13  1.201317e+20   \n",
      "3487        290736  684127.000         257655  1.546610e+13  1.064910e+20   \n",
      "\n",
      "      mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
      "0               154298.000  1.193000e+03            0.000010   \n",
      "1               401834.000  2.620000e+03            0.000243   \n",
      "2               481473.000  4.048000e+03            0.000022   \n",
      "3               431831.000  2.341000e+03            0.000000   \n",
      "4               460783.000  2.122000e+03            0.000000   \n",
      "...                    ...           ...                 ...   \n",
      "3483                 0.163  8.336367e+09            0.561000   \n",
      "3484                 0.148  1.365361e+10            0.555000   \n",
      "3485                 0.153  1.126273e+10            0.631000   \n",
      "3486                 0.149  7.668679e+09            0.541000   \n",
      "3487                 0.159  6.486338e+09            0.548000   \n",
      "\n",
      "      median_transaction_feeUSD  confirmationtime  ...  price3rsiUSD  \\\n",
      "0                         0.000             8.324  ...         0.000   \n",
      "1                         0.000             8.372  ...         0.000   \n",
      "2                         0.000             8.276  ...         0.000   \n",
      "3                         0.000             7.956  ...        82.751   \n",
      "4                         0.000             6.957  ...        78.603   \n",
      "...                         ...               ...  ...           ...   \n",
      "3483                      0.221             9.000  ...        93.577   \n",
      "3484                      0.213             9.231  ...        94.137   \n",
      "3485                      0.270            10.000  ...        87.140   \n",
      "3486                      0.219             9.536  ...        88.385   \n",
      "3487                      0.206            10.070  ...        88.689   \n",
      "\n",
      "      price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  \\\n",
      "0            0.000          0.000          0.000          0.000         0.000   \n",
      "1            0.000          0.000          0.000          0.000         0.000   \n",
      "2            0.000          0.000          0.000          0.000         0.000   \n",
      "3            0.000          0.000          0.000          0.000        58.099   \n",
      "4            0.000          0.000          0.000          0.000         5.652   \n",
      "...            ...            ...            ...            ...           ...   \n",
      "3483        80.644         73.588         64.882         54.040        10.430   \n",
      "3484        81.436         74.176         65.272         54.195         7.432   \n",
      "3485        79.116         73.100         64.815         54.082         3.505   \n",
      "3486        79.762         73.498         65.058         54.175         0.473   \n",
      "3487        79.897         73.576         65.104         54.192         0.041   \n",
      "\n",
      "      price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
      "0            0.000          0.000          0.000          0.000  \n",
      "1            0.000          0.000          0.000          0.000  \n",
      "2            0.000          0.000          0.000          0.000  \n",
      "3            0.000          0.000          0.000          0.000  \n",
      "4            0.000          0.000          0.000          0.000  \n",
      "...            ...            ...            ...            ...  \n",
      "3483         7.538          6.497         26.536          1.663  \n",
      "3484        10.930          8.061         28.817          2.376  \n",
      "3485        11.368          5.611         29.412          0.800  \n",
      "3486        12.499          5.457         31.791          1.606  \n",
      "3487        11.011          6.081         29.624          1.220  \n",
      "\n",
      "[3488 rows x 735 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_15480\\3812082222.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3a6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transactions', 'size', 'sentbyaddress', 'difficulty', 'hashrate',\n",
      "       'mining_profitability', 'sentinusdUSD', 'transactionfeesUSD',\n",
      "       'median_transaction_feeUSD', 'confirmationtime',\n",
      "       ...\n",
      "       'price3rsiUSD', 'price7rsiUSD', 'price14rsiUSD', 'price30rsiUSD',\n",
      "       'price90rsiUSD', 'price3rocUSD', 'price7rocUSD', 'price14rocUSD',\n",
      "       'price30rocUSD', 'price90rocUSD'],\n",
      "      dtype='object', length=735)\n"
     ]
    }
   ],
   "source": [
    "list_of_column_names = list(n.columns)\n",
    "print(n.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc0148",
   "metadata": {},
   "source": [
    "### Reading the MINMAX Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2    3         4         5  \\\n",
       "0           0  0.145302  0.000000  0.179782  0.0  0.000000  0.238634   \n",
       "1           1  0.203855  0.000000  0.136095  0.0  0.005416  0.282885   \n",
       "2           2  0.155377  0.000000  0.170912  0.0  0.000000  0.371988   \n",
       "3           3  0.081168  0.056898  0.152915  0.0  0.001428  0.429266   \n",
       "4           4  0.083447  0.066815  0.103083  0.0  0.000000  0.416309   \n",
       "\n",
       "          6         7    8  ...   29        30        31        32        33  \\\n",
       "0  0.088901  0.305821  0.0  ...  0.0  0.173201  0.000000  0.056773  0.070532   \n",
       "1  0.103172  0.288340  0.0  ...  0.0  0.131363  0.000000  0.089604  0.058761   \n",
       "2  0.016288  0.304093  0.0  ...  0.0  0.172211  0.000000  0.085838  0.086743   \n",
       "3  0.003453  0.371735  0.0  ...  0.0  0.123929  0.000000  0.117967  0.175683   \n",
       "4  0.034490  0.336175  0.0  ...  0.0  0.101451  0.003113  0.109843  0.155952   \n",
       "\n",
       "         34        35   36        37  priceUSD  \n",
       "0  0.000000  0.146290  0.0  0.244239    0.0495  \n",
       "1  0.041308  0.122358  0.0  0.245734    0.0726  \n",
       "2  0.069722  0.043386  0.0  0.236507    0.0859  \n",
       "3  0.096189  0.105011  0.0  0.185024    0.0783  \n",
       "4  0.097110  0.108404  0.0  0.139865    0.0767  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_MinMaxScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.386481</td>\n",
       "      <td>0.117555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.247056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>0.144571</td>\n",
       "      <td>0.276913</td>\n",
       "      <td>0.322411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.373520</td>\n",
       "      <td>0.350037</td>\n",
       "      <td>0.132441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229406</td>\n",
       "      <td>0.227104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494760</td>\n",
       "      <td>0.142909</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>0.339183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043156</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.350619</td>\n",
       "      <td>0.426659</td>\n",
       "      <td>0.211410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197371</td>\n",
       "      <td>0.249512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542962</td>\n",
       "      <td>0.148570</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>0.363947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.319798</td>\n",
       "      <td>0.364622</td>\n",
       "      <td>0.152678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214873</td>\n",
       "      <td>0.209499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535941</td>\n",
       "      <td>0.134063</td>\n",
       "      <td>0.288476</td>\n",
       "      <td>0.372253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.340285</td>\n",
       "      <td>0.378646</td>\n",
       "      <td>0.149963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.239973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522454</td>\n",
       "      <td>0.082172</td>\n",
       "      <td>0.271670</td>\n",
       "      <td>0.394370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2    3         4         5         6  \\\n",
       "0     0.145302  0.000000  0.179782  0.0  0.000000  0.238634  0.088901   \n",
       "1     0.203855  0.000000  0.136095  0.0  0.005416  0.282885  0.103172   \n",
       "2     0.155377  0.000000  0.170912  0.0  0.000000  0.371988  0.016288   \n",
       "3     0.081168  0.056898  0.152915  0.0  0.001428  0.429266  0.003453   \n",
       "4     0.083447  0.066815  0.103083  0.0  0.000000  0.416309  0.034490   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3483  0.339125  0.386481  0.117555  0.0  0.203587  0.247056  0.000000   \n",
       "3484  0.373520  0.350037  0.132441  0.0  0.229406  0.227104  0.000000   \n",
       "3485  0.350619  0.426659  0.211410  0.0  0.197371  0.249512  0.000000   \n",
       "3486  0.319798  0.364622  0.152678  0.0  0.214873  0.209499  0.000000   \n",
       "3487  0.340285  0.378646  0.149963  0.0  0.160641  0.239973  0.000000   \n",
       "\n",
       "             7    8         9  ...   29        30        31        32  \\\n",
       "0     0.305821  0.0  0.034986  ...  0.0  0.173201  0.000000  0.056773   \n",
       "1     0.288340  0.0  0.060730  ...  0.0  0.131363  0.000000  0.089604   \n",
       "2     0.304093  0.0  0.055210  ...  0.0  0.172211  0.000000  0.085838   \n",
       "3     0.371735  0.0  0.054605  ...  0.0  0.123929  0.000000  0.117967   \n",
       "4     0.336175  0.0  0.065952  ...  0.0  0.101451  0.003113  0.109843   \n",
       "...        ...  ...       ...  ...  ...       ...       ...       ...   \n",
       "3483  0.321566  0.0  0.000000  ...  0.0  0.505908  0.144571  0.276913   \n",
       "3484  0.313371  0.0  0.000000  ...  0.0  0.494760  0.142909  0.279354   \n",
       "3485  0.313492  0.0  0.000000  ...  0.0  0.542962  0.148570  0.304143   \n",
       "3486  0.265145  0.0  0.000000  ...  0.0  0.535941  0.134063  0.288476   \n",
       "3487  0.255416  0.0  0.000000  ...  0.0  0.522454  0.082172  0.271670   \n",
       "\n",
       "            33        34        35   36        37   priceUSD  \n",
       "0     0.070532  0.000000  0.146290  0.0  0.244239     0.0495  \n",
       "1     0.058761  0.041308  0.122358  0.0  0.245734     0.0726  \n",
       "2     0.086743  0.069722  0.043386  0.0  0.236507     0.0859  \n",
       "3     0.175683  0.096189  0.105011  0.0  0.185024     0.0783  \n",
       "4     0.155952  0.097110  0.108404  0.0  0.139865     0.0767  \n",
       "...        ...       ...       ...  ...       ...        ...  \n",
       "3483  0.322411  0.000000  0.241756  0.0  0.046847  9349.0000  \n",
       "3484  0.339183  0.000000  0.266478  0.0  0.043156  9394.0000  \n",
       "3485  0.363947  0.000000  0.280159  0.0  0.021500  9366.0000  \n",
       "3486  0.372253  0.000000  0.244182  0.0  0.010242  9393.0000  \n",
       "3487  0.394370  0.000000  0.246692  0.0  0.027949  9398.0000  \n",
       "\n",
       "[3488 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81334839822775\n",
      "Test score of trained model: 84.90442428504817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c931f7",
   "metadata": {},
   "source": [
    "### Overall score table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ac3e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00beb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170404e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473229e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.009080e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>4.055422e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490442e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403397e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170404e+06\n",
       "1    RMSE  1.473229e+03\n",
       "2     MAE  1.009080e+03\n",
       "3    MAPE  4.055422e+04\n",
       "4      r2  8.490442e-01\n",
       "5  adj_r2  8.403397e-01"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b98aeb",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "379f72a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81319444658527\n",
      "Test score of trained model: 84.9064540975754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9a991cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170112e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.008650e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490645e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403611e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170112e+06\n",
       "1    RMSE  1.473130e+03\n",
       "2     MAE  1.008650e+03\n",
       "3      r2  8.490645e-01\n",
       "4  adj_r2  8.403611e-01"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc8a47",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "582d4dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81334593809626\n",
      "Test score of trained model: 84.9045902091973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c275084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170380e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473221e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.009035e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403414e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170380e+06\n",
       "1    RMSE  1.473221e+03\n",
       "2     MAE  1.009035e+03\n",
       "3      r2  8.490459e-01\n",
       "4  adj_r2  8.403414e-01"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8b3266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.99211717109155\n",
      "Test score of trained model: 97.19190406689304\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f10dfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>403740.943677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>635.406125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>294.225686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.971919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  403740.943677\n",
       "1    RMSE     635.406125\n",
       "2     MAE     294.225686\n",
       "3      r2       0.971919\n",
       "4  adj_r2       0.970300"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1500,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9618437005970384\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d8eb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: 0.9632266839141869\n",
      "   Metric          Score\n",
      "0     MSE  528717.454542\n",
      "1    RMSE     727.129600\n",
      "2     MAE     351.104524\n",
      "3      r2       0.963227\n",
      "4  adj_r2       0.961106\n",
      "Best Score: 0.9637101002000492\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: 0.9626237914173978\n",
      "   Metric          Score\n",
      "0     MSE  537385.690649\n",
      "1    RMSE     733.065952\n",
      "2     MAE     358.094246\n",
      "3      r2       0.962624\n",
      "4  adj_r2       0.960469\n",
      "Best Score: 0.9642980085489979\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: 0.9633086210077925\n",
      "   Metric          Score\n",
      "0     MSE  527539.383697\n",
      "1    RMSE     726.319065\n",
      "2     MAE     355.896198\n",
      "3      r2       0.963309\n",
      "4  adj_r2       0.961193\n",
      "Best Score: 0.9640338648800467\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: 0.962369208481718\n",
      "   Metric          Score\n",
      "0     MSE  541046.019824\n",
      "1    RMSE     735.558305\n",
      "2     MAE     360.641233\n",
      "3      r2       0.962369\n",
      "4  adj_r2       0.960199\n",
      "Best Score: 0.9635929805714774\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: 0.961869384872451\n",
      "   Metric          Score\n",
      "0     MSE  548232.357488\n",
      "1    RMSE     740.427145\n",
      "2     MAE     359.013098\n",
      "3      r2       0.961869\n",
      "4  adj_r2       0.959671\n",
      "Best Score: 0.962929091970628\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f2a68",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e5c0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90d00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3360072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2118.9924 - mean_absolute_error: 2115.8518 - val_loss: 2217.2546 - val_mean_absolute_error: 2211.1787\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1978.0590 - mean_absolute_error: 1968.2352 - val_loss: 2101.4905 - val_mean_absolute_error: 2090.6023\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1927.3414 - mean_absolute_error: 1915.0345 - val_loss: 2035.3739 - val_mean_absolute_error: 2021.1738\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1784.8583 - mean_absolute_error: 1767.6631 - val_loss: 1783.0354 - val_mean_absolute_error: 1762.1411\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1269.0767 - mean_absolute_error: 1242.6128 - val_loss: 1074.8611 - val_mean_absolute_error: 1043.4764\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 881.3984 - mean_absolute_error: 849.1803 - val_loss: 981.7566 - val_mean_absolute_error: 949.2938\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 837.9564 - mean_absolute_error: 805.4352 - val_loss: 956.4147 - val_mean_absolute_error: 923.6627\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 820.0493 - mean_absolute_error: 787.4191 - val_loss: 934.2426 - val_mean_absolute_error: 901.5616\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 797.5555 - mean_absolute_error: 764.8448 - val_loss: 919.9568 - val_mean_absolute_error: 887.1858\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 784.6730 - mean_absolute_error: 751.8881 - val_loss: 909.2638 - val_mean_absolute_error: 876.1062\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 771.7001 - mean_absolute_error: 738.6081 - val_loss: 895.7653 - val_mean_absolute_error: 862.6522\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 763.2906 - mean_absolute_error: 730.0978 - val_loss: 884.7426 - val_mean_absolute_error: 851.6267\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 747.2259 - mean_absolute_error: 713.9689 - val_loss: 875.0914 - val_mean_absolute_error: 841.7537\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 737.7533 - mean_absolute_error: 704.3644 - val_loss: 874.1382 - val_mean_absolute_error: 840.6001\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 728.9748 - mean_absolute_error: 695.5287 - val_loss: 869.8279 - val_mean_absolute_error: 836.1825\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 713.9504 - mean_absolute_error: 680.2575 - val_loss: 848.6622 - val_mean_absolute_error: 815.1023\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 707.7947 - mean_absolute_error: 674.1311 - val_loss: 848.7993 - val_mean_absolute_error: 815.0458\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 697.2172 - mean_absolute_error: 663.4970 - val_loss: 840.5699 - val_mean_absolute_error: 806.7068\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 690.6034 - mean_absolute_error: 656.8669 - val_loss: 826.8226 - val_mean_absolute_error: 793.0947\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 682.0709 - mean_absolute_error: 648.1696 - val_loss: 816.9877 - val_mean_absolute_error: 783.2700\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 673.6608 - mean_absolute_error: 639.8381 - val_loss: 810.3494 - val_mean_absolute_error: 776.6404\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 665.7205 - mean_absolute_error: 631.8970 - val_loss: 804.0753 - val_mean_absolute_error: 770.3625\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 658.6879 - mean_absolute_error: 624.8652 - val_loss: 814.6407 - val_mean_absolute_error: 780.6730\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 658.3755 - mean_absolute_error: 624.5499 - val_loss: 790.4121 - val_mean_absolute_error: 756.8608\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 646.4787 - mean_absolute_error: 612.8820 - val_loss: 789.7587 - val_mean_absolute_error: 756.0469\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 640.0519 - mean_absolute_error: 606.3817 - val_loss: 777.3214 - val_mean_absolute_error: 743.5798\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 634.1406 - mean_absolute_error: 600.4283 - val_loss: 794.0408 - val_mean_absolute_error: 760.2336\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 628.7657 - mean_absolute_error: 595.0590 - val_loss: 763.8785 - val_mean_absolute_error: 730.2808\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 621.5531 - mean_absolute_error: 588.0959 - val_loss: 755.8467 - val_mean_absolute_error: 722.4099\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 618.9622 - mean_absolute_error: 585.4827 - val_loss: 758.1039 - val_mean_absolute_error: 724.6138\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 615.2304 - mean_absolute_error: 581.8392 - val_loss: 747.9296 - val_mean_absolute_error: 714.5596\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 606.2281 - mean_absolute_error: 572.9696 - val_loss: 740.8560 - val_mean_absolute_error: 707.7370\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 601.3741 - mean_absolute_error: 568.1323 - val_loss: 742.8274 - val_mean_absolute_error: 709.5103\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 594.1077 - mean_absolute_error: 560.9800 - val_loss: 744.0859 - val_mean_absolute_error: 710.8817\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 597.5594 - mean_absolute_error: 564.5867 - val_loss: 719.7902 - val_mean_absolute_error: 686.8079\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 586.4814 - mean_absolute_error: 553.6148 - val_loss: 722.1792 - val_mean_absolute_error: 689.2347\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 584.3054 - mean_absolute_error: 551.4655 - val_loss: 716.0245 - val_mean_absolute_error: 683.1087\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 578.5518 - mean_absolute_error: 545.8104 - val_loss: 699.2233 - val_mean_absolute_error: 666.7139\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 572.2060 - mean_absolute_error: 539.6627 - val_loss: 694.6502 - val_mean_absolute_error: 662.1470\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 564.8188 - mean_absolute_error: 532.4127 - val_loss: 706.4269 - val_mean_absolute_error: 673.9701\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 562.4503 - mean_absolute_error: 530.1304 - val_loss: 680.7807 - val_mean_absolute_error: 648.6913\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 565.0335 - mean_absolute_error: 532.8817 - val_loss: 693.0494 - val_mean_absolute_error: 660.9131\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 556.1998 - mean_absolute_error: 524.2208 - val_loss: 671.6545 - val_mean_absolute_error: 639.7308\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 550.7611 - mean_absolute_error: 518.8486 - val_loss: 672.7176 - val_mean_absolute_error: 641.1412\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.6726 - mean_absolute_error: 523.9725 - val_loss: 664.7456 - val_mean_absolute_error: 633.0200\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 546.4535 - mean_absolute_error: 514.8776 - val_loss: 683.5570 - val_mean_absolute_error: 651.8884\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 538.6406 - mean_absolute_error: 507.2385 - val_loss: 653.4830 - val_mean_absolute_error: 622.0452\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 533.3600 - mean_absolute_error: 502.1092 - val_loss: 654.8603 - val_mean_absolute_error: 623.5674\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 531.5587 - mean_absolute_error: 500.4034 - val_loss: 642.2712 - val_mean_absolute_error: 611.1934\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 528.4154 - mean_absolute_error: 497.4211 - val_loss: 650.2527 - val_mean_absolute_error: 619.2570\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 524.3134 - mean_absolute_error: 493.4699 - val_loss: 632.2418 - val_mean_absolute_error: 601.6274\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 520.9628 - mean_absolute_error: 490.2910 - val_loss: 696.6516 - val_mean_absolute_error: 665.7291\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 519.2086 - mean_absolute_error: 488.6585 - val_loss: 626.3893 - val_mean_absolute_error: 595.9424\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 516.7221 - mean_absolute_error: 486.3325 - val_loss: 625.7446 - val_mean_absolute_error: 595.3588\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 511.3999 - mean_absolute_error: 481.1472 - val_loss: 617.9354 - val_mean_absolute_error: 587.7286\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 517.7868 - mean_absolute_error: 487.7491 - val_loss: 614.7449 - val_mean_absolute_error: 584.7538\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 504.3889 - mean_absolute_error: 474.4028 - val_loss: 608.9525 - val_mean_absolute_error: 579.0911\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.0494 - mean_absolute_error: 470.1819 - val_loss: 610.5687 - val_mean_absolute_error: 581.0073\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.7306 - mean_absolute_error: 471.0721 - val_loss: 599.1140 - val_mean_absolute_error: 569.5215\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 496.3109 - mean_absolute_error: 466.7726 - val_loss: 598.2642 - val_mean_absolute_error: 568.8929\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 491.3277 - mean_absolute_error: 461.9783 - val_loss: 614.0327 - val_mean_absolute_error: 584.5827\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 493.8826 - mean_absolute_error: 464.6398 - val_loss: 593.8611 - val_mean_absolute_error: 564.7026\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 482.9424 - mean_absolute_error: 453.8619 - val_loss: 600.1260 - val_mean_absolute_error: 571.1360\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 485.7369 - mean_absolute_error: 456.8392 - val_loss: 593.9310 - val_mean_absolute_error: 565.0020\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 476.2517 - mean_absolute_error: 447.3920 - val_loss: 582.9829 - val_mean_absolute_error: 554.3189\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 478.3152 - mean_absolute_error: 449.6859 - val_loss: 588.4650 - val_mean_absolute_error: 560.0060\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.5667 - mean_absolute_error: 443.0381 - val_loss: 580.9321 - val_mean_absolute_error: 552.4590\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 474.2137 - mean_absolute_error: 445.7718 - val_loss: 576.1315 - val_mean_absolute_error: 547.8374\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 467.5479 - mean_absolute_error: 439.2813 - val_loss: 567.1937 - val_mean_absolute_error: 538.9714\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.0820 - mean_absolute_error: 436.9369 - val_loss: 585.0283 - val_mean_absolute_error: 557.0068\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 468.7294 - mean_absolute_error: 440.6459 - val_loss: 583.6268 - val_mean_absolute_error: 555.7936\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.8998 - mean_absolute_error: 433.9968 - val_loss: 574.7872 - val_mean_absolute_error: 546.8318\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 455.0855 - mean_absolute_error: 427.2591 - val_loss: 578.1927 - val_mean_absolute_error: 550.2440\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.1651 - mean_absolute_error: 433.4218 - val_loss: 572.8614 - val_mean_absolute_error: 545.0997\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 454.4552 - mean_absolute_error: 426.7677 - val_loss: 569.5358 - val_mean_absolute_error: 541.7859\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 452.5275 - mean_absolute_error: 424.9593 - val_loss: 554.3700 - val_mean_absolute_error: 526.8695\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 450.6194 - mean_absolute_error: 423.1683 - val_loss: 563.5615 - val_mean_absolute_error: 536.2483\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 452.8229 - mean_absolute_error: 425.4682 - val_loss: 554.6036 - val_mean_absolute_error: 527.2186\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 441.4958 - mean_absolute_error: 414.2453 - val_loss: 546.3201 - val_mean_absolute_error: 519.1036\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 442.5009 - mean_absolute_error: 415.3378 - val_loss: 541.6899 - val_mean_absolute_error: 514.5577\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.1081 - mean_absolute_error: 409.0148 - val_loss: 545.8910 - val_mean_absolute_error: 518.7748\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.7642 - mean_absolute_error: 412.7513 - val_loss: 538.7913 - val_mean_absolute_error: 511.8738\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.9341 - mean_absolute_error: 410.0691 - val_loss: 549.1154 - val_mean_absolute_error: 522.3248\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.1584 - mean_absolute_error: 409.3341 - val_loss: 532.8607 - val_mean_absolute_error: 506.1034\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 431.3388 - mean_absolute_error: 404.5894 - val_loss: 540.7156 - val_mean_absolute_error: 514.1083\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 433.7404 - mean_absolute_error: 407.0299 - val_loss: 541.2939 - val_mean_absolute_error: 514.6338\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 431.9586 - mean_absolute_error: 405.3521 - val_loss: 533.3287 - val_mean_absolute_error: 506.8344\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.7861 - mean_absolute_error: 404.2670 - val_loss: 536.7257 - val_mean_absolute_error: 510.1472\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.8235 - mean_absolute_error: 404.3705 - val_loss: 530.7253 - val_mean_absolute_error: 504.2811\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 427.4909 - mean_absolute_error: 401.1477 - val_loss: 525.8492 - val_mean_absolute_error: 499.5973\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 421.9723 - mean_absolute_error: 395.6621 - val_loss: 531.5154 - val_mean_absolute_error: 505.3242\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 423.0895 - mean_absolute_error: 396.8358 - val_loss: 523.3908 - val_mean_absolute_error: 497.1869\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 422.7931 - mean_absolute_error: 396.6096 - val_loss: 531.6688 - val_mean_absolute_error: 505.5991\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 416.2127 - mean_absolute_error: 390.1172 - val_loss: 520.0477 - val_mean_absolute_error: 493.9811\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.0308 - mean_absolute_error: 388.9773 - val_loss: 534.5786 - val_mean_absolute_error: 508.4643\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.7349 - mean_absolute_error: 389.7468 - val_loss: 518.9341 - val_mean_absolute_error: 492.9917\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.5763 - mean_absolute_error: 389.6472 - val_loss: 525.8484 - val_mean_absolute_error: 500.0574\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 414.9501 - mean_absolute_error: 389.0963 - val_loss: 515.4711 - val_mean_absolute_error: 489.6739\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 411.1351 - mean_absolute_error: 385.3844 - val_loss: 517.0731 - val_mean_absolute_error: 491.3025\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 408.4312 - mean_absolute_error: 382.7081 - val_loss: 515.6617 - val_mean_absolute_error: 489.9521\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db6a34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2166.726318359375, 2157.2900390625]\n",
      "[2488.070068359375, 2478.63330078125]\n"
     ]
    }
   ],
   "source": [
    "train_mae = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_mae)\n",
    "test_mae = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd42a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493421fd",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81fe71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29981592",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62433ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2126.3147 - mean_absolute_error: 2124.0818 - val_loss: 2289.1736 - val_mean_absolute_error: 2289.0913\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2041.2072 - mean_absolute_error: 2037.8020 - val_loss: 2105.3357 - val_mean_absolute_error: 2098.4893\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1908.8909 - mean_absolute_error: 1899.5818 - val_loss: 1962.9088 - val_mean_absolute_error: 1949.7023\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1435.6370 - mean_absolute_error: 1416.6802 - val_loss: 1094.8781 - val_mean_absolute_error: 1070.5034\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 897.4827 - mean_absolute_error: 872.4106 - val_loss: 983.0945 - val_mean_absolute_error: 957.8059\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 835.9782 - mean_absolute_error: 810.6457 - val_loss: 946.1695 - val_mean_absolute_error: 920.6973\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 801.8513 - mean_absolute_error: 776.5445 - val_loss: 915.3395 - val_mean_absolute_error: 889.9505\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 768.1614 - mean_absolute_error: 742.7496 - val_loss: 885.0793 - val_mean_absolute_error: 859.7619\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 742.1165 - mean_absolute_error: 716.6484 - val_loss: 864.2316 - val_mean_absolute_error: 838.7606\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 718.5683 - mean_absolute_error: 693.0696 - val_loss: 843.5292 - val_mean_absolute_error: 817.8881\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 706.0325 - mean_absolute_error: 680.3130 - val_loss: 827.4246 - val_mean_absolute_error: 801.8895\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 688.3947 - mean_absolute_error: 662.6596 - val_loss: 820.1432 - val_mean_absolute_error: 794.5195\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 673.0068 - mean_absolute_error: 647.2512 - val_loss: 813.8565 - val_mean_absolute_error: 787.8702\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 664.8401 - mean_absolute_error: 638.9252 - val_loss: 793.3909 - val_mean_absolute_error: 767.2344\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 651.9975 - mean_absolute_error: 625.9636 - val_loss: 773.3257 - val_mean_absolute_error: 747.3052\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 643.8207 - mean_absolute_error: 617.7173 - val_loss: 759.3922 - val_mean_absolute_error: 733.3307\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 627.5123 - mean_absolute_error: 601.3384 - val_loss: 753.0876 - val_mean_absolute_error: 726.9410\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 619.2640 - mean_absolute_error: 592.9838 - val_loss: 754.1174 - val_mean_absolute_error: 727.6131\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 603.6086 - mean_absolute_error: 577.1879 - val_loss: 725.0338 - val_mean_absolute_error: 698.7266\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 594.6434 - mean_absolute_error: 568.1545 - val_loss: 719.2050 - val_mean_absolute_error: 692.6694\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 581.9611 - mean_absolute_error: 555.4324 - val_loss: 713.5228 - val_mean_absolute_error: 686.9250\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 574.4297 - mean_absolute_error: 547.8138 - val_loss: 696.7375 - val_mean_absolute_error: 670.1370\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 569.2962 - mean_absolute_error: 542.7188 - val_loss: 695.6867 - val_mean_absolute_error: 669.1967\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 560.1509 - mean_absolute_error: 533.4929 - val_loss: 676.0221 - val_mean_absolute_error: 649.5025\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 552.0962 - mean_absolute_error: 525.4210 - val_loss: 690.5440 - val_mean_absolute_error: 663.7323\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 549.8569 - mean_absolute_error: 523.1105 - val_loss: 670.7776 - val_mean_absolute_error: 644.0098\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 534.5224 - mean_absolute_error: 507.8701 - val_loss: 666.7653 - val_mean_absolute_error: 640.0070\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 528.8616 - mean_absolute_error: 502.2094 - val_loss: 653.8138 - val_mean_absolute_error: 626.9644\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 523.4412 - mean_absolute_error: 496.7918 - val_loss: 670.9562 - val_mean_absolute_error: 644.1083\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 513.3607 - mean_absolute_error: 486.7130 - val_loss: 632.3380 - val_mean_absolute_error: 605.8110\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 515.1849 - mean_absolute_error: 488.5943 - val_loss: 626.3748 - val_mean_absolute_error: 599.7600\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 513.5683 - mean_absolute_error: 486.9783 - val_loss: 629.8115 - val_mean_absolute_error: 603.1940\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.4165 - mean_absolute_error: 473.9172 - val_loss: 615.5168 - val_mean_absolute_error: 589.0175\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 498.3971 - mean_absolute_error: 471.9140 - val_loss: 615.8057 - val_mean_absolute_error: 589.2650\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 493.1160 - mean_absolute_error: 466.6481 - val_loss: 607.7503 - val_mean_absolute_error: 581.2950\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 494.8444 - mean_absolute_error: 468.4391 - val_loss: 620.6962 - val_mean_absolute_error: 594.3005\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 488.0110 - mean_absolute_error: 461.6414 - val_loss: 600.9825 - val_mean_absolute_error: 574.7758\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 483.7426 - mean_absolute_error: 457.4416 - val_loss: 600.4528 - val_mean_absolute_error: 574.1315\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 478.2813 - mean_absolute_error: 452.0246 - val_loss: 590.1928 - val_mean_absolute_error: 563.9106\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 484.2725 - mean_absolute_error: 458.0567 - val_loss: 584.9672 - val_mean_absolute_error: 558.7507\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 479.4746 - mean_absolute_error: 453.3199 - val_loss: 605.6440 - val_mean_absolute_error: 579.3997\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 473.4608 - mean_absolute_error: 447.3094 - val_loss: 587.2988 - val_mean_absolute_error: 561.0656\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 468.1768 - mean_absolute_error: 442.0406 - val_loss: 573.8484 - val_mean_absolute_error: 547.7972\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.3333 - mean_absolute_error: 439.2837 - val_loss: 573.0131 - val_mean_absolute_error: 546.9662\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.5250 - mean_absolute_error: 445.5474 - val_loss: 567.6307 - val_mean_absolute_error: 541.7632\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.3274 - mean_absolute_error: 439.4305 - val_loss: 567.0016 - val_mean_absolute_error: 541.1518\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 455.6785 - mean_absolute_error: 429.8344 - val_loss: 568.6342 - val_mean_absolute_error: 542.7800\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 2ms/step - loss: 453.8411 - mean_absolute_error: 428.0898 - val_loss: 565.9889 - val_mean_absolute_error: 540.2172\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 450.2781 - mean_absolute_error: 424.5676 - val_loss: 562.5457 - val_mean_absolute_error: 536.8486\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 456.2068 - mean_absolute_error: 430.5749 - val_loss: 552.1459 - val_mean_absolute_error: 526.6281\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 444.4120 - mean_absolute_error: 418.8492 - val_loss: 550.3884 - val_mean_absolute_error: 524.8748\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 443.3136 - mean_absolute_error: 417.8264 - val_loss: 549.5904 - val_mean_absolute_error: 524.2315\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 443.6864 - mean_absolute_error: 418.2696 - val_loss: 545.7551 - val_mean_absolute_error: 520.3244\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.2217 - mean_absolute_error: 410.8647 - val_loss: 556.2736 - val_mean_absolute_error: 530.8325\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 438.1918 - mean_absolute_error: 412.8619 - val_loss: 540.6622 - val_mean_absolute_error: 515.4171\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.9523 - mean_absolute_error: 411.7219 - val_loss: 538.5641 - val_mean_absolute_error: 513.3461\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 433.1453 - mean_absolute_error: 407.9228 - val_loss: 533.7336 - val_mean_absolute_error: 508.5635\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 433.1287 - mean_absolute_error: 407.9886 - val_loss: 539.0222 - val_mean_absolute_error: 513.8260\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.4995 - mean_absolute_error: 405.4096 - val_loss: 533.7788 - val_mean_absolute_error: 508.7917\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 425.2516 - mean_absolute_error: 400.2549 - val_loss: 529.6874 - val_mean_absolute_error: 504.7283\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 428.1543 - mean_absolute_error: 403.2272 - val_loss: 544.7616 - val_mean_absolute_error: 519.8972\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 432.2345 - mean_absolute_error: 407.3451 - val_loss: 542.2622 - val_mean_absolute_error: 517.2574\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 423.8169 - mean_absolute_error: 398.9626 - val_loss: 526.1450 - val_mean_absolute_error: 501.3478\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.1888 - mean_absolute_error: 394.3799 - val_loss: 519.6613 - val_mean_absolute_error: 494.9128\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 416.9436 - mean_absolute_error: 392.2012 - val_loss: 517.8876 - val_mean_absolute_error: 493.2125\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 414.6971 - mean_absolute_error: 389.9509 - val_loss: 514.5770 - val_mean_absolute_error: 489.9396\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.8024 - mean_absolute_error: 389.1819 - val_loss: 521.1113 - val_mean_absolute_error: 496.5042\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.9853 - mean_absolute_error: 391.4035 - val_loss: 556.5270 - val_mean_absolute_error: 531.8892\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 414.0644 - mean_absolute_error: 389.5633 - val_loss: 514.8427 - val_mean_absolute_error: 490.3747\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.5777 - mean_absolute_error: 391.1610 - val_loss: 512.4437 - val_mean_absolute_error: 488.0817\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 408.8119 - mean_absolute_error: 384.4299 - val_loss: 504.8944 - val_mean_absolute_error: 480.5509\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 403.2497 - mean_absolute_error: 378.8588 - val_loss: 506.5705 - val_mean_absolute_error: 482.1863\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 406.7741 - mean_absolute_error: 382.4833 - val_loss: 512.3675 - val_mean_absolute_error: 488.0343\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 402.4904 - mean_absolute_error: 378.2582 - val_loss: 505.9619 - val_mean_absolute_error: 481.6938\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 404.2553 - mean_absolute_error: 380.0209 - val_loss: 512.8680 - val_mean_absolute_error: 488.7199\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 401.3637 - mean_absolute_error: 377.2072 - val_loss: 500.2422 - val_mean_absolute_error: 476.0710\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 395.6831 - mean_absolute_error: 371.5547 - val_loss: 505.3906 - val_mean_absolute_error: 481.3626\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 397.9062 - mean_absolute_error: 373.8489 - val_loss: 512.6586 - val_mean_absolute_error: 488.6048\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 399.6934 - mean_absolute_error: 375.7076 - val_loss: 492.2937 - val_mean_absolute_error: 468.3971\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 394.2257 - mean_absolute_error: 370.3351 - val_loss: 492.7788 - val_mean_absolute_error: 468.8575\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 396.9963 - mean_absolute_error: 373.1041 - val_loss: 498.6931 - val_mean_absolute_error: 474.7882\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 394.0147 - mean_absolute_error: 370.2066 - val_loss: 498.6236 - val_mean_absolute_error: 474.7477\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 388.4493 - mean_absolute_error: 364.6597 - val_loss: 492.9022 - val_mean_absolute_error: 469.1089\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 390.3887 - mean_absolute_error: 366.6632 - val_loss: 486.8509 - val_mean_absolute_error: 463.1484\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 391.3399 - mean_absolute_error: 367.6402 - val_loss: 484.6969 - val_mean_absolute_error: 461.0686\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 390.4789 - mean_absolute_error: 366.8175 - val_loss: 496.3601 - val_mean_absolute_error: 472.6629\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 389.8102 - mean_absolute_error: 366.1978 - val_loss: 486.0941 - val_mean_absolute_error: 462.4935\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 383.5247 - mean_absolute_error: 359.8946 - val_loss: 484.2190 - val_mean_absolute_error: 460.6732\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 379.4956 - mean_absolute_error: 355.9258 - val_loss: 478.3966 - val_mean_absolute_error: 454.8031\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 386.4598 - mean_absolute_error: 362.9766 - val_loss: 520.7063 - val_mean_absolute_error: 497.2690\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 383.9810 - mean_absolute_error: 360.5054 - val_loss: 481.5314 - val_mean_absolute_error: 458.0097\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 381.5352 - mean_absolute_error: 358.0981 - val_loss: 486.5204 - val_mean_absolute_error: 463.0036\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 380.1187 - mean_absolute_error: 356.6667 - val_loss: 478.7078 - val_mean_absolute_error: 455.2061\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 375.9383 - mean_absolute_error: 352.5318 - val_loss: 473.4045 - val_mean_absolute_error: 450.0412\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 376.1767 - mean_absolute_error: 352.8293 - val_loss: 475.3073 - val_mean_absolute_error: 452.0343\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 376.7952 - mean_absolute_error: 353.4667 - val_loss: 475.0511 - val_mean_absolute_error: 451.7920\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 370.8263 - mean_absolute_error: 347.5347 - val_loss: 496.4075 - val_mean_absolute_error: 473.0279\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 373.0316 - mean_absolute_error: 349.7356 - val_loss: 466.5620 - val_mean_absolute_error: 443.3293\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 369.7128 - mean_absolute_error: 346.4657 - val_loss: 469.9373 - val_mean_absolute_error: 446.6839\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 372.5624 - mean_absolute_error: 349.3264 - val_loss: 464.6623 - val_mean_absolute_error: 441.4115\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97fe9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2166.726318359375, 2157.2900390625]\n",
      "[2488.070068359375, 2478.63330078125]\n"
     ]
    }
   ],
   "source": [
    "train_mae = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_mae)\n",
    "test_mae = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91801848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4mUlEQVR4nO3dd3gc1bn48e+7RVr17iLJtoxxx2CwwCaEFhIwJZSbhAAhkJALpN7kpkF+6cnNvdyWQgqE4lACBAIkEMoNhlATDC4Y44Ytd8myJVmyetvV+/vjjMxalmzJKmtr3s/z7OPdM7MzZ7R+3pl5z5lzRFUxxhjjD4FEV8AYY8zIsaBvjDE+YkHfGGN8xIK+Mcb4iAV9Y4zxEQv6xhjjIxb0zVFPRFREjh3ibb4kIv88lNs05khgQd/sR0S2ikiHiOT3KH/LC64lCarXZBHpEpHbErH/gxnsCcL7fpuINMW9/jKUdexHHe4RkX8byX2axLCgb3qzBbiy+4OIzAFSE1cdAK4B6oCPi0hygusyHL6oqulxrw/3tpKIhPpTdjADXd+MLhb0TW/uxwXZbtcC98WvICLJIvI/IrJdRHaLyO0ikuItyxGRp0SkWkTqvPfFcd99SUR+LCJ/F5FGEXmu551Fj32JV5/vAJ1AbwHxAhHZLCI1IvLfIhLwvnusiLwsIvXesofjtvs+EVnqLVsqIu/rY/8/EJHfx30u8e56QiLyE+B04FfeFfqvvHVmiMhiEakVkXdF5PK+ju9gROQsESkXkZtEZBfwO68+j4rI70WkAfiUiBSKyJPe/spE5Poe9d9v/QHW4Xpvm7XePgq9chGRn4lIlYg0iMg7InKct+wCEVnr/b4VIvL1wzl+M/Qs6JveLAEyRWSmiASBK4Df91jnFmAaMBc4FigCvuctCwC/AyYBE4FW4Fc9vn8V8GlgDJAEHCwovB8oBv4APII7CfV0GVAKnARcAlznlf8YeA7I8bbxSwARyQWeBm4F8oCfAk+LSN5B6nEAVf028CrvXal/UUTSgMXAg97xXQH8RkRmDWTbccYBubi/5w1e2SXAo0A28ADub1MOFAIfBf5dRD4Qt42e6/eLt43/AC4HxgPbvH0BnAucgft/kOWts8dbdjdwo6pmAMcBf+vvPs3wsqBv+tJ9tf8hYB1Q0b3Au/K+AfhXVa1V1Ubg33HBDVXdo6qPqWqLt+wnwJk9tv87Vd2gqq24QD73IHW5FnhWVetwgXShiIzpsc5/enXZDvyc99JTnbhgWaiqbar6mld+IbBRVe9X1aiqPgSsp/e7iIG6CNiqqr/ztv0W8BjwsYN851YR2Rv3+nHcsi7g+6ra7v29AF5X1T+raheQD5wG3OQd40rgLva/W9u3ftw2+uMTwCJVXaGq7cC3gFO9tp1OIAOYAYiqrlPVSu97ncAsEclU1TpVXTGAfZphZEHf9OV+3NX4p+iR2gEKcDn+5d1BCvg/rxwRSRWR34rINi+d8AqQ7d01dNsV974FSO+tEl7K6GN4V6eq+jqw3atbvB1x77fhrngBvgkI8KaIrBGR7juAQm89enyvqLd6DNAkYH58EMcFz3EH+c6/qGp23Ou7ccuqVbWtx/rxx1sIdJ98u/U8lvj1B2K/v5OqNuGu5otU9W+4O7hfA1UicoeIZHqrfgS4ANjmpddOPcz9myFmQd/0SlW34Rp0LwAe77G4BpeymR0XpLJUtTtwfw2YDsxX1UxcCgBc8B2oy4BMXHpkl5fXLuLAFM+EuPcTgZ3ecexS1etVtRC40dvOsd7yST22MZG4O5o4zezfkN0zePccqnYH8HKPIJ6uqp876JH2rbehcOPLdgK5IpIRV9bzWA53ON39/k5e6iqve9uqequqzgNm4dI83/DKl6rqJbj01p9xd3PmCGBB3xzMZ4APqGpzfKGXUrgT+Fl3mkVEikTkPG+VDNxJYa+XO//+IOpwLbAImINLAc3FpTJOENerqNs3vAbkCcCXgYe9en0srhG5Dhf8uoBngGkicpXXIPtxXOB6qpc6rATOEJGJIpKFS3HE2w0cE/f5KW/bnxSRsPc6WURmHt6f4OBUdQfwD+A/RCQiIsfjfrue7TCHEvS+3/1KAh4CPi0ic8X1mvp34A1V3eod03wRCeNOjG1Al4gkicgnRCRLVTuBBtzf3BwBLOibPqnqJlVd1sfim4AyYImXwnked3UPLqeegrsjWIJL/QyYiBQB5wA/967Yu1/LvW3GX+0/ASzHBeincQ2JACcDb4hIE/Ak8GVV3ayqe3C596/h0hXfBC5S1Zqe9VDVxbiTyCpvHz1PDL8APiqup9KtXprlXFwbx05cKus/gYN1Ne3u/dP9Wt6fv1GcK4ESb39/wrUBPD/AbdyMO1l3v/7mbeO7uDaJSmAKXtsN7g7sTtzJdBvu7/jf3rJPAlu9/xufxaW3zBFAbBIVY4zxD7vSN8YYH7Ggb4wxPmJB3xhjfMSCvjHG+MgRP/BSfn6+lpSUJLoaxhhz1Fi+fHmNqhb0tuyID/olJSUsW9ZXr0FjjDE9iUjPp833sfSOMcb4iAV9Y4zxEQv6xhjjI0d8Tt8YYwaqs7OT8vJy2tp6Dk46ukQiEYqLiwmHw/3+jgV9Y8yoU15eTkZGBiUlJbjpH0YfVWXPnj2Ul5czefLkfn/P0jvGmFGnra2NvLy8URvwAUSEvLy8Ad/NWNA3xoxKozngdzucYxydQT8WhVd/CmUvJLomxhhzRBmdQT8QhH/cCuv+kuiaGGN8aO/evfzmN78Z8PcuuOAC9u7dO/QVinPIoC8iE0TkRRFZ680x+mWv/L9FZL2IrBKRP4lItldeIiKtIrLSe90et615IvKOiJSJyK0yXPdfIpA/HarfHZbNG2PMwfQV9KPR6EG/98wzz5CdnT1MtXL6c6UfBb6mqrOABcAXRGQWsBg4TlWPBzaw/xRym1R1rvf6bFz5bcD1wFTvtXAoDqJXBdOhxoK+MWbk3XzzzWzatIm5c+dy8sknc/rpp3PxxRcza9YsAC699FLmzZvH7NmzueOOO/Z9r6SkhJqaGrZu3crMmTO5/vrrmT17Nueeey6tra1DUrdDdtlU1UrcNGmoaqOIrAOKVPW5uNWWAB892HZEZDyQqapLvM/3AZcCzx5e1Q+hYDqsuBeaayAtf1h2YYw58v3wL2tYu7NhSLc5qzCT7394dp/Lb7nlFlavXs3KlSt56aWXuPDCC1m9evW+rpWLFi0iNzeX1tZWTj75ZD7ykY+Ql5e33zY2btzIQw89xJ133snll1/OY489xtVXXz3oug8opy8iJcCJwBs9Fl3H/sF7soi8JSIvi8jpXlkRUB63TrlX1tt+bhCRZSKyrLq6eiBVfE+BN12rpXiMMQl2yimn7NeX/tZbb+WEE05gwYIF7Nixg40bNx7wncmTJzN37lwA5s2bx9atW4ekLv1+OEtE0nGTI39FVRviyr+NSwE94BVVAhNVdY+IzAP+LCJ9nxJ7oap3AHcAlJaWHt4kvvndQX89lJx2WJswxhz9DnZFPlLS0tL2vX/ppZd4/vnnef3110lNTeWss87qta99cnLyvvfBYHDk0jsAIhLGBfwHVPXxuPJPARcB56g3w7qqtgPt3vvlIrIJmAZUAMVxmy32yoZHVjEkpduVvjFmxGVkZNDY2Njrsvr6enJyckhNTWX9+vUsWbJkROt2yKDv9bC5G1inqj+NK18IfBM4U1Vb4soLgFpVjYnIMbgG282qWisiDSKyAJceugb45dAezn4Vh/yp1phrjBlxeXl5nHbaaRx33HGkpKQwduzYfcsWLlzI7bffzsyZM5k+fToLFiwY0br150r/NOCTwDsistIr+3/ArUAysNjrebnE66lzBvAjEekEuoDPqmqt973PA/cAKbg2gOFpxO1WMAM2vzSsuzDGmN48+OCDvZYnJyfz7LO9h77uvH1+fj6rV6/eV/71r399yOrVn947rwG99ad/po/1H8Olgnpbtgw4biAVHJSC6fD2Q9BWD5GsEdutMcYcqUbnE7nd9jXmbkhsPYwx5ggxuoN+d7dNy+sbYwww2oN+TgkEk123TWOMMaM86AeCrgePpXeMMQYY7UEfIH+aXekbY4xn9Af9ghmwdzt0tBx6XWOMGQKHO7QywM9//nNaWoYvXo3KoN/cHuXG+5fxyNIdUDANUNhz4NgWxhgzHI7koD8qJ0ZPTQqyqbqZuuZyLv+nGa6w+l0Yf0JiK2aM8YX4oZU/9KEPMWbMGB555BHa29u57LLL+OEPf0hzczOXX3455eXlxGIxvvvd77J792527tzJ2WefTX5+Pi+++OKQ121UBn0R4ZITCvnfxRuoCM6iSII2Bo8xfvXszbDrnaHd5rg5cP4tfS6OH1r5ueee49FHH+XNN99EVbn44ot55ZVXqK6uprCwkKeffhpwY/JkZWXx05/+lBdffJH8/OEZEn5UpncALp5bCMBTq2tcD56h/tGNMaYfnnvuOZ577jlOPPFETjrpJNavX8/GjRuZM2cOixcv5qabbuLVV18lK2tkRg0YlVf6AJPy0pg7IZsnVu7kxoknQdliUHUDsRlj/OMgV+QjQVX51re+xY033njAshUrVvDMM8/wne98h3POOYfvfe97w16fUXulD3DxCYWsrWygKnM2NFdD/Y5EV8kY4wPxQyufd955LFq0iKamJgAqKiqoqqpi586dpKamcvXVV/ONb3yDFStWHPDd4TBqr/QBLjp+PP/29Fqe21vE1QAVKyB7YqKrZYwZ5eKHVj7//PO56qqrOPXUUwFIT0/n97//PWVlZXzjG98gEAgQDoe57bbbALjhhhtYuHAhhYWFw9KQK97cJ0es0tJSXbZs2WF//+q73mBXbT2L2z+BzP8snPvjIaydMeZItG7dOmbOnJnoaoyI3o5VRJaramlv64/q9A64Bt2y2k5acme5K31jjPGxUR/0Fx43jqRQgDVyLFSuhK5YoqtkjDEJM+qDfmYkzLyJObzWMhE6mqDGBl8zxg+O9NT1UDicYzxk0BeRCSLyooisFZE1IvJlrzxXRBaLyEbv3xyvXETkVhEpE5FVInJS3Lau9dbfKCLXDri2h2nepByerXX99qlYPlK7NcYkSCQSYc+ePaM68Ksqe/bsIRKJDOh7/em9EwW+pqorRCQDWC4ii4FPAS+o6i0icjNwM3ATcD5uMvSpwHzgNmC+iOQC3wdKAfW286Sq1g2oxofhpEnZ/LprHNFwOqGKFXDi1cO9S2NMAhUXF1NeXk51dXWiqzKsIpEIxcXFA/pOf+bIrQQqvfeNIrIOKAIuAc7yVrsXeAkX9C8B7lN3il0iItkiMt5bd3H3JOneiWMh8NCAanwYTpyQgxJgV9pMiu1K35hRLxwOM3ny5ERX44g0oJy+iJQAJwJvAGO9EwLALmCs974IiH8Kqtwr66u8t/3cICLLRGTZUJypc9KSmFKQxts6BXavgc62QW/TGGOORv0O+iKSDjwGfEVVG+KXeVf1Q5Y8U9U7VLVUVUsLCgqGZJvzJuXwQkMxdHXC7tVDsk1jjDna9Cvoi0gYF/AfUNXHveLdXtoG798qr7wCmBD39WKvrK/yEXHSxBz+0TrJfbAUjzHGp/rTe0eAu4F1qvrTuEVPAt09cK4Fnogrv8brxbMAqPfSQH8FzhWRHK+nz7le2YiYNymHXeTSmlwAO98aqd0aY8wRpT+9d04DPgm8IyIrvbL/B9wCPCIinwG2AZd7y54BLgDKgBbg0wCqWisiPwaWeuv9qLtRdyRMKUgnMxKmJpDPhObR3aJvjDF96U/vndeAvsYjPqeX9RX4Qh/bWgQsGkgFh0ogIJw0KYe68gATrCHXGONTo/6J3HgnTcyhrjNI1CZJN8b4lK+C/rxJObRrmLZWC/rGGH/yVdA/YUI27STR2WZB3xjjT74K+unJIcKRVLSzNdFVMcaYhPBV0AeQcAqhrvZEV8MYYxLCl0E/SS3oG2P8yXdBPxCOEKYTRvGQq8YY0xffBf1gUipBuiDWmeiqGGPMiPNf0E9OAaCzvTnBNTHGmJHnu6AfSk4FoKmpKcE1McaYkee7oJ8UcUG/udmCvjHGf3wX9JMt6BtjfMx/QT8lDYCWFsvpG2P8x3dBP5Lqgn6bBX1jjA/5LuinpqYD0NZq6R1jjP/4L+inuaDf3mpX+sYY//Fd0E9JcQ257e026Joxxn/6M0fuIhGpEpHVcWUPi8hK77W1expFESkRkda4ZbfHfWeeiLwjImUicqs39+6Ik7B7OCtqwysbY3yoP3Pk3gP8Crivu0BVP979XkT+F6iPW3+Tqs7tZTu3AdcDb+Dm0V0IPDvgGg9WyAv67Rb0jTH+c8grfVV9Beh1AnPvav1y4KGDbUNExgOZqrrEm0P3PuDSAdd2KIQjAMQ6LL1jjPGfweb0Twd2q+rGuLLJIvKWiLwsIqd7ZUVAedw65V5Zr0TkBhFZJiLLqqurB1nFHrwr/S6bSMUY40ODDfpXsv9VfiUwUVVPBL4KPCgimQPdqKreoaqlqlpaUFAwyCr2EEp2++hoG9rtGmPMUaA/Of1eiUgI+CdgXneZqrYD7d775SKyCZgGVADFcV8v9spGngidkgRRu9I3xvjPYK70PwisV9V9aRsRKRCRoPf+GGAqsFlVK4EGEVngtQNcAzwxiH0PSjQQQaJ2pW+M8Z/+dNl8CHgdmC4i5SLyGW/RFRzYgHsGsMrrwvko8FlV7W4E/jxwF1AGbCIRPXc8sWAyoa522qOxRFXBGGMS4pDpHVW9so/yT/VS9hjwWB/rLwOOG2D9hkVXMEJEOmhsi5KcHkx0dYwxZsT47olcAELJJNNJQ6tNmWiM8Rd/Bv1whAgdNLRFE10TY4wZUb4M+hJOIUIn9Xalb4zxGV8G/UBSKhHpsPSOMcZ3fBn0g0kpXnrHgr4xxl98GfRDSSkk0UlDq+X0jTH+4sugH0xOIUXsSt8Y4z++DPoSSiFFrMumMcZ/fBn0CadYl01jjC/5M+iHIiTRQX1LR6JrYowxI8q3QT9IF82tNuiaMcZf/Bn0vdmz2tuaE1wRY4wZWf4M+iEX9DtabZ5cY4y/+DPoh92UiZ3tdqVvjPEXfwZ970o/EGunrdPG1DfG+Ievg36ETntAyxjjK/2ZOWuRiFSJyOq4sh+ISIWIrPReF8Qt+5aIlInIuyJyXlz5Qq+sTERuHvpDGQCvITcZG3TNGOMv/bnSvwdY2Ev5z1R1rvd6BkBEZuGmUZztfec3IhL05s39NXA+MAu40ls3MUIupx+RDupt/B1jjI/0Z7rEV0SkpJ/buwT4g6q2A1tEpAw4xVtWpqqbAUTkD966awde5SEQ7k7v2Pg7xhh/GUxO/4sisspL/+R4ZUXAjrh1yr2yvsoTo/tK39I7xhifOdygfxswBZgLVAL/O1QVAhCRG0RkmYgsq66uHspNO6FkADdPro2/Y4zxkcMK+qq6W1VjqtoF3Ml7KZwKYELcqsVeWV/lfW3/DlUtVdXSgoKCw6niwYXfy+nblb4xxk8OK+iLyPi4j5cB3T17ngSuEJFkEZkMTAXeBJYCU0Vksogk4Rp7nzz8ag+S12UzPWBdNo0x/nLIhlwReQg4C8gXkXLg+8BZIjIXUGArcCOAqq4RkUdwDbRR4AuqGvO280Xgr0AQWKSqa4b6YPrNu9LPCseosCt9Y4yP9Kf3zpW9FN99kPV/Avykl/JngGcGVLvh4l3pZ4airLMum8YYH/HnE7kiEEwmPRSz9I4xxlf8GfQBwhHSA1FryDXG+Ip/g34ohbRAJ43tlt4xxviHf4N+OEJqoIMm66dvjPER/wb9UAoROmmyK31jjI/4OOgnE5FOWjpixLo00bUxxpgR4d+gH04hmQ4Au9o3xviGf4N+KEKSuqDfaN02jTE+4d+gH04hSdsBu9I3xviHf4N+KEKoywv61oPHGOMTPg/6XnrHrvSNMT7h36AfjhDoagPsSt8Y4x/+DfqhFAJRF/QbLegbY3zCv0E/HEG8oN/Ubr13jDH+4N+gH0pBNEZYopbeMcb4ho+DvpsnNzdZrSHXGOMb/g363uxZ+Ukxu9I3xvjGIYO+iCwSkSoRWR1X9t8isl5EVonIn0Qk2ysvEZFWEVnpvW6P+848EXlHRMpE5FYRkWE5ov7yZs/KSe6yhlxjjG/050r/HmBhj7LFwHGqejywAfhW3LJNqjrXe302rvw24HrcZOlTe9nmyPKu9HPCMXsi1xjjG4cM+qr6ClDbo+w5Ve2OlEuA4oNtQ0TGA5mqukRVFbgPuPSwajxUvCv97KQuy+kbY3xjKHL61wHPxn2eLCJvicjLInK6V1YElMetU+6V9UpEbhCRZSKyrLq6egiq2Asv6GeFYzTZgGvGGJ8YVNAXkW8DUeABr6gSmKiqJwJfBR4UkcyBbldV71DVUlUtLSgoGEwV+xb2gn4oaukdY4xvhA73iyLyKeAi4BwvZYOqtgPt3vvlIrIJmAZUsH8KqNgrS5yQy+lnBKPWkGuM8Y3DutIXkYXAN4GLVbUlrrxARILe+2NwDbabVbUSaBCRBV6vnWuAJwZd+8HwrvTTQ1GbPcsY4xv96bL5EPA6MF1EykXkM8CvgAxgcY+umWcAq0RkJfAo8FlV7W4E/jxwF1AGbGL/doCR5+X00wMun28pHmOMHxwyvaOqV/ZSfHcf6z4GPNbHsmXAcQOq3XDqDvrBGOCCflZKOJE1MsaYYef7J3JTAt48uZbXN8b4gH+DvnelnyIuvWPz5Bpj/MCCPjZ7ljHGP/wb9AMBCCaTjKV3jDH+4d+gDxCKkIz13jHG+Ie/g344QpJd6RtjfMTfQT8UIRRrQ8Qaco0x/uDvoB9OQaJtpCeFrCHXGOML/g76oQhE20iPhCy9Y4zxBQv60TYyIiFryDXG+IK/g356AezdTnqyBX1jjD/4O+iXnA51WykJ1dBg6R1jjA/4O+gfczYA86Jv2+xZxhhf8HfQz58KGYUc1/aWpXeMMb7g76AvAlPOZmrLcprbOhJdG2OMGXb+DvoAx5xFarSeSZ2bbfYsY8yoZ0F/8pkAnB54x1I8xphRr19BX0QWiUiViKyOK8sVkcUistH7N8crFxG5VUTKRGSViJwU951rvfU3isi1Q384hyFjLHszpnJaYLUFfWPMqNffK/17gIU9ym4GXlDVqcAL3meA83ETok8FbgBuA3eSAL4PzAdOAb7ffaJItNqx7+OUwLs0NzUmuirGGDOs+hX0VfUVoLZH8SXAvd77e4FL48rvU2cJkC0i44HzgMWqWquqdcBiDjyRJERz0ekkSyfsWJLoqhhjzLAaTE5/rKpWeu93AWO990XAjrj1yr2yvsoPICI3iMgyEVlWXV09iCr2T2ziqXRokMj2V4d9X8YYk0hD0pCrqgoMWdcXVb1DVUtVtbSgoGCoNtuntPQs3tKp5G7/P+hoHvb9GWNMogwm6O/20jZ4/1Z55RXAhLj1ir2yvsoTLj0S4lfRS0ltLocnvghqXTeNMaPTYIL+k0B3D5xrgSfiyq/xevEsAOq9NNBfgXNFJMdrwD3XK0u49OQQr3Ydz9IpX4I1j8NrP0t0lYwxZliE+rOSiDwEnAXki0g5rhfOLcAjIvIZYBtwubf6M8AFQBnQAnwaQFVrReTHwFJvvR+pas/G4YRISwohAn8f+wnmp1TACz+CscfBtHMTXTVjjBlS/Qr6qnplH4vO6WVdBb7Qx3YWAYv6XbsREggI6UkhmtpjcPEvoWYDPHodXPNnKC5NdPWMMWbI2BO5nvRIyM2Tm5QKVz0MaXlw/z/BzpWJrpoxxgwZC/qe/SZSySyEa/8CkUy4/zLYvSaxlTPGmCFiQd+T3nPKxOyJcO2TEEqG+y6BqvWJq5wxxgwRC/qejEiYxp6zZ+Ue4674JQD3fhiqNySmcsYYM0Qs6HuyU8KU17XSGevaf0H+VBf4wQX+mrKRr5wxxgwRC/qeS08spKapnT+91cvzYgXTXeDvisI9F8KWV0a+gsYYMwQs6HvOnj6G2YWZ/ObFst4nUxkzAz71FCSnw70Xw1+/DdH2ka+oMcYMggV9j4jwpQ8cy9Y9LTy1amfvK42ZCTe+AqXXweu/gjvOhl2re1/XGGOOQBb045w7axzTxqbz6xfL6Opr6sSkNLjop3DVH6GlBu48G177OXTFRrSuxhhzOCzoxwkEhC+cfSwbdjfx3NpdB1952rnwuddh2nnw/Pddrn/XOyNTUWOMOUwW9Hu46PhCJuen8bPFG2ntOMTVe1oeXH4/XHo7VK2D20+Hx2+Eum0jU1ljjBkgC/o9BAPCdy6cyYaqRr7y8Fu9N+rGE4G5V8KXV8Jp/wJr/gS/nAeLFsILP4ayF6CtfkTqbowxhyJ6hI8dX1paqsuWLRvx/S56bQs/emot1502me99eFb/v1hfDm/eCVtfdeP2qHe3kDfVDd42/7NQOHc4qmyMMQCIyHJV7XW0yH6NsulH171/MuV1rSz6+xaKclL4zPsn9++LWcXwoR+69+2NUL4UKpZDxQp491l4549w5k3w/q9C0P78xpiRZVHnIL594Ux27m3l355eS2FWhPPnjB/YBpIzYMoH3AugtQ6e+Sa8+BN3Arjst1AwbegrbowxfbCc/kEEA8LPr5jLSRNz+PLDK3lzyyDnfEnJgY/cCR+7B+q2wO3vh3/80rp7GmNGjAX9Q4iEg9x1TSnFOSlcf98yNu5uHPxGZ18Gn38Djv0gPPcd+N35NnyzMWZEHHbQF5HpIrIy7tUgIl8RkR+ISEVc+QVx3/mWiJSJyLsict7QHMLwy0lL4t5Pn0I4GODaRW9SVtU0+I1mjIUrHoB/uhOq34Xb3gcPXA7bXh/8to0xpg9D0ntHRIJABTAfNyduk6r+T491ZgEPAacAhcDzwDRVPWhuI1G9d3qzZmc919z9JtEu5c5rSjllcu7QbLilFpbeBUtug9ZayJnsevoUzYP0sRBtg85WGD8XiucNzT6NMaPWSPTeOQfYpKrbRKSvdS4B/qCq7cAWESnDnQCOmkvb2YVZ/Onzp/Gpe97k6rve4H8vP4EPn1A4+A2n5sKZ34RTvwhvPwibX4Jt/3A9feIFQvCRu1x6yBhjDsNQBf0rcFfx3b4oItcAy4CvqWodUAQsiVun3Cs7gIjcANwAMHHixCGq4tCYmJfK4597Hzfct5wvPfQWG3Y38pUPTiMY6PNk139JqXDyP7sXQOMu1+MnFHEPgT1+o5uwPRaF4z82+P0ZY3xn0A25IpIEXAx0X5beBkwB5gKVwP8OdJuqeoeqlqpqaUFBwWCrOOSyU5O4/59P4eOlE/jl38q47p6l7G3pGPodZYxzI3vmToacErj6MZh0Gjx+Pbz2M9f4G4secjPGGNNtKK70zwdWqOpugO5/AUTkTuAp72MFMCHue8Ve2VEpORTkPz96PHMnZvP9J9Zw0S9f40sfOJaLTygiJSk4TDtNh6segYevhud/4F6hCIyZBeOPh3HHw8QFMHb28OzfGHPUG3RDroj8Afirqv7O+zxeVSu99/8KzFfVK0RkNvAg7zXkvgBMPZoacvvy1vY6vvX4O6zf1UhWSpjLS4u58cwp5KcnD88Ou7pgTxlUvg2VK92/u1a9N8bPrEvhgz9wdwjGGN85WEPuoIK+iKQB24FjVLXeK7sfl9pRYCtwY9xJ4NvAdUAU+IqqPnuofRwNQR9AVVm6tY57X9/KX1fvIiUpyFc/NI1PLphEKDgCj0Oowt7t8PZD8PdfuKkd537CDQsRToHUfJh9KYSG6URkjDliDFvQHwlHS9CPV1bVxA//soZXN9YwfWwGN58/g7OmF3CQnk1Dq6ES/vZvsOoPLvh3K5gJl/4Gik6CjhZYcS+s+TPM+SiUfgYC9qyeMaOBBf0EUFWeW7ubnzy9ju21LZw0MZuvnzudU6fkjVzwV3Xz+EZb3UNfT38VmnbDcR+FTX9zM39lTYD6HVByOlx8K+QeMzJ1M8YMGwv6CdQZ6+KPy8r55d82UlnfRlF2CmdMy+f0qQWcNb2A1KQRHPOudS8s/i6suA+mnANnfMM1/L51v5voPdYJE07xegtNhmkL3YTw3XaudHcQk0+H0748cvU2xgyIBf0jQFtnjCdWVvDCuipe37SHxvYomZEQV5wykU8umMSE3NSRq0ysE4Lh/cvqK+DlW2D3WjcYXMseV37M2VD6adj4HLz1AASCLmV05cMwfeHI1dkY028W9I8wnbEulm2t44E3tvHs6l2oKieX5HLGtAJOn5rPcYVZBIbiYa/BaKpyOf+ld0NjJQTCMP9GeN+/wIMfg7qtcMPL1kPImCOQBf0jWGV9Kw+9sZ0X1lexZmcDAFPHpHPz+TP4wIwxI5f/70us0w0LkXsM5E1xZXVb4bdnQPYk+MxzrneQMeaIYUH/KFHT1M5L71bzmxfL2FzTzCmTc/n8WVNYcEwekfAwPfB1uDb8FR683PUImvQ+NwVkciY0VLgpI1NyofQ6N3m8MWZEWdA/ynTGuvjD0h384vkN1DR1kBwKMP+YPC6cM45/OqmY8Ej0+++Ptx5wzwVUvg3tDe+Vh9Ogs8XdAcz7NMy9yg0Wp13uqeKsCW4sIXC9i9b8yU0nOf/G9+4mjDGHzYL+Uaq1I8aSLXt4ZUM1L79bzeaaZiblpfLVD03jw8cXJj7v362ryzX+dra4h8Ei2W6OgNd+5kYK7fnQdfZE10Cclg8r7ofmKpAABJPhnO+6yeMDA7izaW90Jxp7zsAYwIL+qKCqvPhuFf/91w2sq2xgUl4q584ayzkzx1I6KWdknvo9HHVboXyZu7KXoGsg3vwSbH3V3R1MPdcF+YIZ7jmCDf/nxhAaM9PdHYRT3Ani2A9COLL/tlXdPATPfdfNNXzRz9wcBMb4nAX9UaSrS3n6nUoeWbaDNzbX0hHrIj89iStOnsgnFkxkfNZR0qgai7qxguJz/qqw6hE3jERHk+sa2tYAHY2uvWDGhe45gjGzITUPnv2Ge8is5HSo2egePCu9Dj7wHTdHgTE+ZUF/lGpqj/LqhmoeW1HBC+t3ExDhAzPGcMa0Ak49Jo8pBWmJ7/0zWLEobHkZVj8O6//y3qByAOFUOPfHbgiJ9kZ48Sfw5h0QSoETr4YFn7MupcaXLOj7wI7aFu5fso2/vL2Tyvo2APLTk5gxLpNpYzOYMT6DM6cVMDYzcogtHcG6B5WrWgu1m90Twz0bfnevhX/88r22hNwpbpC5YJKbn2DsbPfKmgjBkCvXLnfSaPfuLtIKIL0A0sYcmFIy5ihgQd9HVJXttS28vmkPy7fVsWF3Ixt2N9Ha6RpTjy/O4oMzx3LmtAKOK8oamhm/jkQNO2HZIjcEdbQDYu2uK2nNxgMblg8mNR+yitxzCjMugunnQ1LawOqi+l5vpSNdV2xgjejmiGRB3+e6upQNVY28sK6K59ft5q3tewHISglz6jF5FOWkkJuWRF5aEufMHEtBxigefrmzDarXu/x/rBNiHa7nUHKGazeQADRXux5FjbuhodwNUbHrHWja5XoJHXsOZBZBJNN9LxRxw1qEUiCzEHImuZPF5hfdHceGv7oG5nO+59okjlS1m+F3F8Ccj7m0mTlqWdA3+6lpaufvZTW8urGGN7fUUt3Yvu9OICUc5Nr3lXDjGceQk5aU4JoeQbq6YPs/4J1HYdMLbvC6+GcT+pKa53oolT3vTibTFrq7hZQc98oqdk82d19dd7ZBzQZ3N5I/3c2b3FNDJbz2U9jyittGap5ru5j/OXdXcjha98LdH3J3QqiboW3aeYe3LZNwFvTNIbV1xti2p4XbXirjibd3kpYU4v3H5jOrMJPZhZnMHJ/J+KzI0d8wPJS6ulwvo2i7Sx91troU0t5tLjAXl8IxZ7m7gI5meON21zMpvjEa3J1C3lR317GnLC79JC6tVDDDBfXcyVBT5tJWXVGYcrbbd3M17NnkThzzb4T3/6s7GfRXrBMe+BhsfQ2uehgWfw8ad8Hn/gEZY4fqr2VG0LAGfRHZCjQCMSCqqqUikgs8DJTgZs+6XFXrxEWMXwAXAC3Ap1R1xcG2b0F/5G3Y3chvX97M8m21bN3Tsq88KyXMjHEZnDolj4uOH8+xYzISWMujVLTDBenWOmitdc8xVL/rXsEkGDvLzXkcCLpG6ao17uq7bitE29yzDnOvhNO/vn/PpL3b4cV/h7f/4NocJpwCRaVQeKJrmI5kQiTLve++q+iKQdU6eP3X8PaDcMmvXa+nqvVwx5lQ8n646o/+fegt2g473nBdgo+yi52RCPqlqloTV/ZfQK2q3iIiNwM5qnqTiFwAfAkX9OcDv1DV+QfbvgX9xGpqj7KusoH1lQ2srWxk7c56VlXUowozxmUwpSCdhrZOGtqiqCrpySHSk0NMGZPOJ+ZPpDhnBIeMHs26ulybggQPfvW9azUsuxvKl8LuNa5nUjwJQsZ493xETRl0Nrvy938VPvj999Zbehc8/TUoPgWyJ7gUUsF0FwDzp+0fBDta3L4qV7qnsgtPdK9wqutptX2JG6p7zsd6H2ajqQq2/d3VZ+5Vh5+iGmpP/osbafZDPzrq5o9IRNB/FzhLVStFZDzwkqpOF5Hfeu8f6rleX9u3oH/kqWpo49nVu3j6nUr2NLWTmRImIxJGgOb2KI1tUcqqmwBYOHscl51YRH5GMlkpYfLTk8iIhA++AzM02ptco3VrnUsptda5tE3DTteQnTcFik92aaieM6apwt9+DFtedTOsNde814aRNsa1RbQ3uldz1YEnF8QF/e6TSnfZ1A/B7MvcwHy718KuVS6l1S05Cy74Lzj+471fXbfUulQZuOVpYyA0DG1P656Chz8B6WPdsX/qKTew4FFiuIP+FqAONxH6b1X1DhHZq6rZ3nIB6lQ1W0SeAm5R1de8ZS8AN6nqsh7bvAG4AWDixInztm3bNqg6mpFXsbeV+/6xlYfe3E5DW3S/ZUXZKUwfl8GEnBRaOmI0tUeJdinHFWZRWpLD3AnZpCWP4Ixi5tBU3fhKW151uf+WPV7vpUz3/MP4E9wrnOoGz6tY5tYpKoWJ8127xfJ7XHtE0263zexJ7pmJiQtg0mluW09+CXYsgekXuB5PXTGX1qpe7wb2a6jYv16BsBuyY/zxMH4uFJ7kthn/fEUsCmWL3ThPLXtg5ofdiaevO4rGXfCbU92J7ZN/dg3cnS1w46vu+Y3BqK+AZ77uBh1ceMuwpc6GO+gXqWqFiIwBFuPSN092B31vnTpVzelv0I9nV/pHt5aOKGt3NlDf2kl9ayeV9W28u6uRd3c1snNvK2nJITIiIbpU2VzTvK9Le2FWCiX5qZTkpTF9XAYzx2cypSCdHbUtrKqoZ31lAzmpSRw7Jn3f64gbftocKNrheifllLgRV3vqirk2hhd/4oI9uG60ece+d2KJZAPq1q3bApWr3B1D92xvgZAL2Cm5rkF79xqXGksf6167Vrn1xsx2w3VEsiB9DIyb47b/t5+4dNONr7iU1q7VcNc5LmU1Yb47Ae3d7tpejjkTJp/pBhE8VN5/7ZPupNbZ4hrt514NF/9yWAL/iPXeEZEfAE3A9Vh6xwxQfWsnb22v4+0d9Wzd08yWmmY2VzcdcKcAkBEJ0dIRI9bl/v+GAsL0cRnMKcpiVmEmM8ZlMn1cBlkp+6eS2jpjrNnZQDTWxeyiLNLtjuLIFOt0KaNAqH8Pi6m6nlM733Kv+h0undVS6+5ETrzadZ0Nhl1Pp9WPQcVy11W1rd6lvNrjelVd8D9wyvXvfX7r9/DEF9ydRf5Ud1LZudKltsC1eYzxGuFF3Dbb6t2JSQIuzbXlFXfi+Mjdboypl295L/CDa+AHdwIaZMPxsAV9EUkDAqra6L1fDPwIOAfYE9eQm6uq3xSRC4Ev8l5D7q2qetCnVSzo+5uqsquhjXWVDWyubqYoO4U5xVkUZafQGVO27mlm4+4m1uys550K99rb0rnv+9mpYcZkJFOQkczelk7e3dVI1DtRiMCxBemUluRy3uyxvG9KPkkhn/ZU8TtV19W28m3XFjL3qgMDb+MuF9y755dWdVf9W16F3e+4O4rqd11jeSTLvQJBd/JSdc89nHnTe20QL/6HC/xpY9wJqsv7f9t9Ahk3B87798M6AQxn0D8G+JP3MQQ8qKo/EZE84BFgIrAN12Wz1svv/wpYiOuy+emDpXbAgr4ZmO6TxPpdjayvdCmkqsY2qhrbSUsKcXxxFscXZ5McCvB2+V5WldfzxuY9NHfEyIiEmD85j9y0MJmRMDlpSYzPilCUnUJacoh1lQ2srqinsr6ND84ay0XHjyc1ye4UzCAsvdv1bsoqck95d8VcN93da1wK6LOvHdZm7eEsYw6irTPG38tqeHb1Lt7esZeGtk4a26K0dBw4Rk9qUpDslDA769vISA5xwZzxFGanEAkHSA4FUNiXcpoxLpN5k3JISbK2BnMYBjFm08GCvl2mGN+LhIOcM9NNSBOvrTNGxd5Wdu5tpaE1yvRx6UzOTycgsHRrHX9Yup2nVu2kuZeTQ7dwUJhTlEUkHKS+tZOGtk4EITUpSCQcJD89mQm5KUzISSUzxXV7BUhJCpKXlkR+RjLjMiN99mZq7Yixo66FxrYoxxVlkhyyE8yoMUwPhNmVvjGDFOtS2jpjtEe7ECAQEGJdyqryvbyxpZZlW2vpUvdEc1ZKGFWlpSNGa2eMqoZ2dtS19HpXEW9ibirTx2VQkJFMdWM7VY3tVO5tpaqxfd86qUlB3jclj9OnFjBtbAZTxqRRkJ5sQ2f4kKV3jDmCqSq1zR00t7vAr7iTQk1TO3uaOthe2+K6ue5upK65gwKvYXpsZoRJualMzEslKRjg75tqeOndasrrWvdtOz05RF56EjmpSeSkht2/aUlkp4RJSQqSHAqQFArQ1B5jb0sHe1s6CQcDZKWEyUwJ0aXugbvm9ij56cmcNCnH7iiOApbeMeYIJiLkpSeT10u39YE4f854VJWd9W1sqmpic3UTW/e0UNvcQV1LB9VN7WzY3cTelo5eU1IBgcyUMJ3RrgOWJwUDdMTcU7dJoQCzxrtB+GYVZpIZCbFzbxs797bSGetiYl4qk/PSyM9IpqktSkNbJ50xJT89iTEZEcZnRWwE1wSyK31jfKgj2kVbNEZHtIv2aBdpSUEyI2EC3qQ60VgXDW1RgiKkJgcJBwNUNbSxYnsdy7fV8U5FPesqG6lvfa97bFZKmHBQqGnqOOT+x2YmM7swiykFabR0xNjb0kldS8d+jegTclKYOd49b9ER7aKmqYOapnbSkoKMyYwwNjPC5Pw0ZozL6LXNIxpzx6a4k1Y4KL5JdVl6xxgz5LrvKlrao4zPTtn3oFtjWyfbvDuMjEiIjEj3yaCdqoZ2yutaWVvZwJqd9Wzd00JGcojs1DDZqUlkpYTJiISIhIJsqWlm3a4GGr2H85KCAXLTkmjpiO73wJ4ITMpNJTUpREObe/K7tSO273mM+PVc8HcngJzUJOZ4XXjnFGVRkpe6bwKhHbWtLN1ay8aqJjIiIfLSktxEQ+lJ5KYlk5uaRFpykFDwyHyuw9I7xpghJyIUZaccUJ4RCXNcUdYB5ZPyBjjNJO7EsruhnZRwkMyU0L4r9bbOGLvq2yiramJtZQPrKhvoiHYxY1wGmSnhfb2jkkMBRNh3R9MR7aIzpkS7utjd0MabW2p5YuXOffuLhAOkJoWobXZ3K6GAHHDyiJccCpCeHKIoJ4WJualMykslEgrSpdClbj/RmNIZU8ZlJTOnKJvZRZmkeyeovS2dBAPC2MzIvgcDVdX19GqNMjFv6EeptSt9Y4yv7fae+N5e28L2PS00tHVyfHE2J5fkMnVMOh2xLvY0d7CnqZ09zR3UNrk2kqZ2l4ZqbOukvK6VbXtaKK9rIf4cEQwIIe8V304SEOh5LslPTyY5FKC6sZ2OWBdjMpJ589sfPKxjsit9Y4zpw1ivfaAvkUCQouyUXu9qeop1KapKQAQR9mtD2NPUzjsV9ayuqKc92kW216MqGlMq69uorG+lI9pFQWYyYzIijDtInQbDgr4xxgyRYECA3huL89KTOWv6GM6aPmZkK9XDkdkKYYwxZlhY0DfGGB+xoG+MMT5iQd8YY3zEgr4xxviIBX1jjPERC/rGGOMjFvSNMcZHjvhhGESkGjfP7uHIB2qGsDpHAz8eM/jzuP14zODP4x7oMU9S1YLeFhzxQX8wRGRZX+NPjFZ+PGbw53H78ZjBn8c9lMds6R1jjPERC/rGGOMjoz3o35HoCiSAH48Z/Hncfjxm8OdxD9kxj+qcvjHGmP2N9it9Y4wxcSzoG2OMj4zKoC8iC0XkXREpE5GbE12f4SIiE0TkRRFZKyJrROTLXnmuiCwWkY3evzmJrutQE5GgiLwlIk95nyeLyBveb/6wiCQluo5DTUSyReRREVkvIutE5NTR/luLyL96/7dXi8hDIhIZjb+1iCwSkSoRWR1X1utvK86t3vGvEpGTBrKvURf0RSQI/Bo4H5gFXCkisxJbq2ETBb6mqrOABcAXvGO9GXhBVacCL3ifR5svA+viPv8n8DNVPRaoAz6TkFoNr18A/6eqM4ATcMc/an9rESkC/gUoVdXjgCBwBaPzt74HWNijrK/f9nxgqve6AbhtIDsadUEfOAUoU9XNqtoB/AG4JMF1GhaqWqmqK7z3jbggUIQ73nu91e4FLk1IBYeJiBQDFwJ3eZ8F+ADwqLfKaDzmLOAM4G4AVe1Q1b2M8t8aN6VrioiEgFSgklH4W6vqK0Btj+K+fttLgPvUWQJki8j4/u5rNAb9ImBH3Odyr2xUE5ES4ETgDWCsqlZ6i3YBYxNVr2Hyc+CbQJf3OQ/Yq6pR7/No/M0nA9XA77y01l0iksYo/q1VtQL4H2A7LtjXA8sZ/b91t75+20HFuNEY9H1HRNKBx4CvqGpD/DJ1fXJHTb9cEbkIqFLV5YmuywgLAScBt6nqiUAzPVI5o/C3zsFd1U4GCoE0DkyB+MJQ/rajMehXABPiPhd7ZaOSiIRxAf8BVX3cK97dfbvn/VuVqPoNg9OAi0VkKy519wFcrjvbSwHA6PzNy4FyVX3D+/wo7iQwmn/rDwJbVLVaVTuBx3G//2j/rbv19dsOKsaNxqC/FJjqtfAn4Rp+nkxwnYaFl8u+G1inqj+NW/QkcK33/lrgiZGu23BR1W+parGqluB+27+p6ieAF4GPequNqmMGUNVdwA4Rme4VnQOsZRT/1ri0zgIRSfX+r3cf86j+reP09ds+CVzj9eJZANTHpYEOTVVH3Qu4ANgAbAK+nej6DONxvh93y7cKWOm9LsDluF8ANgLPA7mJruswHf9ZwFPe+2OAN4Ey4I9AcqLrNwzHOxdY5v3efwZyRvtvDfwQWA+sBu4Hkkfjbw08hGu36MTd1X2mr98WEFwPxU3AO7jeTf3elw3DYIwxPjIa0zvGGGP6YEHfGGN8xIK+Mcb4iAV9Y4zxEQv6xhjjIxb0jTHGRyzoG2OMj/x/pFpcyareD5sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769353df",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "171a3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_logarithmic_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c7d233e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dbff0ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 32.2780 - mse: 15853977.0000 - val_loss: 15.8616 - val_mse: 17421436.0000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 12.2372 - mse: 15519761.0000 - val_loss: 10.2716 - val_mse: 16940752.0000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 9.3505 - mse: 15197965.0000 - val_loss: 8.6471 - val_mse: 16719758.0000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 8.4193 - mse: 15034823.0000 - val_loss: 8.0528 - val_mse: 16550090.0000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 7.9767 - mse: 14940348.0000 - val_loss: 7.6718 - val_mse: 16444444.0000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 7.6775 - mse: 14840586.0000 - val_loss: 7.3823 - val_mse: 16381389.0000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 7.3371 - mse: 14785659.0000 - val_loss: 6.9093 - val_mse: 16369921.0000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 6.0549 - mse: 14613157.0000 - val_loss: 5.0979 - val_mse: 15731716.0000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 4.8618 - mse: 13849148.0000 - val_loss: 4.6261 - val_mse: 15125443.0000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 4.3738 - mse: 13205615.0000 - val_loss: 4.2169 - val_mse: 14468164.0000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 4.0624 - mse: 12742826.0000 - val_loss: 3.9435 - val_mse: 13925494.0000\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.8314 - mse: 12358486.0000 - val_loss: 3.7885 - val_mse: 13653716.0000\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.5869 - mse: 11975134.0000 - val_loss: 3.5792 - val_mse: 13034202.0000\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.4203 - mse: 11641337.0000 - val_loss: 3.4245 - val_mse: 12794959.0000\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.3459 - mse: 11389776.0000 - val_loss: 3.3171 - val_mse: 12484091.0000\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.1699 - mse: 11129052.0000 - val_loss: 3.2520 - val_mse: 12121895.0000\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 3.0937 - mse: 10846184.0000 - val_loss: 3.1097 - val_mse: 12173973.0000\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.9644 - mse: 10675171.0000 - val_loss: 3.0227 - val_mse: 11924555.0000\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.8926 - mse: 10552654.0000 - val_loss: 2.9187 - val_mse: 11661760.0000\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.7904 - mse: 10305152.0000 - val_loss: 2.8711 - val_mse: 11574001.0000\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.7319 - mse: 10214447.0000 - val_loss: 2.8941 - val_mse: 11498946.0000\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.6824 - mse: 10074028.0000 - val_loss: 2.7801 - val_mse: 11392391.0000\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.5957 - mse: 9930264.0000 - val_loss: 2.7128 - val_mse: 11237014.0000\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.5489 - mse: 9825614.0000 - val_loss: 2.6620 - val_mse: 10862537.0000\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.5186 - mse: 9706975.0000 - val_loss: 2.6021 - val_mse: 10847578.0000\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.4810 - mse: 9589908.0000 - val_loss: 2.5774 - val_mse: 10887056.0000\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.4331 - mse: 9514400.0000 - val_loss: 2.5217 - val_mse: 10797897.0000\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.3931 - mse: 9440944.0000 - val_loss: 2.4834 - val_mse: 10697534.0000\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.3537 - mse: 9358738.0000 - val_loss: 2.4514 - val_mse: 10637793.0000\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.3307 - mse: 9326240.0000 - val_loss: 2.4193 - val_mse: 10544178.0000\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.3040 - mse: 9253442.0000 - val_loss: 2.4056 - val_mse: 10507982.0000\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.2661 - mse: 9144021.0000 - val_loss: 2.3597 - val_mse: 10455077.0000\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.2250 - mse: 9081164.0000 - val_loss: 2.3172 - val_mse: 10228318.0000\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.1869 - mse: 9010159.0000 - val_loss: 2.2916 - val_mse: 10152793.0000\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.1714 - mse: 8943210.0000 - val_loss: 2.2738 - val_mse: 9977257.0000\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.1289 - mse: 8819905.0000 - val_loss: 2.2919 - val_mse: 9878830.0000\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.1099 - mse: 8832725.0000 - val_loss: 2.2571 - val_mse: 10183775.0000\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.0810 - mse: 8816420.0000 - val_loss: 2.1939 - val_mse: 9900444.0000\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.0625 - mse: 8684910.0000 - val_loss: 2.1884 - val_mse: 9799902.0000\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.0082 - mse: 8562951.0000 - val_loss: 2.1273 - val_mse: 9743070.0000\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 2.0028 - mse: 8519880.0000 - val_loss: 2.1064 - val_mse: 9735325.0000\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.9864 - mse: 8494454.0000 - val_loss: 2.0807 - val_mse: 9896481.0000\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.9504 - mse: 8497246.0000 - val_loss: 2.0764 - val_mse: 9476572.0000\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.9198 - mse: 8413950.0000 - val_loss: 2.0295 - val_mse: 9469643.0000\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.8909 - mse: 8331334.5000 - val_loss: 1.9967 - val_mse: 9460717.0000\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.8687 - mse: 8292933.0000 - val_loss: 2.0196 - val_mse: 9088360.0000\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.8378 - mse: 8094181.5000 - val_loss: 2.0013 - val_mse: 9148850.0000\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.8249 - mse: 8091621.5000 - val_loss: 1.9254 - val_mse: 9118905.0000\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7892 - mse: 8066878.5000 - val_loss: 1.9073 - val_mse: 9149712.0000\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7649 - mse: 7920620.5000 - val_loss: 1.8614 - val_mse: 9116118.0000\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7454 - mse: 7800590.0000 - val_loss: 1.8375 - val_mse: 9063142.0000\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7246 - mse: 7794753.0000 - val_loss: 1.8633 - val_mse: 8657709.0000\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7050 - mse: 7600834.5000 - val_loss: 1.8122 - val_mse: 8766785.0000\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.6856 - mse: 7521632.0000 - val_loss: 1.7836 - val_mse: 8744729.0000\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.6513 - mse: 7357198.0000 - val_loss: 1.7703 - val_mse: 8452209.0000\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.6289 - mse: 7108407.0000 - val_loss: 1.7534 - val_mse: 8138334.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5948 - mse: 6942070.0000 - val_loss: 1.6990 - val_mse: 8147009.0000\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5758 - mse: 6701292.5000 - val_loss: 1.7144 - val_mse: 7828127.5000\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5419 - mse: 6610392.5000 - val_loss: 1.7433 - val_mse: 7242591.5000\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5187 - mse: 6233877.0000 - val_loss: 1.5980 - val_mse: 7501535.5000\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4916 - mse: 6206895.0000 - val_loss: 1.6096 - val_mse: 6878894.5000\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.4546 - mse: 5806429.0000 - val_loss: 1.5514 - val_mse: 6917240.5000\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4418 - mse: 5657035.0000 - val_loss: 1.5307 - val_mse: 6633291.5000\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4164 - mse: 5431050.0000 - val_loss: 1.5086 - val_mse: 6418117.5000\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4079 - mse: 5340723.0000 - val_loss: 1.5085 - val_mse: 6202063.5000\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4163 - mse: 5164908.5000 - val_loss: 1.4802 - val_mse: 5995718.5000\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3565 - mse: 4985765.0000 - val_loss: 1.4722 - val_mse: 5846584.5000\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3574 - mse: 4884938.5000 - val_loss: 1.4675 - val_mse: 6473809.5000\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3520 - mse: 4845883.5000 - val_loss: 1.4349 - val_mse: 5850101.0000\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3372 - mse: 4597613.0000 - val_loss: 1.4666 - val_mse: 5589639.5000\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3147 - mse: 4400901.0000 - val_loss: 1.4442 - val_mse: 5448616.5000\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2896 - mse: 4326797.5000 - val_loss: 1.3859 - val_mse: 5197626.0000\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2947 - mse: 4348479.5000 - val_loss: 1.3853 - val_mse: 5254438.0000\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2684 - mse: 4281909.0000 - val_loss: 1.3949 - val_mse: 5221309.0000\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2813 - mse: 4083824.7500 - val_loss: 1.3862 - val_mse: 5384484.0000\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2621 - mse: 3970848.0000 - val_loss: 1.3438 - val_mse: 4972694.0000\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2406 - mse: 3883503.0000 - val_loss: 1.3455 - val_mse: 4727775.0000\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2262 - mse: 3768219.0000 - val_loss: 1.3741 - val_mse: 4635151.0000\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2175 - mse: 3745629.2500 - val_loss: 1.3036 - val_mse: 4606216.5000\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2046 - mse: 3691037.0000 - val_loss: 1.3120 - val_mse: 4997597.0000\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2038 - mse: 3702311.7500 - val_loss: 1.3121 - val_mse: 5115850.5000\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2036 - mse: 3608764.2500 - val_loss: 1.2816 - val_mse: 4398602.0000\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1773 - mse: 3497274.5000 - val_loss: 1.2753 - val_mse: 4230854.5000\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1832 - mse: 3529369.5000 - val_loss: 1.2834 - val_mse: 4561466.5000\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1716 - mse: 3392018.2500 - val_loss: 1.2672 - val_mse: 4470665.0000\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1574 - mse: 3387863.2500 - val_loss: 1.2399 - val_mse: 4340282.0000\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1580 - mse: 3494298.5000 - val_loss: 1.2389 - val_mse: 4330540.5000\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1401 - mse: 3307883.5000 - val_loss: 1.2409 - val_mse: 4311916.5000\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1399 - mse: 3385515.7500 - val_loss: 1.2393 - val_mse: 4438708.0000\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1291 - mse: 3300790.2500 - val_loss: 1.2144 - val_mse: 4130042.5000\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1285 - mse: 3280744.5000 - val_loss: 1.2521 - val_mse: 4200400.5000\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1423 - mse: 3289945.7500 - val_loss: 1.1984 - val_mse: 4060879.0000\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1162 - mse: 3227433.0000 - val_loss: 1.2246 - val_mse: 4341267.0000\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1132 - mse: 3306977.7500 - val_loss: 1.1925 - val_mse: 4142856.7500\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.1073 - mse: 3166457.0000 - val_loss: 1.2571 - val_mse: 4451899.5000\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0953 - mse: 3148675.5000 - val_loss: 1.2220 - val_mse: 3824056.2500\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0835 - mse: 3077827.5000 - val_loss: 1.1697 - val_mse: 3836928.2500\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0742 - mse: 3022333.7500 - val_loss: 1.1923 - val_mse: 3860404.2500\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0867 - mse: 3020669.2500 - val_loss: 1.1766 - val_mse: 4102674.2500\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0723 - mse: 3087264.0000 - val_loss: 1.1640 - val_mse: 4169673.7500\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8cf337fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.88811492919922, 16214766.0]\n",
      "[48.74056625366211, 20521370.0]\n"
     ]
    }
   ],
   "source": [
    "train_msle = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_msle)\n",
    "test_msle = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f131a250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e18c2",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfe4d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MSE Loss\n",
    "#mean_squared_error\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8dd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e2f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14608904.0000 - mse: 14608899.0000 - val_loss: 10696312.0000 - val_mse: 10696294.0000\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 9066578.0000 - mse: 9066559.0000 - val_loss: 8935004.0000 - val_mse: 8934977.0000\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 7178179.0000 - mse: 7178148.0000 - val_loss: 6169700.0000 - val_mse: 6169667.0000\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 3899737.5000 - mse: 3899701.7500 - val_loss: 3309805.5000 - val_mse: 3309767.2500\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2400015.0000 - mse: 2399976.2500 - val_loss: 2769332.2500 - val_mse: 2769292.0000\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2162544.2500 - mse: 2162503.5000 - val_loss: 2628769.2500 - val_mse: 2628728.0000\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2036106.3750 - mse: 2036066.3750 - val_loss: 2542170.7500 - val_mse: 2542129.7500\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1934748.0000 - mse: 1934707.3750 - val_loss: 2495458.5000 - val_mse: 2495417.7500\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1870507.0000 - mse: 1870466.2500 - val_loss: 2378029.7500 - val_mse: 2377988.7500\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1802467.5000 - mse: 1802425.7500 - val_loss: 2332277.2500 - val_mse: 2332236.0000\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1747963.2500 - mse: 1747921.3750 - val_loss: 2270820.0000 - val_mse: 2270779.0000\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1678796.1250 - mse: 1678755.1250 - val_loss: 2239129.0000 - val_mse: 2239087.7500\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1634426.0000 - mse: 1634384.8750 - val_loss: 2173635.0000 - val_mse: 2173593.5000\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1575331.5000 - mse: 1575289.7500 - val_loss: 2128364.0000 - val_mse: 2128322.5000\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1533905.3750 - mse: 1533864.0000 - val_loss: 2082698.3750 - val_mse: 2082657.0000\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1499229.5000 - mse: 1499187.0000 - val_loss: 2018434.5000 - val_mse: 2018392.5000\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1452869.0000 - mse: 1452828.0000 - val_loss: 1960846.8750 - val_mse: 1960805.8750\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1411580.7500 - mse: 1411538.7500 - val_loss: 1917620.6250 - val_mse: 1917578.5000\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1377884.2500 - mse: 1377842.3750 - val_loss: 1880005.7500 - val_mse: 1879964.1250\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1368340.1250 - mse: 1368298.0000 - val_loss: 1842142.7500 - val_mse: 1842100.6250\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1320659.8750 - mse: 1320617.8750 - val_loss: 1937287.3750 - val_mse: 1937246.0000\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1273733.8750 - mse: 1273692.0000 - val_loss: 1946207.8750 - val_mse: 1946166.6250\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1228172.0000 - mse: 1228130.3750 - val_loss: 1909796.1250 - val_mse: 1909754.1250\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1237500.2500 - mse: 1237457.3750 - val_loss: 1777391.5000 - val_mse: 1777349.7500\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1191716.8750 - mse: 1191675.3750 - val_loss: 1693048.3750 - val_mse: 1693007.1250\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1164531.0000 - mse: 1164489.6250 - val_loss: 1670427.8750 - val_mse: 1670385.6250\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1139100.3750 - mse: 1139059.1250 - val_loss: 1639139.2500 - val_mse: 1639097.2500\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1143498.8750 - mse: 1143457.2500 - val_loss: 1586097.5000 - val_mse: 1586055.7500\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1109181.5000 - mse: 1109139.0000 - val_loss: 1552988.8750 - val_mse: 1552947.3750\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1095623.3750 - mse: 1095582.3750 - val_loss: 1636627.7500 - val_mse: 1636585.7500\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1081554.5000 - mse: 1081512.1250 - val_loss: 1543568.0000 - val_mse: 1543526.1250\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1061492.3750 - mse: 1061450.5000 - val_loss: 1516616.0000 - val_mse: 1516573.8750\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1049488.1250 - mse: 1049446.2500 - val_loss: 1488277.6250 - val_mse: 1488235.7500\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1043802.5000 - mse: 1043760.3750 - val_loss: 1503838.2500 - val_mse: 1503796.2500\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1007972.8125 - mse: 1007930.6250 - val_loss: 1445336.6250 - val_mse: 1445294.6250\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1038356.4375 - mse: 1038314.0625 - val_loss: 1473002.3750 - val_mse: 1472960.2500\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1012110.6875 - mse: 1012068.5625 - val_loss: 1422529.1250 - val_mse: 1422487.0000\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 994910.1875 - mse: 994868.3125 - val_loss: 1401926.6250 - val_mse: 1401884.5000\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 967266.6250 - mse: 967224.4375 - val_loss: 1410196.7500 - val_mse: 1410154.6250\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 971772.1250 - mse: 971729.6875 - val_loss: 1461593.8750 - val_mse: 1461551.5000\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 955292.8125 - mse: 955250.4375 - val_loss: 1395381.3750 - val_mse: 1395339.0000\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 989527.1875 - mse: 989484.9375 - val_loss: 1416427.3750 - val_mse: 1416385.1250\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 930038.5625 - mse: 929996.1875 - val_loss: 1436268.0000 - val_mse: 1436225.5000\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 939352.3750 - mse: 939309.8125 - val_loss: 1355295.6250 - val_mse: 1355253.0000\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 916930.5625 - mse: 916887.6875 - val_loss: 1394301.1250 - val_mse: 1394258.6250\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 924452.0625 - mse: 924409.5000 - val_loss: 1327547.6250 - val_mse: 1327505.0000\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 913955.8750 - mse: 913913.0000 - val_loss: 1470318.0000 - val_mse: 1470275.1250\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 910055.9375 - mse: 910013.3125 - val_loss: 1371901.1250 - val_mse: 1371858.5000\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 896316.6875 - mse: 896274.0625 - val_loss: 1341521.3750 - val_mse: 1341479.1250\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 900157.3125 - mse: 900114.3750 - val_loss: 1480497.0000 - val_mse: 1480454.7500\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 898926.8125 - mse: 898883.7500 - val_loss: 1310652.6250 - val_mse: 1310610.1250\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 893000.6875 - mse: 892957.7500 - val_loss: 1299044.7500 - val_mse: 1299001.7500\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 1s 3ms/step - loss: 877280.1250 - mse: 877237.6250 - val_loss: 1311867.1250 - val_mse: 1311824.3750\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 866975.1875 - mse: 866932.5000 - val_loss: 1255237.7500 - val_mse: 1255195.5000\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 864225.8125 - mse: 864183.3125 - val_loss: 1267213.6250 - val_mse: 1267170.8750\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 861394.3750 - mse: 861351.1875 - val_loss: 1309801.6250 - val_mse: 1309758.8750\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 867293.0000 - mse: 867250.5000 - val_loss: 1242350.2500 - val_mse: 1242307.2500\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 844451.3750 - mse: 844408.1250 - val_loss: 1296686.5000 - val_mse: 1296643.5000\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 842543.8750 - mse: 842501.3125 - val_loss: 1213519.8750 - val_mse: 1213476.8750\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 839215.5625 - mse: 839172.5000 - val_loss: 1208268.5000 - val_mse: 1208225.6250\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 832325.0625 - mse: 832281.7500 - val_loss: 1224241.1250 - val_mse: 1224198.2500\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 823280.2500 - mse: 823237.1875 - val_loss: 1252333.2500 - val_mse: 1252290.0000\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 849051.8125 - mse: 849008.2500 - val_loss: 1200297.7500 - val_mse: 1200254.5000\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 826900.9375 - mse: 826857.7500 - val_loss: 1205604.8750 - val_mse: 1205561.6250\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 817186.0625 - mse: 817142.6250 - val_loss: 1180166.3750 - val_mse: 1180123.2500\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 804133.3750 - mse: 804090.3125 - val_loss: 1179109.1250 - val_mse: 1179066.3750\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 810585.0000 - mse: 810542.0625 - val_loss: 1177043.1250 - val_mse: 1176999.8750\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 801966.1250 - mse: 801923.3125 - val_loss: 1194488.1250 - val_mse: 1194445.2500\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 809125.6875 - mse: 809082.6875 - val_loss: 1177507.0000 - val_mse: 1177463.5000\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 810209.1875 - mse: 810165.8750 - val_loss: 1241671.2500 - val_mse: 1241627.8750\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 785929.6875 - mse: 785886.3125 - val_loss: 1185031.0000 - val_mse: 1184987.7500\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 798645.8125 - mse: 798602.5625 - val_loss: 1141846.5000 - val_mse: 1141803.5000\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 795075.4375 - mse: 795032.1250 - val_loss: 1195958.0000 - val_mse: 1195915.0000\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 776635.1875 - mse: 776591.8750 - val_loss: 1136489.0000 - val_mse: 1136445.8750\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 772512.5625 - mse: 772469.3125 - val_loss: 1133203.7500 - val_mse: 1133160.2500\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 777710.8125 - mse: 777666.9375 - val_loss: 1159232.8750 - val_mse: 1159189.1250\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 791897.5000 - mse: 791854.4375 - val_loss: 1116753.1250 - val_mse: 1116709.6250\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 757430.1875 - mse: 757386.5000 - val_loss: 1169387.3750 - val_mse: 1169343.7500\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 748364.0625 - mse: 748320.6875 - val_loss: 1115705.3750 - val_mse: 1115661.5000\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 748435.4375 - mse: 748392.3125 - val_loss: 1108402.7500 - val_mse: 1108359.1250\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 753991.7500 - mse: 753948.1250 - val_loss: 1118303.7500 - val_mse: 1118260.5000\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 761590.6250 - mse: 761546.9375 - val_loss: 1241698.1250 - val_mse: 1241654.0000\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 764332.5625 - mse: 764289.5000 - val_loss: 1114749.1250 - val_mse: 1114705.8750\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 744780.1250 - mse: 744736.3125 - val_loss: 1160592.2500 - val_mse: 1160548.6250\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 742791.0625 - mse: 742747.4375 - val_loss: 1103600.2500 - val_mse: 1103556.5000\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 729616.4375 - mse: 729572.3125 - val_loss: 1086235.7500 - val_mse: 1086191.7500\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 721130.7500 - mse: 721086.9375 - val_loss: 1087400.6250 - val_mse: 1087357.0000\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 757593.2500 - mse: 757549.5000 - val_loss: 1087702.3750 - val_mse: 1087658.3750\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 719475.8750 - mse: 719431.9375 - val_loss: 1142061.7500 - val_mse: 1142017.7500\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 743538.6250 - mse: 743494.7500 - val_loss: 1099013.8750 - val_mse: 1098970.0000\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 712114.8750 - mse: 712070.7500 - val_loss: 1082252.5000 - val_mse: 1082208.7500\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 714158.1250 - mse: 714114.1875 - val_loss: 1114313.8750 - val_mse: 1114269.8750\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 711917.3125 - mse: 711872.7500 - val_loss: 1090649.0000 - val_mse: 1090605.0000\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 705982.9375 - mse: 705938.5625 - val_loss: 1047234.4375 - val_mse: 1047190.1250\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 693613.5000 - mse: 693569.0625 - val_loss: 1052822.5000 - val_mse: 1052778.3750\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 727756.2500 - mse: 727712.6875 - val_loss: 1038043.5000 - val_mse: 1037999.6250\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 697330.0000 - mse: 697285.5000 - val_loss: 1035215.8125 - val_mse: 1035171.4375\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 728406.1875 - mse: 728361.8750 - val_loss: 1057923.8750 - val_mse: 1057879.3750\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 687287.0000 - mse: 687242.6875 - val_loss: 1060057.3750 - val_mse: 1060013.1250\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 688541.7500 - mse: 688497.8750 - val_loss: 1035285.0000 - val_mse: 1035240.6250\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "354495dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891309f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
