{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transactions        size  sentbyaddress    difficulty      hashrate  \\\n",
      "0              235     649.653            390  1.815430e+02  2.775561e+09   \n",
      "1              248     765.285            424  1.815430e+02  1.554461e+09   \n",
      "2              354     756.040            553  1.815430e+02  1.551287e+09   \n",
      "3              413     984.707            632  1.815430e+02  1.640430e+09   \n",
      "4              256     542.483            440  1.815430e+02  1.723493e+09   \n",
      "...            ...         ...            ...           ...           ...   \n",
      "3483        340402  706867.000         433958  1.546610e+13  1.157542e+20   \n",
      "3484        332402  704883.000         416980  1.546610e+13  1.253033e+20   \n",
      "3485        334290  770486.000         398021  1.546610e+13  1.113635e+20   \n",
      "3486        303573  650769.000         338567  1.546610e+13  1.201317e+20   \n",
      "3487        290736  684127.000         257655  1.546610e+13  1.064910e+20   \n",
      "\n",
      "      mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
      "0               154298.000  1.193000e+03            0.000010   \n",
      "1               401834.000  2.620000e+03            0.000243   \n",
      "2               481473.000  4.048000e+03            0.000022   \n",
      "3               431831.000  2.341000e+03            0.000000   \n",
      "4               460783.000  2.122000e+03            0.000000   \n",
      "...                    ...           ...                 ...   \n",
      "3483                 0.163  8.336367e+09            0.561000   \n",
      "3484                 0.148  1.365361e+10            0.555000   \n",
      "3485                 0.153  1.126273e+10            0.631000   \n",
      "3486                 0.149  7.668679e+09            0.541000   \n",
      "3487                 0.159  6.486338e+09            0.548000   \n",
      "\n",
      "      median_transaction_feeUSD  confirmationtime  ...  price3rsiUSD  \\\n",
      "0                         0.000             8.324  ...         0.000   \n",
      "1                         0.000             8.372  ...         0.000   \n",
      "2                         0.000             8.276  ...         0.000   \n",
      "3                         0.000             7.956  ...        82.751   \n",
      "4                         0.000             6.957  ...        78.603   \n",
      "...                         ...               ...  ...           ...   \n",
      "3483                      0.221             9.000  ...        93.577   \n",
      "3484                      0.213             9.231  ...        94.137   \n",
      "3485                      0.270            10.000  ...        87.140   \n",
      "3486                      0.219             9.536  ...        88.385   \n",
      "3487                      0.206            10.070  ...        88.689   \n",
      "\n",
      "      price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  \\\n",
      "0            0.000          0.000          0.000          0.000         0.000   \n",
      "1            0.000          0.000          0.000          0.000         0.000   \n",
      "2            0.000          0.000          0.000          0.000         0.000   \n",
      "3            0.000          0.000          0.000          0.000        58.099   \n",
      "4            0.000          0.000          0.000          0.000         5.652   \n",
      "...            ...            ...            ...            ...           ...   \n",
      "3483        80.644         73.588         64.882         54.040        10.430   \n",
      "3484        81.436         74.176         65.272         54.195         7.432   \n",
      "3485        79.116         73.100         64.815         54.082         3.505   \n",
      "3486        79.762         73.498         65.058         54.175         0.473   \n",
      "3487        79.897         73.576         65.104         54.192         0.041   \n",
      "\n",
      "      price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
      "0            0.000          0.000          0.000          0.000  \n",
      "1            0.000          0.000          0.000          0.000  \n",
      "2            0.000          0.000          0.000          0.000  \n",
      "3            0.000          0.000          0.000          0.000  \n",
      "4            0.000          0.000          0.000          0.000  \n",
      "...            ...            ...            ...            ...  \n",
      "3483         7.538          6.497         26.536          1.663  \n",
      "3484        10.930          8.061         28.817          2.376  \n",
      "3485        11.368          5.611         29.412          0.800  \n",
      "3486        12.499          5.457         31.791          1.606  \n",
      "3487        11.011          6.081         29.624          1.220  \n",
      "\n",
      "[3488 rows x 735 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_20536\\3812082222.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3a6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transactions', 'size', 'sentbyaddress', 'difficulty', 'hashrate',\n",
      "       'mining_profitability', 'sentinusdUSD', 'transactionfeesUSD',\n",
      "       'median_transaction_feeUSD', 'confirmationtime',\n",
      "       ...\n",
      "       'price3rsiUSD', 'price7rsiUSD', 'price14rsiUSD', 'price30rsiUSD',\n",
      "       'price90rsiUSD', 'price3rocUSD', 'price7rocUSD', 'price14rocUSD',\n",
      "       'price30rocUSD', 'price90rocUSD'],\n",
      "      dtype='object', length=735)\n"
     ]
    }
   ],
   "source": [
    "list_of_column_names = list(n.columns)\n",
    "print(n.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc0148",
   "metadata": {},
   "source": [
    "### Reading the MINMAX Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2    3         4         5  \\\n",
       "0           0  0.145302  0.000000  0.179782  0.0  0.000000  0.238634   \n",
       "1           1  0.203855  0.000000  0.136095  0.0  0.005416  0.282885   \n",
       "2           2  0.155377  0.000000  0.170912  0.0  0.000000  0.371988   \n",
       "3           3  0.081168  0.056898  0.152915  0.0  0.001428  0.429266   \n",
       "4           4  0.083447  0.066815  0.103083  0.0  0.000000  0.416309   \n",
       "\n",
       "          6         7    8  ...   29        30        31        32        33  \\\n",
       "0  0.088901  0.305821  0.0  ...  0.0  0.173201  0.000000  0.056773  0.070532   \n",
       "1  0.103172  0.288340  0.0  ...  0.0  0.131363  0.000000  0.089604  0.058761   \n",
       "2  0.016288  0.304093  0.0  ...  0.0  0.172211  0.000000  0.085838  0.086743   \n",
       "3  0.003453  0.371735  0.0  ...  0.0  0.123929  0.000000  0.117967  0.175683   \n",
       "4  0.034490  0.336175  0.0  ...  0.0  0.101451  0.003113  0.109843  0.155952   \n",
       "\n",
       "         34        35   36        37  priceUSD  \n",
       "0  0.000000  0.146290  0.0  0.244239    0.0495  \n",
       "1  0.041308  0.122358  0.0  0.245734    0.0726  \n",
       "2  0.069722  0.043386  0.0  0.236507    0.0859  \n",
       "3  0.096189  0.105011  0.0  0.185024    0.0783  \n",
       "4  0.097110  0.108404  0.0  0.139865    0.0767  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_MinMaxScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.386481</td>\n",
       "      <td>0.117555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.247056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>0.144571</td>\n",
       "      <td>0.276913</td>\n",
       "      <td>0.322411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.373520</td>\n",
       "      <td>0.350037</td>\n",
       "      <td>0.132441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229406</td>\n",
       "      <td>0.227104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494760</td>\n",
       "      <td>0.142909</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>0.339183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043156</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.350619</td>\n",
       "      <td>0.426659</td>\n",
       "      <td>0.211410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197371</td>\n",
       "      <td>0.249512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542962</td>\n",
       "      <td>0.148570</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>0.363947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.319798</td>\n",
       "      <td>0.364622</td>\n",
       "      <td>0.152678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214873</td>\n",
       "      <td>0.209499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535941</td>\n",
       "      <td>0.134063</td>\n",
       "      <td>0.288476</td>\n",
       "      <td>0.372253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.340285</td>\n",
       "      <td>0.378646</td>\n",
       "      <td>0.149963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.239973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522454</td>\n",
       "      <td>0.082172</td>\n",
       "      <td>0.271670</td>\n",
       "      <td>0.394370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2    3         4         5         6  \\\n",
       "0     0.145302  0.000000  0.179782  0.0  0.000000  0.238634  0.088901   \n",
       "1     0.203855  0.000000  0.136095  0.0  0.005416  0.282885  0.103172   \n",
       "2     0.155377  0.000000  0.170912  0.0  0.000000  0.371988  0.016288   \n",
       "3     0.081168  0.056898  0.152915  0.0  0.001428  0.429266  0.003453   \n",
       "4     0.083447  0.066815  0.103083  0.0  0.000000  0.416309  0.034490   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3483  0.339125  0.386481  0.117555  0.0  0.203587  0.247056  0.000000   \n",
       "3484  0.373520  0.350037  0.132441  0.0  0.229406  0.227104  0.000000   \n",
       "3485  0.350619  0.426659  0.211410  0.0  0.197371  0.249512  0.000000   \n",
       "3486  0.319798  0.364622  0.152678  0.0  0.214873  0.209499  0.000000   \n",
       "3487  0.340285  0.378646  0.149963  0.0  0.160641  0.239973  0.000000   \n",
       "\n",
       "             7    8         9  ...   29        30        31        32  \\\n",
       "0     0.305821  0.0  0.034986  ...  0.0  0.173201  0.000000  0.056773   \n",
       "1     0.288340  0.0  0.060730  ...  0.0  0.131363  0.000000  0.089604   \n",
       "2     0.304093  0.0  0.055210  ...  0.0  0.172211  0.000000  0.085838   \n",
       "3     0.371735  0.0  0.054605  ...  0.0  0.123929  0.000000  0.117967   \n",
       "4     0.336175  0.0  0.065952  ...  0.0  0.101451  0.003113  0.109843   \n",
       "...        ...  ...       ...  ...  ...       ...       ...       ...   \n",
       "3483  0.321566  0.0  0.000000  ...  0.0  0.505908  0.144571  0.276913   \n",
       "3484  0.313371  0.0  0.000000  ...  0.0  0.494760  0.142909  0.279354   \n",
       "3485  0.313492  0.0  0.000000  ...  0.0  0.542962  0.148570  0.304143   \n",
       "3486  0.265145  0.0  0.000000  ...  0.0  0.535941  0.134063  0.288476   \n",
       "3487  0.255416  0.0  0.000000  ...  0.0  0.522454  0.082172  0.271670   \n",
       "\n",
       "            33        34        35   36        37   priceUSD  \n",
       "0     0.070532  0.000000  0.146290  0.0  0.244239     0.0495  \n",
       "1     0.058761  0.041308  0.122358  0.0  0.245734     0.0726  \n",
       "2     0.086743  0.069722  0.043386  0.0  0.236507     0.0859  \n",
       "3     0.175683  0.096189  0.105011  0.0  0.185024     0.0783  \n",
       "4     0.155952  0.097110  0.108404  0.0  0.139865     0.0767  \n",
       "...        ...       ...       ...  ...       ...        ...  \n",
       "3483  0.322411  0.000000  0.241756  0.0  0.046847  9349.0000  \n",
       "3484  0.339183  0.000000  0.266478  0.0  0.043156  9394.0000  \n",
       "3485  0.363947  0.000000  0.280159  0.0  0.021500  9366.0000  \n",
       "3486  0.372253  0.000000  0.244182  0.0  0.010242  9393.0000  \n",
       "3487  0.394370  0.000000  0.246692  0.0  0.027949  9398.0000  \n",
       "\n",
       "[3488 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81334839822775\n",
      "Test score of trained model: 84.90442428504817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_score = regressor.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = regressor.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c931f7",
   "metadata": {},
   "source": [
    "### Overall score table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ac3e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = np.mean(np.abs( (y_test-y_pred) / y_test))*100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00beb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170404e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473229e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.009080e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>4.055422e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490442e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403397e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170404e+06\n",
       "1    RMSE  1.473229e+03\n",
       "2     MAE  1.009080e+03\n",
       "3    MAPE  4.055422e+04\n",
       "4      r2  8.490442e-01\n",
       "5  adj_r2  8.403397e-01"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [MSE, RMSE, MAE, MAPE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'MAPE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b98aeb",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "379f72a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81319444658527\n",
      "Test score of trained model: 84.9064540975754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.001, normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "\n",
    "train_score = ridge.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = ridge.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9a991cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170112e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.008650e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490645e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403611e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170112e+06\n",
       "1    RMSE  1.473130e+03\n",
       "2     MAE  1.008650e+03\n",
       "3      r2  8.490645e-01\n",
       "4  adj_r2  8.403611e-01"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc8a47",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "582d4dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 84.81334593809626\n",
      "Test score of trained model: 84.9045902091973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 0.001, normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "pred = lasso.predict(X_test)\n",
    "\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c275084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.170380e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.473221e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.009035e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>8.490459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>8.403414e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric         Score\n",
       "0     MSE  2.170380e+06\n",
       "1    RMSE  1.473221e+03\n",
       "2     MAE  1.009035e+03\n",
       "3      r2  8.490459e-01\n",
       "4  adj_r2  8.403414e-01"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8b3266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of trained model: 99.99211717109155\n",
      "Test score of trained model: 97.19190406689304\n"
     ]
    }
   ],
   "source": [
    "pred=grid_GBR.predict(X_test)\n",
    "train_score = grid_GBR.score(X_train, y_train)\n",
    "print(f'Train score of trained model: {train_score*100}')\n",
    "\n",
    "test_score = grid_GBR.score(X_test, y_test)\n",
    "print(f'Test score of trained model: {test_score*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f10dfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>403740.943677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>635.406125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>294.225686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.971919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_r2</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metric          Score\n",
       "0     MSE  403740.943677\n",
       "1    RMSE     635.406125\n",
       "2     MAE     294.225686\n",
       "3      r2       0.971919\n",
       "4  adj_r2       0.970300"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "MAE = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1500,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9618437005970384\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_predict)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    MAE = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    adj_r2 = 1-(1-r2) * (n-1)/(n-k-1)\n",
    "\n",
    "    results = [MSE, RMSE, MAE, r2, adj_r2]\n",
    "    metrics = ['MSE', 'RMSE', 'MAE', 'r2', 'adj_r2']\n",
    "\n",
    "    table_results = pd.DataFrame({'Metric': metrics, 'Score': results})\n",
    "    print(table_results)\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d8eb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: 0.9632266839141869\n",
      "   Metric          Score\n",
      "0     MSE  528717.454542\n",
      "1    RMSE     727.129600\n",
      "2     MAE     351.104524\n",
      "3      r2       0.963227\n",
      "4  adj_r2       0.961106\n",
      "Best Score: 0.9637101002000492\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: 0.9626237914173978\n",
      "   Metric          Score\n",
      "0     MSE  537385.690649\n",
      "1    RMSE     733.065952\n",
      "2     MAE     358.094246\n",
      "3      r2       0.962624\n",
      "4  adj_r2       0.960469\n",
      "Best Score: 0.9642980085489979\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: 0.9633086210077925\n",
      "   Metric          Score\n",
      "0     MSE  527539.383697\n",
      "1    RMSE     726.319065\n",
      "2     MAE     355.896198\n",
      "3      r2       0.963309\n",
      "4  adj_r2       0.961193\n",
      "Best Score: 0.9640338648800467\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: 0.962369208481718\n",
      "   Metric          Score\n",
      "0     MSE  541046.019824\n",
      "1    RMSE     735.558305\n",
      "2     MAE     360.641233\n",
      "3      r2       0.962369\n",
      "4  adj_r2       0.960199\n",
      "Best Score: 0.9635929805714774\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: 0.961869384872451\n",
      "   Metric          Score\n",
      "0     MSE  548232.357488\n",
      "1    RMSE     740.427145\n",
      "2     MAE     359.013098\n",
      "3      r2       0.961869\n",
      "4  adj_r2       0.959671\n",
      "Best Score: 0.962929091970628\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f2a68",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e5c0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSLE Loss\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90d00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss=tf.keras.losses.MeanSquaredLogarithmicError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3360072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 31.4842 - val_loss: 14.0972\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 11.2756 - val_loss: 10.0421\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 9.4023 - val_loss: 8.8101\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 8.5081 - val_loss: 8.1300\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 8.0180 - val_loss: 7.7419\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 7.6690 - val_loss: 7.3801\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 7.3622 - val_loss: 7.0733\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 6.7933 - val_loss: 5.8136\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 5.1832 - val_loss: 4.8116\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.5018 - val_loss: 4.2577\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.0493 - val_loss: 3.9451\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.8030 - val_loss: 3.7967\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.5912 - val_loss: 3.6667\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.4399 - val_loss: 3.4518\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.3039 - val_loss: 3.4137\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.1614 - val_loss: 3.2865\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 3.0069 - val_loss: 3.0928\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.9254 - val_loss: 3.0021\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.9152 - val_loss: 2.9076\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.7458 - val_loss: 2.8528\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.6759 - val_loss: 2.7872\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.6183 - val_loss: 2.8445\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.5656 - val_loss: 2.7024\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.5185 - val_loss: 2.6112\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.4741 - val_loss: 2.5826\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.4336 - val_loss: 2.5411\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3973 - val_loss: 2.5213\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3595 - val_loss: 2.4904\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.3150 - val_loss: 2.4306\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.2490 - val_loss: 2.3584\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.1647 - val_loss: 2.2970\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.1211 - val_loss: 2.2852\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0878 - val_loss: 2.3071\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0653 - val_loss: 2.2017\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0198 - val_loss: 2.1627\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2.0016 - val_loss: 2.1549\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9594 - val_loss: 2.1326\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9586 - val_loss: 2.0811\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9126 - val_loss: 2.0805\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.9035 - val_loss: 2.0319\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.8543 - val_loss: 2.0509\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.8361 - val_loss: 2.0083\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.8085 - val_loss: 1.9565\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.9389\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.9165\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7357 - val_loss: 1.8928\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.7139 - val_loss: 1.8671\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6864 - val_loss: 1.8258\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6627 - val_loss: 1.8100\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.6389 - val_loss: 1.7784\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5979 - val_loss: 1.7585\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5867 - val_loss: 1.7519\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.5534 - val_loss: 1.7135\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5315 - val_loss: 1.6945\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5076 - val_loss: 1.6624\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.5023 - val_loss: 1.6406\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4706 - val_loss: 1.6203\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.5997\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4591 - val_loss: 1.6014\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4158 - val_loss: 1.5616\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.5476\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3893 - val_loss: 1.5406\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.3740 - val_loss: 1.5067\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3714 - val_loss: 1.5520\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3565 - val_loss: 1.5669\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3429 - val_loss: 1.5167\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3200 - val_loss: 1.4263\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.3078 - val_loss: 1.4238\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2894 - val_loss: 1.4031\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2726 - val_loss: 1.3700\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2605 - val_loss: 1.4096\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2352 - val_loss: 1.3628\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.2133 - val_loss: 1.3449\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.2203 - val_loss: 1.3212\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1878 - val_loss: 1.2927\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1656 - val_loss: 1.2561\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1579 - val_loss: 1.2489\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1420 - val_loss: 1.2407\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1281 - val_loss: 1.2213\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1138 - val_loss: 1.2035\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 1.1035 - val_loss: 1.1919\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0861 - val_loss: 1.1857\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0980 - val_loss: 1.2232\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0873 - val_loss: 1.1798\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.1421\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0481 - val_loss: 1.1975\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0353 - val_loss: 1.1571\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0299 - val_loss: 1.1536\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0197 - val_loss: 1.1117\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0131 - val_loss: 1.0963\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1.0020 - val_loss: 1.0876\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9927 - val_loss: 1.0790\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9822 - val_loss: 1.0746\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9824 - val_loss: 1.0606\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9736 - val_loss: 1.1171\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9823 - val_loss: 1.0961\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9588 - val_loss: 1.0441\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 1.0599\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9393 - val_loss: 1.0568\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 1.0154\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db6a34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9394335150718689\n",
      "0.9566461443901062\n"
     ]
    }
   ],
   "source": [
    "train_msle = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_msle)\n",
    "test_msle = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63303d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1575.855"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_msle = classifier.predict(X_train)\n",
    "np.mean(train_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b3525a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1684.7773"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msle = classifier.predict(X_test)\n",
    "np.mean(test_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd42a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Squared Logarithmic Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493421fd",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81fe71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE Loss\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29981592",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62433ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2126.3147 - mean_absolute_error: 2124.0818 - val_loss: 2289.1736 - val_mean_absolute_error: 2289.0913\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2041.2072 - mean_absolute_error: 2037.8020 - val_loss: 2105.3357 - val_mean_absolute_error: 2098.4893\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1908.8909 - mean_absolute_error: 1899.5818 - val_loss: 1962.9088 - val_mean_absolute_error: 1949.7023\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1435.6370 - mean_absolute_error: 1416.6802 - val_loss: 1094.8781 - val_mean_absolute_error: 1070.5034\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 897.4827 - mean_absolute_error: 872.4106 - val_loss: 983.0945 - val_mean_absolute_error: 957.8059\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 835.9782 - mean_absolute_error: 810.6457 - val_loss: 946.1695 - val_mean_absolute_error: 920.6973\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 801.8513 - mean_absolute_error: 776.5445 - val_loss: 915.3395 - val_mean_absolute_error: 889.9505\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 768.1614 - mean_absolute_error: 742.7496 - val_loss: 885.0793 - val_mean_absolute_error: 859.7619\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 742.1165 - mean_absolute_error: 716.6484 - val_loss: 864.2316 - val_mean_absolute_error: 838.7606\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 718.5683 - mean_absolute_error: 693.0696 - val_loss: 843.5292 - val_mean_absolute_error: 817.8881\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 706.0325 - mean_absolute_error: 680.3130 - val_loss: 827.4246 - val_mean_absolute_error: 801.8895\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 688.3947 - mean_absolute_error: 662.6596 - val_loss: 820.1432 - val_mean_absolute_error: 794.5195\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 673.0068 - mean_absolute_error: 647.2512 - val_loss: 813.8565 - val_mean_absolute_error: 787.8702\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 664.8401 - mean_absolute_error: 638.9252 - val_loss: 793.3909 - val_mean_absolute_error: 767.2344\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 651.9975 - mean_absolute_error: 625.9636 - val_loss: 773.3257 - val_mean_absolute_error: 747.3052\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 643.8207 - mean_absolute_error: 617.7173 - val_loss: 759.3922 - val_mean_absolute_error: 733.3307\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 627.5123 - mean_absolute_error: 601.3384 - val_loss: 753.0876 - val_mean_absolute_error: 726.9410\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 619.2640 - mean_absolute_error: 592.9838 - val_loss: 754.1174 - val_mean_absolute_error: 727.6131\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 603.6086 - mean_absolute_error: 577.1879 - val_loss: 725.0338 - val_mean_absolute_error: 698.7266\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 594.6434 - mean_absolute_error: 568.1545 - val_loss: 719.2050 - val_mean_absolute_error: 692.6694\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 581.9611 - mean_absolute_error: 555.4324 - val_loss: 713.5228 - val_mean_absolute_error: 686.9250\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 574.4297 - mean_absolute_error: 547.8138 - val_loss: 696.7375 - val_mean_absolute_error: 670.1370\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 569.2962 - mean_absolute_error: 542.7188 - val_loss: 695.6867 - val_mean_absolute_error: 669.1967\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 560.1509 - mean_absolute_error: 533.4929 - val_loss: 676.0221 - val_mean_absolute_error: 649.5025\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 552.0962 - mean_absolute_error: 525.4210 - val_loss: 690.5440 - val_mean_absolute_error: 663.7323\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 549.8569 - mean_absolute_error: 523.1105 - val_loss: 670.7776 - val_mean_absolute_error: 644.0098\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 534.5224 - mean_absolute_error: 507.8701 - val_loss: 666.7653 - val_mean_absolute_error: 640.0070\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 528.8616 - mean_absolute_error: 502.2094 - val_loss: 653.8138 - val_mean_absolute_error: 626.9644\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 523.4412 - mean_absolute_error: 496.7918 - val_loss: 670.9562 - val_mean_absolute_error: 644.1083\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 513.3607 - mean_absolute_error: 486.7130 - val_loss: 632.3380 - val_mean_absolute_error: 605.8110\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 515.1849 - mean_absolute_error: 488.5943 - val_loss: 626.3748 - val_mean_absolute_error: 599.7600\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 513.5683 - mean_absolute_error: 486.9783 - val_loss: 629.8115 - val_mean_absolute_error: 603.1940\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.4165 - mean_absolute_error: 473.9172 - val_loss: 615.5168 - val_mean_absolute_error: 589.0175\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 498.3971 - mean_absolute_error: 471.9140 - val_loss: 615.8057 - val_mean_absolute_error: 589.2650\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 493.1160 - mean_absolute_error: 466.6481 - val_loss: 607.7503 - val_mean_absolute_error: 581.2950\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 494.8444 - mean_absolute_error: 468.4391 - val_loss: 620.6962 - val_mean_absolute_error: 594.3005\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 488.0110 - mean_absolute_error: 461.6414 - val_loss: 600.9825 - val_mean_absolute_error: 574.7758\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 483.7426 - mean_absolute_error: 457.4416 - val_loss: 600.4528 - val_mean_absolute_error: 574.1315\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 478.2813 - mean_absolute_error: 452.0246 - val_loss: 590.1928 - val_mean_absolute_error: 563.9106\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 484.2725 - mean_absolute_error: 458.0567 - val_loss: 584.9672 - val_mean_absolute_error: 558.7507\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 479.4746 - mean_absolute_error: 453.3199 - val_loss: 605.6440 - val_mean_absolute_error: 579.3997\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 473.4608 - mean_absolute_error: 447.3094 - val_loss: 587.2988 - val_mean_absolute_error: 561.0656\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 468.1768 - mean_absolute_error: 442.0406 - val_loss: 573.8484 - val_mean_absolute_error: 547.7972\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.3333 - mean_absolute_error: 439.2837 - val_loss: 573.0131 - val_mean_absolute_error: 546.9662\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.5250 - mean_absolute_error: 445.5474 - val_loss: 567.6307 - val_mean_absolute_error: 541.7632\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.3274 - mean_absolute_error: 439.4305 - val_loss: 567.0016 - val_mean_absolute_error: 541.1518\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 455.6785 - mean_absolute_error: 429.8344 - val_loss: 568.6342 - val_mean_absolute_error: 542.7800\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 2ms/step - loss: 453.8411 - mean_absolute_error: 428.0898 - val_loss: 565.9889 - val_mean_absolute_error: 540.2172\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 450.2781 - mean_absolute_error: 424.5676 - val_loss: 562.5457 - val_mean_absolute_error: 536.8486\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 456.2068 - mean_absolute_error: 430.5749 - val_loss: 552.1459 - val_mean_absolute_error: 526.6281\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 444.4120 - mean_absolute_error: 418.8492 - val_loss: 550.3884 - val_mean_absolute_error: 524.8748\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 443.3136 - mean_absolute_error: 417.8264 - val_loss: 549.5904 - val_mean_absolute_error: 524.2315\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 443.6864 - mean_absolute_error: 418.2696 - val_loss: 545.7551 - val_mean_absolute_error: 520.3244\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.2217 - mean_absolute_error: 410.8647 - val_loss: 556.2736 - val_mean_absolute_error: 530.8325\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 438.1918 - mean_absolute_error: 412.8619 - val_loss: 540.6622 - val_mean_absolute_error: 515.4171\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.9523 - mean_absolute_error: 411.7219 - val_loss: 538.5641 - val_mean_absolute_error: 513.3461\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 433.1453 - mean_absolute_error: 407.9228 - val_loss: 533.7336 - val_mean_absolute_error: 508.5635\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 433.1287 - mean_absolute_error: 407.9886 - val_loss: 539.0222 - val_mean_absolute_error: 513.8260\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.4995 - mean_absolute_error: 405.4096 - val_loss: 533.7788 - val_mean_absolute_error: 508.7917\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 425.2516 - mean_absolute_error: 400.2549 - val_loss: 529.6874 - val_mean_absolute_error: 504.7283\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 428.1543 - mean_absolute_error: 403.2272 - val_loss: 544.7616 - val_mean_absolute_error: 519.8972\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 432.2345 - mean_absolute_error: 407.3451 - val_loss: 542.2622 - val_mean_absolute_error: 517.2574\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 423.8169 - mean_absolute_error: 398.9626 - val_loss: 526.1450 - val_mean_absolute_error: 501.3478\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 419.1888 - mean_absolute_error: 394.3799 - val_loss: 519.6613 - val_mean_absolute_error: 494.9128\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 416.9436 - mean_absolute_error: 392.2012 - val_loss: 517.8876 - val_mean_absolute_error: 493.2125\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 414.6971 - mean_absolute_error: 389.9509 - val_loss: 514.5770 - val_mean_absolute_error: 489.9396\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 413.8024 - mean_absolute_error: 389.1819 - val_loss: 521.1113 - val_mean_absolute_error: 496.5042\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.9853 - mean_absolute_error: 391.4035 - val_loss: 556.5270 - val_mean_absolute_error: 531.8892\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 414.0644 - mean_absolute_error: 389.5633 - val_loss: 514.8427 - val_mean_absolute_error: 490.3747\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.5777 - mean_absolute_error: 391.1610 - val_loss: 512.4437 - val_mean_absolute_error: 488.0817\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 408.8119 - mean_absolute_error: 384.4299 - val_loss: 504.8944 - val_mean_absolute_error: 480.5509\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 403.2497 - mean_absolute_error: 378.8588 - val_loss: 506.5705 - val_mean_absolute_error: 482.1863\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 406.7741 - mean_absolute_error: 382.4833 - val_loss: 512.3675 - val_mean_absolute_error: 488.0343\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 402.4904 - mean_absolute_error: 378.2582 - val_loss: 505.9619 - val_mean_absolute_error: 481.6938\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 404.2553 - mean_absolute_error: 380.0209 - val_loss: 512.8680 - val_mean_absolute_error: 488.7199\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 401.3637 - mean_absolute_error: 377.2072 - val_loss: 500.2422 - val_mean_absolute_error: 476.0710\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 395.6831 - mean_absolute_error: 371.5547 - val_loss: 505.3906 - val_mean_absolute_error: 481.3626\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 397.9062 - mean_absolute_error: 373.8489 - val_loss: 512.6586 - val_mean_absolute_error: 488.6048\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 399.6934 - mean_absolute_error: 375.7076 - val_loss: 492.2937 - val_mean_absolute_error: 468.3971\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 394.2257 - mean_absolute_error: 370.3351 - val_loss: 492.7788 - val_mean_absolute_error: 468.8575\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 396.9963 - mean_absolute_error: 373.1041 - val_loss: 498.6931 - val_mean_absolute_error: 474.7882\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 394.0147 - mean_absolute_error: 370.2066 - val_loss: 498.6236 - val_mean_absolute_error: 474.7477\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 388.4493 - mean_absolute_error: 364.6597 - val_loss: 492.9022 - val_mean_absolute_error: 469.1089\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 390.3887 - mean_absolute_error: 366.6632 - val_loss: 486.8509 - val_mean_absolute_error: 463.1484\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 391.3399 - mean_absolute_error: 367.6402 - val_loss: 484.6969 - val_mean_absolute_error: 461.0686\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 390.4789 - mean_absolute_error: 366.8175 - val_loss: 496.3601 - val_mean_absolute_error: 472.6629\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 389.8102 - mean_absolute_error: 366.1978 - val_loss: 486.0941 - val_mean_absolute_error: 462.4935\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 383.5247 - mean_absolute_error: 359.8946 - val_loss: 484.2190 - val_mean_absolute_error: 460.6732\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 379.4956 - mean_absolute_error: 355.9258 - val_loss: 478.3966 - val_mean_absolute_error: 454.8031\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 386.4598 - mean_absolute_error: 362.9766 - val_loss: 520.7063 - val_mean_absolute_error: 497.2690\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 383.9810 - mean_absolute_error: 360.5054 - val_loss: 481.5314 - val_mean_absolute_error: 458.0097\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 381.5352 - mean_absolute_error: 358.0981 - val_loss: 486.5204 - val_mean_absolute_error: 463.0036\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 380.1187 - mean_absolute_error: 356.6667 - val_loss: 478.7078 - val_mean_absolute_error: 455.2061\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 375.9383 - mean_absolute_error: 352.5318 - val_loss: 473.4045 - val_mean_absolute_error: 450.0412\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 376.1767 - mean_absolute_error: 352.8293 - val_loss: 475.3073 - val_mean_absolute_error: 452.0343\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 376.7952 - mean_absolute_error: 353.4667 - val_loss: 475.0511 - val_mean_absolute_error: 451.7920\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 370.8263 - mean_absolute_error: 347.5347 - val_loss: 496.4075 - val_mean_absolute_error: 473.0279\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 373.0316 - mean_absolute_error: 349.7356 - val_loss: 466.5620 - val_mean_absolute_error: 443.3293\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 369.7128 - mean_absolute_error: 346.4657 - val_loss: 469.9373 - val_mean_absolute_error: 446.6839\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 372.5624 - mean_absolute_error: 349.3264 - val_loss: 464.6623 - val_mean_absolute_error: 441.4115\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97fe9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2166.726318359375, 2157.2900390625]\n",
      "[2488.070068359375, 2478.63330078125]\n"
     ]
    }
   ],
   "source": [
    "train_mae = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_mae)\n",
    "test_mae = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603f79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "[[-2.49608245e-04]\n",
      " [-6.79282603e-05]\n",
      " [-2.16549597e-04]\n",
      " [-8.20213754e-05]\n",
      " [-5.92568540e-05]\n",
      " [-8.84667825e-05]\n",
      " [-1.48783220e-04]\n",
      " [-1.14182818e-04]\n",
      " [-1.31815556e-04]\n",
      " [-4.68414219e-05]\n",
      " [-1.68615574e-04]\n",
      " [-9.39602833e-05]\n",
      " [-3.28033639e-04]\n",
      " [-1.64324738e-04]\n",
      " [-8.78180945e-05]\n",
      " [-6.35983452e-05]\n",
      " [-4.15006652e-05]\n",
      " [-1.80126677e-04]\n",
      " [-1.87249767e-04]\n",
      " [-1.05664651e-04]\n",
      " [-1.39492884e-04]\n",
      " [-1.51426051e-04]\n",
      " [-1.10784284e-04]\n",
      " [-2.28084449e-04]\n",
      " [-4.47766797e-05]\n",
      " [ 1.24237704e-05]\n",
      " [-2.23242154e-04]\n",
      " [-9.49245659e-05]\n",
      " [-1.59424264e-04]\n",
      " [-1.03123253e-04]\n",
      " [-1.25245424e-04]\n",
      " [-2.24962452e-04]\n",
      " [-1.32380359e-04]\n",
      " [-6.81619567e-05]\n",
      " [-1.78127506e-04]\n",
      " [-8.24568124e-05]\n",
      " [-1.93676999e-04]\n",
      " [-2.77944084e-04]\n",
      " [-2.24293894e-04]\n",
      " [-2.22178074e-04]\n",
      " [-1.67101534e-04]\n",
      " [-2.67167197e-05]\n",
      " [-3.88691551e-05]\n",
      " [-2.55159306e-04]\n",
      " [-1.45763101e-04]\n",
      " [-1.21568344e-04]\n",
      " [-1.18262236e-04]\n",
      " [-1.60213895e-04]\n",
      " [-1.67127873e-04]\n",
      " [-1.12906011e-04]\n",
      " [-1.96864130e-04]\n",
      " [-2.14644868e-04]\n",
      " [-2.13657768e-05]\n",
      " [-1.67013364e-04]\n",
      " [-2.79066560e-04]\n",
      " [-9.67193555e-05]\n",
      " [-5.29895187e-05]\n",
      " [-2.89679883e-04]\n",
      " [-3.34584562e-04]\n",
      " [-2.44903349e-05]\n",
      " [-2.52494821e-04]\n",
      " [-6.46749104e-05]\n",
      " [-6.61836748e-05]\n",
      " [-1.13894537e-04]\n",
      " [-6.42030500e-05]\n",
      " [-2.76855135e-05]\n",
      " [-3.35092976e-04]\n",
      " [-1.45090497e-04]\n",
      " [-4.89668455e-05]\n",
      " [-1.13030037e-04]\n",
      " [-6.98300282e-05]\n",
      " [-1.88926293e-04]\n",
      " [-8.45600589e-05]\n",
      " [-1.65769976e-04]\n",
      " [-1.64087251e-04]\n",
      " [-1.87106052e-04]\n",
      " [-3.55087628e-04]\n",
      " [-2.35911197e-04]\n",
      " [-3.06642760e-05]\n",
      " [-1.39083786e-04]\n",
      " [-1.29078719e-04]\n",
      " [-1.20272038e-04]\n",
      " [-2.52968806e-04]\n",
      " [-1.60748183e-04]\n",
      " [-2.77020357e-04]\n",
      " [-4.64670826e-04]\n",
      " [ 2.04953176e-04]\n",
      " [-6.43048916e-05]\n",
      " [-2.01726347e-04]\n",
      " [-7.32610351e-05]\n",
      " [-2.64519796e-04]\n",
      " [-1.79014605e-04]\n",
      " [-8.88913055e-05]\n",
      " [-9.45933425e-05]\n",
      " [-2.78935564e-04]\n",
      " [-1.04388368e-04]\n",
      " [-2.13118969e-04]\n",
      " [-2.29052253e-04]\n",
      " [-1.56548718e-04]\n",
      " [-8.45033064e-05]\n",
      " [-1.33440626e-05]\n",
      " [-2.24757066e-04]\n",
      " [-9.77315212e-05]\n",
      " [-1.13601418e-04]\n",
      " [-1.37157680e-04]\n",
      " [-1.32299319e-05]\n",
      " [-2.57641834e-04]\n",
      " [-1.10966212e-04]\n",
      " [-1.31170003e-04]\n",
      " [ 1.04116421e-04]\n",
      " [-4.38800431e-04]\n",
      " [ 5.76240127e-05]\n",
      " [-1.65804508e-04]\n",
      " [-1.85073048e-04]\n",
      " [-2.36073465e-04]\n",
      " [-9.92866699e-05]\n",
      " [-1.06472813e-04]\n",
      " [-1.50294567e-04]\n",
      " [-1.15267336e-04]\n",
      " [-8.28089687e-05]\n",
      " [-1.93396147e-04]\n",
      " [-4.74362751e-05]\n",
      " [-2.26518663e-04]\n",
      " [-1.30520450e-04]\n",
      " [-1.63935474e-05]\n",
      " [-6.18165504e-05]\n",
      " [ 1.18401163e-04]\n",
      " [-7.25880673e-05]\n",
      " [-1.76500893e-04]\n",
      " [-3.05287424e-04]\n",
      " [-2.75723345e-04]\n",
      " [ 4.92032268e-06]\n",
      " [-1.52983645e-04]\n",
      " [-2.67220283e-04]\n",
      " [-2.02038820e-04]\n",
      " [ 2.43130780e-04]\n",
      " [-7.38812669e-05]\n",
      " [-1.70986430e-04]\n",
      " [-8.83638204e-05]\n",
      " [-2.04853888e-04]\n",
      " [-1.78912625e-04]\n",
      " [ 3.03213950e-04]\n",
      " [-1.88496488e-04]\n",
      " [-1.01361395e-04]\n",
      " [-2.28906167e-04]\n",
      " [-1.29765074e-04]\n",
      " [-8.66401242e-05]\n",
      " [-3.58160614e-05]\n",
      " [-2.56725005e-04]\n",
      " [-1.42453922e-04]\n",
      " [-1.73869630e-05]\n",
      " [-2.26087184e-04]\n",
      " [-1.30199143e-04]\n",
      " [-2.73691374e-04]\n",
      " [-2.41866685e-04]\n",
      " [ 7.12871406e-05]\n",
      " [-7.45348952e-05]\n",
      " [-1.64896206e-04]\n",
      " [-1.39159340e-04]\n",
      " [-6.83839316e-05]\n",
      " [-7.94353837e-05]\n",
      " [ 9.53138224e-05]\n",
      " [-8.41211004e-05]\n",
      " [-1.14919443e-04]\n",
      " [-1.39674303e-04]\n",
      " [-2.48481811e-04]\n",
      " [-1.76828413e-04]\n",
      " [-2.00052556e-04]\n",
      " [-2.70938908e-04]\n",
      " [-2.35586253e-04]\n",
      " [-2.56211672e-04]\n",
      " [-2.13519146e-04]\n",
      " [-2.21495866e-04]\n",
      " [-1.65342470e-04]\n",
      " [-1.82524469e-04]\n",
      " [-4.03458253e-05]\n",
      " [-1.96686684e-04]\n",
      " [-3.08348826e-05]\n",
      " [-2.73050769e-04]\n",
      " [ 8.25380266e-06]\n",
      " [-1.06363877e-05]\n",
      " [-1.17765187e-04]\n",
      " [-6.66196283e-05]\n",
      " [-1.99641654e-04]\n",
      " [-8.24438903e-05]\n",
      " [-2.23876268e-04]\n",
      " [-2.11470964e-04]\n",
      " [ 1.23740319e-05]\n",
      " [-3.22269625e-05]\n",
      " [-3.39853286e-04]\n",
      " [-1.84884688e-04]\n",
      " [-1.59991701e-04]\n",
      " [-8.46851472e-05]\n",
      " [-1.89084312e-04]\n",
      " [-2.20893140e-04]\n",
      " [-7.14519701e-05]\n",
      " [-7.67233432e-05]\n",
      " [-1.75086723e-04]\n",
      " [-1.31875699e-04]\n",
      " [-4.25784965e-05]\n",
      " [-1.30022687e-04]\n",
      " [-1.16742624e-04]\n",
      " [-8.19727647e-05]\n",
      " [-2.80219479e-04]\n",
      " [-2.27734155e-04]\n",
      " [-6.46914996e-05]\n",
      " [-7.98397814e-05]\n",
      " [-3.62849620e-04]\n",
      " [-1.51028828e-04]\n",
      " [-1.37713359e-04]\n",
      " [-1.38256655e-04]\n",
      " [-1.88554797e-04]\n",
      " [-7.83660507e-05]\n",
      " [-1.44766353e-04]\n",
      " [ 3.37545935e-05]\n",
      " [-2.58143991e-05]\n",
      " [-1.47405663e-04]\n",
      " [-1.24596467e-04]\n",
      " [-1.55388407e-04]\n",
      " [-4.08092747e-05]\n",
      " [-1.70294836e-04]\n",
      " [-1.74635061e-04]\n",
      " [-6.45137043e-05]\n",
      " [-1.62811964e-04]\n",
      " [-1.70514424e-04]\n",
      " [-4.84748889e-04]\n",
      " [-1.81266529e-04]\n",
      " [-1.17212592e-04]\n",
      " [-7.57748203e-05]\n",
      " [-1.01977312e-04]\n",
      " [-1.95308763e-04]\n",
      " [-1.54834910e-04]\n",
      " [-1.49490836e-04]\n",
      " [-1.68471335e-04]\n",
      " [-9.37802906e-05]\n",
      " [-6.90669112e-05]\n",
      " [-3.61777114e-04]\n",
      " [-3.41441046e-05]\n",
      " [-1.01891550e-04]\n",
      " [-2.20111455e-04]\n",
      " [-1.48345862e-04]\n",
      " [-1.63093195e-04]\n",
      " [ 3.85702588e-05]\n",
      " [-1.38951349e-04]\n",
      " [-2.06988858e-04]\n",
      " [-1.27703097e-04]\n",
      " [-1.17352873e-04]\n",
      " [-1.35532580e-04]\n",
      " [-1.14895098e-04]\n",
      " [-4.83304466e-05]\n",
      " [-1.42479053e-04]\n",
      " [-1.57505579e-04]\n",
      " [-1.06725551e-04]\n",
      " [ 1.06062420e-04]\n",
      " [-1.62020733e-04]\n",
      " [-1.23523350e-05]\n",
      " [-3.25409288e-04]\n",
      " [-8.37570406e-06]\n",
      " [-7.22809200e-05]\n",
      " [-3.50489630e-04]\n",
      " [-4.07690881e-04]\n",
      " [-3.08375922e-04]\n",
      " [-2.66145886e-04]\n",
      " [-2.14562926e-04]\n",
      " [ 1.88462756e-04]\n",
      " [-1.24556231e-04]\n",
      " [-1.71317253e-04]\n",
      " [-1.32831599e-04]\n",
      " [-6.90481174e-05]\n",
      " [-4.92225518e-05]\n",
      " [-2.17289708e-04]\n",
      " [-1.72196058e-04]\n",
      " [-8.78936553e-05]\n",
      " [-3.79483681e-05]\n",
      " [-1.25621926e-04]\n",
      " [-2.31620623e-04]\n",
      " [-1.26877567e-04]\n",
      " [-6.89426815e-05]\n",
      " [-3.22241278e-04]\n",
      " [-2.55044783e-04]\n",
      " [-1.33299327e-05]\n",
      " [-1.52548339e-04]\n",
      " [-6.18345803e-05]\n",
      " [-1.30471482e-04]\n",
      " [-8.15198873e-05]\n",
      " [-2.21117443e-04]\n",
      " [-7.86849996e-05]\n",
      " [-1.49395753e-04]\n",
      " [-2.84845300e-04]\n",
      " [-2.99093721e-04]\n",
      " [-3.45001026e-05]\n",
      " [-2.07101752e-04]\n",
      " [-1.32794026e-04]\n",
      " [-4.82148025e-05]\n",
      " [-6.35786564e-05]\n",
      " [-3.48637986e-05]\n",
      " [-1.56448048e-04]\n",
      " [-2.60756671e-04]\n",
      " [-1.09486966e-04]\n",
      " [-7.69617764e-05]\n",
      " [-2.56975589e-04]\n",
      " [-2.37877466e-04]\n",
      " [-1.82883159e-04]\n",
      " [ 1.11682035e-04]\n",
      " [-3.95899988e-05]\n",
      " [-1.03204802e-04]\n",
      " [ 6.80712546e-05]\n",
      " [-2.36267893e-04]\n",
      " [-1.87288839e-04]\n",
      " [-5.86966198e-05]\n",
      " [-1.50107691e-04]\n",
      " [-1.30088665e-04]\n",
      " [-1.69476567e-04]\n",
      " [-1.63981298e-04]\n",
      " [-1.39705997e-04]\n",
      " [-2.73843965e-04]\n",
      " [ 1.54913389e-04]\n",
      " [-1.35227892e-04]\n",
      " [-1.24381011e-04]\n",
      " [-1.83339522e-04]\n",
      " [-1.30364977e-04]\n",
      " [-8.51897057e-05]\n",
      " [-2.82716966e-04]\n",
      " [-3.03763722e-04]\n",
      " [-2.29569239e-04]\n",
      " [ 9.10135277e-05]\n",
      " [-1.82355405e-04]\n",
      " [-1.99672955e-04]\n",
      " [-3.46569141e-05]\n",
      " [-2.16117507e-04]\n",
      " [-9.84713261e-05]\n",
      " [-3.07863287e-04]\n",
      " [-1.41351833e-04]\n",
      " [-1.43728335e-04]\n",
      " [-1.17612319e-04]\n",
      " [-3.90013010e-05]\n",
      " [-6.40775397e-05]\n",
      " [-1.34265923e-04]\n",
      " [-1.45248952e-04]\n",
      " [-2.11617575e-04]\n",
      " [-5.68598480e-05]\n",
      " [-1.18777025e-04]\n",
      " [-3.93312512e-04]\n",
      " [-7.09950109e-05]\n",
      " [-1.63558288e-04]\n",
      " [-2.82856199e-05]\n",
      " [-1.58486757e-04]\n",
      " [-1.87826867e-04]\n",
      " [-1.25925420e-04]\n",
      " [-1.12637426e-04]\n",
      " [-9.29066300e-05]\n",
      " [-1.36286471e-04]\n",
      " [-2.14471700e-04]\n",
      " [-1.72008207e-04]\n",
      " [-7.47123704e-05]\n",
      " [-2.40505542e-04]\n",
      " [-2.09025107e-04]\n",
      " [-1.14487309e-04]\n",
      " [ 8.11973878e-05]\n",
      " [-1.34116126e-04]\n",
      " [-6.53960160e-05]\n",
      " [-5.76783495e-05]\n",
      " [-1.69299048e-04]\n",
      " [-8.00147027e-05]\n",
      " [-3.76806216e-04]\n",
      " [-1.44381833e-04]\n",
      " [-1.60416123e-04]\n",
      " [-7.58422539e-05]\n",
      " [-1.89308659e-04]\n",
      " [-1.79652066e-04]\n",
      " [-1.43567362e-04]\n",
      " [-2.76523759e-04]\n",
      " [-1.84070930e-04]\n",
      " [-3.48287285e-05]\n",
      " [-1.85150217e-04]\n",
      " [-1.67589111e-04]\n",
      " [ 1.92882188e-04]\n",
      " [-2.25951662e-05]\n",
      " [-1.83775133e-04]\n",
      " [-1.26096420e-04]\n",
      " [-1.71103427e-04]\n",
      " [-1.81491618e-04]\n",
      " [-9.03902692e-05]\n",
      " [-1.43845566e-04]\n",
      " [-1.52973749e-04]\n",
      " [-1.23174948e-04]\n",
      " [-1.37514682e-04]\n",
      " [-3.07248905e-04]\n",
      " [ 1.81680924e-04]\n",
      " [-1.76158530e-04]\n",
      " [-4.62153694e-05]\n",
      " [-2.12723782e-04]\n",
      " [-1.33258509e-04]\n",
      " [-2.32557359e-04]\n",
      " [-1.16914220e-04]\n",
      " [-9.98708565e-05]\n",
      " [-3.08492279e-04]\n",
      " [-3.16476420e-04]\n",
      " [-1.80334042e-04]\n",
      " [-2.14661486e-04]\n",
      " [ 2.02747469e-05]\n",
      " [-2.52801197e-04]\n",
      " [-1.79874623e-04]\n",
      " [-9.54949646e-05]\n",
      " [-1.59055664e-04]\n",
      " [-2.52802158e-04]\n",
      " [-1.63577846e-04]\n",
      " [-8.85614427e-05]\n",
      " [-3.74244642e-04]\n",
      " [-1.12627007e-04]\n",
      " [-1.62862139e-04]\n",
      " [-1.72277665e-04]\n",
      " [-1.36025148e-04]\n",
      " [-2.06014520e-04]\n",
      " [-6.73293689e-05]\n",
      " [-3.72926879e-05]\n",
      " [-1.01345664e-04]\n",
      " [-1.68385319e-04]\n",
      " [-1.56398717e-04]\n",
      " [-1.40445336e-04]\n",
      " [-2.53286795e-04]\n",
      " [-3.17851896e-04]\n",
      " [-2.29802623e-04]\n",
      " [-2.41763497e-04]\n",
      " [-9.75017610e-05]\n",
      " [-1.12760390e-04]\n",
      " [-9.27504589e-05]\n",
      " [-8.20197456e-05]\n",
      " [-1.73046690e-04]\n",
      " [-1.19540055e-05]\n",
      " [-9.06390633e-05]\n",
      " [-1.65677237e-04]\n",
      " [-2.52158672e-04]\n",
      " [-8.57771520e-05]\n",
      " [-2.64676783e-04]\n",
      " [-1.56025490e-05]\n",
      " [-1.75471359e-04]\n",
      " [ 2.26789809e-04]\n",
      " [-2.61529931e-04]\n",
      " [-3.07540176e-04]\n",
      " [-9.49081586e-05]\n",
      " [-1.67384715e-05]\n",
      " [-1.04025268e-04]\n",
      " [-2.07530640e-04]\n",
      " [-1.68136641e-04]\n",
      " [-1.00222169e-04]\n",
      " [-1.67867751e-04]\n",
      " [-1.33153779e-04]\n",
      " [-9.78966709e-05]\n",
      " [-7.88764737e-05]\n",
      " [-4.61769523e-05]\n",
      " [-3.90125118e-04]\n",
      " [ 2.14216852e-04]\n",
      " [-1.22307829e-04]\n",
      " [-4.46621852e-05]\n",
      " [-2.21898372e-04]\n",
      " [ 3.01565306e-05]\n",
      " [-1.45540835e-04]\n",
      " [-2.34557214e-04]\n",
      " [-1.03618615e-04]\n",
      " [-6.12866424e-05]\n",
      " [-2.00317038e-04]\n",
      " [-1.47431143e-04]\n",
      " [-2.06427183e-04]\n",
      " [-2.32046717e-04]\n",
      " [-1.14869617e-05]\n",
      " [-1.64054916e-04]\n",
      " [-1.11780828e-04]\n",
      " [-6.67137065e-05]\n",
      " [-3.67471366e-05]\n",
      " [-1.90781459e-04]\n",
      " [-3.51172930e-04]\n",
      " [-1.24306534e-04]\n",
      " [-2.72626727e-04]\n",
      " [ 5.09694510e-05]\n",
      " [-4.99261660e-05]\n",
      " [-2.60728266e-05]\n",
      " [-1.46835810e-04]\n",
      " [-2.32320075e-04]\n",
      " [-1.88405043e-04]\n",
      " [ 1.36072747e-04]\n",
      " [-2.33031911e-04]\n",
      " [-1.94595486e-04]\n",
      " [-1.11273890e-04]\n",
      " [-8.05870804e-05]\n",
      " [-2.19981826e-04]\n",
      " [-1.24290527e-04]\n",
      " [-2.43974500e-05]\n",
      " [-1.20143595e-04]\n",
      " [-1.20144352e-04]\n",
      " [-2.07103207e-04]\n",
      " [-1.47530300e-04]\n",
      " [-1.56358830e-04]\n",
      " [-9.29891248e-05]\n",
      " [-9.61792466e-05]\n",
      " [-2.67496129e-04]\n",
      " [-2.38545617e-04]\n",
      " [-2.24660937e-04]\n",
      " [-6.96143543e-05]\n",
      " [-4.81691241e-05]\n",
      " [-1.57515111e-04]\n",
      " [-5.21380280e-05]\n",
      " [-8.38333799e-05]\n",
      " [-1.61919248e-04]\n",
      " [-2.08195444e-04]\n",
      " [-1.51007407e-05]\n",
      " [-1.75210895e-04]\n",
      " [-5.41899644e-05]\n",
      " [-1.38281233e-04]\n",
      " [-1.54308174e-04]\n",
      " [-1.19049801e-04]\n",
      " [-1.45602316e-04]\n",
      " [-1.48794410e-04]\n",
      " [-1.31336245e-04]\n",
      " [-6.02858781e-05]\n",
      " [-1.83636846e-04]\n",
      " [-2.58346699e-04]\n",
      " [-1.21353922e-04]\n",
      " [-1.96887326e-04]\n",
      " [-1.76659611e-04]\n",
      " [-3.01264314e-04]\n",
      " [-1.50714171e-04]\n",
      " [-2.99623585e-04]\n",
      " [-4.30532120e-04]\n",
      " [-1.18702555e-04]\n",
      " [-1.14304989e-04]\n",
      " [-9.91975830e-05]\n",
      " [-2.17354536e-05]\n",
      " [-8.83474422e-05]\n",
      " [-2.06738026e-04]\n",
      " [-2.96946557e-04]\n",
      " [-1.05908963e-04]\n",
      " [-1.59685573e-04]\n",
      " [-9.28123918e-05]\n",
      " [-4.68088547e-05]\n",
      " [-1.58374314e-06]\n",
      " [-3.16510588e-04]\n",
      " [-1.03806364e-04]\n",
      " [-5.70000411e-05]\n",
      " [-1.41737735e-04]\n",
      " [-3.05185677e-04]\n",
      " [-8.14263767e-05]\n",
      " [-4.13825124e-04]\n",
      " [-2.65264825e-04]\n",
      " [-5.81228232e-05]\n",
      " [-6.86059939e-05]\n",
      " [-2.15329492e-04]\n",
      " [-1.82588949e-04]\n",
      " [-2.03868956e-04]\n",
      " [-9.67439555e-05]\n",
      " [-1.61185832e-04]\n",
      " [-7.57524831e-05]\n",
      " [-1.58725481e-04]\n",
      " [-4.13411180e-06]\n",
      " [-1.55324611e-04]\n",
      " [-1.57785267e-04]\n",
      " [-1.74007437e-05]\n",
      " [-2.62320886e-04]\n",
      " [-2.70805380e-04]\n",
      " [-1.46646446e-04]\n",
      " [-2.32636725e-04]\n",
      " [-1.41184806e-04]\n",
      " [-3.36412981e-04]\n",
      " [ 2.05135439e-06]\n",
      " [-2.17613924e-04]\n",
      " [ 6.69022265e-05]\n",
      " [-1.45469836e-04]\n",
      " [-1.47012863e-04]\n",
      " [-3.39133403e-05]\n",
      " [-5.77830651e-05]\n",
      " [-9.78483295e-05]\n",
      " [-1.25457562e-04]\n",
      " [-1.73769935e-04]\n",
      " [-5.81239437e-05]\n",
      " [-1.49289626e-04]\n",
      " [-5.19694877e-05]\n",
      " [-1.32202025e-04]\n",
      " [ 2.26497068e-05]\n",
      " [-7.63876160e-05]\n",
      " [-3.45611334e-05]\n",
      " [-2.34354680e-04]\n",
      " [-6.24344975e-05]\n",
      " [-1.40164091e-04]\n",
      " [-1.50803724e-04]\n",
      " [-2.76674167e-04]\n",
      " [-1.70834886e-04]\n",
      " [-7.85513912e-05]\n",
      " [-1.50130174e-04]\n",
      " [-2.63882976e-04]\n",
      " [ 3.39686812e-06]\n",
      " [-1.33605194e-04]\n",
      " [-1.19913399e-04]\n",
      " [-1.34116446e-04]\n",
      " [-1.80632269e-04]\n",
      " [-7.89204641e-05]\n",
      " [-5.63933427e-05]\n",
      " [-3.63274303e-05]\n",
      " [-2.38795372e-04]\n",
      " [-2.42199952e-04]\n",
      " [ 8.17916007e-05]\n",
      " [-6.60926380e-05]\n",
      " [-1.11708418e-04]\n",
      " [-2.56054249e-04]\n",
      " [-1.86504723e-04]\n",
      " [-2.36647116e-04]\n",
      " [-1.39830707e-04]\n",
      " [-1.45052050e-04]\n",
      " [-1.24889935e-04]\n",
      " [-4.17001575e-05]\n",
      " [-1.20913406e-04]\n",
      " [-1.64611236e-04]\n",
      " [-2.83226836e-04]\n",
      " [-3.97806580e-05]\n",
      " [-8.72495148e-05]\n",
      " [-1.35302602e-04]\n",
      " [ 9.86580562e-05]\n",
      " [-8.27640033e-05]\n",
      " [ 4.56568087e-05]\n",
      " [-1.89877450e-04]\n",
      " [ 3.08973540e-06]\n",
      " [-4.80055460e-05]\n",
      " [-1.63294288e-04]\n",
      " [-1.92911160e-04]\n",
      " [-5.37060259e-05]\n",
      " [-1.21155914e-04]\n",
      " [-4.85919300e-05]\n",
      " [-7.89375626e-05]\n",
      " [-4.22621582e-04]\n",
      " [-7.05710263e-05]\n",
      " [-1.27393985e-04]\n",
      " [-2.79459055e-04]\n",
      " [-1.65987964e-04]\n",
      " [-2.20326212e-04]\n",
      " [-1.99402552e-04]\n",
      " [-1.59800213e-04]\n",
      " [-9.33822885e-05]\n",
      " [-1.65968246e-04]\n",
      " [-1.45784245e-04]\n",
      " [-1.33208261e-04]\n",
      " [-1.43967743e-04]\n",
      " [-1.32964618e-04]\n",
      " [-1.63291668e-04]\n",
      " [-3.25619621e-05]\n",
      " [-5.77352184e-05]\n",
      " [-2.07427205e-04]\n",
      " [-9.94779475e-05]\n",
      " [-1.06081206e-04]\n",
      " [-5.35123982e-05]\n",
      " [ 9.17027937e-05]\n",
      " [-1.10776724e-04]\n",
      " [-1.61061122e-04]\n",
      " [-1.99196642e-04]\n",
      " [-1.66364349e-04]\n",
      " [-3.24779714e-04]\n",
      " [-1.58666720e-04]\n",
      " [-1.50857231e-04]\n",
      " [-1.00708843e-04]\n",
      " [-2.68411357e-04]\n",
      " [-1.81693642e-04]\n",
      " [-2.86826456e-04]\n",
      " [-4.80350573e-05]\n",
      " [-1.97885194e-04]\n",
      " [-1.78517337e-04]\n",
      " [-1.71993452e-04]\n",
      " [-9.72389753e-05]\n",
      " [-1.37346375e-04]\n",
      " [-1.09601737e-04]\n",
      " [-2.08379308e-04]\n",
      " [-1.19694654e-04]\n",
      " [-5.00149763e-05]\n",
      " [-2.26245567e-04]\n",
      " [-3.67445173e-05]\n",
      " [-3.90815374e-04]\n",
      " [-1.62469427e-04]\n",
      " [ 1.63010554e-05]\n",
      " [-8.65114125e-05]\n",
      " [-9.51623078e-05]\n",
      " [-2.51526944e-06]\n",
      " [-7.22194527e-05]\n",
      " [-2.20366885e-04]\n",
      " [-3.12027929e-04]\n",
      " [-1.23205507e-04]\n",
      " [-2.20390008e-04]\n",
      " [-1.80160787e-04]\n",
      " [-3.05585010e-04]\n",
      " [-1.74821660e-04]\n",
      " [-7.40682881e-05]\n",
      " [-1.68440180e-04]\n",
      " [-1.73217588e-04]\n",
      " [-1.42811070e-04]\n",
      " [ 2.71807949e-06]\n",
      " [-1.73923094e-04]\n",
      " [-4.16844123e-05]\n",
      " [ 5.63974027e-07]\n",
      " [-1.38867210e-04]\n",
      " [-2.99443549e-04]\n",
      " [-1.11232366e-04]\n",
      " [-1.83456679e-04]]\n"
     ]
    }
   ],
   "source": [
    "test_mae = classifier.predict(X_test)\n",
    "print(test_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2109a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00013851552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78608b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00013666898"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mae = classifier.predict(X_train)\n",
    "np.mean(train_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91801848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769353df",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "171a3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE Loss\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd8fbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mse',metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbff0ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 15729400.0000 - root_mean_squared_error: 3966.0295 - val_loss: 16312766.0000 - val_root_mean_squared_error: 4038.9048\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 10705833.0000 - root_mean_squared_error: 3271.9734 - val_loss: 9880294.0000 - val_root_mean_squared_error: 3143.2878\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 8722636.0000 - root_mean_squared_error: 2953.4048 - val_loss: 8807413.0000 - val_root_mean_squared_error: 2967.7222\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 7260337.5000 - root_mean_squared_error: 2694.4932 - val_loss: 6655277.5000 - val_root_mean_squared_error: 2579.7739\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4578348.0000 - root_mean_squared_error: 2139.6965 - val_loss: 3705912.5000 - val_root_mean_squared_error: 1925.0612\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2613879.2500 - root_mean_squared_error: 1616.7334 - val_loss: 2837328.2500 - val_root_mean_squared_error: 1684.4207\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2226172.0000 - root_mean_squared_error: 1492.0172 - val_loss: 2694761.0000 - val_root_mean_squared_error: 1641.5558\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2100748.0000 - root_mean_squared_error: 1449.3763 - val_loss: 2634676.2500 - val_root_mean_squared_error: 1623.1511\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 2017640.1250 - root_mean_squared_error: 1420.4164 - val_loss: 2537495.2500 - val_root_mean_squared_error: 1592.9340\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1940342.8750 - root_mean_squared_error: 1392.9415 - val_loss: 2482741.5000 - val_root_mean_squared_error: 1575.6537\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1892971.6250 - root_mean_squared_error: 1375.8322 - val_loss: 2429579.2500 - val_root_mean_squared_error: 1558.6925\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1862303.8750 - root_mean_squared_error: 1364.6420 - val_loss: 2391424.7500 - val_root_mean_squared_error: 1546.4047\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1814211.7500 - root_mean_squared_error: 1346.9053 - val_loss: 2360064.7500 - val_root_mean_squared_error: 1536.2314\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1767576.3750 - root_mean_squared_error: 1329.4805 - val_loss: 2450059.2500 - val_root_mean_squared_error: 1565.2483\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1746708.5000 - root_mean_squared_error: 1321.6095 - val_loss: 2306400.5000 - val_root_mean_squared_error: 1518.6647\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1711380.1250 - root_mean_squared_error: 1308.1749 - val_loss: 2295973.5000 - val_root_mean_squared_error: 1515.2279\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1679874.8750 - root_mean_squared_error: 1296.0775 - val_loss: 2230863.0000 - val_root_mean_squared_error: 1493.5879\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1656213.0000 - root_mean_squared_error: 1286.9165 - val_loss: 2204981.0000 - val_root_mean_squared_error: 1484.8979\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1638614.8750 - root_mean_squared_error: 1280.0610 - val_loss: 2189240.0000 - val_root_mean_squared_error: 1479.5883\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1604591.5000 - root_mean_squared_error: 1266.7014 - val_loss: 2156415.7500 - val_root_mean_squared_error: 1468.4542\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1609652.7500 - root_mean_squared_error: 1268.6980 - val_loss: 2143415.7500 - val_root_mean_squared_error: 1464.0209\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1549387.1250 - root_mean_squared_error: 1244.7203 - val_loss: 2108175.2500 - val_root_mean_squared_error: 1451.9354\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1525603.5000 - root_mean_squared_error: 1235.1295 - val_loss: 2281403.2500 - val_root_mean_squared_error: 1510.4120\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1528713.0000 - root_mean_squared_error: 1236.3878 - val_loss: 2064060.7500 - val_root_mean_squared_error: 1436.6633\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1501379.0000 - root_mean_squared_error: 1225.2837 - val_loss: 2220578.7500 - val_root_mean_squared_error: 1490.1409\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1470270.3750 - root_mean_squared_error: 1212.5229 - val_loss: 2021842.6250 - val_root_mean_squared_error: 1421.8942\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1446614.6250 - root_mean_squared_error: 1202.7284 - val_loss: 1992134.2500 - val_root_mean_squared_error: 1411.4088\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1441680.2500 - root_mean_squared_error: 1200.6755 - val_loss: 1969763.3750 - val_root_mean_squared_error: 1403.4615\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1423443.8750 - root_mean_squared_error: 1193.0574 - val_loss: 1962240.5000 - val_root_mean_squared_error: 1400.7789\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1385582.5000 - root_mean_squared_error: 1177.0825 - val_loss: 2002120.2500 - val_root_mean_squared_error: 1414.9423\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1375712.0000 - root_mean_squared_error: 1172.8823 - val_loss: 1925053.0000 - val_root_mean_squared_error: 1387.4413\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1360906.3750 - root_mean_squared_error: 1166.5532 - val_loss: 1899757.2500 - val_root_mean_squared_error: 1378.2953\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1354929.3750 - root_mean_squared_error: 1163.9889 - val_loss: 1885044.1250 - val_root_mean_squared_error: 1372.9475\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1336008.0000 - root_mean_squared_error: 1155.8323 - val_loss: 1871354.2500 - val_root_mean_squared_error: 1367.9528\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1312697.1250 - root_mean_squared_error: 1145.7040 - val_loss: 1858611.8750 - val_root_mean_squared_error: 1363.2874\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1322801.8750 - root_mean_squared_error: 1150.1053 - val_loss: 1824962.1250 - val_root_mean_squared_error: 1350.8896\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1311094.6250 - root_mean_squared_error: 1145.0045 - val_loss: 1963862.7500 - val_root_mean_squared_error: 1401.3578\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1308345.6250 - root_mean_squared_error: 1143.8036 - val_loss: 1816254.7500 - val_root_mean_squared_error: 1347.6630\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1264909.6250 - root_mean_squared_error: 1124.6556 - val_loss: 1888777.2500 - val_root_mean_squared_error: 1374.3064\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1258446.5000 - root_mean_squared_error: 1121.7784 - val_loss: 1788627.0000 - val_root_mean_squared_error: 1337.3735\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1236313.5000 - root_mean_squared_error: 1111.8696 - val_loss: 1807964.8750 - val_root_mean_squared_error: 1344.5840\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1230254.8750 - root_mean_squared_error: 1109.1417 - val_loss: 1731129.1250 - val_root_mean_squared_error: 1315.7013\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1206238.5000 - root_mean_squared_error: 1098.2620 - val_loss: 1719804.2500 - val_root_mean_squared_error: 1311.3904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1215501.7500 - root_mean_squared_error: 1102.4713 - val_loss: 1740953.7500 - val_root_mean_squared_error: 1319.4297\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1217012.2500 - root_mean_squared_error: 1103.1560 - val_loss: 1781091.6250 - val_root_mean_squared_error: 1334.5532\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1178574.6250 - root_mean_squared_error: 1085.5945 - val_loss: 1777219.2500 - val_root_mean_squared_error: 1333.1017\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1181019.1250 - root_mean_squared_error: 1086.7197 - val_loss: 1690039.7500 - val_root_mean_squared_error: 1299.9926\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1159925.1250 - root_mean_squared_error: 1076.9705 - val_loss: 1670143.1250 - val_root_mean_squared_error: 1292.3173\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1151987.6250 - root_mean_squared_error: 1073.2794 - val_loss: 1694969.7500 - val_root_mean_squared_error: 1301.8872\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1152831.7500 - root_mean_squared_error: 1073.6726 - val_loss: 1662151.0000 - val_root_mean_squared_error: 1289.2216\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1127989.2500 - root_mean_squared_error: 1062.0410 - val_loss: 1650094.6250 - val_root_mean_squared_error: 1284.5371\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1130482.5000 - root_mean_squared_error: 1063.2140 - val_loss: 1621969.6250 - val_root_mean_squared_error: 1273.5427\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1117589.2500 - root_mean_squared_error: 1057.1328 - val_loss: 1606116.8750 - val_root_mean_squared_error: 1267.3036\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1109908.7500 - root_mean_squared_error: 1053.4944 - val_loss: 1610653.6250 - val_root_mean_squared_error: 1269.0919\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1124380.7500 - root_mean_squared_error: 1060.3405 - val_loss: 1571972.1250 - val_root_mean_squared_error: 1253.7599\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1102835.5000 - root_mean_squared_error: 1050.1317 - val_loss: 1579738.7500 - val_root_mean_squared_error: 1256.8534\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1087632.1250 - root_mean_squared_error: 1042.8683 - val_loss: 1591372.7500 - val_root_mean_squared_error: 1261.4730\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1092176.0000 - root_mean_squared_error: 1045.0441 - val_loss: 1553183.7500 - val_root_mean_squared_error: 1246.2445\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1066740.7500 - root_mean_squared_error: 1032.8035 - val_loss: 1556945.2500 - val_root_mean_squared_error: 1247.7528\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1053431.7500 - root_mean_squared_error: 1026.3402 - val_loss: 1601878.0000 - val_root_mean_squared_error: 1265.6302\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1046939.3125 - root_mean_squared_error: 1023.1721 - val_loss: 1619686.8750 - val_root_mean_squared_error: 1272.6465\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1059651.8750 - root_mean_squared_error: 1029.3656 - val_loss: 1589239.5000 - val_root_mean_squared_error: 1260.6276\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1032323.1875 - root_mean_squared_error: 1016.0048 - val_loss: 1509764.1250 - val_root_mean_squared_error: 1228.7010\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1030915.6875 - root_mean_squared_error: 1015.3116 - val_loss: 1496530.1250 - val_root_mean_squared_error: 1223.3040\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1015307.2500 - root_mean_squared_error: 1007.5959 - val_loss: 1508077.3750 - val_root_mean_squared_error: 1228.0146\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1012573.6875 - root_mean_squared_error: 1006.2387 - val_loss: 1530690.2500 - val_root_mean_squared_error: 1237.1877\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1022608.5000 - root_mean_squared_error: 1011.2127 - val_loss: 1483258.8750 - val_root_mean_squared_error: 1217.8676\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 988808.6875 - root_mean_squared_error: 994.3599 - val_loss: 1486585.6250 - val_root_mean_squared_error: 1219.2328\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 990341.1875 - root_mean_squared_error: 995.1301 - val_loss: 1473735.6250 - val_root_mean_squared_error: 1213.9517\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 975708.6875 - root_mean_squared_error: 987.7505 - val_loss: 1476068.6250 - val_root_mean_squared_error: 1214.9122\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 989642.0625 - root_mean_squared_error: 994.7790 - val_loss: 1502126.6250 - val_root_mean_squared_error: 1225.5896\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 960532.4375 - root_mean_squared_error: 980.0386 - val_loss: 1427573.1250 - val_root_mean_squared_error: 1194.7871\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 955895.7500 - root_mean_squared_error: 977.6703 - val_loss: 1415658.2500 - val_root_mean_squared_error: 1189.7903\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 962004.0000 - root_mean_squared_error: 980.7892 - val_loss: 1429143.2500 - val_root_mean_squared_error: 1195.4443\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 941490.5000 - root_mean_squared_error: 970.2752 - val_loss: 1394265.7500 - val_root_mean_squared_error: 1180.7666\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 935068.6875 - root_mean_squared_error: 966.9603 - val_loss: 1466994.2500 - val_root_mean_squared_error: 1211.1721\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 949973.5625 - root_mean_squared_error: 974.6371 - val_loss: 1387107.3750 - val_root_mean_squared_error: 1177.7313\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 922121.6875 - root_mean_squared_error: 960.2424 - val_loss: 1374875.1250 - val_root_mean_squared_error: 1172.5269\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 929443.6250 - root_mean_squared_error: 964.0475 - val_loss: 1491631.1250 - val_root_mean_squared_error: 1221.3007\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 926774.6875 - root_mean_squared_error: 962.6624 - val_loss: 1339229.3750 - val_root_mean_squared_error: 1157.2267\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 920516.5000 - root_mean_squared_error: 959.4065 - val_loss: 1377233.3750 - val_root_mean_squared_error: 1173.5322\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 917550.5625 - root_mean_squared_error: 957.8595 - val_loss: 1343299.5000 - val_root_mean_squared_error: 1158.9840\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 887981.6250 - root_mean_squared_error: 942.2985 - val_loss: 1322946.6250 - val_root_mean_squared_error: 1150.1700\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 888368.6250 - root_mean_squared_error: 942.5038 - val_loss: 1384560.3750 - val_root_mean_squared_error: 1176.6500\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 876424.1250 - root_mean_squared_error: 936.1458 - val_loss: 1361156.1250 - val_root_mean_squared_error: 1166.6622\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 879830.1250 - root_mean_squared_error: 937.9634 - val_loss: 1327164.1250 - val_root_mean_squared_error: 1152.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 881235.1875 - root_mean_squared_error: 938.7120 - val_loss: 1306620.2500 - val_root_mean_squared_error: 1143.0509\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 865000.9375 - root_mean_squared_error: 930.0248 - val_loss: 1297535.0000 - val_root_mean_squared_error: 1139.0698\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 862606.3750 - root_mean_squared_error: 928.7365 - val_loss: 1316264.8750 - val_root_mean_squared_error: 1147.2621\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 851609.7500 - root_mean_squared_error: 922.7975 - val_loss: 1333973.3750 - val_root_mean_squared_error: 1154.9542\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 853751.5000 - root_mean_squared_error: 923.9576 - val_loss: 1270803.0000 - val_root_mean_squared_error: 1127.2749\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 846154.8125 - root_mean_squared_error: 919.8374 - val_loss: 1264955.0000 - val_root_mean_squared_error: 1124.6781\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 837950.3750 - root_mean_squared_error: 915.3668 - val_loss: 1250179.1250 - val_root_mean_squared_error: 1118.0901\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 844963.5625 - root_mean_squared_error: 919.1896 - val_loss: 1251600.0000 - val_root_mean_squared_error: 1118.7252\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 823512.8750 - root_mean_squared_error: 907.4465 - val_loss: 1241991.6250 - val_root_mean_squared_error: 1114.4229\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 826579.8750 - root_mean_squared_error: 909.1353 - val_loss: 1250084.7500 - val_root_mean_squared_error: 1118.0479\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 827142.7500 - root_mean_squared_error: 909.4446 - val_loss: 1228058.2500 - val_root_mean_squared_error: 1108.1538\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 824215.8750 - root_mean_squared_error: 907.8339 - val_loss: 1218062.3750 - val_root_mean_squared_error: 1103.6344\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 823319.5625 - root_mean_squared_error: 907.3403 - val_loss: 1232120.5000 - val_root_mean_squared_error: 1109.9854\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 808143.8125 - root_mean_squared_error: 898.9388 - val_loss: 1217457.5000 - val_root_mean_squared_error: 1103.3606\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cf337fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[870824.375, 933.1513671875]\n",
      "[1163894.375, 1078.8148193359375]\n"
     ]
    }
   ],
   "source": [
    "train_rmse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_rmse)\n",
    "test_rmse = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "855af058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2096.4712"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse = classifier.predict(X_train)\n",
    "np.mean(train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cca1b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2375.0908"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse = classifier.predict(X_test)\n",
    "np.mean(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f131a250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Root Mean Squared Error Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e18c2",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfe4d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for MAPE Loss\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f8dd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss=tf.keras.losses.MeanAbsolutePercentageError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9e2f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 2s 4ms/step - loss: 98.4872 - val_loss: 97.2423\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.2371 - val_loss: 97.2339\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.2002 - val_loss: 97.2780\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1947 - val_loss: 97.1703\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1898 - val_loss: 97.1322\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1782 - val_loss: 97.1365\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1672 - val_loss: 97.1852\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1621 - val_loss: 97.1404\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1570 - val_loss: 97.1509\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1668 - val_loss: 97.0892\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1640 - val_loss: 97.2184\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1603 - val_loss: 97.1510\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1605 - val_loss: 97.1720\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1588 - val_loss: 97.0805\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1734 - val_loss: 97.1451\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1759 - val_loss: 97.1601\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1561 - val_loss: 97.1521\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1575 - val_loss: 97.1777\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1721 - val_loss: 97.0986\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1467 - val_loss: 97.1404\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1599 - val_loss: 97.2674\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1665 - val_loss: 97.1009\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1732 - val_loss: 97.1863\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1563 - val_loss: 97.1256\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1401 - val_loss: 97.0639\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1565 - val_loss: 97.1348\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1585 - val_loss: 97.1589\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1508 - val_loss: 97.1750\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1622 - val_loss: 97.0875\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1633 - val_loss: 97.1322\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1585 - val_loss: 97.1427\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1544 - val_loss: 97.0445\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1505 - val_loss: 97.0915\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1657 - val_loss: 97.2210\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1653 - val_loss: 97.1009\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1632 - val_loss: 97.1537\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1498 - val_loss: 97.2119\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1370 - val_loss: 97.1147\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1510 - val_loss: 97.1673\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1611 - val_loss: 97.1761\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1557 - val_loss: 97.1812\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1699 - val_loss: 97.1458\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1660 - val_loss: 97.1086\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1529 - val_loss: 97.1000\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1661 - val_loss: 97.1333\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1685 - val_loss: 97.1687\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1516 - val_loss: 97.1313\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1583 - val_loss: 97.1937\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1687 - val_loss: 97.1625\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1463 - val_loss: 97.2045\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1579 - val_loss: 97.1262\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1612 - val_loss: 97.1116\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1567 - val_loss: 97.1671\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1525 - val_loss: 97.1260\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1472 - val_loss: 97.1455\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1532 - val_loss: 97.2057\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1546 - val_loss: 97.1538\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1516 - val_loss: 97.1457\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1558 - val_loss: 97.0766\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1451 - val_loss: 97.1613\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1518 - val_loss: 97.1275\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1629 - val_loss: 97.1472\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1538 - val_loss: 97.1647\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1396 - val_loss: 97.0780\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1694 - val_loss: 97.1724\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1330 - val_loss: 97.1166\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1558 - val_loss: 97.1517\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1473 - val_loss: 97.1564\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1587 - val_loss: 97.1573\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1499 - val_loss: 97.1103\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1570 - val_loss: 97.1720\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1528 - val_loss: 97.1895\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1749 - val_loss: 97.1871\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1507 - val_loss: 97.1446\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1519 - val_loss: 97.1322\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1456 - val_loss: 97.1900\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1484 - val_loss: 97.1383\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1625 - val_loss: 97.1558\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1483 - val_loss: 97.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1411 - val_loss: 97.1442\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1366 - val_loss: 97.2642\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1972 - val_loss: 97.1637\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1496 - val_loss: 97.2402\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1578 - val_loss: 97.1801\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1664 - val_loss: 97.2086\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1627 - val_loss: 97.1302\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1570 - val_loss: 97.1397\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1541 - val_loss: 97.1569\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 96.1429 - val_loss: 97.1438\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1568 - val_loss: 97.1893\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1533 - val_loss: 97.0919\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1592 - val_loss: 97.1962\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1461 - val_loss: 97.1388\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1544 - val_loss: 97.1851\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1532 - val_loss: 97.1625\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1526 - val_loss: 97.0877\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1582 - val_loss: 97.1853\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1692 - val_loss: 97.1858\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1637 - val_loss: 97.1131\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 96.1587 - val_loss: 97.1630\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b93dd2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.33977508544922\n",
      "96.56974029541016\n"
     ]
    }
   ],
   "source": [
    "train_mape = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(train_mape)\n",
    "test_mape = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "008ebe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.064155154"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mape = classifier.predict(X_train)\n",
    "np.mean(train_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54fca955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06415516"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mape=classifier.predict(X_test)\n",
    "np.mean(test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "354495dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Absolute Percentage Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01396ac",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c2df6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE Loss\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67afe0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0eaff86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 14491280.0000 - val_loss: 10390348.0000\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 8986568.0000 - val_loss: 8848558.0000\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 7155331.0000 - val_loss: 6236812.0000\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 3927256.0000 - val_loss: 3239816.2500\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2408180.7500 - val_loss: 2775962.5000\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2203147.2500 - val_loss: 2665406.5000\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 2060209.7500 - val_loss: 2595004.5000\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1998059.1250 - val_loss: 2529718.5000\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1935160.2500 - val_loss: 2460739.2500\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1882085.0000 - val_loss: 2417240.0000\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1825626.6250 - val_loss: 2369823.2500\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1781251.6250 - val_loss: 2369294.5000\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1778145.8750 - val_loss: 2306071.0000\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1729625.1250 - val_loss: 2273898.2500\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1678066.5000 - val_loss: 2237742.5000\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1651728.0000 - val_loss: 2225660.0000\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1635562.5000 - val_loss: 2205528.5000\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1585895.3750 - val_loss: 2163445.2500\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1570074.8750 - val_loss: 2218695.2500\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1561200.3750 - val_loss: 2116412.2500\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1541732.0000 - val_loss: 2086274.1250\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1519372.6250 - val_loss: 2087718.1250\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1483263.2500 - val_loss: 2051318.3750\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1464836.0000 - val_loss: 2062125.6250\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1454977.6250 - val_loss: 2111142.5000\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1427527.5000 - val_loss: 2015631.3750\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1404303.5000 - val_loss: 2030326.8750\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1407196.8750 - val_loss: 1985492.0000\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1375504.0000 - val_loss: 1953010.2500\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1390543.6250 - val_loss: 1911313.5000\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1378518.5000 - val_loss: 1988022.6250\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1357473.3750 - val_loss: 2017135.7500\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1340157.6250 - val_loss: 1917942.2500\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1319827.3750 - val_loss: 1895345.3750\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1321198.5000 - val_loss: 1854969.2500\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1296951.5000 - val_loss: 1841748.1250\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1295857.6250 - val_loss: 1875600.2500\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1296028.6250 - val_loss: 1953918.8750\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1277903.1250 - val_loss: 1847537.2500\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1268203.8750 - val_loss: 1861016.0000\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1264325.1250 - val_loss: 1825046.8750\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1271079.6250 - val_loss: 1825288.7500\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1241202.8750 - val_loss: 1852305.6250\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1226801.7500 - val_loss: 1773376.0000\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1222342.8750 - val_loss: 1761265.3750\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1207349.6250 - val_loss: 1805992.3750\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1221765.0000 - val_loss: 1749750.1250\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1238023.6250 - val_loss: 1738230.6250\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1198161.3750 - val_loss: 2075483.2500\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1186299.3750 - val_loss: 1798745.0000\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1178366.3750 - val_loss: 1718679.6250\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1195184.1250 - val_loss: 1758348.1250\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1178177.3750 - val_loss: 1701472.6250\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1165876.1250 - val_loss: 1834868.8750\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1180444.2500 - val_loss: 1694646.1250\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1158169.7500 - val_loss: 1735927.0000\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1158323.8750 - val_loss: 1694435.5000\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1144732.5000 - val_loss: 1678210.3750\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1142806.1250 - val_loss: 1682637.8750\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1140541.1250 - val_loss: 1739698.2500\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1144632.0000 - val_loss: 1683303.0000\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1122522.6250 - val_loss: 1648460.5000\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1107475.0000 - val_loss: 1668985.2500\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1135024.2500 - val_loss: 1638904.3750\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1114668.5000 - val_loss: 1646883.5000\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1093000.8750 - val_loss: 1687530.5000\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1112572.7500 - val_loss: 1633363.7500\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1117009.7500 - val_loss: 1630428.7500\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1103357.8750 - val_loss: 1628955.0000\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1084019.6250 - val_loss: 1674884.1250\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1097763.5000 - val_loss: 1624657.5000\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1076851.3750 - val_loss: 1640194.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1085065.0000 - val_loss: 1603830.1250\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1081248.2500 - val_loss: 1601419.7500\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1083784.6250 - val_loss: 1592875.8750\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1081634.5000 - val_loss: 1598065.0000\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1093742.7500 - val_loss: 1602665.6250\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1057068.2500 - val_loss: 1570394.6250\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1066975.2500 - val_loss: 1573541.6250\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1051784.7500 - val_loss: 1568504.0000\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1036044.2500 - val_loss: 1688119.1250\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1053154.1250 - val_loss: 1632655.2500\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1056590.3750 - val_loss: 1558395.1250\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1040043.5625 - val_loss: 1553899.8750\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1041487.0000 - val_loss: 1612084.0000\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1035962.5000 - val_loss: 1542111.2500\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1031698.6875 - val_loss: 1594407.5000\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1023627.5625 - val_loss: 1547007.3750\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 1004254.3750 - val_loss: 1517382.0000\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1009943.8750 - val_loss: 1533661.1250\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1013762.0625 - val_loss: 1517277.7500\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 1006627.8750 - val_loss: 1617066.0000\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 988859.7500 - val_loss: 1513867.3750\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 995391.8750 - val_loss: 1496891.8750\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 988209.1875 - val_loss: 1578368.0000\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 982616.0625 - val_loss: 1496706.0000\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 963036.5625 - val_loss: 1519959.1250\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 978469.0625 - val_loss: 1477235.7500\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 957560.6250 - val_loss: 1474859.7500\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 971184.8750 - val_loss: 1478787.7500\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39ead314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2115.8508"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mse = classifier.predict(X_train)\n",
    "np.mean(train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "097b3182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2374.712"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse=classifier.predict(X_test)\n",
    "np.mean(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afd4b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89257a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
