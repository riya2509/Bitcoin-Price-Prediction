{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01b9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a33391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/07/17</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/07/18</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/07/19</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/07/20</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/07/21</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  priceUSD  transactions     size  sentbyaddress  difficulty  \\\n",
       "0  2010/07/17    0.0495           235  649.653            390     181.543   \n",
       "1  2010/07/18    0.0726           248  765.285            424     181.543   \n",
       "2  2010/07/19    0.0859           354  756.040            553     181.543   \n",
       "3  2010/07/20    0.0783           413  984.707            632     181.543   \n",
       "4  2010/07/21    0.0767           256  542.483            440     181.543   \n",
       "\n",
       "       hashrate  mining_profitability  sentinusdUSD  transactionfeesUSD  ...  \\\n",
       "0  2.775561e+09              154298.0        1193.0            0.000010  ...   \n",
       "1  1.554461e+09              401834.0        2620.0            0.000243  ...   \n",
       "2  1.551287e+09              481473.0        4048.0            0.000022  ...   \n",
       "3  1.640430e+09              431831.0        2341.0            0.000000  ...   \n",
       "4  1.723493e+09              460783.0        2122.0            0.000000  ...   \n",
       "\n",
       "   price3rsiUSD  price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  \\\n",
       "0         0.000           0.0            0.0            0.0            0.0   \n",
       "1         0.000           0.0            0.0            0.0            0.0   \n",
       "2         0.000           0.0            0.0            0.0            0.0   \n",
       "3        82.751           0.0            0.0            0.0            0.0   \n",
       "4        78.603           0.0            0.0            0.0            0.0   \n",
       "\n",
       "   price3rocUSD  price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
       "0         0.000           0.0            0.0            0.0            0.0  \n",
       "1         0.000           0.0            0.0            0.0            0.0  \n",
       "2         0.000           0.0            0.0            0.0            0.0  \n",
       "3        58.099           0.0            0.0            0.0            0.0  \n",
       "4         5.652           0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 737 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('btc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42e09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>transactions</th>\n",
       "      <th>size</th>\n",
       "      <th>sentbyaddress</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>transactionfeesUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price3rsiUSD</th>\n",
       "      <th>price7rsiUSD</th>\n",
       "      <th>price14rsiUSD</th>\n",
       "      <th>price30rsiUSD</th>\n",
       "      <th>price90rsiUSD</th>\n",
       "      <th>price3rocUSD</th>\n",
       "      <th>price7rocUSD</th>\n",
       "      <th>price14rocUSD</th>\n",
       "      <th>price30rocUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>235</td>\n",
       "      <td>649.653</td>\n",
       "      <td>390</td>\n",
       "      <td>181.543</td>\n",
       "      <td>2.775561e+09</td>\n",
       "      <td>154298.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>248</td>\n",
       "      <td>765.285</td>\n",
       "      <td>424</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.554461e+09</td>\n",
       "      <td>401834.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>354</td>\n",
       "      <td>756.040</td>\n",
       "      <td>553</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.551287e+09</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "      <td>413</td>\n",
       "      <td>984.707</td>\n",
       "      <td>632</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.640430e+09</td>\n",
       "      <td>431831.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "      <td>256</td>\n",
       "      <td>542.483</td>\n",
       "      <td>440</td>\n",
       "      <td>181.543</td>\n",
       "      <td>1.723493e+09</td>\n",
       "      <td>460783.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priceUSD  transactions     size  sentbyaddress  difficulty      hashrate  \\\n",
       "0    0.0495           235  649.653            390     181.543  2.775561e+09   \n",
       "1    0.0726           248  765.285            424     181.543  1.554461e+09   \n",
       "2    0.0859           354  756.040            553     181.543  1.551287e+09   \n",
       "3    0.0783           413  984.707            632     181.543  1.640430e+09   \n",
       "4    0.0767           256  542.483            440     181.543  1.723493e+09   \n",
       "\n",
       "   mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
       "0              154298.0        1193.0            0.000010   \n",
       "1              401834.0        2620.0            0.000243   \n",
       "2              481473.0        4048.0            0.000022   \n",
       "3              431831.0        2341.0            0.000000   \n",
       "4              460783.0        2122.0            0.000000   \n",
       "\n",
       "   median_transaction_feeUSD  ...  price3rsiUSD  price7rsiUSD  price14rsiUSD  \\\n",
       "0                        0.0  ...         0.000           0.0            0.0   \n",
       "1                        0.0  ...         0.000           0.0            0.0   \n",
       "2                        0.0  ...         0.000           0.0            0.0   \n",
       "3                        0.0  ...        82.751           0.0            0.0   \n",
       "4                        0.0  ...        78.603           0.0            0.0   \n",
       "\n",
       "   price30rsiUSD  price90rsiUSD  price3rocUSD  price7rocUSD  price14rocUSD  \\\n",
       "0            0.0            0.0         0.000           0.0            0.0   \n",
       "1            0.0            0.0         0.000           0.0            0.0   \n",
       "2            0.0            0.0         0.000           0.0            0.0   \n",
       "3            0.0            0.0        58.099           0.0            0.0   \n",
       "4            0.0            0.0         5.652           0.0            0.0   \n",
       "\n",
       "   price30rocUSD  price90rocUSD  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 736 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0689fd",
   "metadata": {},
   "source": [
    "### Dropping the priceUSD column and storing it in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b7d90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transactions        size  sentbyaddress    difficulty      hashrate  \\\n",
      "0              235     649.653            390  1.815430e+02  2.775561e+09   \n",
      "1              248     765.285            424  1.815430e+02  1.554461e+09   \n",
      "2              354     756.040            553  1.815430e+02  1.551287e+09   \n",
      "3              413     984.707            632  1.815430e+02  1.640430e+09   \n",
      "4              256     542.483            440  1.815430e+02  1.723493e+09   \n",
      "...            ...         ...            ...           ...           ...   \n",
      "3483        340402  706867.000         433958  1.546610e+13  1.157542e+20   \n",
      "3484        332402  704883.000         416980  1.546610e+13  1.253033e+20   \n",
      "3485        334290  770486.000         398021  1.546610e+13  1.113635e+20   \n",
      "3486        303573  650769.000         338567  1.546610e+13  1.201317e+20   \n",
      "3487        290736  684127.000         257655  1.546610e+13  1.064910e+20   \n",
      "\n",
      "      mining_profitability  sentinusdUSD  transactionfeesUSD  \\\n",
      "0               154298.000  1.193000e+03            0.000010   \n",
      "1               401834.000  2.620000e+03            0.000243   \n",
      "2               481473.000  4.048000e+03            0.000022   \n",
      "3               431831.000  2.341000e+03            0.000000   \n",
      "4               460783.000  2.122000e+03            0.000000   \n",
      "...                    ...           ...                 ...   \n",
      "3483                 0.163  8.336367e+09            0.561000   \n",
      "3484                 0.148  1.365361e+10            0.555000   \n",
      "3485                 0.153  1.126273e+10            0.631000   \n",
      "3486                 0.149  7.668679e+09            0.541000   \n",
      "3487                 0.159  6.486338e+09            0.548000   \n",
      "\n",
      "      median_transaction_feeUSD  confirmationtime  ...  price3rsiUSD  \\\n",
      "0                         0.000             8.324  ...         0.000   \n",
      "1                         0.000             8.372  ...         0.000   \n",
      "2                         0.000             8.276  ...         0.000   \n",
      "3                         0.000             7.956  ...        82.751   \n",
      "4                         0.000             6.957  ...        78.603   \n",
      "...                         ...               ...  ...           ...   \n",
      "3483                      0.221             9.000  ...        93.577   \n",
      "3484                      0.213             9.231  ...        94.137   \n",
      "3485                      0.270            10.000  ...        87.140   \n",
      "3486                      0.219             9.536  ...        88.385   \n",
      "3487                      0.206            10.070  ...        88.689   \n",
      "\n",
      "      price7rsiUSD  price14rsiUSD  price30rsiUSD  price90rsiUSD  price3rocUSD  \\\n",
      "0            0.000          0.000          0.000          0.000         0.000   \n",
      "1            0.000          0.000          0.000          0.000         0.000   \n",
      "2            0.000          0.000          0.000          0.000         0.000   \n",
      "3            0.000          0.000          0.000          0.000        58.099   \n",
      "4            0.000          0.000          0.000          0.000         5.652   \n",
      "...            ...            ...            ...            ...           ...   \n",
      "3483        80.644         73.588         64.882         54.040        10.430   \n",
      "3484        81.436         74.176         65.272         54.195         7.432   \n",
      "3485        79.116         73.100         64.815         54.082         3.505   \n",
      "3486        79.762         73.498         65.058         54.175         0.473   \n",
      "3487        79.897         73.576         65.104         54.192         0.041   \n",
      "\n",
      "      price7rocUSD  price14rocUSD  price30rocUSD  price90rocUSD  \n",
      "0            0.000          0.000          0.000          0.000  \n",
      "1            0.000          0.000          0.000          0.000  \n",
      "2            0.000          0.000          0.000          0.000  \n",
      "3            0.000          0.000          0.000          0.000  \n",
      "4            0.000          0.000          0.000          0.000  \n",
      "...            ...            ...            ...            ...  \n",
      "3483         7.538          6.497         26.536          1.663  \n",
      "3484        10.930          8.061         28.817          2.376  \n",
      "3485        11.368          5.611         29.412          0.800  \n",
      "3486        12.499          5.457         31.791          1.606  \n",
      "3487        11.011          6.081         29.624          1.220  \n",
      "\n",
      "[3488 rows x 735 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_17620\\3812082222.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  n=df1.drop('priceUSD',1)\n"
     ]
    }
   ],
   "source": [
    "df1=df_new.reset_index(drop=True)\n",
    "n=df1.drop('priceUSD',1)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3770ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       priceUSD\n",
       "0        0.0495\n",
       "1        0.0726\n",
       "2        0.0859\n",
       "3        0.0783\n",
       "4        0.0767\n",
       "...         ...\n",
       "3483  9349.0000\n",
       "3484  9394.0000\n",
       "3485  9366.0000\n",
       "3486  9393.0000\n",
       "3487  9398.0000\n",
       "\n",
       "[3488 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df1[['priceUSD']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3a6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transactions', 'size', 'sentbyaddress', 'difficulty', 'hashrate',\n",
      "       'mining_profitability', 'sentinusdUSD', 'transactionfeesUSD',\n",
      "       'median_transaction_feeUSD', 'confirmationtime',\n",
      "       ...\n",
      "       'price3rsiUSD', 'price7rsiUSD', 'price14rsiUSD', 'price30rsiUSD',\n",
      "       'price90rsiUSD', 'price3rocUSD', 'price7rocUSD', 'price14rocUSD',\n",
      "       'price30rocUSD', 'price90rocUSD'],\n",
      "      dtype='object', length=735)\n"
     ]
    }
   ],
   "source": [
    "list_of_column_names = list(n.columns)\n",
    "print(n.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc0148",
   "metadata": {},
   "source": [
    "### Reading the MINMAX Autoencoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7cbe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2    3         4         5  \\\n",
       "0           0  0.145302  0.000000  0.179782  0.0  0.000000  0.238634   \n",
       "1           1  0.203855  0.000000  0.136095  0.0  0.005416  0.282885   \n",
       "2           2  0.155377  0.000000  0.170912  0.0  0.000000  0.371988   \n",
       "3           3  0.081168  0.056898  0.152915  0.0  0.001428  0.429266   \n",
       "4           4  0.083447  0.066815  0.103083  0.0  0.000000  0.416309   \n",
       "\n",
       "          6         7    8  ...   29        30        31        32        33  \\\n",
       "0  0.088901  0.305821  0.0  ...  0.0  0.173201  0.000000  0.056773  0.070532   \n",
       "1  0.103172  0.288340  0.0  ...  0.0  0.131363  0.000000  0.089604  0.058761   \n",
       "2  0.016288  0.304093  0.0  ...  0.0  0.172211  0.000000  0.085838  0.086743   \n",
       "3  0.003453  0.371735  0.0  ...  0.0  0.123929  0.000000  0.117967  0.175683   \n",
       "4  0.034490  0.336175  0.0  ...  0.0  0.101451  0.003113  0.109843  0.155952   \n",
       "\n",
       "         34        35   36        37  priceUSD  \n",
       "0  0.000000  0.146290  0.0  0.244239    0.0495  \n",
       "1  0.041308  0.122358  0.0  0.245734    0.0726  \n",
       "2  0.069722  0.043386  0.0  0.236507    0.0859  \n",
       "3  0.096189  0.105011  0.0  0.185024    0.0783  \n",
       "4  0.097110  0.108404  0.0  0.139865    0.0767  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxPCA=pd.read_csv('Autoencoder_MinMaxScaler_data1.csv')\n",
    "#Adding the y column to this dataset\n",
    "combined_data=minmaxPCA.assign(priceUSD=y)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02482116",
   "metadata": {},
   "source": [
    "### Dropping the first unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.070532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244239</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.288340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089604</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245734</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371988</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.304093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>0.043386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.429266</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.096189</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083447</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.386481</td>\n",
       "      <td>0.117555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.247056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>0.144571</td>\n",
       "      <td>0.276913</td>\n",
       "      <td>0.322411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>9349.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.373520</td>\n",
       "      <td>0.350037</td>\n",
       "      <td>0.132441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229406</td>\n",
       "      <td>0.227104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494760</td>\n",
       "      <td>0.142909</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>0.339183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043156</td>\n",
       "      <td>9394.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.350619</td>\n",
       "      <td>0.426659</td>\n",
       "      <td>0.211410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197371</td>\n",
       "      <td>0.249512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542962</td>\n",
       "      <td>0.148570</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>0.363947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>9366.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.319798</td>\n",
       "      <td>0.364622</td>\n",
       "      <td>0.152678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214873</td>\n",
       "      <td>0.209499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535941</td>\n",
       "      <td>0.134063</td>\n",
       "      <td>0.288476</td>\n",
       "      <td>0.372253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>9393.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.340285</td>\n",
       "      <td>0.378646</td>\n",
       "      <td>0.149963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.239973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522454</td>\n",
       "      <td>0.082172</td>\n",
       "      <td>0.271670</td>\n",
       "      <td>0.394370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>9398.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3488 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2    3         4         5         6  \\\n",
       "0     0.145302  0.000000  0.179782  0.0  0.000000  0.238634  0.088901   \n",
       "1     0.203855  0.000000  0.136095  0.0  0.005416  0.282885  0.103172   \n",
       "2     0.155377  0.000000  0.170912  0.0  0.000000  0.371988  0.016288   \n",
       "3     0.081168  0.056898  0.152915  0.0  0.001428  0.429266  0.003453   \n",
       "4     0.083447  0.066815  0.103083  0.0  0.000000  0.416309  0.034490   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3483  0.339125  0.386481  0.117555  0.0  0.203587  0.247056  0.000000   \n",
       "3484  0.373520  0.350037  0.132441  0.0  0.229406  0.227104  0.000000   \n",
       "3485  0.350619  0.426659  0.211410  0.0  0.197371  0.249512  0.000000   \n",
       "3486  0.319798  0.364622  0.152678  0.0  0.214873  0.209499  0.000000   \n",
       "3487  0.340285  0.378646  0.149963  0.0  0.160641  0.239973  0.000000   \n",
       "\n",
       "             7    8         9  ...   29        30        31        32  \\\n",
       "0     0.305821  0.0  0.034986  ...  0.0  0.173201  0.000000  0.056773   \n",
       "1     0.288340  0.0  0.060730  ...  0.0  0.131363  0.000000  0.089604   \n",
       "2     0.304093  0.0  0.055210  ...  0.0  0.172211  0.000000  0.085838   \n",
       "3     0.371735  0.0  0.054605  ...  0.0  0.123929  0.000000  0.117967   \n",
       "4     0.336175  0.0  0.065952  ...  0.0  0.101451  0.003113  0.109843   \n",
       "...        ...  ...       ...  ...  ...       ...       ...       ...   \n",
       "3483  0.321566  0.0  0.000000  ...  0.0  0.505908  0.144571  0.276913   \n",
       "3484  0.313371  0.0  0.000000  ...  0.0  0.494760  0.142909  0.279354   \n",
       "3485  0.313492  0.0  0.000000  ...  0.0  0.542962  0.148570  0.304143   \n",
       "3486  0.265145  0.0  0.000000  ...  0.0  0.535941  0.134063  0.288476   \n",
       "3487  0.255416  0.0  0.000000  ...  0.0  0.522454  0.082172  0.271670   \n",
       "\n",
       "            33        34        35   36        37   priceUSD  \n",
       "0     0.070532  0.000000  0.146290  0.0  0.244239     0.0495  \n",
       "1     0.058761  0.041308  0.122358  0.0  0.245734     0.0726  \n",
       "2     0.086743  0.069722  0.043386  0.0  0.236507     0.0859  \n",
       "3     0.175683  0.096189  0.105011  0.0  0.185024     0.0783  \n",
       "4     0.155952  0.097110  0.108404  0.0  0.139865     0.0767  \n",
       "...        ...       ...       ...  ...       ...        ...  \n",
       "3483  0.322411  0.000000  0.241756  0.0  0.046847  9349.0000  \n",
       "3484  0.339183  0.000000  0.266478  0.0  0.043156  9394.0000  \n",
       "3485  0.363947  0.000000  0.280159  0.0  0.021500  9366.0000  \n",
       "3486  0.372253  0.000000  0.244182  0.0  0.010242  9393.0000  \n",
       "3487  0.394370  0.000000  0.246692  0.0  0.027949  9398.0000  \n",
       "\n",
       "[3488 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = combined_data.iloc[: , 1:]\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd3216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.950e-02 7.260e-02 8.590e-02 ... 9.366e+03 9.393e+03 9.398e+03]\n"
     ]
    }
   ],
   "source": [
    "X = finaldata.iloc[:, :-1].values\n",
    "y = finaldata.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0e16d",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9f15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0a92",
   "metadata": {},
   "source": [
    "### Training the Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f426bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2b012",
   "metadata": {},
   "source": [
    "### Printing R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73fabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8485560681977264\n"
     ]
    }
   ],
   "source": [
    "r_squared = regressor.score(X, y)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca17c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055caa",
   "metadata": {},
   "source": [
    "### Displaying adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7527dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468875064672288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0fa2",
   "metadata": {},
   "source": [
    "### Accuracy on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76278b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490442428504816"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)\n",
    "pred=regressor.predict(X_test)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197432f0",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039dcd",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36be2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767 2058  985 ... 1049 2116 2661]\n",
      "continuous\n",
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(training_scores_encoded)\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473ad7",
   "metadata": {},
   "source": [
    "### Applying grid search to find best model and the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a625fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4fc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(),param_grid,refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 735, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\KIIT\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 200, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c96be4",
   "metadata": {},
   "source": [
    "### Gradient boosting Model and its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03, 0.04],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000, 1500],\n",
       "                         &#x27;subsample&#x27;: [0.9, 0.5, 0.2, 0.1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 1500],\n",
       "                         'subsample': [0.9, 0.5, 0.2, 0.1]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=1500,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9618437005970384\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1500, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3c24a",
   "metadata": {},
   "source": [
    "### Training the Random forest regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fb4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5001",
   "metadata": {},
   "source": [
    "### Randomforest regressor using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c89d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop:  0\n",
      "--------------\n",
      "R2 score: 0.9656820495593353\n",
      "Best Score: 0.9637163621315429\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  1\n",
      "--------------\n",
      "R2 score: 0.9661301778142349\n",
      "Best Score: 0.9635172070292952\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  2\n",
      "--------------\n",
      "R2 score: 0.9596413995819469\n",
      "Best Score: 0.9629831391935818\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Loop:  3\n",
      "--------------\n",
      "R2 score: 0.9656607605683257\n",
      "Best Score: 0.963975324491801\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n",
      "Loop:  4\n",
      "--------------\n",
      "R2 score: 0.962818577555858\n",
      "Best Score: 0.9632032681611242\n",
      "Best params: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "    y_test , y_predict = RFR(X_train, X_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f2a68",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1baa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=735,kernel_initializer='he_normal',activation='relu'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=32,kernel_initializer='normal',activation='relu',kernel_regularizer = 'l1'))\n",
    "Dropout(0.2)\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "classifier.add(Dense(units=8,kernel_initializer='normal',activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90d00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3360072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 2s 6ms/step - loss: 2118.9924 - mean_absolute_error: 2115.8518 - val_loss: 2217.2546 - val_mean_absolute_error: 2211.1787\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1978.0590 - mean_absolute_error: 1968.2352 - val_loss: 2101.4905 - val_mean_absolute_error: 2090.6023\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1927.3414 - mean_absolute_error: 1915.0345 - val_loss: 2035.3739 - val_mean_absolute_error: 2021.1738\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1784.8583 - mean_absolute_error: 1767.6631 - val_loss: 1783.0354 - val_mean_absolute_error: 1762.1411\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 1269.0767 - mean_absolute_error: 1242.6128 - val_loss: 1074.8611 - val_mean_absolute_error: 1043.4764\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 881.3984 - mean_absolute_error: 849.1803 - val_loss: 981.7566 - val_mean_absolute_error: 949.2938\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 837.9564 - mean_absolute_error: 805.4352 - val_loss: 956.4147 - val_mean_absolute_error: 923.6627\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 820.0493 - mean_absolute_error: 787.4191 - val_loss: 934.2426 - val_mean_absolute_error: 901.5616\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 797.5555 - mean_absolute_error: 764.8448 - val_loss: 919.9568 - val_mean_absolute_error: 887.1858\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 784.6730 - mean_absolute_error: 751.8881 - val_loss: 909.2638 - val_mean_absolute_error: 876.1062\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 771.7001 - mean_absolute_error: 738.6081 - val_loss: 895.7653 - val_mean_absolute_error: 862.6522\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 763.2906 - mean_absolute_error: 730.0978 - val_loss: 884.7426 - val_mean_absolute_error: 851.6267\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 747.2259 - mean_absolute_error: 713.9689 - val_loss: 875.0914 - val_mean_absolute_error: 841.7537\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 737.7533 - mean_absolute_error: 704.3644 - val_loss: 874.1382 - val_mean_absolute_error: 840.6001\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 728.9748 - mean_absolute_error: 695.5287 - val_loss: 869.8279 - val_mean_absolute_error: 836.1825\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 713.9504 - mean_absolute_error: 680.2575 - val_loss: 848.6622 - val_mean_absolute_error: 815.1023\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 707.7947 - mean_absolute_error: 674.1311 - val_loss: 848.7993 - val_mean_absolute_error: 815.0458\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 697.2172 - mean_absolute_error: 663.4970 - val_loss: 840.5699 - val_mean_absolute_error: 806.7068\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 690.6034 - mean_absolute_error: 656.8669 - val_loss: 826.8226 - val_mean_absolute_error: 793.0947\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 682.0709 - mean_absolute_error: 648.1696 - val_loss: 816.9877 - val_mean_absolute_error: 783.2700\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 673.6608 - mean_absolute_error: 639.8381 - val_loss: 810.3494 - val_mean_absolute_error: 776.6404\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 665.7205 - mean_absolute_error: 631.8970 - val_loss: 804.0753 - val_mean_absolute_error: 770.3625\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 658.6879 - mean_absolute_error: 624.8652 - val_loss: 814.6407 - val_mean_absolute_error: 780.6730\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 658.3755 - mean_absolute_error: 624.5499 - val_loss: 790.4121 - val_mean_absolute_error: 756.8608\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 646.4787 - mean_absolute_error: 612.8820 - val_loss: 789.7587 - val_mean_absolute_error: 756.0469\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 640.0519 - mean_absolute_error: 606.3817 - val_loss: 777.3214 - val_mean_absolute_error: 743.5798\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 634.1406 - mean_absolute_error: 600.4283 - val_loss: 794.0408 - val_mean_absolute_error: 760.2336\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 628.7657 - mean_absolute_error: 595.0590 - val_loss: 763.8785 - val_mean_absolute_error: 730.2808\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 621.5531 - mean_absolute_error: 588.0959 - val_loss: 755.8467 - val_mean_absolute_error: 722.4099\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 618.9622 - mean_absolute_error: 585.4827 - val_loss: 758.1039 - val_mean_absolute_error: 724.6138\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 615.2304 - mean_absolute_error: 581.8392 - val_loss: 747.9296 - val_mean_absolute_error: 714.5596\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 606.2281 - mean_absolute_error: 572.9696 - val_loss: 740.8560 - val_mean_absolute_error: 707.7370\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 601.3741 - mean_absolute_error: 568.1323 - val_loss: 742.8274 - val_mean_absolute_error: 709.5103\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 594.1077 - mean_absolute_error: 560.9800 - val_loss: 744.0859 - val_mean_absolute_error: 710.8817\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 597.5594 - mean_absolute_error: 564.5867 - val_loss: 719.7902 - val_mean_absolute_error: 686.8079\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 586.4814 - mean_absolute_error: 553.6148 - val_loss: 722.1792 - val_mean_absolute_error: 689.2347\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 584.3054 - mean_absolute_error: 551.4655 - val_loss: 716.0245 - val_mean_absolute_error: 683.1087\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 578.5518 - mean_absolute_error: 545.8104 - val_loss: 699.2233 - val_mean_absolute_error: 666.7139\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 572.2060 - mean_absolute_error: 539.6627 - val_loss: 694.6502 - val_mean_absolute_error: 662.1470\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 564.8188 - mean_absolute_error: 532.4127 - val_loss: 706.4269 - val_mean_absolute_error: 673.9701\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 562.4503 - mean_absolute_error: 530.1304 - val_loss: 680.7807 - val_mean_absolute_error: 648.6913\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 565.0335 - mean_absolute_error: 532.8817 - val_loss: 693.0494 - val_mean_absolute_error: 660.9131\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 556.1998 - mean_absolute_error: 524.2208 - val_loss: 671.6545 - val_mean_absolute_error: 639.7308\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 550.7611 - mean_absolute_error: 518.8486 - val_loss: 672.7176 - val_mean_absolute_error: 641.1412\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 555.6726 - mean_absolute_error: 523.9725 - val_loss: 664.7456 - val_mean_absolute_error: 633.0200\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 546.4535 - mean_absolute_error: 514.8776 - val_loss: 683.5570 - val_mean_absolute_error: 651.8884\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 538.6406 - mean_absolute_error: 507.2385 - val_loss: 653.4830 - val_mean_absolute_error: 622.0452\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 533.3600 - mean_absolute_error: 502.1092 - val_loss: 654.8603 - val_mean_absolute_error: 623.5674\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 531.5587 - mean_absolute_error: 500.4034 - val_loss: 642.2712 - val_mean_absolute_error: 611.1934\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 528.4154 - mean_absolute_error: 497.4211 - val_loss: 650.2527 - val_mean_absolute_error: 619.2570\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 524.3134 - mean_absolute_error: 493.4699 - val_loss: 632.2418 - val_mean_absolute_error: 601.6274\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 520.9628 - mean_absolute_error: 490.2910 - val_loss: 696.6516 - val_mean_absolute_error: 665.7291\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 519.2086 - mean_absolute_error: 488.6585 - val_loss: 626.3893 - val_mean_absolute_error: 595.9424\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 516.7221 - mean_absolute_error: 486.3325 - val_loss: 625.7446 - val_mean_absolute_error: 595.3588\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 511.3999 - mean_absolute_error: 481.1472 - val_loss: 617.9354 - val_mean_absolute_error: 587.7286\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 517.7868 - mean_absolute_error: 487.7491 - val_loss: 614.7449 - val_mean_absolute_error: 584.7538\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 504.3889 - mean_absolute_error: 474.4028 - val_loss: 608.9525 - val_mean_absolute_error: 579.0911\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.0494 - mean_absolute_error: 470.1819 - val_loss: 610.5687 - val_mean_absolute_error: 581.0073\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 500.7306 - mean_absolute_error: 471.0721 - val_loss: 599.1140 - val_mean_absolute_error: 569.5215\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 496.3109 - mean_absolute_error: 466.7726 - val_loss: 598.2642 - val_mean_absolute_error: 568.8929\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 491.3277 - mean_absolute_error: 461.9783 - val_loss: 614.0327 - val_mean_absolute_error: 584.5827\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 493.8826 - mean_absolute_error: 464.6398 - val_loss: 593.8611 - val_mean_absolute_error: 564.7026\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 482.9424 - mean_absolute_error: 453.8619 - val_loss: 600.1260 - val_mean_absolute_error: 571.1360\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 485.7369 - mean_absolute_error: 456.8392 - val_loss: 593.9310 - val_mean_absolute_error: 565.0020\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 476.2517 - mean_absolute_error: 447.3920 - val_loss: 582.9829 - val_mean_absolute_error: 554.3189\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 478.3152 - mean_absolute_error: 449.6859 - val_loss: 588.4650 - val_mean_absolute_error: 560.0060\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 471.5667 - mean_absolute_error: 443.0381 - val_loss: 580.9321 - val_mean_absolute_error: 552.4590\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 474.2137 - mean_absolute_error: 445.7718 - val_loss: 576.1315 - val_mean_absolute_error: 547.8374\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 467.5479 - mean_absolute_error: 439.2813 - val_loss: 567.1937 - val_mean_absolute_error: 538.9714\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 465.0820 - mean_absolute_error: 436.9369 - val_loss: 585.0283 - val_mean_absolute_error: 557.0068\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 468.7294 - mean_absolute_error: 440.6459 - val_loss: 583.6268 - val_mean_absolute_error: 555.7936\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.8998 - mean_absolute_error: 433.9968 - val_loss: 574.7872 - val_mean_absolute_error: 546.8318\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 455.0855 - mean_absolute_error: 427.2591 - val_loss: 578.1927 - val_mean_absolute_error: 550.2440\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 461.1651 - mean_absolute_error: 433.4218 - val_loss: 572.8614 - val_mean_absolute_error: 545.0997\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 454.4552 - mean_absolute_error: 426.7677 - val_loss: 569.5358 - val_mean_absolute_error: 541.7859\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 452.5275 - mean_absolute_error: 424.9593 - val_loss: 554.3700 - val_mean_absolute_error: 526.8695\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 450.6194 - mean_absolute_error: 423.1683 - val_loss: 563.5615 - val_mean_absolute_error: 536.2483\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 452.8229 - mean_absolute_error: 425.4682 - val_loss: 554.6036 - val_mean_absolute_error: 527.2186\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 441.4958 - mean_absolute_error: 414.2453 - val_loss: 546.3201 - val_mean_absolute_error: 519.1036\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 442.5009 - mean_absolute_error: 415.3378 - val_loss: 541.6899 - val_mean_absolute_error: 514.5577\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.1081 - mean_absolute_error: 409.0148 - val_loss: 545.8910 - val_mean_absolute_error: 518.7748\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 439.7642 - mean_absolute_error: 412.7513 - val_loss: 538.7913 - val_mean_absolute_error: 511.8738\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.9341 - mean_absolute_error: 410.0691 - val_loss: 549.1154 - val_mean_absolute_error: 522.3248\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 436.1584 - mean_absolute_error: 409.3341 - val_loss: 532.8607 - val_mean_absolute_error: 506.1034\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 431.3388 - mean_absolute_error: 404.5894 - val_loss: 540.7156 - val_mean_absolute_error: 514.1083\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 433.7404 - mean_absolute_error: 407.0299 - val_loss: 541.2939 - val_mean_absolute_error: 514.6338\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 431.9586 - mean_absolute_error: 405.3521 - val_loss: 533.3287 - val_mean_absolute_error: 506.8344\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.7861 - mean_absolute_error: 404.2670 - val_loss: 536.7257 - val_mean_absolute_error: 510.1472\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 430.8235 - mean_absolute_error: 404.3705 - val_loss: 530.7253 - val_mean_absolute_error: 504.2811\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 427.4909 - mean_absolute_error: 401.1477 - val_loss: 525.8492 - val_mean_absolute_error: 499.5973\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 421.9723 - mean_absolute_error: 395.6621 - val_loss: 531.5154 - val_mean_absolute_error: 505.3242\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 423.0895 - mean_absolute_error: 396.8358 - val_loss: 523.3908 - val_mean_absolute_error: 497.1869\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 422.7931 - mean_absolute_error: 396.6096 - val_loss: 531.6688 - val_mean_absolute_error: 505.5991\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 416.2127 - mean_absolute_error: 390.1172 - val_loss: 520.0477 - val_mean_absolute_error: 493.9811\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 3ms/step - loss: 415.0308 - mean_absolute_error: 388.9773 - val_loss: 534.5786 - val_mean_absolute_error: 508.4643\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.7349 - mean_absolute_error: 389.7468 - val_loss: 518.9341 - val_mean_absolute_error: 492.9917\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 415.5763 - mean_absolute_error: 389.6472 - val_loss: 525.8484 - val_mean_absolute_error: 500.0574\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 414.9501 - mean_absolute_error: 389.0963 - val_loss: 515.4711 - val_mean_absolute_error: 489.6739\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 411.1351 - mean_absolute_error: 385.3844 - val_loss: 517.0731 - val_mean_absolute_error: 491.3025\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 408.4312 - mean_absolute_error: 382.7081 - val_loss: 515.6617 - val_mean_absolute_error: 489.9521\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.2,batch_size=16,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db6a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd42a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Mean Absolute Error Loss')\n",
    "plt.plot(model_history.history['loss'], label='train')\n",
    "plt.plot(model_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04292b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
